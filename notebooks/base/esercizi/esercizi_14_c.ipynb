{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2305af9-294e-449b-9cf7-422e5fe797ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d969b-13f7-4a4a-893a-0ee2ba69d355",
   "metadata": {},
   "source": [
    "In questa esercitazione, vedremo come codificare rapidamente le categorical feature presenti in un insieme di dati, e come sfruttare un metodo di ricerca ottimizzato per identificare i migliori iperparametri da applicare ad uno stimatore.\n",
    "\n",
    "## Parte 1: caricamento e preprocessing dei dati\n",
    "\n",
    "Useremo gli stessi identici dati dell'esercitazione precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181bed21-e358-49bc-893b-f5ee08d178f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/train.csv')\n",
    "df = df[['Sex', 'Age', 'Fare']]\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317db43-5270-4053-811e-c6e9523656b5",
   "metadata": {},
   "source": [
    "Ricordiamo che, nell'esercitazione precedente, abbiamo dovuto utilizzare un oggetto di tipo [`OrdinalEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) per trasformare i dati da stringa in numero.\n",
    "\n",
    "Questo approccio però risulta essere inefficace quando ci troviamo di fronte ad un dataframe in cui coesistono più categorical feature. In questi casi, Scikit Learn ci mette a disposizione un oggetto chiamato [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) il quale permette di codificare contemporaneamente un insieme di feature.\n",
    "\n",
    "In particolare, dovremo specificare ciascuna delle feature da trasformare sotto forma di tupla del tipo:\n",
    "\n",
    "`(name, transformer, columns)`\n",
    "\n",
    "dove `name` rappresenta il nuovo nome che sarà associato alla feature, `transformer` il tipo di trasformazione che vogliamo effettuare, e `columns` un indice che ci permette di identificare la colonna da modificare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7376910-2817-4b8d-b690-042cb021e884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [('Sex_', OrdinalEncoder(), ['Sex'])],\n",
    "    remainder='passthrough')\n",
    "data = ct.fit_transform(df)\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c0d15f7-338b-4670-984c-d1ccb57afeae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 22.],\n",
       "       [ 0., 38.],\n",
       "       [ 0., 26.],\n",
       "       ...,\n",
       "       [ 0., 19.],\n",
       "       [ 1., 26.],\n",
       "       [ 1., 32.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2439c8a-cb1e-4dd3-b0e0-c2ef1e97a1ee",
   "metadata": {},
   "source": [
    "## Parte 2: ottimizzazione degli iperparametri\n",
    "\n",
    "Finora abbiamo usato un approccio *trial & error* alla ricerca della combinazione ottimale di iperparametri da usare per uno stimatore.\n",
    "\n",
    "Ovviamente, questo approccio risulta essere subottimale, ed è stata sviluppata un'apposita branca del machine learning, chiamata *hyperparameters tuning*, dedicata proprio a \"semplificarci la vita\".\n",
    "\n",
    "Esistono molte tecniche di hyperparameters tuning; alcune tra di esse sono ovviamente disponibili in Scikit Learn. In particolare, proveremo ad usare la *grid search*, ovvero una ricerca \"a griglia\", che prevede che siano provate tutte le possibili combinazioni di iperparametri prima della scelta dei migliori. Ad ogni prova, corrisponderà un determinato scoring (ad esempio, in termini di accuracy o di MSE); al termine delle prove, sarà selezionata la combinazione che ha ottenuto il risultato migliore.\n",
    "\n",
    "Per implementare la grid search, Scikit Learn ci offre la classe [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) che, come suggerisce il nome stesso, implementa in automatico la cross validazione. Proviamo ad usarla su un albero decisionale, scegliendo come parametri possibili una serie di [criteri di valutazione per lo split](https://www.analyticsvidhya.com/blog/2020/06/4-ways-split-decision-tree/) (ovvero, come i nodi vengono suddivisi fino a che non sono considerati *omogenei*) e la massima profondità raggiungibile dall'albero di regressione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b9f9d9-ea3d-44a4-8928-832d3929d4ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor()\n",
    "pars = {\n",
    "    'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    "    'max_depth': list(range(1, 11))\n",
    "}\n",
    "rgr = GridSearchCV(dt, pars, cv=10)\n",
    "rgr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc125a6-1928-48e7-90f8-e204a8f2e292",
   "metadata": {},
   "source": [
    "Una volta terminato l'addestramento, che avviene sempre e comunque usando il metodo `fit()`, è possibile consultare diversi attributi, come ad esempio quello relativo ai migliori parametri individuati ed al miglior punteggio ottenuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a99384b-49e9-4501-921d-f52a7bd0bf04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migliori parametri selezionati:\t{'criterion': 'friedman_mse', 'max_depth': 2}\n",
      "Miglior punteggio di MSE:\t0.0018751601472768442\n"
     ]
    }
   ],
   "source": [
    "print('Migliori parametri selezionati:\\t{}'.format(rgr.best_params_))\n",
    "print('Miglior punteggio di MSE:\\t{}'.format(rgr.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c698c4d-edd1-4b6b-a090-06506ff41579",
   "metadata": {},
   "source": [
    "Interessante infine notare come l'interfaccia offerta dagli oggetti di classe `GridSearchCV` sia coerente con quella dei predittori. Potremo quindi chiamare i principali metodi che ci aspettiamo di invocare su un classificatore o un regressore, come ad esempio `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b6a06d3-d557-4803-8e46-bff19a9dcfa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prezzo del biglietto pagato da un uomo di venti anni: 38.69\n"
     ]
    }
   ],
   "source": [
    "print('Prezzo del biglietto pagato da un uomo di venti anni: {}'.format(\n",
    "    round(rgr.predict([[0, 12]])[0], 2))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ec3b6-8951-4adc-a16a-bb1299b1c572",
   "metadata": {},
   "source": [
    "## Esercizio\n",
    "\n",
    "Proviamo ad usare la `GridSearchCV` su un random forest. Individuiamo come parametri il numero di alberi nella foresta, il criterio e la massima profondità di ciascun albero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33a13503-aeda-4c4f-aea5-9846a195cd5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migliori parametri selezionati:\t{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 150}\n",
      "Miglior punteggio di MSE:\t0.011150434020413847\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "pars = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'criterion': ['mae', 'mse'],\n",
    "    'max_depth': list(range(1, 10))\n",
    "}\n",
    "clf = GridSearchCV(rf, pars)\n",
    "clf.fit(X, y)\n",
    "print('Migliori parametri selezionati:\\t{}'.format(clf.best_params_))\n",
    "print('Miglior punteggio di MSE:\\t{}'.format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee59df-85fb-48d1-9cc4-4c0b34cbacb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

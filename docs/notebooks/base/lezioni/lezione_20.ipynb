{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82069089-8ac7-47d9-bddc-fd211c4382d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8893b4-bc63-490c-8783-b3953f72a0e3",
   "metadata": {},
   "source": [
    "In questa lezione, vedremo una panoramica sull'utilizzo di Keras e sulle due API offerte per la creazione di modelli per il deep learning.\n",
    "\n",
    "## Parte 1: lettura dei dati\n",
    "\n",
    "Al solito, iniziamo leggendo i dati che vogliamo utilizzare. In questo caso, useremo uno tra i dataset forniti di default con Keras (potete trovare un elenco completo[qui](https://keras.io/api/datasets/)), ovvero *MNIST*.\n",
    "\n",
    "MNIST è un dataset che contiene un gran numero di immagini rappresentative delle cifre decimali; per i più attenti, lo abbiamo già utilizzato brevemente nelle operazioni di clustering con Scikit-Learn usando il metodo `load_digits`.\n",
    "\n",
    "Specifichiamo anche due costanti, ovvero `NUM_CLASSES`, rappresentativa del numero di classi (ovvero 10), e `INPUT_SHAPE`, che indica le dimensioni del tensore in ingresso alla rete (ovvero, le dimensioni in pixel di ciascuna immagine).\n",
    "\n",
    "> **Nota**: il valore di `INPUT_SHAPE` è pari a 28 (numero di pixel in altezza) per 28 (numero di pixel in larghezza) per 1 (numero di canali per un'immagine in bianco e nero). Se l'immagine fosse stata a colori, o RGB, avremmo avuto 3 canali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2920fc5c-9df0-48d3-854e-5fef0f45c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490a1cc-9751-4660-a3d1-c67dc0301177",
   "metadata": {},
   "source": [
    "### Parte 1.1: preprocessing\n",
    "\n",
    "In questo caso, però, useremo la funzione [`load_data`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data), e dovremo effettuare alcune semplici operazioni di preprocessing.\n",
    "\n",
    "In particolare:\n",
    "\n",
    "1. normalizzeremo i valori assunti dai pixel delle singole immagini in modo che ricadano tra 0 ed 1;\n",
    "2. useremo la funzione [`expand_dims`](https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html) di NumPy per fare in modo che sia aggiunta una nuova dimensione ai dati, in modo che rispettino il parametro `INPUT_SHAPE`;\n",
    "3. infine, convertiremo le label in dati *categorical*, mediante la funzione `to_categorical` contenuta nel package `keras.utils`. In particolare, questa funzione effettua il *one-hot encoding* del vettore passato in ingresso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8c7af1-0027-4e56-9db4-4ab4dae6d8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Normalizzazione dei dati\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "# 2. Aggiunta del numero di canali\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# 3. One hot encoding delle label\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2568057-686f-491b-a6ab-f27cd01c3527",
   "metadata": {},
   "source": [
    "## Parte 2: la Sequential API\n",
    "\n",
    "Keras offre due diverse possibilità per creare un modello di rete neurale. \n",
    "\n",
    "La prima che tratteremo è la [**Sequential API**](https://keras.io/guides/sequential_model/), che modella la rete come una sequenza *strettamente lineare* di layer, ognuno dei quali ha esattamente un tensore in ingresso ed un tensore in uscita.\n",
    "\n",
    "### Parte 2.1: creazione del modello\n",
    "\n",
    "L'idea è quindi quella di creare una rete, di dimensioni *volutamente* ridotte, con una struttura di questo tipo:\n",
    "\n",
    "1. un layer di [`Input`](https://keras.io/api/layers/core_layers/input), che si occupa dell'ingresso dei dati all'interno della rete;\n",
    "2. due sequenze (alternate) fatte da un layer di convoluzione (layer [`Conv2d`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)) ed uno di max pooling (layer [`MaxPool2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)), utili ad estrarre due diversi \"strati\" di feature dall'immagine in ingresso;\n",
    "3. un layer [`Flatten`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), che serve a \"vettorizzare\" le feature estratte prima della funzione di classificazione;\n",
    "4. il layer di classificazione vero e proprio, dato da un layer completamente connesso ([`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) con funzione di attivazione `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb187d1-8bef-4599-bc6b-50267b4998a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smodel = keras.Sequential([\n",
    "    layers.Input(shape=INPUT_SHAPE),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "], name='sequential_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049b47e-00fa-47b1-8a8a-6a6d31bbbd93",
   "metadata": {},
   "source": [
    "Possiamo vedere l'architettura della nostra rete usando la funzione `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f4a70c-1eb5-4307-a732-0488ec687930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 17,578\n",
      "Trainable params: 17,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "smodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157bded-383e-4764-af86-7eba841e1299",
   "metadata": {},
   "source": [
    "### Parte 2.2: addestramento del modello\n",
    "\n",
    "Possiamo adesso passare a finalizzare la struttura del modello, specificando le funzioni di costo e di ottimizzazione mediante il metodo `compile`.\n",
    "\n",
    "In particolare, useremo come funzione di costo la `categorical_crossentropy`, dato che si tratta di un problema multi-classe, mentre come ottimizzatore useremo la funzione `sgd`. Specifichiamo anche la metrica che andrà calcolata ad ogni iterazione (o *epoca*) di addestramento, ovvero l'accuracy sui dati di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ef0a80-ac69-45de-8ae4-fcd83304b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "smodel.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30514e79-56df-4bd0-a1ff-ca24b743b361",
   "metadata": {},
   "source": [
    "Addestriamo ora il modello usando il metodo `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "846caf06-b55c-42ab-803b-0f6ee25d890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5405 - accuracy: 0.5423\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2820 - accuracy: 0.9158\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1930 - accuracy: 0.9444\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1542 - accuracy: 0.9552\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1308 - accuracy: 0.9616\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1138 - accuracy: 0.9666\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1011 - accuracy: 0.9704\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0916 - accuracy: 0.9724\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0909 - accuracy: 0.9724\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0826 - accuracy: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19285bfba60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smodel.fit(X_train, y_train, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf882d-e8e7-4145-844d-8734e552539a",
   "metadata": {},
   "source": [
    "Come possiamo vedere, l'accuracy raggiunta dal modello dopo dieci epoche di addestramento è del 97.46%.\n",
    "\n",
    "## Parte 3: la Functional API\n",
    "\n",
    "La seconda possibilità offerta da Keras è quella relativa all'uso della [**Functional API**](https://keras.io/guides/functional_api), che ci offre maggior controllo sul modello da creare, al prezzo di una sintassi leggermente più complessa.\n",
    "\n",
    "Rispetto alla Sequential API, la Functional API basa il suo funzionamento sul concetto di *grafo aciclico diretto*, il che permette quindi topologie più complesse, con layer condivisi, input ed output multipli, e così via. Per fare un esempio, sarebbe impossibile implementare un'architettura come [Inception](https://i.stack.imgur.com/iNy2U.png) senza usare un'API di questo tipo.\n",
    "\n",
    "Vediamo quindi come creare un modello analogo al precedente usando questa funzionalità.\n",
    "\n",
    "### Parte 3.1: creazione del modello\n",
    "\n",
    "Notiamo che i layer che utilizzeremo *non cambiano*; cambia solo la sintassi e le funzioni utilizzate per concatenarli. Partiamo quindi dal layer di `Input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929226fe-9bbb-490d-8fdf-5e375bb6d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0303d0c-3144-4bb9-8e4c-b21e3f3eb9fb",
   "metadata": {},
   "source": [
    "A questo punto, aggiungiamo un nodo al *grafo* di layer che compone la rete neurale andando a \"chiamare\" un nuovo layer su quello precedente, e creando così un collegamento tra i due.\n",
    "\n",
    "Dal punto di vista pratico, usiamo una sintassi del tipo:\n",
    "\n",
    "```py\n",
    "# architettura = nuovo_layer(layer_esistente)\n",
    "```\n",
    "\n",
    "che equivale a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab171ec-9802-4b98-b5fb-cc84a1c1e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000671a7-3207-4839-9f6e-71a87e1cbd33",
   "metadata": {},
   "source": [
    "Ripetiamo questa operazione fino a raggiungere il layer `outputs`, che sarà quello della classificazione mediante `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3393ec20-9905-47fe-abc4-e2d27207de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c07e5-1931-4889-9c64-dd91b5f34607",
   "metadata": {},
   "source": [
    "Creiamo adesso un nuovo oggetto di tipo [`Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model). Ricordiamo di definire i layer di input ed output per il modello e, opzionalmente, specificare un nome.\n",
    "\n",
    "Verifichiamo inoltre con `summary()` che la struttura sia coerente a quella vista in precedenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b329ec-e8cb-4f9e-bb03-b5b82dc1f78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 17,578\n",
      "Trainable params: 17,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fmodel = keras.Model(inputs=inputs, outputs=outputs, name='functional_model')\n",
    "fmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f91f93-4ae1-443d-8cad-aaaab232eb15",
   "metadata": {},
   "source": [
    "Una nota: vediamo che, a differenza del modello ottenuto mediante Sequential API, qui siamo in grado di vedere la forma del layer di input. Questo effetto è *voluto*.\n",
    "\n",
    "In ultimo, compiliamo il modello ed addestriamolo alla stessa maniera del precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "069e92e6-ba04-411f-8bb2-08ed7f8b22d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 16ms/step - loss: 1.4128 - accuracy: 0.5809\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.2863 - accuracy: 0.9143\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1955 - accuracy: 0.9425\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1527 - accuracy: 0.9541\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1274 - accuracy: 0.9623\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1144 - accuracy: 0.9664\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1041 - accuracy: 0.9683\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0955 - accuracy: 0.9720\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0897 - accuracy: 0.9727\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0864 - accuracy: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19285fb6190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "fmodel.fit(X_train, y_train, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902220b1-aa14-457b-8e24-f394f43c4ceb",
   "metadata": {},
   "source": [
    "Ovviamente, le prestazioni sono molto simili, trattandosi, nei fatti, dello stesso modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19b9f8-67f4-46b4-a6c0-ae71baa900bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

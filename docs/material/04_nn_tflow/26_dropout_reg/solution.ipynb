{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.datasets import imdb\n",
    "from keras import models, layers, losses, regularizers, optimizers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=1000)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "782/782 [==============================] - 10s 10ms/step - loss: 0.6391 - acc: 0.7963 - val_loss: 0.4679 - val_acc: 0.8323\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4944 - acc: 0.8351 - val_loss: 0.5860 - val_acc: 0.8232\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4420 - acc: 0.8567 - val_loss: 0.4808 - val_acc: 0.8370\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4254 - acc: 0.8691 - val_loss: 0.5058 - val_acc: 0.8426\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4038 - acc: 0.8700 - val_loss: 0.5835 - val_acc: 0.8476\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4363 - acc: 0.8666 - val_loss: 0.7180 - val_acc: 0.8266\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3735 - acc: 0.8910 - val_loss: 0.6345 - val_acc: 0.8366\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3362 - acc: 0.9011 - val_loss: 0.6765 - val_acc: 0.8433\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.2960 - acc: 0.9224 - val_loss: 0.7608 - val_acc: 0.8484\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.2959 - acc: 0.9342 - val_loss: 0.8447 - val_acc: 0.8443\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2480 - acc: 0.9441 - val_loss: 0.9244 - val_acc: 0.8476\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2112 - acc: 0.9609 - val_loss: 1.0142 - val_acc: 0.8494\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.1767 - acc: 0.9759 - val_loss: 1.1042 - val_acc: 0.8475\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1551 - acc: 0.9850 - val_loss: 1.1998 - val_acc: 0.8456\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1411 - acc: 0.9894 - val_loss: 1.2979 - val_acc: 0.8431\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1372 - acc: 0.9902 - val_loss: 1.3591 - val_acc: 0.8420\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.1518 - acc: 0.9879 - val_loss: 1.5581 - val_acc: 0.8343\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1932 - acc: 0.9746 - val_loss: 1.4675 - val_acc: 0.8372\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1683 - acc: 0.9844 - val_loss: 1.5859 - val_acc: 0.8379\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1491 - acc: 0.9868 - val_loss: 1.5342 - val_acc: 0.8390\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1395 - acc: 0.9882 - val_loss: 1.6936 - val_acc: 0.8292\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1257 - acc: 0.9908 - val_loss: 1.6060 - val_acc: 0.8416\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1322 - acc: 0.9898 - val_loss: 1.6692 - val_acc: 0.8384\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1575 - acc: 0.9836 - val_loss: 1.6925 - val_acc: 0.8324\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1330 - acc: 0.9885 - val_loss: 1.6171 - val_acc: 0.8389\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1197 - acc: 0.9917 - val_loss: 1.6316 - val_acc: 0.8386\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1197 - acc: 0.9921 - val_loss: 1.6790 - val_acc: 0.8391\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1176 - acc: 0.9922 - val_loss: 1.6732 - val_acc: 0.8381\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1192 - acc: 0.9920 - val_loss: 1.6907 - val_acc: 0.8389\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1213 - acc: 0.9913 - val_loss: 1.7348 - val_acc: 0.8393\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1211 - acc: 0.9913 - val_loss: 1.7259 - val_acc: 0.8382\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1212 - acc: 0.9905 - val_loss: 1.7854 - val_acc: 0.8368\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1867 - acc: 0.9805 - val_loss: 2.1741 - val_acc: 0.8141\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2194 - acc: 0.9773 - val_loss: 1.7969 - val_acc: 0.8366\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1839 - acc: 0.9816 - val_loss: 1.8846 - val_acc: 0.8371\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1374 - acc: 0.9891 - val_loss: 1.8740 - val_acc: 0.8356\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1278 - acc: 0.9907 - val_loss: 1.8477 - val_acc: 0.8374\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1224 - acc: 0.9918 - val_loss: 1.8578 - val_acc: 0.8375\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1210 - acc: 0.9919 - val_loss: 1.8956 - val_acc: 0.8360\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1380 - acc: 0.9880 - val_loss: 1.8996 - val_acc: 0.8346\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1271 - acc: 0.9903 - val_loss: 1.8940 - val_acc: 0.8358\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1231 - acc: 0.9906 - val_loss: 1.8966 - val_acc: 0.8359\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1181 - acc: 0.9916 - val_loss: 1.8677 - val_acc: 0.8380\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1151 - acc: 0.9920 - val_loss: 1.8971 - val_acc: 0.8398\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1724 - acc: 0.9828 - val_loss: 1.9288 - val_acc: 0.8369\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.1240 - acc: 0.9898 - val_loss: 1.9065 - val_acc: 0.8379\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1204 - acc: 0.9913 - val_loss: 1.9095 - val_acc: 0.8369\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1163 - acc: 0.9914 - val_loss: 1.9017 - val_acc: 0.8352\n",
      "Epoch 49/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1119 - acc: 0.9926 - val_loss: 1.9254 - val_acc: 0.8354\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1111 - acc: 0.9928 - val_loss: 1.9151 - val_acc: 0.8356\n"
     ]
    }
   ],
   "source": [
    "# overfitting ed underfitting con modello ad un layer ed 8 neuroni\n",
    "model_small = models.Sequential()\n",
    "model_small.add(\n",
    "    layers.Dense(\n",
    "        64,\n",
    "        activation='relu',\n",
    "        input_shape=(1000,)))\n",
    "model_small.add(\n",
    "    layers.Dense(1),\n",
    "    activation='sigmoid')\n",
    "model_small.compile(optimizer=optimizers.Adam(),\n",
    "            loss=losses.BinaryCrossentropy(),\n",
    "            metrics=['acc'])\n",
    "\n",
    "history_small=model_small.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('python-calcolo-numerico-5v4ihblp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bff96ae05cbca38553397e8b82810313cdead769dbf63fb2d18b6e7c166b3c3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

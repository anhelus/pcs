# Multi-layer perceptron

I *multi-layer perceptron* sono i modelli di deep learning fondamentali. L'obiettivo di un MLP è quello di approssimare una funzione $f^*$. Ad esempio, per un classificatore $y=f^*(x)$ mappa un input $x$ ad una classe $y$. Un MLP definisce quindi un mapping $y = f(x; \theta)$ ed apprende il valore dei parametri $\theta$ che restituiscono la migliore approssimazione della funzione.

Questi modelli sono chiamati anche *feedforward network*, dato chel'informazione fluisce attraverso la funzione valutata da $x$, attraverso dei blocchi di calcolo intermedi ustai per definire $f$, ed infine verso l'output $y$. In pratica, non vi sono dei *feedback* che l'output del modello dà a se stesso. Quando questo tipo di rete è esteso per includere delle connessioni di fedback, siamo di fronte a delle *recurrent neural network*.

Gli MLP sono di estrema importanza nelle applicazioni di machine learning, e formano la base di molte applicazioni commerciali di interesse. Ad esempio, le reti convoluzionali usate per il riconoscimento degli oggetti non sono altro se non un tipo specializzato di rete feedforward.

Il termine *rete* si riferisce al fatto che sono tipicamente rappresentate componendo insieme diverse funzioni. Il modello ottenuto è associato ad un grafo aciclico diretto che descrive come queste funzioni sono composte tra lroo. Ad esempio, possiamo avere tre funzioni $f^{(1)}$, $f^{(2)}$ ed $f^{(3)}$ connesse a formare una $f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x))). Queste strutture a catena sono quelle più comuni tra le reti neurali. In questo caso, $f^{(1)}$ sarà il primo layer della rete, $f^{(2)}$ il secondo layer, e così via. La lunghezza complessiva ci dà il numero di layer della rete e, conseguentemente, la *profondità* del modello. Il nome *deep learning* deriva proprio da questa terminologia. L'ultimo strato di un MLP è chiamato *strato di output*. 

Durante l'addestramento di una rete neurale, modifichiamo $f(x)$ per fare in modo che rispecchi quanto più possibile $f^{*}(x)$. I dati di training ci forniscono esempi rumorosi ed approssimati di $f^{*}(x)$ in diversi punti di addestramento. Ogni campione $x$ è accompagnato da una label $y \sim f*(x)$. I campioni di training specificanod irettamente quello che deve fare il layer di output in ogni punto $x$: deve produrre quindi un valore che sia quanto più vicino possibile ad $y$. Il comprotamento degli altri layer non è direttamente specificato dai dati di training. L'algoritmo di apprendimento deve qeuindi decidere come usare questi layer per produrre l'output deisderato, ma i dati di training non dicono quello che dve fare goni singolo layer. Invece, l'algoritmo di apprendimento deve decieder come usare questi layer per implementare al meglio un'approssimazione di $f^{*}$. Dato che i dati di training non mostrano l'output deisderato per ciascuno di questi layer, questi sono chiamati *hidden layer*.

Infine, queste reti sono chiamate *neurali* perché sono ispirate dalla neuroscienza. Ogni strato nascosto della rete è tipicamente valutato come un vettore. La dimensionalità di questi strati nascosti determina l'*ampiezza* del modello. Ogni elemento del vettore gioca un ruolo analogo a quello di un neurone. Pituttosto che pensare al layer come rappresentativo di una singola funzioen vettore-vettore, possiamo pensare al layer come composto da diverse unità che agiscono in parallelo, ognuna rappresentativa di una funzione che prende in ingresso un vettore dando in uscita uno scalare. Ogni unità ricorda un neurone nel senso che riceve l'input da moltre altre unità e calcola il suo valore di attivazione. L'idea di usare molti layer di rappresentazioni vettoriali è estratta dalla neuroscienza. La sclet a delle funzioni $f^{(i)}(x)$ usate per caloclare queste rappresentazioni è anche guidata dalle osservazioni neuroscientifiche sul funzionamento del neurone bioogoico. La ricerca moderna nel campo delle reti neurali, tuttavia, è guidata da molte discipline matematiche ed ingengeristiche, e l'obiettivo delle reti neurali non è quello di modellare perfettamente il cervello umano. E' meglio pensare alle MLP come funzioni approssimate che sono progettate per ottnere una generalizzazione statisitca, occasionalmente estraendo delle nozioni da quello che sappiamo sul cervello, piuttosto che come modelli del funzionamento del cervello.

Un modo per comprendere le reti feedforward è quello di partire dai modelli lineari, e comprendere come superano i loro limiti. I modelli lineari, come la regressione lineare o logistica, sono invitanti perché possono effettuare un'approssimazione efficiente ed affidabile, sia in forma chiusa che mediante ottimizzazione convessa. I modelli lineari hanno anche il difetto ovvio che la loro capacità di modellazione è limitata alle funzioni lineari, per cui il modello non può modellare l'interazione tra una qualsiasi coppia di variabili.

Per estendere un modello lineare e rappreesntare una funzione non ilneare di $x$, possiamo applicarlo non ad $x$ stessa, ma ad un output trasformato $\phi(x)$ dove $\phi$ è una trasformazione non lineare. In pratica, $\phi$ è un insieme di feature che descrive $x$, o una nuova rappresentazione di $x$. La domanda, quindi, diventa *come scegliere il mapping $\phi$*. Le opzioni sono le seguenti:

1. La prima opzione è quella di usare uno $\phi$ estremamente generico, come quello a dimensionalità infita usato dalle macchine kernel basate su kernel RBF. Se $\phi(x)$ è di dimensionalità molto alta, possiamo pensare di avere sempre capacità per rappresentare il training set; tuttavia, la generalizzazione sul test set spesso dà risultati deludenti. Dei feature mapping molto generici sono di solito infatti basati solo sul principio dell'approssimazione locale, e non hanno al loro interno abbastanza informazioni per risolvere problemi avanzati.
2. Un'altra opzione è quella di ingegnerizzare $\phi$ manualmente. Fino all'avvento del deep learning, questo era l'approccio predominante. Richiede però decadi di sforzi per ogni singolo task, con esperit di dominio per ciascun dominio, e poca replicabilità tra domini anche leggermente differenti.
3. La strategia usata dal deep learning è quella di *apprendere* $\phi$. In questo approccio, abbiamo un modello $y=f(x; \theta, v)=\phi(x; \theta)^Tw$. Abbiamo adessod ei parametri $\theta$ che usiamo per apprendere $\phi$ da un'ampia classe di funzioni, e dei parametri $w$ che mappano da $\phi(x)$ all'output desiderato. Questo è un esempio di MLP, con $\phi$ che definisce uno strato nascosto. Questo approccio è l'unico dei tre che non considera un problema di addestramento non convesso, ma i benefici superano i problemi. In questo approccio, parametrizziamo la rappresentazione come $\phi(x; \theta)$ ed usiamo l'algoritmo di ottimizzazione per trovare la $\theta$ che corrisponde ad una buona rappresentazione. Volendo, questo approccio può catturare i benefici del primo approccio, in quanto è altamente generico (possiamo farlo scegliendo una famglia molto ampia di $\phi(x; \theta)$). Il deep learning può anceh catturare il beneficio del secondo approccio. Gli esperit di domniono possono codificare la loro conoscenza per aiturare la generalizzazione progettando famiglie $\phi(x; \theta)$ che si aspettano che vadano bene. Il vantaggio è che il progettista umano deve solo indivudare la gisuta famiglia di funzioni generichepituttosto che idnividuare la funzione cofrretta in maniera precisa.



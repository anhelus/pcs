{"config":{"lang":["it"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Corso di Python per il Calcolo Scientifico","text":"<p>Benvenuti nel sito per il corso di Python per il Calcolo Scientifico.</p>"},{"location":"#struttura-del-sito","title":"Struttura del sito","text":"<p>La seguente tabella descrive, in breve, la struttura del sito.</p> Nome Link Spiegazione Slides Elenco delle slide visualizzate a lezione. Liberamente scaricabili. Modalit\u00e0 di esame Descrizione dettagliata delle modalit\u00e0 per il conseguimento dei CFU. Calendario delle lezioni Calendario dettagliato delle lezioni, con ore ed aula. Date di appello Date di appello previste. In arrivo. Temi d'anno Proposte per i temi d'anno. In arrivo. Registrazioni Elenco delle registrazioni delle lezioni, rigorosamente non editate. <p>Inoltre, selezionando un argomento di interesse dal menu a sinistra, \u00e8 possibile navigare nella sezione del sito contentente le apposite dispense, da considerarsi integrative rispetto alle slides ed alle lezioni.</p>"},{"location":"#aa-precedenti","title":"A.A. precedenti","text":""},{"location":"#20212022","title":"2021/2022","text":"<ul> <li>Registrazioni</li> </ul>"},{"location":"#ricevimento","title":"Ricevimento","text":"<p>E' possibile concordare un ricevimento inviando una e-mail all'indirizzo angelo.cardellicchio@stiima.cnr.it.</p>"},{"location":"contributors/","title":"Crediti","text":"<p>Un particolare ringraziamento a tutti coloro che hanno contribuito alla costruzione e manutenzione del materiale del corso.</p> Nome Contributo Mirko Cal\u00f2 Registrazione delle lezioni. Simone Fidanza Revisione ed update della repository."},{"location":"projects/","title":"Elenco delle tematiche di interesse per il tema d'anno","text":"<p>Nella seguente tabella sono elencate alcune tematiche di interesse per effettuare un tema d'anno di tipo compilativo. Questa modalit\u00e0, prevalentemente indirizzata a studenti dei corsi triennali e magistrali, prevede un approfondimento sul tema proposto, composto da:</p> <ol> <li>presentazione;</li> <li>relazione;</li> <li>codice di esempio testato e funzionante.</li> </ol> <p>Non \u00e8 possibile assegnare lo stesso tema a pi\u00f9 di un gruppo; in tal senso, l'assegnazione sar\u00e0 data in base alla priorit\u00e0 acquisita, ovvero all'ordine temporale in cui saranno ricevute le richieste.</p> <p>Per prenotare un tema d'anno, \u00e8 necessario compilare il form a questo indirizzo. Il form sar\u00e0 attivo fino al 5 luglio; oltre quella data,ed in base alle necessit\u00e0, potr\u00e0 essere pubblicato un nuovo form con temi aggiornati.</p> <p>Suggerimento</p> <p>La data da segnalare sul modulo \u00e8, ovviamente, indicativa. Tuttavia, anche per permettere una migliore organizzazione del lavoro a tutti, si consiglia di \"bloccare\" un tema di interesse soltanto se si \u00e8 effettivamente sicuri di sostenere l'esame in questa modalit\u00e0.</p> Ambito Tema d'anno Disponibile Assegnatari Scikit Learn Support Vector Machines Di Cosmo Scikit Learn Algoritmi multiclasse-multioutput Dipalma Scikit Learn Novelty/Outlier detection Leserri Scikit Learn Reti neurali non supervisionate Fazio - Ambrosio Scipy Clustering Giorgio - Tota - Susca Scipy Problemi di ottimizzazione Cagnazzi - Rago Scipy Fattorizzazione di matrici De Rosa - Leone TensorFlow/Keras Tuning degli iperparametri Fiume TensorFlow/Keras AutoML Capodiferro - Nenna - Racanati TensorFlow/Keras Image segmentation Bellino - Gentile TensorFlow/Keras Classificazione del testo con RNN Maldera TensorFlow/Keras Classificazione del testo con BERT Cotimbo TensorFlow/Keras Predizione di serie temporali Disanto - Ginestra - Pisani TensorFlow/Keras Autoencoders Loizzo"},{"location":"projects/#proposte-approvate","title":"Proposte approvate","text":"<p>Di seguito l'elenco delle proposte per il tema d'anno approvate.</p> Tema d'anno Assegnatari Decomposizione SVD Gioiosa - Rubino - Nicoletti - Erione Color detection De Giglio - Percoco Big transfer Antonacci - Pacucci"},{"location":"2022-23/calendar/","title":"Calendario delle lezioni A.A. 2022/2023","text":"Data Orario Aula Argomento 28/02/2023 15:00 - 17:00 XI Introduzione a Python 02/03/2023 15:00 - 17:00 XI Concetti base di Python 07/03/2023 15:00 - 17:00 XI OOP in Python 09/03/2023 15:00 - 17:00 XI Introduzione a NumPy 14/03/2023 15:00 - 17:00 XI Operazioni algebriche in NumPy 16/03/2023 15:00 - 17:00 XI Polinomi e statistica in NumPy 21/03/2023 15:00 - 17:00 XI Visualizzazione in Matplotlib 23/02/2023 15:00 - 17:00 XI Visualizzazione in Seaborn 28/03/2023 15:00 - 17:00 XI Introduzione a Pandas 05/04/2023 15:00 - 17:00 XII Introduzione al machine learning ed a Scikit Learn 27/04/2023 15:00 - 17:00 XII Regressione lineare e logistica 02/05/2023 15:00 - 17:00 XII Alberi decisionali 04/05/2023 15:00 - 17:00 XII Metriche di classificazione e regressione 09/05/2023 15:00 - 17:00 XII Clustering 11/05/2023 15:00 - 17:00 XII Concetti avanzati di Scikit Learn 16/05/2023 15:00 - 17:00 XII Introduzione a TensorFlow 18/05/2023 15:00 - 17:00 XII Reti neurali feedforward 23/05/2023 15:00 - 17:00 XII Autoencoder 25/05/2023 15:00 - 17:00 XII RNNs e CNNs 30/05/2023 15:00 - 17:00 XII Object detection 01/06/2023 15:00 - 18:00 XII Explainability 06/06/2023 15:00 - 18:00 XII Reti generative"},{"location":"2022-23/dates/","title":"Date d'appello A.A. 2022/2023","text":"<p>Studenti A.A. precedenti</p> <p>Gli studenti degli A.A. precedenti potranno (eccezionalmente) sostenere l'appello nelle date indicate previa comunicazione che dovr\u00e0 pervenire entro e non oltre 20 (venti) giorni prima della data scelta.</p> <p>In Arrivo</p>"},{"location":"2022-23/exams/","title":"Modalit\u00e0 di esame (A.A. 2022/2023)","text":""},{"location":"2022-23/exams/#studenti-l3lm","title":"Studenti L3/LM","text":"<p>Consiste nella stesura di un tema d\u2019anno che descriva e risolva un determinato problema.</p> <p>Il tema pu\u00f2 essere proposto dagli studenti o, in alternativa, selezionato da un elenco di temi proposto dal docente.</p> <p>Il tema dovr\u00e0 essere redatto da gruppi formati da uno a quattro studenti, e sar\u00e0 articolato in:</p> <ul> <li>una relazione sintetica (quattro pagine) delle attivit\u00e0 svolte, valutata fino a tre punti (3/30);</li> <li>una presentazione sintetica (12 slides) delle attivit\u00e0 svolte, valutata fino a tre punti (3/30);</li> <li>il codice relativo alle attivit\u00e0 svolte, consegnato secondo le modalit\u00e0 indicate a lezione, valutato fino a 12 punti (12/30);</li> <li>una discussione orale, focalizzata sul tema d\u2019anno, valutata fino a 12 punti (12/30).</li> </ul> <p>In alternativa, \u00e8 possibile sostenere un orale riguardante tutte le tematiche affrontate durante il corso.</p>"},{"location":"2022-23/exams/#dottorandialtro","title":"Dottorandi/altro","text":"<p>Consiste nella stesura di un tema d\u2019anno relativo alle proprie attivit\u00e0 di ricerca.</p> <p>Il tema dovr\u00e0 essere redatto da gruppi formati da uno a quattro dottorandi, e sar\u00e0 articolato in:</p> <ul> <li>una presentazione sintetica (12 slides) delle attivit\u00e0 svolte;</li> <li>una discussione orale, con annessa dimostrazione pratica dei risultati ottenuti e valutazione del codice.</li> </ul>"},{"location":"2022-23/proposals/","title":"Temi d'anno A.A. 2022/2023","text":"<p>In Arrivo</p>"},{"location":"2022-23/recordings/","title":"Registrazione delle lezioni A.A. 2022/2023","text":"Data Link 28/02/2023 02/03/2023 07/03/2023 09/03/2023 14/03/2023 16/03/2023 21/03/2023 23/02/2023 28/03/2023 30/03/2023 05/04/2023 27/04/2023 02/05/2023 04/05/2023 09/05/2023 11/05/2023 16/05/2023 18/05/2023 23/05/2023 25/05/2023 30/05/2023 01/06/2023"},{"location":"2022-23/slides/","title":"Slide proiettate a lezione","text":"Argomento Link 00 - Programma del corso 01 - Introduzione a Python 02 - Concetti sintattici fondamentali 03 - Strutture dati in Python 04 - OOP in Python 05 - Script, moduli, librerie 06 - Introduzione a NumPy 07 - Operazioni in NumPy 08 - Strumenti per la visualizzazione dei dati 09 - Pandas 10 - Introduzione al machine learning 11 - Introduzione a Scikit Learn"},{"location":"material/01_python/01_intro/01_intro/","title":"1.1 - Introduzione al Python","text":"<p>Prima di iniziare a parlare del linguaggio Python, \u00e8 opportuno verificare che l'interprete sia installato nel nostro sistema. Per farlo, apriamo un terminale (Shell o Command Prompt, a seconda del nostro sistema), e scriviamo:</p> <pre><code>python\n</code></pre> <p>Se apparir\u00e0 una schermata simile a quella mostrata in figura 1, Python sar\u00e0 gi\u00e0 correttamente installato sul nostro sistema.</p> <p> </p> Figura 1 - Interprete Python <p>In alternativa, dovremo provvedere ad installarlo seguendo la procedura indicata sul sito ufficiale, ed aggiungerlo al path di sistema.</p>"},{"location":"material/01_python/01_intro/01_intro/#python-e-tipizzazione","title":"Python e tipizzazione","text":""},{"location":"material/01_python/01_intro/01_intro/#tipizzazione-dinamica","title":"Tipizzazione dinamica","text":"<p>Python \u00e8 un linguaggio interpretato ed a tipizzazione dinamica. In breve, questo significa che l'interprete valuta il tipo di ciascuna variabile a runtime, e che questo pu\u00f2 cambiare durante l'esecuzione del programma.</p> <p>Ma, a conti fatti, in cosa si traduce per il programmatore? Beh, molto semplice.</p> <p>Immaginiamo di dover definire ed inizializzare una variabile di tipo intero in un linguaggio a tipizzazione statica, come ad esempio il C++. Per farlo, scriveremo qualcosa simile a:</p> <pre><code>int var = 0;\n</code></pre> <p>In Python, potremo omettere il tipo, che sar\u00e0 inferito direttamente dal valore assegnato alla variabile:</p> <pre><code>var = 0\n</code></pre> <p>Immaginiamo ora che la nostra variabile debba diventare un decimale. In C++, dovremo effettuare il casting:</p> <pre><code>float fVar = float(var);\nfVar + 1.1;\n</code></pre> <p>In Python questo non sar\u00e0 necessario, e potremo effettuare direttamente le operazioni desiderate:</p> <pre><code>var + 1.1           # Il risultato sar\u00e0 1.1\n</code></pre> <p>Questo pu\u00f2 apparentemente semplificare di molto la vita, in quanto non \u00e8 pi\u00f9 necessario preoccuparsi del tipo della variabile. Non \u00e8 per\u00f2 tutto oro ci\u00f2 che luccica: per comprenderlo, infatti, \u00e8 il momento di parlare del (pilatesco) principio del duck typing.</p>"},{"location":"material/01_python/01_intro/01_intro/#duck-typing","title":"Duck Typing","text":"<p>Il duck typing \u00e8 riassumibile nella seguente massima:</p> <p>Duck Typing</p> <p>If it walks like a duck and it quacks like a duck, then it must be a duck.</p> <p>che in italiano suona pi\u00f9 o meno Se cammina come un papero, e starnazza come un papero, deve essere un papero. Traduciamola brevemente in \"informatichese\". </p> <p>Immaginiamo di istruire il nostro interprete Python ad assegnare alla nostra variabile <code>var</code> il valore di <code>1</code>. L'interprete nota che la variabile si \"comporta\" come un numero intero, e quindi \"stabilir\u00e0\" che si tratti proprio di questo.</p> <p>Proviamo ora a sommare a <code>var</code> un valore pari ad <code>1.1</code>. Il risultato, come ovvio, sar\u00e0 un numero decimale, e quindi l'interprete \"cambier\u00e0 idea\", in quanto i comportamenti assunti da <code>var</code> sono adesso assimilabili ad una variabile di tipo <code>float</code>.</p> <p>L'utilit\u00e0 del duck typing \u00e8 evidente: permette allo sviluppatore di \"risparmiare\" numerose operazioni di cast, rendendo il codice pi\u00f9 semplice da scrivere e manutenere. Tuttavia, occorre tenerne conto nel momento in cui si usano classi ed oggetti, in quanto l'interprete prover\u00e0 ad inferire ed usare automaticamente un tipo in base al contesto in cui viene usata la variabile, con le comodit\u00e0 (ed i potenziali disastri) che questo comporta.</p>"},{"location":"material/01_python/01_intro/01_intro/#tipi-built-in-in-python","title":"Tipi built-in in Python","text":"<p>Python prevede una serie di tipi built-in, ovvero nativamente disponibili nel linguaggio. Ne esiste un gran numero; tuttavia, quelli che ci troveremo pi\u00f9 frequentemente ad utilizzare sono riassunti in tabella 1.</p> Tipo Descrizione Esempio <code>int</code> Numeri interi <code>1</code> <code>float</code> Numeri decimali <code>1.0</code> <code>complex</code> Numeri complessi <code>1 + 1j</code> <code>list</code> Liste di oggetti <code>[1, 'pippo', [1, 2, 3]]</code> <code>tuple</code> Tuple di oggetti <code>(1, 'pippo', [1, 2, 3])</code> <code>str</code> Stringhe <code>'pippo'</code> <code>set</code> Insiemi <code>{1, 2, 3}</code> <code>dict</code> Dizionari <code>{'a': 1, 2: 'b'}</code> <p>Nella prossima lezione, vedremo alcuni tra gli operatori pi\u00f9 comunemente utilizzati sui dati di tipo numerico.</p>"},{"location":"material/01_python/01_intro/02_operators/","title":"1.2 - Operatori aritmetici e logici","text":"<p>Come brevemente accennato nella scorsa lezione, vediamo di seguito quelli che sono gli operatori aritmetici e logici, e come possono essere utilizzati sui tipi numerici di base.</p>"},{"location":"material/01_python/01_intro/02_operators/#operatori-aritmetici","title":"Operatori aritmetici","text":""},{"location":"material/01_python/01_intro/02_operators/#addizione-moltiplicazione-e-sottrazione","title":"Addizione, moltiplicazione e sottrazione","text":"<p>Proviamo ad usare l'interprete come una semplice calcolatrice; per farlo, scriviamo direttamente dopo il simbolo <code>&gt;&gt;&gt;</code> le operazioni che vogliamo eseguire, e premiamo il tasto <code>Invio</code>. Ad esempio:</p> <pre><code>&gt;&gt;&gt; 2 + 2\n4\n&gt;&gt;&gt; 3 * 5\n15\n&gt;&gt;&gt; 10 - 2 * 4\n2\n</code></pre>"},{"location":"material/01_python/01_intro/02_operators/#divisione","title":"Divisione","text":"<p>Le divisioni restituiscono sempre un numero in virgola mobile. Ad esempio:</p> <pre><code>&gt;&gt;&gt; 16 / 3\n5.333333333333333\n&gt;&gt;&gt; 2 / 2\n1.0\n</code></pre> <p>Valutare il tipo di una variabile</p> <p>Per valutare il tipo di una variabile <code>a</code> possiamo usare la funzione <code>type()</code> cui passeremo la variabile come argomento. Ad esempio:</p> <pre><code>&gt;&gt;&gt; a = 10\n&gt;&gt;&gt; type(a)\nint\n&gt;&gt;&gt; b = 3.3\n&gt;&gt;&gt; type(b)\nfloat\n</code></pre>"},{"location":"material/01_python/01_intro/02_operators/#quoziente-e-resto-di-una-divisione","title":"Quoziente e resto di una divisione","text":"<p>Esistono due operazioni contestuali, ma distinte, rispetto alla classica divisione. In particolare, possiamo utilizzare l'operatore <code>//</code> per ottenere il quoziente della divisione. Ad esempio, provando a dividere <code>16</code> per <code>3</code> avremo un quoziente di <code>5</code>:</p> <pre><code>&gt;&gt;&gt; 16 // 3\n5\n</code></pre> <p>L'operatore <code>%</code>, invece, restituisce il resto della divisione. Nel caso precedente, restituir\u00e0 quindi <code>1</code>:</p> <pre><code>&gt;&gt;&gt; 16 % 3\n1\n</code></pre> <p>Aritmetica modulare</p> <p>Va da s\u00e8 che l'operatore <code>%</code> pu\u00f2 essere usato per applicazioni di aritmetica modulare.</p> <p>E' importante sottolineare come gli operatori <code>//</code> e <code>%</code> restituiscano dei valori interi.</p>"},{"location":"material/01_python/01_intro/02_operators/#elevazione-a-potenza","title":"Elevazione a potenza","text":"<p>Per elevare un numero a potenza, \u00e8 necessario usare l'operatore <code>**</code>, in cui l'operando sinistro \u00e8 la base, mentre quello destro l'esponente:</p> <pre><code>&gt;&gt;&gt; 3 ** 2\n9\n&gt;&gt;&gt; 2 ** 8\n256\n</code></pre>"},{"location":"material/01_python/01_intro/02_operators/#sommario","title":"Sommario","text":"<p>Terminiamo questa sezione con un breve sommario dei diversi tipi di operatore aritmetico, e degli effetti che hanno sulle variabili di tipo numerico.</p> Operatore Descrizione Esempio Risultato <code>+</code> Somma <code>1 + 1</code> <code>2</code> <code>-</code> Sottrazione <code>1 - 1</code> <code>0</code> <code>*</code> Moltiplicazione <code>2 * 1</code> <code>2</code> <code>**</code> Elevazione a potenza <code>2 ** 3</code> <code>8</code> <code>/</code> Divisione <code>2 / 1</code> <code>2</code> <code>//</code> Quoziente <code>4 // 3</code> <code>1</code> <code>%</code> Modulo <code>5 % 3</code> <code>2</code>"},{"location":"material/01_python/01_intro/02_operators/#operatori-logici","title":"Operatori logici","text":"<p>Gli operatori logici permettono di implementare le operazioni base dell'algebra booleana.</p> <p>In tal senso, \u00e8 opportuno riassumere brevemente i principi e le operazioni alla base di questo tipo di algebra.</p> <ol> <li>Nell'algebra booleana, le variabili possono assumere solo due possibili valori: vero, o \\(1\\), e falso, o \\(0\\).</li> <li>Combinando i valori di pi\u00f9 variabili, \u00e8 possibile valutare condizioni pi\u00f9 o meno complesse partendo dalle operazioni \\(AND\\), \\(OR\\) e \\(NOT\\).</li> <li>I valori assunti da una condizione sono esprimibili mediante le tabelle di verit\u00e0.</li> </ol> <p>L'operazione XOR</p> <p>Esiste una quarta operazione fondamentale, la XOR, che per\u00f2 non tratteremo in questa sede.</p>"},{"location":"material/01_python/01_intro/02_operators/#tabelle-di-verita-delle-operazioni-logiche-fondamentali","title":"Tabelle di verit\u00e0 delle operazioni logiche fondamentali","text":"<p>Vediamo brevemente le tabelle di verit\u00e0 per le tre operazioni logiche fondamentali descritte al punto \\(2\\) del paragrafo precedente. Per ciascuna di queste tabelle, considereremo due variabili booleane \\(A\\) e \\(B\\), le quali potranno assumere valore \\(0\\) o \\(1\\). Nelle colonne \\(AND\\) ed \\(OR\\) saranno quindi riportati i risultati della rispettiva operazione logica.</p> \\(A\\) \\(B\\) \\(AND\\) \\(OR\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(1\\) \\(0\\) \\(1\\) \\(1\\) \\(0\\) \\(0\\) \\(1\\) \\(1\\) \\(1\\) \\(1\\) \\(1\\) <p>In particolare, notiamo che il risultato dell'\\(AND\\) \u00e8 pari ad \\(1\\) quando entrambe le variabili sono \\(1\\); altrimenti, il risultato \u00e8 \\(0\\). Per quello che riguarda invece la \\(OR\\), il risultato \u00e8 \\(1\\) quando almeno una delle variabili \u00e8 pari ad \\(1\\).</p> <p>Trasponendo questo concetto nella verifica di una o pi\u00f9 condizioni:</p> <ul> <li>un AND \u00e8 vero se e solo se entrambe le condizioni sono vere;</li> <li>un OR \u00e8 vero se e solo se almeno una delle condizioni \u00e8 vera.</li> </ul> <p>In ultimo, l'operazione \\(NOT\\) agisce su un'unica variabile, negandola. Di conseguenza, la tabella di verit\u00e0 \u00e8 riassumibile come segue:</p> \\(A\\) \\(NOT\\) \\(0\\) \\(1\\) \\(1\\) \\(0\\) <p>Di conseguenza, la \\(NOT\\) di una condizione \u00e8 vera se la condizione \u00e8 falsa, e viceversa.</p> <p>Facciamo un esempio pratico. Immaginiamo di voler verificare che un numero intero \\(x\\) sia compreso tra \\(0\\) e \\(10\\). Ragionando mediante l'algebra booleana, potremo scrivere:</p> \\[ \\begin{aligned}     &amp;cond_{min} = x &lt; 10 \\\\     &amp;cond_{max} = x &gt; 0 \\\\     &amp;res = cond_{min} \\text{ AND } cond_{max} \\end{aligned} \\] <p>In altri termini, il risultato finale (\\(res\\)) sar\u00e0 vero se e solo se sia \\(cond_{min}\\) e \\(cond_{max}\\) sono vere.</p>"},{"location":"material/01_python/01_intro/02_operators/#operazioni-logiche-in-python","title":"Operazioni logiche in Python","text":"<p>Per realizzare le operazioni logiche, Python ci mette a disposizione tre parole chiave, ovvero <code>and</code>, <code>or</code> e <code>not</code>. L'associazione tra parola chiave ed operazione logica \u00e8 lasciata al lettore come esercizio.</p>"},{"location":"material/01_python/01_intro/03_strings/","title":"1.3 - Stringhe","text":"<p>In Python le stringhe possono indifferentemente essere racchiuse tra virgolette singole e doppie.</p> <pre><code>&gt;&gt;&gt; \"una stringa\"\n'una stringa'\n&gt;&gt;&gt; 'un\\'altra stringa'\n\"un'altra stringa\"\n</code></pre> <p>Notiamo nella seconda istruzione l'uso del carattere di escape (<code>\\</code>) che precede l'apostrofo; se lo omettessimo, l'interprete ci restituirebbe un errore sintattico (<code>SyntaxError</code>):</p> <pre><code>&gt;&gt;&gt; 'un'altra stringa'\nFile \"&lt;stdin&gt;\", line 1\n'un'altra stringa\n^\nSyntaxError: invalid syntax\n</code></pre> <p>Nota</p> <p>Tutti i caratteri preceduti dal simbolo <code>\\</code> saranno interpretati come escape character, a meno di aggiungere il simbolo <code>r</code> prima dell'inizio della stringa:</p> <pre><code>&gt;&gt;&gt; print('C:\\nuova_cartella')\nC:\nuova_cartella\n&gt;&gt;&gt; print(r'C:\\nuova_cartella')\nC:\\nuova_cartella\n</code></pre>"},{"location":"material/01_python/01_intro/03_strings/#stringhe-su-righe-multiple","title":"Stringhe su righe multiple","text":"<p>Stringhe e liste</p> <p>La maggior parte dei concetti che vedremo nel seguito sono applicabili anche alle liste. Anzi, per essere precisi, derivano proprio dalle liste, in quanto Python considera una stringa un particolare tipo di lista.</p> <p>Le stringhe possono articolarsi su pi\u00f9 righe. Per farlo, possiamo usare le triple-quotes, ovvero tre virgolette di seguito, per indicare l'inizio e la fine della stringa:</p> <pre><code>&gt;&gt;&gt; print(\"\"\"Questo \u00e8 un esempio\\\n         di\n        riga multipla\\\n        \"\"\")\nQuesto \u00e8 un esempio di\nriga multipla\n</code></pre> <p>Nota</p> <p>Notiamo nel precedente snippet il carattere <code>\\</code>, usato per evitare che venga automaticamente inserito dall'interprete il carattere newline (<code>\\n</code>) al termine di ogni riga. Infatti, si vede come il newline non sia stato aggiunto nelle righe evidenziate, mentre sia presente nella riga 2.</p>"},{"location":"material/01_python/01_intro/03_strings/#concatenazione-di-stringhe","title":"Concatenazione di stringhe","text":"<p>Concatenare due stringhe in Python \u00e8 estremamente semplice, e basta usare l'operatore <code>+</code>:</p> <pre><code>&gt;&gt;&gt; stringa_a = \"Prima stringa\"\n&gt;&gt;&gt; stringa_b = \"Seconda stringa\"\n&gt;&gt;&gt; print(stringa_a + \" - \" + stringa_b)\nPrima stringa - Seconda stringa\n</code></pre> <p>Nota</p> <p>Se usiamo l'operatore <code>*</code> possiamo concatenare pi\u00f9 volte la stessa stringa:</p> <pre><code>&gt;&gt;&gt; 3 * 'co.'\n'co.co.co.'\n</code></pre> <p>Possiamo anche semplicemente porre le due stringhe l'una di seguito all'altra:</p> <pre><code>&gt;&gt;&gt; \"Py\" \"thon\"\n'Python'\n</code></pre> <p>Attenzione</p> <p>Bisogna fare particolare attenzione a non concatenare un literal (ovvero una stringa racchiusa tra virgolette) ad una variabile di tipo stringa. Se proviamo a farlo, l'interprete ci restituir\u00e0 questo errore:</p> <pre><code>&gt;&gt;&gt; py=\"Py\"\n&gt;&gt;&gt; py \"thon\"\nFile \"&lt;stdin&gt;\", line 1\npy \"thon\"\n^\nSyntaxError: invalid syntax\n</code></pre> <p>Lo stesso errore si presenterebbe se al posto della variabile <code>py</code> usassimo il risultato di una operazione di concatenazione:</p> <p><pre><code>&gt;&gt;&gt; ('p' + 'y') 'thon'\nFile \"&lt;stdin&gt;\", line 1\n('p' + 'y') 'thon'\n^\nSyntaxError: invalid syntax\n</code></pre> Il consiglio, in questi casi \"ibridi\", \u00e8 quello di usare l'operatore standard di concatenazione, ovvero il <code>+</code>.</p> <p>Nota</p> <p>Esistono modi pi\u00f9 efficienti di concatenare delle stringhe, specialmente quando si ha a che fare con numerose operazioni di concatenazione in grossi cicli; l'approfondimento di tali metodi \u00e8 demandato al lettore.</p>"},{"location":"material/01_python/01_intro/03_strings/#indicizzazione-di-stringhe","title":"Indicizzazione di stringhe","text":"<p>Python definisce le stringhe come degli array di caratteri; \u00e8 quindi possibile indicizzarli. Ad esempio:</p> <pre><code>&gt;&gt;&gt; stringa = 'Python'\n&gt;&gt;&gt; stringa[0]\n'P'\n</code></pre> <p>Anche i singoli caratteri sono considerati come delle stringhe, ovviamente di lunghezza unitaria:</p> <pre><code>&gt;&gt;&gt; lettera = 'P'\n&gt;&gt;&gt; lettera[0]\n'P'\n</code></pre> <p>Python permette di accedere anche usando degli indici negativi, considerando quindi gli elementi che vanno da destra verso sinistra. In questo caso, l'indice del primo elemento da destra sar\u00e0 indicato con <code>-1</code>:</p> <pre><code>&gt;&gt;&gt; stringa[-1]\n'n'\n</code></pre>"},{"location":"material/01_python/01_intro/03_strings/#slicing-su-stringhe","title":"Slicing su stringhe","text":"<p>L'operazione di slicing permette di estrarre una certa parte di una stringa. In generale, assume la seguente forma:</p> <pre><code>&gt;&gt;&gt; stringa[i:j:s]\n</code></pre> <p>dove <code>i</code> \u00e8 l'indice iniziale, <code>j</code> quello finale ed <code>s</code> lo step utilizzato. E' importante sottolineare come l'elemento all'indice iniziale sar\u00e0 incluso, mentre quello all'indice finale sar\u00e0 escluso.</p> <p>Ad esempio:</p> <pre><code>&gt;&gt;&gt; stringa[0:2]\n'Py'\n&gt;&gt;&gt; stringa[2:5]\n'tho'\n</code></pre> <p>Se volessimo considerare tutti i caratteri fino a <code>j</code> (escluso), dovremmo usare la seguente notazione:</p> <pre><code>&gt;&gt;&gt; stringa [:j]\n</code></pre> <p>Se invece volessimo considerare tutti i caratteri a partire da <code>i</code> (incluso), dovremmo usare la seguente notazione:</p> <pre><code>&gt;&gt;&gt; stringa [i:]\n</code></pre> <p>Ad esempio:</p> <pre><code>&gt;&gt;&gt; stringa[1:]\n'ython'\n&gt;&gt;&gt; stringa[:5]\n'Pytho'\n</code></pre> <p>Anche in questo caso, \u00e8 possibile usare degli indici negativi. Ad esempio, se volessimo prendere tutti i caratteri dalla terzultima lettera fino alla fine, potremmo scrivere:</p> <pre><code>&gt;&gt;&gt; stringa[-3:]\n'hon'\n</code></pre> <p>mentre se volessimo prendere tutti i caratteri fino alla terzultima lettera (esclusa):</p> <pre><code>&gt;&gt;&gt; stringa[:-3]\n'Pyt'\n</code></pre> <p>Suggerimento</p> <p>E' possibile ottenere un'intera stringa mediante l'operazione di slicing in questo modo:</p> <pre><code>&gt;&gt;&gt; stringa[:]\n'Python'\n</code></pre>"},{"location":"material/01_python/01_intro/03_strings/#lunghezza-di-una-stringa","title":"Lunghezza di una stringa","text":"<p>La funzione <code>len()</code> ci restituisce la lunghezza di una stringa:</p> <pre><code>&gt;&gt;&gt; len(stringa)\n6\n</code></pre>"},{"location":"material/01_python/01_intro/03_strings/#immutabilita-di-una-stringa","title":"Immutabilit\u00e0 di una stringa","text":"<p>Le stringhe in Python sono immutabili. Come indica la parola stessa, questo significa che non possono essere modificate: se, ad esempio, provassimo a ridefinirne uno o pi\u00f9 elementi, acceduti magari mediante indexing o slicing, avremmo un errore.</p> <pre><code>&gt;&gt;&gt; stringa[0] = 'C'# Errore!\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'str' object does not support item assignment\n</code></pre> <p>Suggerimento</p> <p>Possiamo comunque assegnare il nome <code>stringa</code> ad una nuova variabile.</p>"},{"location":"material/01_python/01_intro/04_lists/","title":"1.4 - Liste","text":"<p>Abbiamo gi\u00e0 detto che una stringa altro non \u00e8 se non un caso particolare di lista. La domanda che sorge spontanea \u00e8 quindi: cosa \u00e8 una lista?</p> <p>Le liste sono uno dei quattro tipi di strutture built-in che Python offre per memorizzare sequenze di dati. Da un punto di vista puramente \"concettuale\", potremmo considerarle alla stregua degli array presenti in altri linguaggi di programmazione, seppur con alcune, significative differenze.</p> <p>Possiamo creare una lista in questo modo:</p> <pre><code>&gt;&gt;&gt; lista = [1, 2, 3, 4, 5]\n[1, 2, 3, 4, 5]\n</code></pre>"},{"location":"material/01_python/01_intro/04_lists/#concatenazione-indicizzazione-e-slicing-su-liste","title":"Concatenazione, indicizzazione e slicing su liste","text":"<p>Come sulle stringhe, sulle liste \u00e8 possibile effettuare operazioni di indicizzazione, slicing e concatenazione:</p> <pre><code>&gt;&gt;&gt; lista[0]\n1\n&gt;&gt;&gt; lista[2:]\n[3, 4, 5]\n&gt;&gt;&gt; lista_due = [6,7]\n&gt;&gt;&gt; lista + lista_due\n[1, 2, 3, 4, 5, 6, 7]\n&gt;&gt;&gt; lista + [6]\n[1, 2, 3, 4, 5, 6]\n</code></pre> <p>Facciamo alcuni esempi. Consideriamo la seguente stringa:</p> <pre><code>&gt;&gt;&gt; l = [1, 2, 3, 4, 5, 6]\n</code></pre> <p>Prendiamo gli elementi sugli indice pari (ovvero 0, 2 e 4):</p> <pre><code>&gt;&gt;&gt; l[0::2]\n[1, 3, 5]\n</code></pre> <p>Prendiamo tutti gli elementi a partire dal terzultimo e con indice pari:</p> <pre><code>&gt;&gt;&gt; l[(-3 + 1)::2]\n[5]\n</code></pre> <p>Nota</p> <p>Nell'esempio precedente, usato un piccolo \"trucco\" per tenere in conto il fatto che l'indicizzazione parte da 0 e non da 1.</p> <p>Partiamo dal terzultimo elemento, e proseguiamo all'indietro verso l'origine:</p> <pre><code>&gt;&gt;&gt; l[-3::-1]\n[4, 3, 2, 1]\n</code></pre> <p>Partiamo dall'ultimo elemento e proseguiamo sino al terz'ultimo dall'origine:</p> <pre><code>&gt;&gt;&gt; l[:3:-1]\n[6, 5]\n</code></pre> <p>Prendiamo gli ultimi tre elementi in ordine inverso:</p> <pre><code>&gt;&gt;&gt; l[len(l)-1:len(l)-4:-1]\n[6, 5, 4]\n</code></pre> <p>Prendiamo gli elementi agli indici pari in ordine inverso:</p> <pre><code>&gt;&gt;&gt; l[::-2]\n[6, 4, 2]\n</code></pre>"},{"location":"material/01_python/01_intro/04_lists/#mutabilita-di-una-lista","title":"Mutabilit\u00e0 di una lista","text":"<p>A differenza delle stringhe, le liste sono oggetti mutabili. Di conseguenza, possiamo modificarne il contenuto:</p> <pre><code>&gt;&gt;&gt; lista[0] = 99\n&gt;&gt;&gt; lista\n[99, 2, 3, 4, 5]\n</code></pre>"},{"location":"material/01_python/01_intro/04_lists/#operazioni-sulle-liste","title":"Operazioni sulle liste","text":"<p>Possiamo anche eliminare elementi da una lista usando l'operatore <code>[]</code> combinato all'operazione di slicing:</p> <pre><code>&gt;&gt;&gt; lista[4:] = []\n&gt;&gt;&gt; lista\n[99, 2, 3, 4]\n</code></pre> <p>Nota</p> <p>I pi\u00f9 attenti avranno notato che l'operatore <code>[]</code> non fa altro che indicare una lista vuota.</p> <p>Suggerimento</p> <p>Possiamo eliminare tutti gli elementi contenuti in una lista mediante lo slicing e l'operatore <code>[]</code>:</p> <pre><code>&gt;&gt;&gt; lista[:] = []\n&gt;&gt;&gt; lista\n[]\n</code></pre> <p>Una lista pu\u00f2 contenere elementi tra loro eterogenei. E' addirittura consentito contenere degli iterabili, tra cui altre liste:</p> <pre><code>&gt;&gt;&gt; lista.append([1,2,3])\n&gt;&gt;&gt; lista\n[99, 2, 3, 4, [1, 2, 3]]\n</code></pre> <p>Nell'esempio precedente, abbiamo usato la funzione <code>append()</code> per inserire un elemento in coda alla lista. E' interessante notare l'elemento inserito in coda sia esso stesso una lista, e \"conviva\" tranquillamente con gli altri elementi di tipo numerico.</p> <p>Proviamo ad estendere ulteriormente la lista cambiando il primo elemento con una stringa:</p> <pre><code>&gt;&gt;&gt; lista [0] = stringa\n&gt;&gt;&gt; lista\n['Python', 2, 3, 4, [1, 2, 3]]\n</code></pre>"},{"location":"material/01_python/01_intro/exercises/","title":"Modulo 1 - Il linguaggio Python: Esercizi","text":""},{"location":"material/01_python/01_intro/exercises/#esercizio-11","title":"Esercizio 1.1","text":"<p>Traccia: Creiamo una stringa che assuma valore PCS usando l'interprete integrato.</p> <p>Soluzione</p> <p>Apriamo l'interprete Python digitando <code>python</code> da riga di comando. A quel punto, inseriamo la seguente istruzione, e premiamo <code>Invio</code>:</p> <pre><code>&gt;&gt;&gt; s = 'PCS'\nPCS\n</code></pre>"},{"location":"material/01_python/01_intro/exercises/#esercizio-12","title":"Esercizio 1.2","text":"<p>Traccia: Valutiamo la lunghezza della stringa creata nell'esercizio precedente, e verifichiamo che sia uguale a 3.</p> <p>Soluzione</p> <p>Innanzitutto, possiamo usare la funzione <code>len()</code> che, come abbiamo visto nella lezione, accetta una sequenza (ovvero un oggetto su cui si possa iterare), e restituisce un intero rappresentativo della lunghezza dell'iterabile.</p> <p>Dato che la stringa \u00e8 una sequenza, possiamo invocare la funzione <code>len()</code> passandogli come argomento <code>s</code>:</p> <pre><code>&gt;&gt;&gt; len(s)\n3\n</code></pre> <p>Chiamando la funzione <code>len(s)</code> notiamo come il valore restituito sia quello atteso, ovvero <code>3</code>.</p> <p>Possiamo anche provare ad assegnare il valore restituito ad una variabile <code>l</code>:</p> <pre><code>&gt;&gt;&gt; l = len(s)\n</code></pre> <p>A questo punto, possiamo verificare che <code>l</code> sia pari a <code>3</code> utilizzando l'operatore di uguaglianza:</p> <pre><code>&gt;&gt;&gt; l == 3\nTrue\n</code></pre>"},{"location":"material/01_python/01_intro/exercises/#esercizio-13","title":"Esercizio 1.3","text":"<p>Traccia: Verifichiamo che il numero <code>x</code> sia compreso tra <code>0</code> e <code>10</code>.</p> <p>Soluzione</p> <p>Per prima cosa, dichiariamo un valore qualsiasi per <code>x</code>:</p> <pre><code>&gt;&gt;&gt; x = 1\n</code></pre> <p>A questo punto, verifichiamo che <code>x</code> sia compreso tra <code>0</code> e <code>10</code> mediante l'operatore booleano <code>and</code>:</p> <pre><code>&gt;&gt;&gt; x &lt; 10 and x &gt; 0\nTrue\n</code></pre>"},{"location":"material/01_python/01_intro/exercises/#esercizio-14","title":"Esercizio 1.4","text":"<p>Traccia: Creare una lista a partire dalla stringa definita negli esercizi precedenti.</p> <p>Soluzione</p> <p>Una prima possibilit\u00e0 \u00e8 quella di utilizzare il costruttore di classe <code>list()</code> che accetta una sequenza e restituisce una lista a partire da questa. Possiamo quindi scrivere:</p> <pre><code>&gt;&gt;&gt; l_1 = list(s)\n</code></pre> <p>Se proviamo a visualizzare <code>l_1</code>, avremo il seguente risultato:</p> <pre><code>&gt;&gt;&gt; l_1\n['p', 'c', 's']\n</code></pre> <p>Un altro modo \u00e8 quello di usare l'operatore <code>[]</code>, che per\u00f2 avr\u00e0 risultati leggermente differenti, in quanto creer\u00e0 una lista con all'interno un unico elemento, ovvero la stringa <code>s</code>. In pratica:</p> <pre><code>&gt;&gt;&gt; l_2 = [s]\n&gt;&gt;&gt; l_2\n['pcs']\n</code></pre>"},{"location":"material/01_python/02_syntax/01_syntax/","title":"2.1 - Sintassi fondamentale","text":"<p>Vediamo alcuni dei concetti fondamentali che caratterizzano la sintassi del linguaggio Python.</p>"},{"location":"material/01_python/02_syntax/01_syntax/#commenti","title":"Commenti","text":"<p>Python prevede due tipi di commento. Il primo, e pi\u00f9 semplice, \u00e8 quello a singola riga, anteceduto da un carattere <code>#</code> (asterisco):</p> <pre><code>&gt;&gt;&gt; # Questo \u00e8 un commento!\n</code></pre> <p>L'altro tipo di commento \u00e8 un commento multilinea, ed \u00e8 definito esattamente allo stesso modo in cui si definisce una stringa multilinea:</p> <pre><code>\"\"\" Questo \u00e8 un esempio\ndi commento multilinea!\n\"\"\"\n</code></pre> <p>Singole e doppie apici</p> <p>Cos\u00ec come per le stringhe, \u00e8 possibile usare indifferentemente (ma coerentemente!) singole o doppie apici.</p>"},{"location":"material/01_python/02_syntax/01_syntax/#uso-delle-parentesi","title":"Uso delle parentesi","text":"<p>L'utilizzo delle parentesi in Python differisce da quello che ne si fa in molti linguaggi C-like. In particolare, vediamo come sono utilizzate (ed a cosa servono) le parentesi tonde, quadre e graffe.</p>"},{"location":"material/01_python/02_syntax/01_syntax/#parentesi-tonde","title":"Parentesi tonde","text":"<p>Le parentesi tonde sono usate in tre casi:</p> <ul> <li>per le chiamate a funzione;</li> <li>per la creazione di una tupla;</li> <li>per esprimere la precedenza in un'operazione matematica.</li> </ul> <p>Negli altri casi, sono opzionali, e possono essere tranquillamente omesse.</p> <p>Vediamo un breve esempio di come esprimere la precedenza in un'operazione matematica:</p> <pre><code>&gt;&gt;&gt; a = 2\n&gt;&gt;&gt; b = 3\n&gt;&gt;&gt; c = 4\n&gt;&gt;&gt; r_1 = a + b * c\n14\n&gt;&gt;&gt; r_2 = (a + b) * c\n20\n</code></pre> <p>Nelle prossime lezioni vedremo come utilizzare le parentesi tonde nelle tuple e nelle chiamate a funzione.</p>"},{"location":"material/01_python/02_syntax/01_syntax/#parentesi-quadre","title":"Parentesi quadre","text":"<p>Le parentesi quadre sono usate per la creazione e l'accesso agli elementi di una struttura dati.</p> <pre><code># Creo una lista\nlista = [1, 2, 3]\n# Accedo al secondo elemento della lista\nlista[1]            # Il valore acceduto \u00e8 2\n</code></pre> <p>Ne parleremo pi\u00f9 diffusamente nella prossima lezione.</p>"},{"location":"material/01_python/02_syntax/01_syntax/#parentesi-graffe","title":"Parentesi graffe","text":"<p>Le parentesi graffe sono usate per creare set e dizionari.</p> <pre><code>dizionario = {'a': 1, 'b': 2}\ninsieme = {1, 2, 3}\n</code></pre> <p>Anche in questo caso, ne parleremo pi\u00f9 diffusamente nella prossima lezione.</p>"},{"location":"material/01_python/02_syntax/01_syntax/#termine-di-unistruzione","title":"Termine di un'istruzione","text":"<p>A differenza dei linguaggi C-like, che prevedono che la singola istruzione termini con un <code>;</code> (un punto e virgola), Python fa in modo che il carattere di terminazione di un'istruzione sia dato dal newline <code>\\n</code>. In altri termini, l'interprete associer\u00e0 il termine dell'istruzione all'andata a capo.</p>"},{"location":"material/01_python/02_syntax/01_syntax/#blocchi-di-codice","title":"Blocchi di codice","text":"<p>Per delimitare un blocco di codice Python ricorre al carattere <code>:</code> (due punti) ed all'indentazione. In particolare, tutto il codice che segue un carattere <code>:</code> ed \u00e8 ad uno stesso livello di indentazione risulta far parte di uno stesso blocco. Ad esempio:</p> <pre><code>&gt;&gt;&gt; a = 1               # Codice non in un blocco\n&gt;&gt;&gt; if a &lt; 10:          # Inizia il blocco if esterno\n&gt;&gt;&gt;     b = 5\n&gt;&gt;&gt;     print('blocco esterno')\n&gt;&gt;&gt;     if b &gt; 1:       # Inizia il blocco if annidato\n&gt;&gt;&gt;         print('blocco interno')\n</code></pre> <p>Indentazioni e parentesi graffe</p> <p>I pi\u00f9 attenti avranno notato che le indentazioni svolgono, in buona sostanza, un ruolo analogo a quello delle parentesi graffe nei linguaggi C-like.</p>"},{"location":"material/01_python/02_syntax/02_structured/","title":"2.2 - Programmazione strutturata","text":"<p>Come tutti i linguaggi derivati da C, anche Python offre il supporto ai principali costrutti della programmazione strutturata. Vediamoli brevemente.</p>"},{"location":"material/01_python/02_syntax/02_structured/#istruzione-condizionale","title":"Istruzione condizionale","text":"<p>Partiamo dall'istruzione condizionale che, come in tutti i linguaggi di programmazione, \u00e8 espressa dalle parole chiave <code>if</code> ed <code>else</code>.</p> <p>La sintassi base \u00e8 di questo tipo:</p> <pre><code>if condizione_verificata:\nistruzioni\nelse:\naltre_istruzioni\n</code></pre> <p>In pratica, se <code>condizione_verificata</code> \u00e8 vero, allora saranno eseguite le <code>istruzioni</code>. In alternativa, se <code>condizione_verificata</code> \u00e8 falso, allora saranno eseguite le <code>altre_istruzioni</code>. Ad esempio:</p> <pre><code>&gt;&gt;&gt; if a &lt; 5:\n&gt;&gt;&gt;     print('a \u00e8 minore di 5')\n&gt;&gt;&gt; else:\n&gt;&gt;&gt;     print('a \u00e8 maggiore di 5')\n</code></pre> <p>Per utilizzare la notazione <code>else if</code> dovremo ricorrere alla parola chiave <code>elif</code>. Ad esempio:</p> <pre><code>&gt;&gt;&gt; if a &lt; 5:\n&gt;&gt;&gt;     print('a \u00e8 minore di 5')\n&gt;&gt;&gt; elif a == 5:\n&gt;&gt;&gt;     print('a \u00e8 uguale a 5')\n&gt;&gt;&gt; else:\n&gt;&gt;&gt;     print('a \u00e8 maggiore di 5')\n</code></pre> <p>Switch/case in Python</p> <p>Fino alla versione 3.10, Python non offriva un'implementazione per il costrutto <code>switch/case</code>. A partire da quest'ultima, per\u00f2, \u00e8 stato implementato il cosiddetto pattern matching mediante la sintassi <code>match/case</code>:</p> <p><pre><code>match command:\ncase \"caso 1\":\nistruzioni()\ncase \"altro caso\":\nprint(\"Comando sconosciuto\")\n</code></pre> Approfondiremo questo costrutto nell'apposita lezione.</p>"},{"location":"material/01_python/02_syntax/02_structured/#cicli","title":"Cicli","text":""},{"location":"material/01_python/02_syntax/02_structured/#ciclo-for","title":"Ciclo <code>for</code>","text":"<p>Il ciclo <code>for</code> itera su una sequenza, come una lista o una stringa, ed ha una sintassi del tipo:</p> <pre><code>for elemento in sequenza:\nistruzioni()\n</code></pre> <p>Per fare un esempio, nel seguente blocco di codice vediamo come mostrare a schermo in maniera iterativa i numeri che vanno da 0 a 5 (escluso):</p> <pre><code>vals = [0,1,2,3,4]\nfor i in vals:\nprint(i)\n</code></pre> <p>Il risultato che sar\u00e0 stampato a schermo \u00e8:</p> <pre><code>0\n1\n2\n3\n4\n</code></pre> <p>Rispetto ai linguaggi \"classici\", quindi, il ciclo <code>for</code> opera esclusivamente sugli iterabili, per cui potrebbe in qualche caso occorrere una riprogettazione del codice. Tuttavia, questa caratteristica di Python comporta anche una maggiore semplicit\u00e0 del codice; ad esempio, vediamo come \u00e8 molto semplice iterare su una stringa:</p> <pre><code>string = \"Python\"\nfor char in string:\nprint(char)\n</code></pre> <p>A schermo vedremo in entrambi i casi il seguente risultato:</p> <pre><code>P\ny\nt\nh\no\nn\n</code></pre> <p>No free lunches!</p> <p>Come ci ricorda il no free lunches theorem, non esistono pasti gratuiti! Infatti, la maggiore semplicit\u00e0 sintattica offerta da Python non \u00e8 indolore, ma ha un costo. Uno script Python, infatti, per quanto ottimizzato, non potr\u00e0 quasi mai offrire performance paragonabili ad un codice ottimizzato in C o C++, a meno di non usare particolari (ed avanzati) accorgimenti.</p>"},{"location":"material/01_python/02_syntax/02_structured/#ciclo-while","title":"Ciclo <code>while</code>","text":"<p>A differenza del ciclo <code>for</code>, il funzionamento del <code>while</code> \u00e8 analogo a quello delle controparti negli altri linguaggi di programmazione. La sintassi generica \u00e8:</p> <pre><code>while(condizione):\nistruzioni()\n</code></pre> <p>Ad esempio:</p> <pre><code>import random\ni = True\nwhile (i):\nif random.randint(-5, 5) &gt; 0:\nprint(\"Continuo!\")\nelse:\nprint(\"Esco!\")\ni = False\n</code></pre> <p>Il codice nel blocco precedente non fa altro che generare un valore numerico intero casuale nell'intervallo \\([-5, 5]\\) mediante la funzione <code>randint</code>. Se tale valore \u00e8 superiore a \\(0\\), il ciclo continua, altrimenti si esce dallo stesso.</p> <p>A schermo vedremo, ad esempio:</p> <pre><code>Continuo!\nContinuo!\nEsco!\n</code></pre> <p>I valori booleani in Python</p> <p>I pi\u00f9 attenti avranno notato come i valori booleani in Python siano stati scritti come <code>True</code> e <code>False</code>. Questo non \u00e8 un refuso: la prima lettera \u00e8 proprio una maiuscola.</p>"},{"location":"material/01_python/02_syntax/02_structured/#la-funzione-range","title":"La funzione <code>range()</code>","text":"<p>Riprendiamo adesso il ciclo <code>for</code> visto in precedenza.</p> <pre><code>vals = [0, 1, 2, 3, 4]\nfor i in vals:\nprint(i)\n</code></pre> <p>Nonostante il codice sia gi\u00e0 compatto, scrivere manualmente la sequenza da iterare pu\u00f2 facilmente diventare un'operazione abbastanza complessa. Python ci viene quindi in aiuto tramite la funzione <code>range(i, j, s)</code>, che genera una sequenza avente tutti i numeri compresi tra <code>i</code> (incluso) e <code>j</code> (escluso) a passo <code>s</code>. Ad esempio, per generare i numeri compresi tra 0 e 4 scriveremo:</p> <pre><code>&gt;&gt;&gt; r = range(0, 5, 1)\n&gt;&gt;&gt; print(list(r))\n[0, 1, 2, 3, 4]\n</code></pre> <p>Nota</p> <p>Notiamo che per mandare in output i valori di <code>r</code> dovremo convertirlo in lista (<code>list(r)</code>).</p> <p>Qualora omessi, <code>i</code> ed <code>s</code> assumono valori di default rispettivamente 0 ed 1:</p> <pre><code>&gt;&gt;&gt; r = range(5)\n&gt;&gt;&gt; print(list(r))\n[0, 1, 2, 3, 4]\n</code></pre> <p>E' anche possibile specificare una sequenza decrementale ponendo <code>i &gt; j</code> ed <code>s &lt; 0</code>:</p> <pre><code>&gt;&gt;&gt; r = range(5, 1, -1)\n&gt;&gt;&gt; print(list(r))\n[5, 4, 3, 2]\n</code></pre>"},{"location":"material/01_python/02_syntax/02_structured/#istruzioni-break-e-continue","title":"Istruzioni <code>break</code> e <code>continue</code>","text":"<p>Le istruzioni <code>break</code> e <code>continue</code> permettono rispettivamente di uscire dal ciclo o di saltare all'iterazione successiva. Ad esempio:</p> <pre><code>while (True):\nif randint(-5, 5) &gt; 0:\nprint(\"Continuo!\")\ncontinue\nelse:\nprint(\"Esco!\")\nbreak\nprint(\"Sono uscito!\")\n</code></pre> <p>Le istruzioni precedenti usciranno dal ciclo quando viene generato casualmente un numero negativo, mentre continueranno ad iterare quando viene generato casualmente un numero positivo.</p>"},{"location":"material/01_python/02_syntax/03_functions/","title":"2.3 - Funzioni","text":""},{"location":"material/01_python/02_syntax/03_functions/#definizione-di-funzione","title":"Definizione di funzione","text":"<p>Python permette di definire una funzione utilizzando la parola chiave <code>def</code>. La sintassi generica \u00e8 la seguente:</p> <pre><code>def nome_funzione(parametri):\n# istruzioni\nreturn valore_ritorno\n</code></pre> <p>E' importante notare che:</p> <ul> <li>non \u00e8 necessario definire un tipo, ma soltanto un valore di ritorno. Qualora la funzione non restituisca alcun valore, potr\u00e0 essere omessa l'istruzione <code>return</code>;</li> <li>non \u00e8 (strettamente) necessario definire il tipo di ciascuno dei parametri passati;</li> <li>\u00e8 consentito inserire dei parametri opzionali, con valori di default.</li> </ul> <p>Ad esempio, la seguente funzione somma <code>1</code> al valore in ingresso e restituisce il nuovo valore:</p> <pre><code>def aggiungi_uno(i):\nval = i + 1\nreturn val\n</code></pre> <p>Tipo dei parametri di ingresso</p> <p>Il duck typing fa s\u00ec che non venga effettuato alcun controllo sui parametri in ingresso. Ci\u00f2 per\u00f2 non significa che non si possa provare a chiamare (ad esempio) la funzione <code>aggiungi_uno()</code> passando come parametro una stringa; ci\u00f2 tuttavia causer\u00e0 un (prevedibile) errore.</p>"},{"location":"material/01_python/02_syntax/03_functions/#passaggio-di-parametri-a-funzione","title":"Passaggio di parametri a funzione","text":"<p>Python prevede che i parametri siano passati ad una funzione secondo una modalit\u00e0 ibrida chiamata call-by-assignment. In pratica, il passaggio avviene esclusivamente per valore, ma con effetti differenti su tipi mutabili ed immutabili.</p> <p>Ad esempio, provando a passare un valore primitivo (come un intero), Python si comporter\u00e0 come se si stesse effettuando un passaggio per valore:</p> <pre><code>def raddoppia(intero):\nintero = intero * 2\nprint(f'Valore all\\'interno della funzione: {intero}')\n</code></pre> <p>Il risultato sar\u00e0:</p> <pre><code>&gt;&gt;&gt; intero = 1\n&gt;&gt;&gt; raddoppia(intero)\n\"Valore all'interno della funzione: 2\"\n&gt;&gt;&gt; print(f'Valore all\\'esterno della funzione: {intero}')\n\"Valore all'interno della funzione: 1\"\n</code></pre> <p>Ci\u00f2 \u00e8 legato al fatto che il passaggio viene effettuato per valore, per cui la funzione <code>raddoppia()</code> agir\u00e0 su una copia della variabile passata come argomento, e non sulla variabile originaria. Se invece usassimo una funzione che modifica una lista:</p> <pre><code>def aggiungi_a_lista(lista, elemento):\nlista.append(elemento)\nprint(f'Valore all\\'interno della funzione: {lista}')\n</code></pre> <p>Il risultato sar\u00e0:</p> <pre><code>&gt;&gt;&gt; lista = [1, 2]\n&gt;&gt;&gt; aggiungi_a_lista(lista, 3)\n\"Valore all'interno della funzione: [1, 2, 3]\"\n&gt;&gt;&gt; print(f'Valore all\\'esterno della funzione: {lista}')\n\"Valore all'interno della funzione: [1, 2, 3]\"\n</code></pre> <p>In questo caso, essendo la lista mutabile, il passaggio viene effettuato nei fatti per reference: ci\u00f2 significa che le operazioni compiute all'interno della funzione <code>aggiungi_a_lista()</code> agiranno sulla lista originaria.</p> <p>Shallow e deep copy</p> <p>Di default, Python copia le variabili per mezzo di una shallow copy: ci\u00f2 significa che un'operazione di assignment del tipo <code>a = b</code> fa in modo che <code>a</code> punti allo stesso indirizzo di memoria di <code>b</code> e, di conseguenza, ogni modifica a <code>b</code> si rifletta su <code>a</code>. Per evitare un fenomeno di questo tipo occorre usare una deep copy grazie alla funzione <code>deepcopy()</code> della libreria <code>copy</code>.</p>"},{"location":"material/01_python/02_syntax/03_functions/#listruzione-pass","title":"L'istruzione <code>pass</code>","text":"<p>Chiudiamo accennando all'istruzione <code>pass</code>. Questa non fa assolutamente nulla; \u00e8 utile, ad esempio, quando vogliamo inserire una funzione (o una classe) vuota, che definiremo per qualche motivo in seguito:</p> <pre><code>&gt;&gt;&gt; def funzione_vuota():\n...     pass\n...\n&gt;&gt;&gt; funzione_vuota()\n</code></pre> <p>Nota</p> <p>Anche se di primo acchitto potrebbe non essere evidente, esistono diverse situazioni in cui l'istruzione <code>pass</code> risulta essere estremamente utile.</p>"},{"location":"material/01_python/02_syntax/04_data_structures/","title":"2.4 - Strutture dati","text":"<p>In questa lezione approfondiremo alcune tecniche per manipolare le liste, oltre ad altre strutture dati fondamentali.</p>"},{"location":"material/01_python/02_syntax/04_data_structures/#list-comprehension","title":"List comprehension","text":"<p>Una delle tecniche pi\u00f9 usate per creare una lista a partire da un'altra sequenza \u00e8 la cosiddetta list comprehension, che sostituisce la sintassi definita dai classici cicli con costrutti decisamente pi\u00f9 pythonic.</p> <p>Nella forma base, una list comprehension ha una sintassi di questo tipo:</p> <pre><code>lista_output = [f(elemento) for elemento in lista_input]\n</code></pre> <p>In altre parole, otterremo in output una lista (<code>lista_output</code>) applicando ad ogni <code>elemento</code> della lista originaria (<code>lista_input</code>) la funzione <code>f()</code>.</p> <p>Ad esempio, prendendo una lista di interi, possiamo creare una lista che abbia all'\\(i\\)-mo elemento il doppio del valore \\(i\\)-mo della lista di ingresso.</p> <pre><code>&gt;&gt;&gt; lista_input = [1, 2, 3]\n&gt;&gt;&gt; lista_output = [x * 2 for x in lista_input]\n[2, 4, 6]\n</code></pre>"},{"location":"material/01_python/02_syntax/04_data_structures/#forma-estesa-con-if-else","title":"Forma estesa con if-else","text":"<p>La list comprehension pu\u00f2 anche includere delle istruzioni condizionali. Un primo esempio \u00e8 la seguente forma:</p> <pre><code>lista_output_if = [f(elemento) for elemento in lista_input if condizione]\n</code></pre> <p>In questo caso, la funzione <code>f()</code> sar\u00e0 chiamata esclusivamente sugli elementi che soddisfano la <code>condizione</code> indicata. Ad esempio, possiamo utilizzare una list comprehension per restituire tutti i valori pari in una lista:</p> <pre><code>&gt;&gt;&gt; lista_output_pari = [x for x in lista_input if x % 2 == 0]\n[2]\n</code></pre> <p>Se invece volessimo integrare l'<code>else</code>:</p> <pre><code>lista_output_if_else = [f(elemento) if condizione else g(elemento) for elemento in lista_input]\n</code></pre> <p>la funzione <code>f()</code> sarebbe invocata su tutti gli elementi che soddisfano la <code>condizione</code>, mentre la funzione <code>g()</code> su tutti quelli che non la soddisfano. Potremmo ad esempio restituire tutti gli elementi pari, raddoppiando contestualmente i dispari:</p> <pre><code>&gt;&gt;&gt; lista_output_complessa = [x if x % 2 == 0 else x * 2 for elemento in lista_input]\n[2, 2, 6]\n</code></pre>"},{"location":"material/01_python/02_syntax/04_data_structures/#tuple","title":"Tuple","text":"<p>Le tuple permettono di rappresentano un insieme di valori eterogenei separadoli da una virgola. Ad esempio:</p> <pre><code>tupla = ('hello', 'world', 12)\n</code></pre> <p>Un po' come avviene per le liste, uno dei valori della tupla pu\u00f2 a sua volta essere un'altra tupla. Ad esempio:</p> <pre><code>tupla = ('hello', 'world', (1, 2))\n</code></pre> <p>A differenza di una lista, per\u00f2, le tuple sono immutabili. Ci\u00f2 non implica per\u00f2 che non possano contenere al loro interno oggetti mutabili. Guardiamo il seguente esempio:</p> <pre><code>tupla = ('hello', 'world', [1, 2, 3])\n</code></pre> <p>La tupla avr\u00e0 al suo interno due stringhe (immutabili) ed una lista (mutabile). Proviamo a modificare la lista:</p> <pre><code>tupla[2] = [2, 2, 3]\n</code></pre> <p>Apparir\u00e0 un errore simile a questo:</p> <pre><code>Traceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'tuple' object does not support item assignment\n</code></pre> <p>Come prevedibile, abbiamo avuto un errore di assegnazione legato all'immutabilit\u00e0 della tupla. Proviamo adesso per\u00f2 a modificare direttamente la lista:</p> <pre><code>tupla[2][0] = 2         # La tupla sar\u00e0 ('hello', 'world', [2, 2, 3])\n</code></pre> <p>L'operazione \u00e8 evidentemente ammissibile, ed il risultato \u00e8 stato proprio quello atteso.</p> <p>Tuple e liste</p> <p>Ad un attento osservatore non sfuggir\u00e0 come tuple e liste siano simili dal punto di vista sintattico, e differiscano in buona sostanza per la mutabilit\u00e0. Da qui discende che le tuple sono estremamente efficaci nel caso si debba esclusivamente accedere agli elementi contenuti, mentre le liste devono essere usate quando \u00e8 anche necessario modificare all'occorrenza detti elementi.</p>"},{"location":"material/01_python/02_syntax/04_data_structures/#set","title":"Set","text":"<p>Anche i set sono molto simili alle liste dal punto di vista sintattico, ma offrono una significativa differenza: infatti, in un set non possono esserci elementi ripetuti.</p> <p>Nota</p> <p>Notiamo un'evidente analogia con il concetto matematico di insieme.</p> <p>La sintassi da usare per creare un set \u00e8 la seguente.</p> <pre><code>insieme = {1, \"stringa\", 2}\n</code></pre> <p>Il set ammette al suo interno dati eterogenei, tuttavia non pu\u00f2 contenere al suo interno delle liste o dei dizionari. Questo \u00e8 legato al fatto che i set (cos\u00ec come gli stessi dizionari) sono delle hash table, e quindi sfruttano il concetto di hash per rappresentare i dati contenuti in maniera compatta ed efficiente. Il fatto che le liste ed i dizionari non possano essere rappresentati in questo modo li esclude in automatico dall'includibilit\u00e0 all'interno di un set.</p> <p>Un'altra considerazione da fare \u00e8 che il set non \u00e8 ordinato: ci\u00f2 rende impossibile accedere ad (e modificare) un elemento del set mediante il suo indice, come succedeva per liste e tuple.</p> <p>Suggerimento</p> <p>I set possono essere usati per isolare gli elementi univoci presenti in una lista. Per farlo, basta convertire la lista in set:</p> <pre><code>l = [1, 2, 2, 3]      # La lista sar\u00e0 [1, 2, 2, 3]\ns = set(l)            # Il set sar\u00e0 [1, 2, 3]\n</code></pre>"},{"location":"material/01_python/02_syntax/04_data_structures/#dizionari","title":"Dizionari","text":"<p>Il quarto ed ultimo tipo di contenitore per sequenze di dati \u00e8 il dizionario, presente anche in altri linguaggi di programmazione con il nome di array associativo o hash map.</p> <p>L'elemento base di un dizionario \u00e8 la coppia chiave - valore, nella quale un certo valore (di qualsiasi tipo) \u00e8 associato ad una determinata chiave (di tipo immutabile).</p> <p>I dizionari hanno diverse caratteristiche comuni ai set, dall'inutilizzabilit\u00e0 delle liste come chiavi al fatto di non permettere chiavi ripetute. Inoltre, le coppie chiave - valore sono accedute, per l'appunto, per chiave, e non in base all'ordine delle coppie.</p> <p>Nota</p> <p>Una differenza tra set e dizionari sta nel fatto che questi ultimi sono ordinati a partire da Python 3.7.</p> <p>Per creare un dizionario, possiamo usare una sintassi simile a quella usata per i set. Ad esempio, per creare un dizionario vuoto:</p> <pre><code>&gt;&gt;&gt; dizionario = {}\n</code></pre> <p>Possiamo quindi inserire delle coppie chiave - valore in questo modo:</p> <pre><code>&gt;&gt;&gt; dizionario['k'] = 'v'\n&gt;&gt;&gt; dizionario[1] = 'n'\n{'k': 'v', 1: 'n'}\n</code></pre> <p>Per accedere al valore associato ad una determinata chiave:</p> <pre><code>&gt;&gt;&gt; dizionario[1]\n'n'\n</code></pre>"},{"location":"material/01_python/02_syntax/04_data_structures/#chiavi-e-valori","title":"Chiavi e valori","text":"<p>E' possibile recuperare la lista di tutte le chiavi presenti in un dizionario usando il metodo <code>keys()</code>, che restituisce un oggetto di tipo <code>dict_keys</code>, a sua volta convertibile in lista:</p> <pre><code>&gt;&gt;&gt; chiavi = dizionario.keys()\ndict_keys(['k', 1])\n&gt;&gt;&gt; list(chiavi)\n['k', 1]\n</code></pre> <p>In modo analogo, si pu\u00f2 accedere a tutti i valori presenti nel dizionario mediante il metodo <code>values()</code>, che restituir\u00e0 un oggetto di tipo <code>dict_values</code>, da convertire anch'esso in lista:</p> <pre><code>&gt;&gt;&gt; valori = dizionario.values()\ndict_values(['v', 'n'])\n&gt;&gt;&gt; list(valori)\n['v', 'n']\n</code></pre> <p>Possiamo accedere anche a tutte le coppie chiave - valore mediante il metodo <code>items()</code>, che ci restituisce un oggetto di tipo <code>dict_items</code>, il quale pu\u00f2 essere convertito in una lista di tuple:</p> <pre><code>&gt;&gt;&gt; coppie = dizionario.items()\ndict_items([('k', 'v'), (1, 'n')])\n&gt;&gt;&gt; list(coppie)\n[('k', 'v'), (1, 'n')]\n</code></pre>"},{"location":"material/01_python/02_syntax/04_data_structures/#creazione-di-un-dizionario-non-vuoto","title":"Creazione di un dizionario (non vuoto)","text":"<p>Abbiamo diversi modi per creare un dizionario non vuoto.</p>"},{"location":"material/01_python/02_syntax/04_data_structures/#uso-delloperatore","title":"Uso dell'operatore <code>{}</code>","text":"<p>Il pi\u00f9 semplice, che \u00e8 quello che useremo pi\u00f9 spesso, \u00e8 quello di dichiarare nell'operatore <code>{}</code> le coppie chiave - valore iniziali:</p> <pre><code>&gt;&gt;&gt; dizionario = {'k1': 1, 'k2': 2}\n&gt;&gt;&gt; dizionario\n{'k1': 1, 'k2': 2}\n</code></pre>"},{"location":"material/01_python/02_syntax/04_data_structures/#uso-del-costruttore-dict","title":"Uso del costruttore <code>dict()</code>","text":"<p>Un altro modo \u00e8 usare il metodo costruttore <code>dict()</code>:</p> <pre><code>&gt;&gt;&gt; dizionario = dict(k1=1, k2=2)\n</code></pre>"},{"location":"material/01_python/02_syntax/04_data_structures/#uso-della-funzione-zip","title":"Uso della funzione <code>zip</code>","text":"<p>Possiamo poi usare la funzione <code>zip</code> per creare un dizionario a partire da due liste:</p> <pre><code>&gt;&gt;&gt; chiavi = ['k1', 'k2']\n&gt;&gt;&gt; valori = [1, 2]\n&gt;&gt;&gt; dizionario = dict(zip(chiavi, valori))\n</code></pre>"},{"location":"material/01_python/02_syntax/04_data_structures/#dict-comprehension","title":"Dict comprehension","text":"<p>Un modo per ottenere un dizionario a partire da un altro oggetto iterabile \u00e8 la dict comprehension, che ha una forma del tipo:</p> <pre><code>&gt;&gt;&gt; output = {chiave: valore for valore in iterabile}\n</code></pre> <p>Possiamo ad esempio creare un dizionario contenente come chiave i numeri da 1 a 9, e come valori corrispondenti i quadrati degli stessi:</p> <pre><code>&gt;&gt;&gt; quadrati = {str(i): i ** 2 for i in range(1, 10)}\n</code></pre>"},{"location":"material/01_python/02_syntax/05_classes/","title":"2.5 - Classi ed OOP","text":"<p>Python offre un esteso supporto alla programmazione orientata agli oggetti. Prima di proseguire, per\u00f2, \u00e8 opportuno introdurre brevemente questo concetto.</p>"},{"location":"material/01_python/02_syntax/05_classes/#la-programmazione-orientata-agli-oggetti","title":"La programmazione orientata agli oggetti","text":"<p>Quello della programmazione orientata agli oggetti (OOP) \u00e8 un paradigma di programmazione che permette di creare nuovi tipi definiti dall'utente, da intendersi come complementari ai tipi definiti dal linguaggio di programmazione. In tal senso, la OOP sposta il focus dalle funzioni, centrali nei linguaggi come il C e nel paradigma procedurale, ai dati.</p> <p>In tal senso, si arriva a dire che nella OOP tutto \u00e8 un oggetto.</p>"},{"location":"material/01_python/02_syntax/05_classes/#classi","title":"Classi","text":"<p>Una classe \u00e8 un prototipo per un determinato tipo di dati definito dall'utente. Ad esempio:</p> <ul> <li>la classe <code>Studente</code> rappresenta tutte le propriet\u00e0 e le azioni associate ad uno studente;</li> <li>la classe <code>Auto</code> rappresenta tutte le propriet\u00e0 e le azioni associate ad un'auto;</li> <li>la classe <code>Motore</code> definisce i comportamenti dei motori;</li> </ul> <p>e via discorrendo.</p> <p>In generale, quindi, pu\u00f2 esistere una classe per ogni tipologia di oggetti presenti nel mondo, sia esso reale o informatico.</p> <p>Importante \u00e8 non confondere la classe con il singolo oggetto, chiamato istanza. Ad esempio:</p> <ul> <li>lo studente Angelo Cardellicchio \u00e8 un'istanza della classe <code>Studente</code>;</li> <li>l'auto Opel Corsa targata AB 123 CD \u00e8 un'istanza della classe <code>Auto</code>;</li> <li>l'auto Hyundai Tucson CD 321 AB \u00e8 un'istanza della classe <code>Auto</code>;</li> <li>l'auto Opel Corsa targata AA 123 CC \u00e8 un'altra istanza della classe <code>Auto</code>.</li> </ul>"},{"location":"material/01_python/02_syntax/05_classes/#metodi-ed-attributi","title":"Metodi ed attributi","text":"<p>Ogni classe ha dei metodi, che caratterizzano delle azioni che \u00e8 possibile effettuare su ogni istanza della classe, e degli attributi, ovvero delle caratteristiche dell'istanza.</p> <p>In particolare, ogni nuovo tipo, chiamato classe, avr\u00e0 opportuni attributi e metodi, ognuno dei quali accessibile dall'esterno mediante opportuni modificatori.</p> <p>Ad esempio, l'auto Opel Corsa targata AB 123 CD ha una casa costruttrice (Opel), un modello (Corsa), una targa (AB 123 CD), una cilindrata, e via dicendo.</p> <p>Approfondimento</p> <p>Possiamo approfondire i concetti alla base della OOP in questa appendice.</p>"},{"location":"material/01_python/02_syntax/05_classes/#classi-in-python","title":"Classi in Python","text":"<p>Per definire una classe, dovremo usare la parola chiave <code>class</code>:</p> <pre><code>class NomeClasse(ClasseBase):\n# Attributi e metodi di classe...\n</code></pre> <p>Con la sintassi precedente, abbiamo creato una classe chiamata <code>NomeClasse</code> discendente da una classe base (<code>ClasseBase</code>).</p>"},{"location":"material/01_python/02_syntax/05_classes/#il-metodo-__init__","title":"Il metodo <code>__init__</code>","text":"<p>La maggior parte dei linguaggi di programmazione utilizza il concetto di costruttore per creare un'istanza di una classe. Il Python, tuttavia, non prevede l'utilizzo di un costruttore vero e proprio, quanto piuttosto di un metodo di inizializzazione dei singoli attributi dell'istanza. Da qui deriva il nome del metodo, ovvero <code>__init__</code>:</p> <pre><code>class NomeClasse(ClasseBase):\ndef __init__(self, *args, **kwargs):\n# ...\nself.arg_1 = arg_1\n# ...\n</code></pre> <p>Unpacking</p> <p>Con la sintassi <code>*args</code> e <code>**kwargs</code> vogliamo rappresentare l'azione di unpacking di (rispettivamente) una lista ed un dizionario, mediante la quale stiamo passando tutti i valori contenuti all'interno della sequenza.</p> <p>Occorre prestare particolare attenzione all'uso della keyword <code>self</code>, che permette di riferirsi alla specifica istanza di una classe (per chi ha familiarit\u00e0 con i linguaggi come il C++, \u00e8 concettualmente simile alla parola chiave <code>this</code>). Ad esempio:</p> <pre><code>class Persona(object):\ndef __init__(self, nome, cognome, eta=18):\nself.nome = nome\nself._cognome = cognome\nself.__eta = eta\n</code></pre> <p>Questo snippet ci permette di evidenziare quattro punti:</p> <ol> <li>la classe generica <code>object</code>, da cui derivano tutte le classi Python (ma la cui dichiarazione pu\u00f2 comunque essere omessa);</li> <li>il funzionamento della parola chiave <code>self</code>, che permette di associare agli attributi della singola istanza un determinato valore;</li> <li>la possibilit\u00e0 di inserire tra i parametri dei valori opzionali e di default (in questo caso <code>eta</code>, che di default vale <code>18</code>);</li> <li>la presenza di uno o due simboli <code>_</code> (underscore) davanti ad alcuni attributi.</li> </ol> <p>Approfondiamo brevemente il punto 4.</p>"},{"location":"material/01_python/02_syntax/05_classes/#modificatori-di-accesso","title":"Modificatori di accesso","text":"<p>Python prevede l'uso di modificatori di accesso ai dati; nello specifico, troviamo i classici <code>public</code>, <code>protected</code> e <code>private</code>. Tuttavia, a differenza di altri linguaggi, per distinguere tra i tre modificatori di accesso si utilizzano uno o due underscore come suffisso al nome dell'attributo; in particolare, usare un underscore singolo indica un attributo protected, mentre un underscore doppio indica un attributo <code>private</code>. Nel nostro caso:</p> <pre><code>class Persona(object):\ndef __init__(self, nome, cognome, eta=18):\nself.nome = nome                # Membro \"public\"\nself._cognome = cognome         # Membro \"protected\"\nself.__eta = eta                # Membro \"private\"\n</code></pre> <p>Attenzione</p> <p>Nonostante il modificatore di accesso, \u00e8 possibile accedere ai membri protetti dall'esterno della classe. Infatti:</p> <pre><code>&gt;&gt;&gt; p = Persona('Jax', 'Teller')\n&gt;&gt;&gt; print(p.nome)\n'Jax'\n&gt;&gt;&gt; print(p._cognome)\n'Teller'\n</code></pre> <p>Questo non vale per gli attributi privati:</p> <pre><code>&gt;&gt;&gt; try:\n&gt;&gt;&gt;     print(p.__eta)\n&gt;&gt;&gt; except AttributeError:\n&gt;&gt;&gt;     print('Et\u00e0 \u00e8 privato!')\nEt\u00e0 \u00e8 privato!\n</code></pre> <p>Questa sintassi pu\u00f2 ovviamente essere utilizzata per definire dei metodi protetti o privati.</p> <p>Suggerimento</p> <p>La sintassi che abbiamo mostrato nello snippet precedente \u00e8 relativa alla gestione delle eccezioni.</p>"},{"location":"material/01_python/02_syntax/05_classes/#metodi","title":"Metodi","text":"<p>La sintassi per definire il metodo di una classe \u00e8 analoga a quella usata per definire una funzione.</p> <pre><code>def metodo(self, *args, **kwargs):\npass\n</code></pre> <p>Esiste tuttavia una differenza fondamentale: infatti, il primo attributo di un metodo appartenente ad una classe \u00e8 sempre un riferimento all'istanza tramite la parola chiave <code>self</code>. Tale riferimento non va specificato quando il metodo viene chiamato dall'esterno:</p> <pre><code># ...\np = Persona()           # p \u00e8 un'istanza di Persona\np.metodo(parametro)     # richiamo il metodo dall'istanza\n# ...\n</code></pre> <p>Nel codice precedente, abbiamo usato l'operatore <code>.</code> per accedere a <code>metodo()</code> definito all'interno della classe <code>Persona</code>.</p> <p>Approfondiamo adesso alcune particolari tipologie di metodi, ottenibili usando determinati decorator (cfr. appendice B).</p>"},{"location":"material/01_python/02_syntax/05_classes/#metodi-di-classe","title":"Metodi di classe","text":"<p>Il decorator <code>@classmethod</code> ci permette di definire i cosiddetti metodi di classe:</p> <pre><code>@classmethod\ndef builder_stringa(cls, stringa: str):\nnome, cognome, eta = stringa.split(' ')\nreturn Persona(nome, cognome, eta)\n</code></pre> <p>A differenza dei metodi standard, i metodi di classe hanno un riferimento alla classe (<code>cls</code>) e non all'istanza (<code>self</code>). Questo significa che sono dei metodi che si applicano all'intera classe, e non alla singola istanza. Un tipico esempio di utilizzo di un metodo di classe \u00e8 mostrato nello snippet precedente, nel quale stiamo creando un oggetto di classe <code>Persona</code> a partire da una stringa.</p> <p>Curiosit\u00e0</p> <p>Il metodo precedente \u00e8, di fatto, un'implementazione del design pattern Builder.</p> <p>Per richiamare un metodo di classe occorre riferirsi al nome della classe stessa, e non ad una singola istanza:</p> <pre><code>&gt;&gt;&gt; persona = Persona.builder_stringa('Bobby Munson 58')\n&gt;&gt;&gt; print(\"{} {}\".format(persona.nome, persona._cognome))\nBobby Munson\n</code></pre>"},{"location":"material/01_python/02_syntax/05_classes/#metodi-statici","title":"Metodi statici","text":"<p>Mediante il decoratore <code>@staticmethod</code> possiamo definire un metodo statico. In Python il funzionamento di un metodo di questo tipo \u00e8 riassumibile in un comportamento assimilabile ad una funzione \"semplice\", definita per\u00f2 all'interno della classe, e richiamabile su istanze della stessa. Ad esempio:</p> <pre><code>@staticmethod\ndef nome_valido(nome):\nif len(nome) &lt; 2:\nreturn False\nelse:\nreturn True\n</code></pre> <p>Questo metodo \u00e8 quindi liberamente richiamabile mediante l'operatore <code>.</code> da una singola istanza:</p> <pre><code>&gt;&gt;&gt; print(Persona.nome_valido('Li'))\nTrue\n</code></pre> <p>Un'altra possibilit\u00e0 \u00e8 richiamarlo sulla classe stessa:</p> <pre><code>&gt;&gt;&gt; print(Persona.nome_valido('X'))\nFalse\n</code></pre>"},{"location":"material/01_python/02_syntax/05_classes/#metodi-astratti","title":"Metodi astratti","text":"<p>Possiamo definire dei metodi astratti (cfr. Appendice C) mediante il decorator <code>@abstractmethod</code>. Per farlo, la nostra classe deve discendere dalla classe <code>ABC</code> (acronimo che sta per Abstract Base Class), contenuta nel package <code>abc</code>:</p> <pre><code>from abc import ABC\nclass ClasseBase(ABC):\n# ...\n@abstractmethod\ndef metodo_da_sovrascrivere(self):\npass\n</code></pre> <p>I metodi contrassegnati con il decorator <code>@abstractmethod</code> dovranno essere implementati nelle classi derivate (in altre parole, dovremo farne l'override):</p> <pre><code>class ClasseDerivata(ClasseBase):\n# ...\ndef metodo_da_sovrascrivere(self):\n# ...\n</code></pre>"},{"location":"material/01_python/02_syntax/05_classes/#le-proprieta","title":"Le propriet\u00e0","text":"<p>In molti linguaggi di programmazione si usano tradizionalmente i metodi accessori (getter) e modificatori (setter) per accedere agli attributi delle istanze di una classe. Python non vieta di farlo: ad esempio, possiamo scrivere un metodo <code>get_nome(self)</code> per accedere al nome di una persona, ed un metodo <code>set_nome(self, nome)</code> per impostare detta propriet\u00e0.</p> <p>Tuttavia, \u00e8 possibile usare una sintassi pi\u00f9 compatta (e, in definitiva, maggiormente pythonic) mediante il decorator <code>@property</code>, che rappresenta una funzione a quattro parametri:</p> <pre><code>property(fget=None, fset=None, fdel=None, doc=None)\n</code></pre> <p>In particolare:</p> <ul> <li><code>fget</code> \u00e8 la funzione usata per recuperare il valore dell'attributo;</li> <li><code>fset</code> \u00e8 la funzione usata per impostare il valore dell'attributo;</li> <li><code>fdel</code> \u00e8 la funzione per rimuovere l'attributo;</li> <li><code>doc</code> \u00e8 la funzione per documentare e descrivere l'attributo.</li> </ul> <p>Grazie a <code>property</code>, potremo seguire le \"best practice\" della OOP, rendendo privati gli attributi della classe ed accedendovi mediante opportuni metodi.</p> <pre><code>class Persona():\ndef __init__(self, nome, cognome, eta):\nself.nome = nome\nself.cognome = cognome\nself.eta = eta\n@property\ndef nome(self):\nreturn self.__nome\n@nome.setter\ndef nome(self, value):\nif len(value) &lt; 2:\nraise ValueError('La lunghezza del nome non pu\u00f2 essere inferiore a due caratteri.')\nelse:\nself.__nome = value\n@property\ndef cognome(self):\nreturn self.__cognome\n@cognome.setter\ndef cognome(self, value):\nif len(value) &lt; 2:\nraise ValueError('La lunghezza del cognome non pu\u00f2 essere inferiore a due caratteri.')\nelse:\nself.__cognome = value\n@property\ndef eta(self):\nreturn self.__eta\n@eta.setter\ndef eta(self, value):\nif value &lt; 0:\nraise ValueError(\"L'et\u00e0 non pu\u00f2 essere negativa.\")\nelse:\nself.__eta = value\n</code></pre> <p>Alcune note:</p> <ul> <li>abbiamo riscritto la classe <code>Persona</code> in modo da trasformare tutti gli attributi in propriet\u00e0;</li> <li>per ogni propriet\u00e0, abbiamo specificato un getter, che restituisce il valore della stessa;</li> <li>oltre al getter, \u00e8 stato specificato un setter, nel quale vi \u00e8 anche una forma di validazione del valore passato in input.</li> </ul> <p>Vediamo come usare la nostra nuova classe:</p> <pre><code>&gt;&gt;&gt; draco = Persona('Draco', 'Malfoy', 12)\n&gt;&gt;&gt; print(draco.nome)\n'Draco'\n&gt;&gt;&gt; print(draco.eta)\n12\n&gt;&gt;&gt; hermione = Persona('', 'Granger', 18)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"&lt;stdin&gt;\", line 3, in __init__\nFile \"&lt;stdin&gt;\", line 12, in nome\nValueError: La lunghezza del nome non pu\u00f2 essere inferiore a due caratteri.\n</code></pre> <p>Notiamo che, dal punto di vista dello script che richiama la classe, non ci sono differenze di sorta; tuttavia, la logica di validazione ci permette di evitare errori e situazioni incoerenti, ed \u00e8 inoltre possibile sfruttare le propriet\u00e0 per accedere agli attributi privati della classe.</p>"},{"location":"material/01_python/02_syntax/06_modules/","title":"2.6 - Script, moduli e package","text":"<p>Quando si usa Python la tentazione \u00e8 quella di interagire direttamente con l'interprete, lanciandolo da terminale ed eseguendo di volta in volta le istruzioni necessarie. Ovviamente questo approccio, seppur immediato, presenta diversi svantaggi. Ad esempio:</p> <ul> <li>non avremo a disposizione il syntax highlighting offerto da una normale IDE;</li> <li>non potremo recuperare il codice una volta chiuso l'interprete;</li> <li>non potremo n\u00e9 modificare, n\u00e9 verificare facilmente il funzionamento del codice.</li> </ul> <p>Appare quindi evidente come usare l'interprete non sia un modo ottimale di sviluppare codice Python. Di conseguenza, sar\u00e0 necessario definire, mediante la nostra IDE di riferimento, dei veri e propri script che saranno salvati sotto forma di file con estensione <code>.py</code>, ognuno dei quali contenenti una serie di istruzioni necessarie all'esecuzione del nostro programma.</p>"},{"location":"material/01_python/02_syntax/06_modules/#il-primo-script","title":"Il primo script","text":"<p>Proviamo quindi a creare il nostro primo script Python. Per farlo, apriamo la nostra IDE di riferimento, come Visual Studio Code, e creiamo un file chiamato <code>main.py</code>, all'interno del quale inseriremo il seguente codice:</p> <pre><code># main.py\ndef hello_world():\nprint('Hello, world')\nhello_world()\n</code></pre> <p>Adesso apriamo un terminale, spostiamoci nella cartella nel quale abbiamo salvato questo script, ed eseguiamolo:</p> <pre><code>cd cartella_dove_risiede_lo_script\npython main.py\n</code></pre> <p>Le due istruzioni precedenti:</p> <ul> <li>servono a cambiare cartella (change directory, <code>cd</code>), spostandoci nella cartella dove risiede lo script;</li> <li>dicono all'interprete Python di lanciare lo script <code>main.py</code>.</li> </ul> <p>A schermo, se tutto \u00e8 andato per il verso giusto, apparir\u00e0 la scritta <code>Hello, world</code>:</p> <pre><code>Hello, world\n</code></pre>"},{"location":"material/01_python/02_syntax/06_modules/#i-moduli","title":"I moduli","text":"<p>Quando le dimensioni della nostra code base (ovvero la quantit\u00e0 di codice che scriviamo nel nostro programma) iniziano ad essere particolarmente \"ingombranti\", \u00e8 opportuno adottare un approccio modulare, separando in file differenti parti di codice delegate a funzioni eterogenee. Facciamo un esempio.</p> <p>Immaginiamo di voler scrivere un programma che definisca delle funzioni per calcolare l'area delle principali figure geometriche. Modifichiamo quindi il nostro file <code>main.py</code> come segue:</p> <pre><code># main.py\ndef calcola_area_quadrato(lato):\nreturn lato * lato\ndef calcola_area_rettangolo(base, altezza):\nreturn base * altezza\ndef calcola_area_triangolo(base, altezza):\nreturn (base * altezza) / 2\narea_quadrato = calcola_area_quadrato(4)\narea_rettangolo = calcola_area_rettangolo(2, 3)\narea_triangolo = calcola_area_triangolo(2, 3)\n</code></pre> <p>Immaginiamo di voler quindi aggiungere una funzione di calcolo trigonometrico:</p> <pre><code># main.py\nimport math\ndef calcola_tangente(angolo):\nreturn math.sin(angolo) / math.cos(angolo)\ntangente_pi = calcola_tangente(math.pi)\n</code></pre> <p>Il codice del nostro file <code>main.py</code> comprender\u00e0 adesso funzioni di tipo geometrico e trigonometrico.</p> <p>Cosa succederebbe se volessimo integrare delle funzioni di calcolo integrale, o di altro tipo? Ovviamente, ci sarebbe da un lato un aumento delle dimensioni della code base, dall'altro un \"mix\" tra funzioni che afferiscono ad ambiti differenti (seppur simili tra loro). Una buona idea sarebbe quindi quella di separare le diverse parti del programma, magari raggruppando le funzioni geometriche nel file <code>geometria.py</code>, le funzioni trigonometriche nel file <code>trigonometria.py</code>, e via discorrendo.</p> <p>Questi file, che conterranno al loro interno prevalentemente funzioni (ma non solo), sono chiamati moduli.</p> <p>Nota</p> <p>La linea che distingue gli script dai moduli \u00e8 molto sottile, e nei fatti \u00e8 facile fare confusione ed utilizzarli in maniera \"intercambiabile\". Sottolineamo per\u00f2 che, idealmente, gli script devono contenere al loro interno soltanto del codice che sar\u00e0 eseguito, mentre i moduli solo del codice che sar\u00e0 invocato da uno o pi\u00f9 script.</p> <p>Interprete e nome di un modulo</p> <p>L'interprete \u00e8 in grado di risalire al nome di un modulo dal nome del file in cui \u00e8 contenuto. Se, ad esempio, definiamo un modulo nel file <code>geometria.py</code>, l'interprete associer\u00e0 a quel modulo il nome <code>geometria</code>. Detto nome \u00e8 inoltre accessibile globalmente e dall'interno del modulo richiamando la variabile globale <code>__name__</code>.</p>"},{"location":"material/01_python/02_syntax/06_modules/#i-moduli-geometria-e-trigonometria","title":"I moduli <code>geometria</code> e <code>trigonometria</code>","text":"<p>Creiamo adesso il file <code>geometria.py</code>, all'interno del quale \"sposteremo\" le funzioni definite in precedenza per il calcolo geometrico.</p> <pre><code># geometria.py\ndef calcola_area_quadrato(lato):\nreturn lato * lato\ndef calcola_area_rettangolo(base, altezza):\nreturn base * altezza\ndef calcola_area_triangolo(base, altezza):\nreturn (base * altezza) / 2\n</code></pre> <p>Analogamente, nel file <code>trigonometria.py</code> andremo a definire la funzione per il calcolo della tangente.</p> <pre><code># trigonometria.py\nimport math\ndef calcola_tangente(angolo):\nreturn math.sin(angolo) / math.cos(angolo)\n</code></pre> <p>Riscriviamo ora il file <code>main.py</code>:</p> <pre><code># main.py\nimport geometria\nimport trigonometria\nif __name__ == \"__main__\":\nprint(geometria.calcola_area_quadrato(4))\nprint(trigonometria.calcola_tangente(math.pi))\n</code></pre> <p>Possiamo notare due cose.</p> <ol> <li>In primis, stiamo richiamando le funzioni <code>calcola_area_quadrato()</code> e <code>calcola_tangente()</code> definite nei moduli <code>geometria</code> e <code>trigonometria</code>, rispettivamente. Questi moduli sono importati all'interno del nostro script mediante la direttiva <code>import</code>.</li> <li>Al rigo 5, la \"strana\" sintassi mostrata serve a dichiarare quello che \u00e8 il <code>main</code>, ovvero il punto di \"accesso\" al codice del nostro programma. Il <code>main</code> \u00e8 normalmente presente in tutti i linguaggi di programmazione, alle volte sotto forme un po' differenti da quella qui mostrata; tuttavia, nel caso di script particolarmente semplici, il <code>main</code> pu\u00f2 essere tranquillamente omesso, in quanto l'interprete riuscir\u00e0 ad eseguirlo in maniera autonoma.</li> </ol> <p>Proviamo a lanciare lo script; per farlo, digitiamo l'istruzione <code>python main.py</code> da terminale. A schermo, se tutto \u00e8 andato per il verso giusto, vedremo i valori dell'area di un quadrato e della tangente di \\(\\pi\\).</p>"},{"location":"material/01_python/02_syntax/06_modules/#usare-gli-import","title":"Usare gli import","text":"<p>Relativamente al modulo <code>geometria</code>, abbiamo usato esclusivamente la funzione <code>calcola_area_quadrato()</code>, \"trascurando\" le altre due funzioni comunque presenti nel modulo. In queste circostanze, possiamo usare una versione modificata della direttiva <code>import</code>, che assume la seguente forma:</p> <pre><code>from modulo import funzione_o_classe\n</code></pre> <p>il che, nel nostro caso specifico, diventa:</p> <pre><code>from geometria import calcola_area_quadrato\n</code></pre> <p>In questo modo, possiamo importare solamente quello che ci serve, il che risulta particolarmente utile a migliorare l'efficienza del nostro codice; il perch\u00e9 sar\u00e0 chiaro a breve.</p>"},{"location":"material/01_python/02_syntax/06_modules/#alias","title":"Alias","text":"<p>La direttiva <code>import</code> ci permette di definire anche degli alias, particolarmente utili nel caso si usino dei nomi di package complessi. Ad esempio:</p> <pre><code>import trigonometria as tr\nprint(tr.calcola_tangente(math.pi))\n</code></pre>"},{"location":"material/01_python/02_syntax/06_modules/#la-funzione-dir","title":"La funzione <code>dir()</code>","text":"<p>La funzione <code>dir()</code> restituisce una lista con tutti i nomi (sia di funzione, sia di classe) definiti da un modulo. Ad esempio:</p> <pre><code>&gt;&gt;&gt; dir(geometria)\n['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'calcola_area_quadrato', 'calcola_area_rettangolo', 'calcola_area_triangolo']\n</code></pre> <p>E' interessante notare come, oltre a funzioni, classi e variabili da noi definite, nel modulo <code>geometria</code> siano automaticamente definite altre variabili, che saranno importate usando import:</p> <pre><code>import geometria\nif __name__ == \"__main__\":\nprint(geometria.__file__)\nprint(geometria.calcola_area_quadrato(4))\n</code></pre> <p>Notiamo che saremo in grado di accedere alla variabile <code>__file__</code> del modulo <code>geometria</code>, che indica il percorso relativo dello stesso all'interno del file system. Ovviamente, questa variabile non \u00e8 quasi mai utile, ma comporta un ulteriore carico sul codice, da cui diventa evidente l'importanza dell'opportuno uso della direttiva <code>from</code>.</p>"},{"location":"material/01_python/02_syntax/06_modules/#moduli-della-libreria-standard","title":"Moduli della libreria standard","text":"<p>Python ha diversi moduli appartenenti ad una libreria standard, i quali sono automaticamente disponibili a valle dell'installazione dell'interprete. Alcuni tra i pi\u00f9 utilizzati sono:</p> <ul> <li><code>sys</code>: \u00e8 il modulo integrato nell'interprete, ed offre diverse utility necessarie al suo funzionamento;</li> <li><code>os</code>: modulo delegato all'interazione con il sistema operativo su cui gira l'interprete;</li> <li><code>time</code>: modulo usato per tutte le utility riguardanti il \"cronometraggio\" del tempo di esecuzione di una funzione;</li> <li><code>datetime</code>: modulo usato per le funzionalit\u00e0 di data ed ora;</li> <li><code>copy</code>: modulo usato per gestire, tra le altre cose, la deep copy di un oggetto.</li> </ul> <p>Per una lista esaustiva, si rimanda alla Python Library Reference.</p>"},{"location":"material/01_python/02_syntax/06_modules/#package","title":"Package","text":"<p>Chiudiamo la trattazione con un accenno ai package, ovvero a delle vere e proprie \"collezioni\" che raggruppano moduli tra loro coerenti, in modo da facilitarne il successivo accesso. In pratica, i package non sono altro se non delle cartelle contenenti pi\u00f9 moduli (quindi, file con estensione <code>nome_modulo.py</code>), oltre ad un file, chiamato <code>__init__.py</code>, che permette all'interprete di riconoscere quella cartella come package e, occasionalmente, contiene delle istruzioni di inizializzazione del package.</p> <p>Per poter accedere ad un modulo contenuto all'interno di un package, possiamo usare la direttiva <code>import</code>, modificandola come segue:</p> <pre><code>import nome_package.nome_modulo\n# oppure...\nfrom nome_package.nome_modulo import nome_funzione\n</code></pre>"},{"location":"material/01_python/02_syntax/exercises/exercises/","title":"Esercitazione 2 - Programmare in Python","text":""},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizi-sulla-programmazione-strutturata","title":"Esercizi sulla programmazione strutturata","text":""},{"location":"material/01_python/02_syntax/exercises/exercises/#esecizio-21","title":"Esecizio 2.1","text":"<p>Scriviamo un ciclo che iteri fino a che il valore associato ad un contatore intero risulta essere minore di 10. Usiamo sia un ciclo <code>while</code>, sia un ciclo <code>for</code>.</p> <p>Soluzione</p> <p>Per prima cosa, \u00e8 opportuno tracciare un breve diagramma di flusso che mostri l'andamento delle informazioni all'interno del nostro codice.</p> <pre><code>flowchart TD\n    A(START) --&gt; B[i = 1]\n    B --&gt; C{i &lt;= 10}\n    C --&gt;|No| E[/\"print(i)\"/]\n    C --&gt; |S\u00ec| D[i = i + 1]\n    D --&gt; C\n    E --&gt; F(END)</code></pre> <p>Implementiamo il codice in primis utilizzando un ciclo <code>while</code>. Per farlo, inizializziamo a zero un contatore <code>i</code> e come condizione verifichiamo che <code>i</code> sia minore di <code>10</code>:</p> <pre><code>&gt;&gt;&gt; i = 1\n&gt;&gt;&gt; while i &lt;= 10:\n...     print(f'Il valore di i \u00e8 {i}')\n...     i = i + 1\n</code></pre> <p>Se proviamo ad eseguire questo codice, otterremo il seguente risultato:</p> <pre><code>Il valore di i \u00e8 1\nIl valore di i \u00e8 2\nIl valore di i \u00e8 3\nIl valore di i \u00e8 4\nIl valore di i \u00e8 5\nIl valore di i \u00e8 6\nIl valore di i \u00e8 7\nIl valore di i \u00e8 8\nIl valore di i \u00e8 9\nIl valore di i \u00e8 10\n</code></pre> <p>Proviamo adesso ad usare un <code>for</code>. In questo caso, potremo limitarci ad usare in maniera opportuna la funzione <code>range()</code>:</p> <pre><code>&gt;&gt;&gt; for i in range(1, 11):\n...     print(f'Il valore di i \u00e8 {i}')\n</code></pre> <p>Eseguendo questa istruzione, otterremo un risultato analogo al precedente.</p>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-22","title":"Esercizio 2.2","text":"<p>Data una lista di numeri, scrivere una funzione che iteri fino a che non si trova un numero divisibile per \\(7\\). Utilizzare un ciclo <code>for</code>.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio prevede l'utilizzo dell'istruzione <code>break</code>, che dovr\u00e0 essere lanciata quando troveremo un multiplo intero di \\(7\\).</p> <pre><code>def multiplo_sette(lista):\nfor el in lista:\nif el % 7 == 0:\nprint(f'{el} \u00e8 multiplo di 7. Uscita in corso.')\nbreak\nelse:\nprint(f'{el} non \u00e8 multiplo di 7.')\n</code></pre> <p>In pratica:</p> <ul> <li>alla riga 2 iteriamo su ogni elemento della lista;</li> <li>alla riga 3, se l'elemento \u00e8 perfettamente divisibile per \\(7\\) (e, quindi, il modulo della divisione \u00e8 \\(0\\)), stampiamo a schermo un messaggio ed usciamo dalla funzione;</li> <li>se la precedente non \u00e8 verficata, continuiamo l'iterazione sulla lista.</li> </ul> <p>Ad esempio:</p> <pre><code>&gt;&gt;&gt; l = [1, 2, 5, 13, 21, 5]\n&gt;&gt;&gt; multiplo_sette(l)\n1 non \u00e8 multiplo di 7.\n2 non \u00e8 multiplo di 7.\n5 non \u00e8 multiplo di 7.\n13 non \u00e8 multiplo di 7.\n21 \u00e8 multiplo di 7. Uscita in corso.\n</code></pre>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizi-sulle-funzioni","title":"Esercizi sulle funzioni","text":""},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-23","title":"Esercizio 2.3","text":"<p>Estraiamo tutti gli indici pari di una lista arbitraria di dieci elementi in ordine inverso. Per farlo, usiamo sia la funzione <code>range</code> sia lo slicing.</p> <p>Soluzione</p> <p>Una possibile implementazione delle funzioni \u00e8 la seguente:</p> <pre><code>def estrai_con_slice(l):\nreturn l[-1::-2]\ndef estrai_con_range(l):\nl_out = []\nfor i in range(len(l) - 1, -2, -2):\nl_out.append(l[i])\nreturn l_out\n</code></pre> <p>Partiamo dalla funzione <code>estrai_con_slice(l)</code>. Qui sfruttiamo il meccanismo di slicing su lista, che ricordiamo essere dato dall'espressione:</p> <pre><code>l[i:f:s]\n</code></pre> <p>dove <code>l</code> \u00e8 la lista sotto analisi, <code>i</code> \u00e8 l'indice iniziale, <code>f</code> \u00e8 l'indice di terminazione, ed <code>s</code> \u00e8 lo step da utilizzare. In questo caso, stiamo specificando <code>i</code> pari a <code>-1</code>, per cui lo slicing partir\u00e0 dall'ultimo elemento della lista, ed andr\u00e0 verso l'indice finale (che omettiamo). Tuttavia, se omettessimo anche <code>s</code>, lo slicing ci restituirebbe esclusivamente l'ultimo elemento della lista; di conseguenza, specifichiamo un passo negativo, che ci assicurer\u00e0 che <code>l</code> venga completamente attraversata considerando soltanto gli elementi pari. Un altro modo sarebbe stato il seguente:</p> <pre><code>&gt;&gt;&gt; l_out = l[1::2]\n&gt;&gt;&gt; l_out.reverse()\n&gt;&gt;&gt; l_out\n[10, 8, 6, 4, 2]\n</code></pre> <p>In questo caso, aabbiamo potuto utilizzare uno slicing \"classico\", da sinistra verso destra, ma abbiamo dovuto utilizzare il metodo <code>reverse()</code> per invertire l'ordine della lista.</p> <p>Applichiamo la funzione alla lista <code>l</code>:</p> <pre><code>&gt;&gt;&gt; l = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n&gt;&gt;&gt; estrai_con_slice(l)\n[10, 8, 6, 4, 2]\n</code></pre> <p>Nella funzione <code>estrai_con_range()</code>, invece, definiamo un ciclo <code>for</code> su una sequenza generata dalla funzione <code>range(i, f, s)</code>, specificando <code>i = len(l) - 1</code>, ovvero <code>9</code>, ed <code>f = 0</code>. Ci\u00f2 \u00e8 legato al fatto che <code>l[9]</code> \u00e8, a causa dello 0-indexing di Python, l'ultimo elemento della lista. Come step manteniamo, come prevedibile, <code>-2</code>.</p> <pre><code>&gt;&gt;&gt; estrai_con_range(l)\n[10, 8, 6, 4, 2]\n</code></pre> <p>Suggerimento</p> <p>Nel caso della funzione <code>estrai_con_range()</code>, anche <code>f = -1</code> \u00e8 valido. Tuttavia, se impostassimo <code>f = -2</code>, il risultato sarebbe <code>[10, 8, 6, 4, 2, 10]</code>. Il motivo \u00e8 legato al fatto che, all'ultima iterazione, staremmo considerando <code>l[-1]</code>, che \u00e8 proprio <code>10</code>.</p>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-24","title":"Esercizio 2.4","text":"<p>Duplicare una lista passata come argomento in ingresso. Provare ad utilizzare un ciclo <code>for</code>.</p> <p>Soluzione</p> <p>Potremmo essere tentati di scrivere una funzione come la seguente:</p> <pre><code>def raddoppia_lista(lista):\nfor elemento in lista:\nlista.append(elemento)\nprint(f\"Lista all'iterazione attuale: {lista}\")\n</code></pre> <p>Se provassimo ad utilizzare questa funzione, faremmo finire l'interprete in un ciclo infinito. Infatti, la funzione tenta di agire sulla lista originaria che, ad ogni iterazione, aumenta le sue dimensioni di un elemento, il che, ovviamente, rende impossibile raggiungere il termine della stessa!</p> <p>Per ottenere il risultato previsto, dobbiamo usare una deep copy, ovvero fare una copia esatta della lista. Per chi ha familiarit\u00e0 con il C, si tratta, in poche parole, di una copia per valore. Usiamo il metodo <code>deepcopy</code>:</p> <pre><code>from copy import deepcopy\ndef raddoppia_lista_deep(lista):\nlista_appoggio = deepcopy(lista)\nfor elemento in lista_appoggio:\nlista.append(elemento)\nprint(f\"Lista di appoggio: {lista_appoggio}\")\nprint(f\"Lista attuale: {lista}\")\n</code></pre> <p>Stiamo creando una nuova lista, chiamata <code>lista_appoggio</code>, che sar\u00e0 utilizzata come base per duplicare la lista originaria. Provando a chiamare questa funzione, otterremo il risultato desiderato:</p> <pre><code>&gt;&gt;&gt; raddoppia_lista_deep([1, 2])\nLista di appoggio: [1, 2]\nLista attuale: [1, 2, 1]\nLista di appoggio: [1, 2]\nLista attuale: [1, 2, 1, 2]\n</code></pre>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-25","title":"Esercizio 2.5","text":"<p>Generare una lista di elementi casuali compresi tra \\(0\\) e \\(10\\). Usare sia una funzione con un unico parametro opzionale.</p> <p>Soluzione</p> <p>Scriviamo la seguente funzione:</p> <pre><code>import random\ndef genera_lista_casuale(lunghezza=5):\nl = []\nfor i in range(lunghezza):\nl.append(random.randint(0, 10))\nreturn l\n</code></pre> <p>In particolare, <code>genera_lista_casuale()</code> accetta come parametro opzionale <code>lunghezza</code>, il cui valore \u00e8 5, ed usa la funzione <code>append()</code> per aggiungere un valore generato casualmente.</p> <p>Volendo, \u00e8 possibile usare anche una list comprehension:</p> <pre><code>def genera_lista_casuale_con_l_c(lunghezza=5):\nreturn [random.randint(0, 10) for i in range(lunghezza)]\n</code></pre> <p>Verifichiamo entrambe le funzioni:</p> <pre><code>&gt;&gt;&gt; genera_lista_casuale()\n[0, 2, 1, 0, 2]\n&gt;&gt;&gt; genera_lista_casuale(lunghezza=10) \n[2, 2, 2, 9, 5, 1, 5, 10, 9, 6]\n&gt;&gt;&gt; genera_lista_casuale_con_l_c()\n[10, 7, 2, 5, 1]\n&gt;&gt;&gt; genera_lista_casuale_con_l_c(lunghezza=10) \n[0, 9, 3, 7, 1, 3, 9, 3, 8, 7]\n</code></pre>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizi-su-liste-e-strutture-dati","title":"Esercizi su liste e strutture dati","text":""},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-26","title":"Esercizio 2.6","text":"<p>Selezionare tutti i nomi che iniziano con la lettera <code>B</code> dalla seguente lista. Utilizzare sia un ciclo sia una list comprehension.</p> <pre><code>lista_nomi = [\n\"Jax Teller\",\n\"Walter White\",\n\"Billy Butcher\",\n\"Luke Skywalker\",\n\"Bobby Singer\",\n\"Johnny Lawrence\"\n]\n</code></pre> <p>Soluzione</p> <p>Proviamo innanzitutto ad usare un ciclo. In particolare, useremo un <code>for</code> che itera su tutti le stringhe nella lista, verificando se il primo carattere \u00e8 <code>B</code>.</p> <pre><code>l_out = []\nfor nome in lista_nomi:\nif nome[0] == \"B\":\nl_out.append(nome)\n</code></pre> <p>La formulazione mediante list comprehension \u00e8 molto pi\u00f9 compatta, ma utilizza lo stesso principio:</p> <pre><code>output = [nome for nome in lista_nomi if nome[0] == \"B\"]\n</code></pre>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-27","title":"Esercizio 2.7","text":"<p>Ottenere la lista di tutti i quadrati dei numeri da 1 a 10. Utilizzare una list comprehension ed un'apposita funzione per il calcolo del quadrato.</p> <p>Soluzione</p> <p>Per prima cosa, definiamo la funzione <code>quadrato()</code> che accetta un <code>numero</code> e restituisce il suo quadrato:</p> <pre><code>def quadrato(numero):\nreturn numero ** 2\n</code></pre> <p>A questo punto, possiamo invocare la funzione direttamente da una list comprehension:</p> <pre><code>l_out = [quadrato(i) for i in range(1, 11)]\n</code></pre>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-28","title":"Esercizio 2.8","text":"<p>Data una lista di interi <code>l_int</code>, ottenere una lista <code>l_out</code> il cui \\(i\\)-mo elemento sia la stringa <code>'pari'</code> se l'\\(i\\)-mo elemento di <code>l_int</code> \u00e8 pari, e <code>'dispari'</code> altrimenti.</p> <p>Soluzione</p> <p>Possiamo risolvere l'esercizio utilizzando la list comprehension nella forma completa (ovvero con l'<code>if/else</code>). Ad esempio:</p> <pre><code>&gt;&gt;&gt; l_int = [1, 5, 2, 4]\n&gt;&gt;&gt; l_out = ['pari' if el % 2 == 0 else 'dispari' for el in l_int] \n&gt;&gt;&gt; l_out\n['dispari', 'dispari', 'pari', 'pari']\n</code></pre>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-29","title":"Esercizio 2.9","text":"<p>Scrivere una dict comprehension che permetta di ottenere il dizionario <code>vecchio_o_giovane</code> dato il seguente dizionario:</p> <pre><code>dizionario = {\n'Jax Teller': 27,\n'Walter White': 52,\n'Billy Butcher': 41,\n'Luke Skywalker': 79,\n'Bobby Singer': 68,\n'Johnny Lawrence': 49\n}\n</code></pre> <p>In particolare, il dizionario <code>vecchio_o_giovane</code> avr\u00e0 le stesse chiavi del dizionario di partenza, a cui sar\u00e0 associato il valore <code>'giovane'</code> soltanto se il valore della chiave del dizionario di partenza \u00e8 inferiore a 65.</p> <p>Soluzione</p> <p>Ricordando che la sintassi della dict comprehension \u00e8 sostanzialmente analoga a quella della list comprehension, possiamo scrivere:</p> <pre><code>vecchio_o_giovane = {k: 'vecchio' if v &gt; 65 else 'giovane' for (k, v) in dizionario.items()}\n</code></pre> <p>In pratica, stiamo associando il valore <code>'vecchio'</code> alla chiave <code>k</code> se il valore <code>v</code> ad essa associato in <code>dizionario</code> \u00e8 superiore a <code>65</code>. Da notare inoltre come l'iterazione avvenga su tutte le coppie chiave - valore presenti in <code>dizionario</code>, ottenibili mediante il metodo <code>items()</code>.</p>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizi-sulla-programmazione-orientata-agli-oggetti","title":"Esercizi sulla programmazione orientata agli oggetti","text":""},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-210","title":"Esercizio 2.10","text":"<p>Scrivere una classe <code>Persona</code> applicando i concetti visti durante la lezione.</p> <p>Soluzione</p> <p>Supponiamo che la classe <code>Persona</code> abbia tre attributi:</p> <ul> <li>un attributo <code>nome</code>, stringa rappresentativa del nome della persona;</li> <li>un attributo <code>cognome</code>, stringa rappresentativa del cognome della persona;</li> <li>un attributo <code>eta</code>, intero rappresentativo dell'et\u00e0 della persona.</li> </ul> <p>Per prima cosa, scriviamo il metodo <code>__init__</code>:</p> <pre><code>def __init__(self, nome, cognome, eta):\nself.nome = nome\nself.cognome = cognome\nself.eta = eta\n</code></pre> <p>Passeremo al metodo <code>__init__</code> tre parametri che, per semplicit\u00e0, chiameremo proprio <code>nome</code>, <code>cognome</code> ed <code>eta</code>. Questi parametri andranno ad inizializzare gli omonimi attributi di classe.</p> <p>Fatto questo, scriviamo tre propriet\u00e0, una per ciascun attributo:</p> <pre><code>@property\ndef nome(self):\nreturn self.__nome\n@nome.setter\ndef nome(self, value):\nif len(value) &lt; 2:\nraise ValueError('La lunghezza del nome non pu\u00f2 essere inferiore a due caratteri.')\nelse:\nself.__nome = value\n@property\ndef cognome(self):\nreturn self.__cognome\n@cognome.setter\ndef cognome(self, value):\nif len(value) &lt; 2:\nraise ValueError('La lunghezza del cognome non pu\u00f2 essere inferiore a due caratteri.')\nelse:\nself.__cognome = value\n@property\ndef eta(self):\nreturn self.__eta\n@eta.setter\ndef eta(self, value):\nif value &lt; 0:\nraise ValueError(\"L'et\u00e0 non pu\u00f2 essere negativa.\")\nelse:\nself.__eta = value\n</code></pre> <p>Notiamo come le propriet\u00e0 <code>nome</code> e <code>cognome</code> siano fatte in modo che se la lunghezza della stringa passata risulta essere inferiore a due caratteri venga lanciato un errore di tipo <code>ValueError</code>. Analogamente, il valore della propriet\u00e0 <code>eta</code> non potr\u00e0 essere inferiore a zero.</p> <p>Facciamo un esempio di uso della nostra classe mediante l'interprete Python:</p> <pre><code>&gt;&gt;&gt; draco = Persona('Draco', 'Malfoy', 12)\n&gt;&gt;&gt; print(draco.nome)\n'Draco'\n&gt;&gt;&gt; print(draco.eta)\n12\n&gt;&gt;&gt; hermione = Persona('', 'Granger', 18)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"&lt;stdin&gt;\", line 3, in __init__\nFile \"&lt;stdin&gt;\", line 12, in nome\nValueError: La lunghezza del nome non pu\u00f2 essere inferiore a due caratteri.\n</code></pre> <p>Codice</p> <p>Il codice completo per questo esercizio \u00e8 disponibile qui.</p>"},{"location":"material/01_python/02_syntax/exercises/exercises/#esercizio-211","title":"Esercizio 2.11","text":"<p>Creare le classi <code>Quadrato</code> e <code>Cerchio</code> che modellano (rispettivamente) i quadrati ed i cerchi. Entrambe devono essere progettate in modo da discendere da una classe base chiamata <code>Figura</code>.</p> <p>Soluzione</p> <p>Per prima cosa, definiamo la classe <code>Figura</code> come classe astratta. In particolare, definiremo due propriet\u00e0 comuni a tutte le figure, ovvero il <code>perimetro</code> e l'<code>area</code>, e due metodi astratti <code>calcola_perimetro</code> e <code>calcola_area</code> che andremo ad implementare nelle diverse sottoclassi.</p> <pre><code>from abc import ABC, abstractmethod\nclass Figura(ABC):\ndef __init__(self, perimetro=0, area=0):\nself.perimetro = perimetro\nself.area = area\n@property\ndef perimetro(self):\nreturn self.__perimetro\n@area.setter\ndef perimetro(self, value):\nif value &lt;= 0:\nraise ValueError(\"L'area non pu\u00f2 essere negativa.\")\nself.__perimetro = value\n@property\ndef area(self):\nreturn self.__area\n@area.setter\ndef area(self, value):\nif value &lt;= 0:\nraise ValueError(\"L'area non pu\u00f2 essere negativa.\")\nself.__area = value\n@abstractmethod\ndef calcola_perimetro(self):\npass\n@abstractmethod\ndef calcola_area(self):\npass\n</code></pre> <p>Notiamo come implementiamo un metodo <code>__init__</code> di base che inizializza i valori di perimetro ed area; di default, inseriremo dei valori pari a <code>0</code> per entrambe le propriet\u00e0.</p> <p>Fatto questo, potremo implementare le singole sottoclassi. In particolare, il <code>Quadrato</code> sar\u00e0 inizializzato mediante una specifica propriet\u00e0 <code>lato</code>, ed imposter\u00e0 il perimetro e l'area secondo le leggi del quadrato; il <code>Cerchio</code>, invece, avr\u00e0 la propriet\u00e0 <code>raggio</code>, mentre perimetro ed area seguiranno le specifiche convenzioni. </p> <pre><code>from math import pi\nclass Quadrato(Figura):\ndef __init__(self, lato, area=0, perimetro=0):\nsuper().__init__(perimetro, area)\nself.lato = lato\n@property\ndef lato(self):\nreturn self.__lato\n@lato.setter\ndef lato(self, value):\nself.__lato = value\ndef calcola_perimetro(self):\nself.perimetro = self.lato * 4\ndef calcola_area(self):\nself.area = self.lato ** 2\nclass Cerchio(Figura):\ndef __init__(self, raggio, area=0, perimetro=0):\nsuper().__init__(perimetro, area)\nself.raggio = raggio\n@property\ndef raggio(self):\nreturn self.__raggio\n@raggio.setter\ndef raggio(self, value):\nself.__raggio = value\ndef calcola_perimetro(self):\nself.perimetro = 2 * pi * self.raggio\ndef calcola_area(self):\nself.area = pi * (self.raggio ** 2)\n</code></pre> <p>Notiamo che entrambi i metodi <code>__init__</code> richiamano l'omologo della classe <code>Figura</code> mediante il metodo <code>super()</code>.</p> <p>Proviamo ad utilizzare il codice precedente:</p> <pre><code>q = Quadrato(5)\nq.calcola_area()\nq.calcola_perimetro()\nprint(f'Lato: {q.lato} - Perimetro: {q.perimetro} - Area: {q.area}')\nc = Cerchio(5)\nc.calcola_area()\nc.calcola_perimetro()\nprint(f'Raggio: {c.raggio} - Perimetro: {c.perimetro} - Area: {c.area}')\n</code></pre> <p>Codice</p> <p>Il codice completo per questo esercizio \u00e8 disponibile qui.</p>"},{"location":"material/01_python/03_advanced/01_argparse/","title":"3.1 - La libreria <code>argparse</code>","text":"<p>La libreria <code>argparse</code> ci permette di passare ad uno script Python degli argomenti utilizzando la riga di comando.</p> <p>Per farlo, dobbiamo seguire un processo articolato in quattro step:</p> <ol> <li>creiamo un oggetto di classe <code>ArgumentParser</code>;</li> <li>aggiungiamo gli argomenti di cui intendiamo fare il parsing;</li> <li>effettuiamo il parsing di questi argomenti;</li> <li>usiamo gli argomenti passati.</li> </ol> <p>Come molte cose in Python, \u00e8 pi\u00f9 complesso descrivere questa serie di passaggi che implementarla. Di conseguenza, usiamo il solito approccio learn by doing, usando un semplice esempio.</p> <p>Supponiamo di avere una classe <code>Persona</code>, definita come segue:</p> <pre><code>class Persona():\ndef __init__(self, nome, cognome):\nself.nome = nome\nself.cognome = cognome\ndef __str__(self):\nreturn f'{self.nome} {self.cognome}'\n</code></pre> <p>Scriviamo adesso uno script per creare un oggetto di questa classe, specificandone i parametri mediante riga di comando. Per prima cosa, importiamo la libreria <code>argparse</code>:</p> <pre><code>import argparse\n</code></pre> <p>Definiamo quindi un metodo che accetti come parametro un generico insieme di argomenti (che chiameremo <code>args</code>), e che crei al suo interno un'istanza di <code>Persona</code> a partire da questi argomenti.</p> <pre><code>def run(args):\n\"\"\" Definiamo il metodo `run` che sar\u00e0 invocato\n    ad ogni esecuzione dello script.\n    Il metodo accetta un parametro args che rappresenta\n    gli argomenti di cui \u00e8 stato effettuato il parsing.\n    \"\"\"\np = Persona(args.nome, args.cognome)\nprint(p)\n</code></pre> <p>Possiamo adesso definire il punto di accesso al nostro script come segue:</p> <pre><code>if __name__ == '__main__':\nparser = argparse.ArgumentParser()\nparser.add_argument(\n'-n',\n'--nome',\nhelp='Nome della persona',\ndefault='Pippo')\nparser.add_argument(\n'-c',\n'--cognome',\nhelp='Cognome della persona',\nrequired=True)\nargs = parser.parse_args()\nrun(args)\n</code></pre> <p>In particolare:</p> <ul> <li>alla riga 2, creeremo un oggetto di tipo <code>ArgumentParser</code>, che chiameremo <code>parser</code>;</li> <li>alla riga 3, aggiungeremo un primo argomento (il nome) al <code>parser</code> mediante il metodo <code>add_argument()</code>;</li> <li>alla riga 4, aggiungeremo un flag che contrassegner\u00e0 l'argomento;</li> <li>alla riga 5, aggiungeremo un nome per indicare l'argomento;</li> <li>alla riga 6, andremo a definire un messaggio di aiuto mediante il parametro <code>help</code> che descriver\u00e0 a cosa serve l'argomento;</li> <li>alla riga 7, assegneremo un valore di default all'argomento relativo al nome della persona;</li> <li>alla riga 8, creeremo un secondo argomento, ovvero il cognome, aggiungendolo al parser;</li> <li>alla riga 12, specificheremo che l'argomento <code>cognome</code> \u00e8 richiesto settando il parametro <code>required</code> a <code>True</code>;</li> <li>alla riga 13, andremo ad effettuare il parsing degli argomenti passati, salvandoli in una variabile chiamata <code>args</code>;</li> <li>infine, alla riga 14, passeremo la variabile <code>args</code> al metodo <code>run()</code> definito in precedenza.</li> </ul> <p>La variabile <code>args</code></p> <p>La variabile <code>args</code> definisce un oggetto di tipo <code>Namespace</code> all'interno del quale sono salvati tutti gli argomenti passati allo script, ciascuno dei quali invocabile con la notazione <code>args.nome_argomento</code>.</p> <p>Utilizzare l'<code>help</code></p> <p>Definire il parametro <code>help</code> ci permette di usare il comando <code>python nome_script -h</code>, che ci restituisce le righe di aiuto specificate durante il parsing. Di conseguenza, \u00e8 opportuno evitare di inserire dei flag del tipo <code>-h</code>, onde evitare collisioni ed errori del parser.</p> <p>Salviamo il nostro codice in uno script chiamato <code>run.py</code>. Per eseguirlo, sfrutteremo i flag <code>-n</code> e <code>-c</code> per specificare rispettivamente nome e cognome:</p> <pre><code>python run.py -n Nome -c Cognome\n</code></pre> <p>A schermo vedremo:</p> <pre><code>Nome Cognome\n</code></pre> <p>Possiamo anche omettere il nome, ma non il cognome, in quanto \u00e8 un parametro richiesto:</p> <pre><code>python run.py -c Cognome\nPippo Cognome\n</code></pre> <p>Possiamo poi invocare l'help scrivendo:</p> <pre><code>python run.py -h\n</code></pre> <p>Proviamo infine ad utilizzare la notazione completa:</p> <pre><code>python run.py --nome Nome --cognome Cognome\nNome Cognome\n</code></pre> <p>Proviamo adesso a modificare la classe <code>Persona</code> inserendovi l'et\u00e0. In tal senso, specifichiamo che l'et\u00e0 deve essere un valore intero; qualora questo non avvenga, sar\u00e0 lanciata un'eccezione.</p> <pre><code>class Persona():\ndef __init__(self, nome, cognome, eta):\nself.nome = nome\nself.cognome = cognome\nself.eta = eta\n@property\ndef eta(self):\nreturn self._eta\n@eta.setter\ndef eta(self, value):\nif not isinstance(eta, int):\nraise ValueError(\"Fornire un intero per l'et\u00e0.\")\nself._eta = value\ndef __str__(self):\nreturn f'{self.nome} {self.cognome}'\n</code></pre> <p>Modifichiamo il resto dello script per adattarci alle nuove esigenze. Partiamo dal metodo <code>run</code>:</p> <pre><code>def run(args):\n\"\"\" Definiamo il metodo `run` che sar\u00e0 invocato\n    ad ogni esecuzione dello script.\n    Il metodo accetta un parametro args che rappresenta\n    gli argomenti di cui \u00e8 stato effettuato il parsing.\n    \"\"\"\np = Persona(args.nome, args.cognome, args.eta)\nprint(p)\n</code></pre> <p>Aggiungiamo poi un altro argomento al <code>parser</code>:</p> <pre><code>if __name__ == '__main__':\nparser = ArgumentParser()\nparser.add_argument(\n'-n',                       \n'--nome',                   \nhelp='Nome della persona',  \ndefault='Pippo')            \nparser.add_argument(\n'-c',\n'--cognome',\nhelp='Cognome della persona',\nrequired=True)              \nparser.add_argument(\n'-e',\n'--eta',\nhelp='Et\u00e0 della persona')\nargs = parser.parse_args()\nrun(args)\n</code></pre> <p>Proviamo ad eseguire di nuovo lo script:</p> <pre><code>python run.py -n Nome -c Cognome -e 18\n</code></pre> <p>Vedremo che viene lanciato un errore, in quanto gli argomenti passati mediante argparse sono normalmente interpretati come delle stringhe.</p> <p>Per risolvere questo problema dovremo specificare il parametro <code>type</code>, ponendolo ad <code>int</code>:</p> <pre><code>parser.add_argument(\n'-e',\n'--eta',\nhelp='Et\u00e0 della persona',\ntype=int)\n</code></pre> <p>Se proviamo ad eseguire nuovamente lo script non riscontreremo alcun errore.</p>"},{"location":"material/01_python/03_advanced/enumerate/","title":"Enumerate","text":"<p>In Python, un ciclo for \u00e8 normalmente scritto come un ciclo su un oggetto iterabile. Questo singifica che non abbiamo bisogno di un contatore per accedere agli oggetti nell'iterabile. Alle volte, tuttavia, vogliamo avere una variabile che cambia ad ogni iterazione del ciclo. Piuttosto che creare ed incrementare una varaibile, possiamo usare il metodo enumerate() per ottenere un contatore ed un valore dall'iterabile allo stesso tempo.</p>"},{"location":"material/01_python/03_advanced/enumerate/#iterare-con-i-cicli-for-in-python","title":"iterare con i cicli for in Python","text":"<p>Un ciclo for in Python usa delle collection-based iteration. In altri termini, ci\u00f2 singifica che Python assegna l'oggetto successivo in un iterabile alla variabile di loop ad ogni iterazione, come in questo esempio:</p> <pre><code>&gt;&gt;&gt; values = [\"a\", \"b\", \"c\"]\n&gt;&gt;&gt; for value in values:\n...     print(value)\n...\na\nb\nc\n</code></pre> <p>In questo esempio, <code>values</code> \u00e8 una lista con tre stringhe. In Python, le liste sono un tipo di oggetto iterabile. Nel ciclo for, la variabile su cui si cicla \u00e8 il valore. Ad ogni iterazione del ciclo, il valore \u00e8 impostato all'oggetto successivo sui valori.</p> <p>Adesso, stampiamo a schermo <code>value</code>. Il vantaggio delle iterazioni collection-based \u00e8 che ci aiutano ad evitare l'errore <code>off-by-one</code> che \u00e8 comune in altri lingauggi di programmazione.</p> <p>Adesso immaginiamo che, oltre al valore stesso, vogliamo stampare l'indice dell'oggetto nella lista sullo schermo ad ogni iterazione. Un modo di approcciare questo task \u00e8 creare una variabile per memorizzare l'indice ed aggiornarla ad ogni iterazione:</p> <pre><code>&gt;&gt;&gt; index = 0\n&gt;&gt;&gt; for value in values:\n...     print(index, value)\n...     index += 1\n...\n0 a\n1 b\n2 c\n</code></pre> <p>In questo esempio, <code>index</code> \u00e8 un intero che tiene traccia di dove siamo nella lista. Ad ogni iterazione del loop, stampiamo <code>index</code> cos\u00ec come <code>value</code>. L'ultimo step nel ciclo \u00e8 aggiornare il numero memorizzato nell'indice di uno. Un bug comune avviene quando dimentichiamo di aggiornare l'indice ad ogni iterazione:</p> <pre><code>&gt;&gt;&gt; index = 0\n&gt;&gt;&gt; for value in values:\n...     print(index, value)\n...\n0 a\n0 b\n0 c\n</code></pre> <p>In questo esempio, l'indice rimane a 0 ad ogni iterazione percH\u00e9 non c'\u00e8 del codice che ne aggiorna il valore al termine del ciclo. Specie epr cicli lunghi o complicati, questo tipo di bug \u00e8 notoriamente difficile da individuare.</p> <p>Un altro modo comune per approcciare questo problema \u00e8 usare range() combinato con len() per creare automaticamente un indice. In questo modo, non dobbiamo ricordarci di aggiornare l'indiice:</p> <pre><code>&gt;&gt;&gt; for index in range(len(values)):\n...     value = values[index]\n...     print(index, value)\n...\n0 a\n1 b\n2 c\n</code></pre> <p>In questo esempio, <code>len(values)</code> restituisce la lunghezza di <code>values</code>, che \u00e8 \\(3\\). Quindi, <code>range()</code> crea un iteratore che va dal valore di default di partenza di <code>0</code> fino a quando non arriva a <code>len(values)</code> meno uno. In questo caso, <code>index</code> diventa la variabile su cui si cicla. Nel loop, impostiamo il valore uguale all'oggetto nei valori al valore attuale dell'indice. Successivamente, stampiamo l'indice ed il valore.</p> <p>Con questo esempio, un bug comune che pu\u00f2 avvenire \u00e8 quando ci dimentichiamo di aggiornare il valore all'inizio di ogni iterazione. Questo \u00e8 simile al bug precedente in cui ci dimentichiamo di aggiornare l'indice. Questa \u00e8 una delle ragioni per le quali questo loop non viene considerato Pythonic.</p> <p>Questo esempio \u00e8 anche in qualche modo ristretto perch\u00e9 values deve permettere l'accesso ai suoi uggetti usando indici interi. Gli iterabili che permettono questo tipo di accessi sono chiamati sequenze in Python.</p> <p>Dettaglio tecnico</p> <p>Secondo la documentazione Python, un iterabile \u00e8 un qualsiasi oggetto che pu\u00f2 restituire i suoi membri uno alla volta. Per definizione, gli iterabili supportano il protocollo iterator, che specifica come i membri dell'oggetto sono restituiti quando un oggetto \u00e8 usato in un iteratore. Python ha due tipi comuni di iteraotri: sequenze e generatori.</p> <p>Un qualsiasi iterabile pu\u00f2 essere usato in un ciclo for, ma solo le sequenze possono essere accedute da indici interi. Provare ad accedere agli oggetti per indice da un generatore o un iteratore lancer\u00e0 un TypeError:</p> <pre><code>&gt;&gt;&gt; enum = enumerate(values)\n&gt;&gt;&gt; enum[0]\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'enumerate' object is not subscriptable\n</code></pre> <p>In questo esempio, assegnamo il valore di ritorno di <code>enumerate()</code> ad <code>enum</code>. <code>enumerate()</code> \u00e8 un iteratore, per cui provare ad accedere ai suoi valori per indice lancia un <code>TypeError</code>.</p> <p>Fortunatamente, il metodo <code>enumerate()</code> di Python ci permette di evitare tutti questi problemi. E' una funzione integrata, il che significa che \u00e8 stato disponibile in ogni versione di Python dal momento in cui \u00e8 stato aggiunto in Python 2.3, nel 2003.</p>"},{"location":"material/01_python/03_advanced/enumerate/#usare-il-metodo-enumerate","title":"Usare il metodo enumerate()","text":"<p>Possiamo usare enumerate() in un loop allo stesso modo in cui si usa l'oggetto iterabile originario. Invece di inserire l'iterabile direttamente dopo <code>in</code> nel loop, lo mettiamo tra le parentesi di <code>enumerate()</code>. Dobbiamo anche cambiare la variabile di iterazione:</p> <pre><code>&gt;&gt;&gt; for count, value in enumerate(values):\n...     print(count, value)\n...\n0 a\n1 b\n2 c\n</code></pre> <p>QUando usiamo <code>enumerate()</code>, la funzione ci restituisce due variabili su cui iterare:</p> <ul> <li>il conteggio dell'iterazione attuale</li> <li>il valore ell'oggetto all'attuale iterazione</li> </ul> <p>Proprio come nel caso di un normale ciclo for, le variabili di loop possono essere chiamate come vogliamo. Possiamo usare <code>count</code> e <code>value</code> dell'esempio precedente, ma potremmo ad esempio usare <code>i</code> e <code>v</code>, o ogni altro nome Python valido.</p> <p>Con <code>enumerate()</code>, non dobbiamo ricordare l'accesso all'oggetto dall'iterabile, e non dobbiamo ricordare di aumentare l'indice alla fine del ciclo. Tutto viene gestito automaticamente.</p> <p>Dettaglio tecnico</p> <p>L'uso di di due variabili di loop, <code>count</code> e <code>value</code>, separate da una virgola \u00e8 un esempio di argument unpacking. Questa feature Python sar\u00e0 discussa in seguito.</p> <p>La funzione <code>enumerate()</code> ha un ulteriore argomento che possiamo usare per controllare il valore di partenza del conteggio. Di default, il valore di partenza \u00e8 <code>0</code> perch\u00e9 le sequenze Python sono indicizzati partendo da zero. In altre parole, quando vogliamo recuperare il primo elemento di una lista, usiamo l'indice <code>0</code>:</p> <pre><code>&gt;&gt;&gt; print(values[0])\na\n</code></pre> <p>Possiamo vedere in questo esempio che accedere a <code>values</code> con indice <code>0</code> restituisce il primo elemento, <code>a</code>. Tuttavia, ci sono molte volte quando non vogliamo che il conteggio di <code>enumerate()</code> parta a <code>0</code>. Ad esempio, potremmo voler stampare a schermo un contatore come output per l'utente. IN questo caso, possiamo usare l'argomento <code>start</code> passato ad <code>ennumerate()</code> per cambiare il contatore di partenza:</p> <pre><code>&gt;&gt;&gt; for count, value in enumerate(values, start=1):\n...     print(count, value)\n...\n1 a\n2 b\n3 c\n</code></pre> <p>In questo esempio, passiamo <code>start=1</code>, che inizia il conteggio con il valore <code>1</code> sulla prima iterazione del loop. Se compariamo questo con gli esempi precedenti, nei quali <code>start</code> aveva il valore di default di <code>0</code>, e possiamo vedere la diffferenza.</p>"},{"location":"material/01_python/03_advanced/enumerate/#pratica","title":"Pratica","text":"<p>Dovremmo usare <code>enumerate()</code> ogni volta che dobbiamo usare il contatore ed un oggetto in un ciclo. Teniamo a mente che <code>enumerate()</code> aumenta il conteggio di uno ad ogni iterazione. Tuttavia, questo limita soltanto leggermente la nostra flessibilit\u00e0. Dato che <code>count</code> \u00e8 un intero standard, possiamo usarlo in molti modi. Vediamo alcuni esempi.</p>"},{"location":"material/01_python/03_advanced/enumerate/#conteggio-naturale-di-oggetti-iterabili","title":"Conteggio naturale di oggetti iterabili","text":"<p>Nella sezione precedente, abbiamo visto come usare <code>enumerate()</code> per iniziare a creare un contatore naturale da stampare a schermo per l'utente. <code>enumerate()</code> \u00e8 usato anche in questo modo all'interno della codebase Python. Possiamo vedere un esempio in uno script che legge i file reST e dice all'utente se ci sono problemi di formattazione.</p> <p>Nota</p> <p>reST, detto anche reStructured Text, \u00e8 un formato standard per i file di testo che Python usa per la documentazione. Vedremo spesso delle stringhe formattate secondo reST incluse come docstring nelle classi e funzioni Python. Gli script che leggono i file del codice sorgente e dicono all'utente dei problemi di formattazione sono chiamati linter perch\u00e9 cercano i metaphorical lint (TODO: TRADURRE) nel codice.</p> <p>Questo esempio \u00e8 leggermente modificato da rstlint.py. Non ci preoccupiamo come questa funzione controlla i problemi: il punto \u00e8 quello di mostrare un uso vero di enumerate().</p> <pre><code>def check_whitespace(lines):\n\"\"\"Check for whitespace and line length issues.\"\"\"\nfor lno, line in enumerate(lines):\nif \"\\r\" in line:\nyield lno+1, \"\\\\r in line\"\nif \"\\t\" in line:\nyield lno+1, \"OMG TABS!!!1\"\nif line[:-1].rstrip(\" \\t\") != line[:-1]:\nyield lno+1, \"trailing whitespace\"\n</code></pre> <p><code>check_whitespae()</code> prende un argomento, <code>lines</code>, che sono le linee del file che deve essere valutato. Alla terza riga di <code>check_whitespace()</code>, enumerate() \u00e8 usato in un loop su <code>lines</code>. Questo restituisce il numero di linea, abbreviato in <code>lno</code>, e la linea stessa. Dal momento che <code>start</code> non \u00e8usato, <code>lno</code> \u00e8 un contatore che parte da zero delle righe nel file. <code>check_whitespaces()</code> fa diversi controlli per individuare i caratteri fuori psoto:</p> <ul> <li>il carriage return \\r</li> <li>il carattere tab \\t</li> <li>un qualsiasi spazio o tab alla fine della riga</li> </ul> <p>Quando uno di questi oggetti \u00e8 presente, <code>check_whitespace()</code> restituisce il numero di riga attuale ed un messaggio utile all'utente. La variabile contatore <code>lno</code> vi aggiunge uno in modo che restituisca il numero di contatore di linea piuttosto che un idnice preso a partire da zero. QUando un utente di <code>rslint.py</code> legge il messaggio, sapr\u00e0 a quale riga andare e quello da controllare.</p>"},{"location":"material/01_python/03_advanced/enumerate/#istruzioni-condizionali-per-saltare-oggetti","title":"Istruzioni condizionali per saltare oggetti","text":"<p>Usare le istruzioni condizionali per elaborare gli oggetti pu\u00f2 essere una tecnica molto potetne. Alle volte, dobbiamo effettuare un'azione soltanto alla prima iterazione di un loop, come in questo esempio:</p> <pre><code>&gt;&gt;&gt; users = [\"Test User\", \"Real User 1\", \"Real User 2\"]\n&gt;&gt;&gt; for index, user in enumerate(users):\n...     if index == 0:\n...         print(\"Extra verbose output for:\", user)\n...     print(user)\n...\nExtra verbose output for: Test User\nReal User 1\nReal User 2\n</code></pre> <p>In questo esempio, usiamo una lista come mock di un database di utenti. Il primo utente \u00e8 il nostro utente di test, per cui vogliamo creare delle informazioni di diagnostica su quell'utente. Dal momento che abbiamo impostato il sistema in modo che l'utente di test sia il primo, possiamo usare il primo valore dell'indice del loop per stampare dell'output verboso extra.</p> <p>Possiamo anche combinare delle operazionimatematiche con delle condizioni per il conteggio o l'indice. PEr esempio, possiamo restituire degli oggetti da un iterabile, ma soltanto se hanno un indice pari. Possiamo far questo usando enumerate().</p> <pre><code>&gt;&gt;&gt; def even_items(iterable):\n...     \"\"\"Return items from ``iterable`` when their index is even.\"\"\"\n...     values = []\n...     for index, value in enumerate(iterable, start=1):\n...         if not index % 2:\n...             values.append(value)\n...     return values\n...\n</code></pre> <p>La funzione <code>even_items()</code> prende un argomento, chiamato <code>iterable</code>, che dovrebbe essere un qualche tipo di oggetto su cui Python pu\u00f2 ciclare. Per prima cosa, <code>values</code> viene inizializzato ad una lista vuota. Quindi possiamo creare un ciclo for sull'iterabile con <code>enumerate()</code> ed impostare <code>start=1</code>.</p> <p>All'interno del ciclo for, controlliamo se il resto della divisione per due \u00e8 zero. Se questo \u00e8 vero, aggiungiamo l'oggetto a values. Infine, restituiamo values.</p> <p>Possiamo rendere il codice pi\u00f9 Pythonic usando una list comprehension per fare la stessa cosa in una riga senza inizializzare una lista vuota:</p> <pre><code>&gt;&gt;&gt; def even_items(iterable):\n...     return [v for i, v in enumerate(iterable, start=1) if not i % 2]\n...\n</code></pre> <p>In questo codice di esempio, <code>even_items()</code> usa una list comprehension piuttosto che un ciclo for per estrarre ogni oggetto dalla ista il cui indice \u00e8 un numero pari.</p> <p>Possiamo verificare che <code>even_items()</code> funziona come atteso ottenendo gli oggetti con indice pari da un range di interi da 1 a 10. Il risultato sar\u00e0:</p> <pre><code>&gt;&gt;&gt; seq = list(range(1, 11))\n&gt;&gt;&gt; print(seq)\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n&gt;&gt;&gt; even_items(seq)\n[2, 4, 6, 8, 10]\n</code></pre> <p>Come atteso, <code>even_items()</code> restituisce gli oggetti ad indice pari da <code>seq</code>. Questo non \u00e8 il modo pi\u00f9 efficienti per ottenere i numeri pari quando stiamo lavorando con gli interi. Tuttavia, ora che abbiamo verificato che <code>even_items()</code> lavora propriamente, possiamo ottenere le lettere ad indice pari dell'alfabeto ASCII:</p> <pre><code>&gt;&gt;&gt; alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n&gt;&gt;&gt; even_items(alphabet)\n['b', 'd', 'f', 'h', 'j', 'l', 'n', 'p', 'r', 't', 'v', 'x', 'z']\n</code></pre> <p>In questo caso, <code>alphabet</code> \u00e8 una stringa che ha tutte le ventisei lettere minuscole dell'alfabeto ASCII. Chiamare <code>even_items()</code> e passare <code>alphabet</code> restituisce una lista di lettere alternate dall'alfabeto.</p> <p>Le stringhe Python sono sequenze, che possono essere usate in cicli cos\u00ec come nell'indicizzazione intera e nello slicing. In caso di stringhe, possiamo usare delle parentesi quadre per ottenere la stessa funzionalit\u00e0 di <code>evne_items()</code> in modo pi\u00f9 efficiente:</p> <pre><code>&gt;&gt;&gt; list(alphabet[1::2])\n['b', 'd', 'f', 'h', 'j', 'l', 'n', 'p', 'r', 't', 'v', 'x', 'z']\n</code></pre> <p>Usando lo string slicing qui, diamo all'indice di partenza <code>1</code>, che corrisponde al secondo elemento. Non vi \u00e8 un indice finale dopo la prima virgola, per cui Python va fino alla fine della stringa. Quindi aggiungiamo la seconda virgola seguita da un 2, in modo che Python prenda ogni elemento pari.</p> <p>Tuttavia, come visto in precedenza, i generator e gli iterator non possono essere indicizzati o con slicing, per cui troveremo sempre utile <code>enumerate()</code>. Per continuare l'esempio precedente, possiamo creare una funzione generator che restituisce le lettere dell'alfabeto su richiesta:</p> <pre><code>&gt;&gt;&gt; def alphabet():\n...     alpha = \"abcdefghijklmnopqrstuvwxyz\"\n...     for a in alpha:\n...         yield a\n&gt;&gt;&gt; alphabet[1::2]\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'function' object is not subscriptable\n&gt;&gt;&gt; even_items(alphabet())\n['b', 'd', 'f', 'h', 'j', 'l', 'n', 'p', 'r', 't', 'v', 'x', 'z']\n</code></pre> <p>In questo esempio, definiamo <code>alphabet()</code>, una funzione generator che restituisce le lettere dell'alfabeto una ad una quando la funzione \u00e8 usata in un loop. Le funzioni Python, siano esse generator o funzioni regolari, non possono essere accedute mediante l'indicizzazione con parentesi quadre. Questo viene provato sulla seconda riga e lancia un TypeError.</p> <p>Possiamo usare le funzioni generator in dei loop, tuttavia, e lo facciamo sull'ultima riga passando <code>alphabet()</code> ad <code>even_items()</code>. Possiamo vedere che i risultati sono gli stessi dei due esempi precedenti.</p>"},{"location":"material/01_python/03_advanced/enumerate/#comprendere-la-funzione-enumerate","title":"Comprendere la funzione enumerate()","text":"<p>Nell'ultima parte abbiamo visto esempi di quando e come usare enumerate() a nostro vantaggio. Ora che abbiamo visto un assaggio degli aspetti pratici di enumerate(), possiamo capire di pi\u00f9 su come la funzione lavora internamente.</p> <p>Per ottenere un migliore comprensione di come funziona enumerate(), possiamo implementare la nostra versione con Python. La nostra versione di enumerate() ha due requisiti:</p> <ul> <li>accettare un iterabile ed un valore di conteggio iniziale come argomenti</li> <li>mandare indietro una tupla con l'attuale valore di conteggio e l'oggetto associato dall'iterabile</li> </ul> <p>Un modo di scrivere una funzione che rispetti queste specifiche \u00e8 data nella documentazione Python:</p> <pre><code>&gt;&gt;&gt; def my_enumerate(sequence, start=0):\n...     n = start\n...     for elem in sequence:\n...         yield n, elem\n...         n += 1\n...\n</code></pre> <p>La funzione <code>my_enumerate()</code> prende due argomenti, <code>sequence</code> e <code>start</code>. Il valore di default di start \u00e8 0. All'interno della definizione di funzione, si inizializza <code>n</code> per essere il valore di start ed eseguire un ciclo for nella sequenza.</p> <p>Per ogni elem nella sequenza, ci d\u00e0 il controlo alla posizione chiamante ed invia all'indietro il valore attuale di <code>n</code> ed <code>elem</code>. Infine, incrementiamo <code>n</code> per essere pronti all'iterazione successiva. Possiamo vedere <code>my_enumerate()</code> in azione:</p> <pre><code>&gt;&gt;&gt; seasons = [\"Spring\", \"Summer\", \"Fall\", \"Winter\"]\n&gt;&gt;&gt; my_enumerate(seasons)\n&lt;generator object my_enumerate at 0x7f48d7a9ca50&gt;\n&gt;&gt;&gt; list(my_enumerate(seasons))\n[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]\n&gt;&gt;&gt; list(my_enumerate(seasons, start=1))\n[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')]\n</code></pre> <p>Per prima cosa, creiamo una lista di quattro stagioni con cui lavorare. Inoltre, mostriamo che chiamare <code>my_enumerate()</code> con <code>seasons</code> in quanto la sequenza crea un generator. Questo \u00e8 perch\u00e9 usiamo la parola chaive <code>yield</code> per inviare i valori indietro al chiamante.</p> <p>Infine, creiamo due liste da <code>my_enumrate()</code>, uno nel quale il valore <code>start</code> \u00e8 lasciato di default (0) ed uno nel quale start \u00e8 cambiato ad 1. In entrambi i casi, finiamo con una lista di tuple nella quale il primo elemenot di ogni tupla \u00e8 il conteggio ed il secondo elemento \u00e8 il valore da seasons.</p> <p>Anche se possiamo implementare una funzione di equivalente per enumerate() in poche righe di codice Python, il codice vero e proprio di enumerate() \u00e8 scritto in C. Questo significa che \u00e8 molto veloce ed efficiente.</p>"},{"location":"material/01_python/03_advanced/enumerate/#spacchettare-gli-argomenti-con-enumerate","title":"Spacchettare gli argomenti con enumerate()","text":"<p>Quando usiamo enumeratre() in un ciclo for, diciamo a Python di usare due variabili, uno per il conteggio ed uno per il valore. Siamo abile di fare qeusto usando un concetto Python chiamato argument unpacking.</p> <p>TODO DA QUI</p> <p>Unpacking Arguments With enumerate() When you use enumerate() in a for loop, you tell Python to use two variables, one for the count and one for the value itself. You\u2019re able to do this by using a Python concept called argument unpacking.</p> <p>Argument unpacking is the idea that a tuple can be split into several variables depending on the length of the sequence. For instance, you can unpack a tuple of two elements into two variables:</p> <p>tuple2 = (10, \"a\") firstelem, secondelem = tuple2 firstelem 10 secondelem 'a' First, you create a tuple with two elements, 10 and \"a\". Then you unpack that tuple into firstelem and secondelem, which are each assigned one of the values from the tuple.</p> <p>When you call enumerate() and pass a sequence of values, Python returns an iterator. When you ask the iterator for its next value, it yields a tuple with two elements. The first element of the tuple is the count, and the second element is the value from the sequence that you passed:</p> <p>values = [\"a\", \"b\"] enuminstance = enumerate(values) enuminstance  next(enuminstance) (0, 'a') next(enuminstance) (1, 'b') next(enuminstance) Traceback (most recent call last):   File \"\", line 1, in  StopIteration In this example, you create a list called values with two elements, \"a\" and \"b\". Then you pass values to enumerate() and assign the return value to enuminstance. When you print enum_instance, you can see that it\u2019s an instance of enumerate() with a particular memory address. <p>Then you use Python\u2019s built-in next() to get the next value from enuminstance. The first value that enuminstance returns is a tuple with the count 0 and the first element from values, which is \"a\".</p> <p>Calling next() again on enuminstance yields another tuple, this time with the count 1 and the second element from values, \"b\". Finally, calling next() one more time raises StopIteration since there are no more values to be returned from enuminstance.</p> <p>When an iterable is used in a for loop, Python automatically calls next() at the start of every iteration until StopIteration is raised. Python assigns the value it retrieves from the iterable to the loop variable.</p> <p>If an iterable returns a tuple, then you can use argument unpacking to assign the elements of the tuple to multiple variables. This is what you did earlier in this tutorial by using two loop variables.</p> <p>Another time you might have seen argument unpacking with a for loop is with the built-in zip(), which allows you to iterate through two or more sequences at the same time. On each iteration, zip() returns a tuple that collects the elements from all the sequences that were passed:</p> <p>first = [\"a\", \"b\", \"c\"] second = [\"d\", \"e\", \"f\"] third = [\"g\", \"h\", \"i\"] for one, two, three in zip(first, second, third): ...     print(one, two, three) ... a d g b e h c f i By using zip(), you can iterate through first, second, and third at the same time. In the for loop, you assign the element from first to one, from second to two, and from third to three. Then you print the three values.</p> <p>You can combine zip() and enumerate() by using nested argument unpacking:</p> <p>for count, (one, two, three) in enumerate(zip(first, second, third)): ...     print(count, one, two, three) ... 0 a d g 1 b e h 2 c f i In the for loop in this example, you nest zip() inside enumerate(). This means that each time the for loop iterates, enumerate() yields a tuple with the first value as the count and the second value as another tuple containing the elements from the arguments to zip(). To unpack the nested structure, you need to add parentheses to capture the elements from the nested tuple of elements from zip().</p> <p>There are other ways to emulate the behavior of enumerate() combined with zip(). One method uses itertools.count(), which returns consecutive integers by default, starting at zero. You can change the previous example to use itertools.count():</p> <p>import itertools for count, one, two, three in zip(itertools.count(), first, second, third): ...     print(count, one, two, three) ... 0 a d g 1 b e h 2 c f i Using itertools.count() in this example allows you to use a single zip() call to generate the count as well as the loop variables without nested argument unpacking.</p> <p>Remove ads Conclusion Python\u2019s enumerate() lets you write Pythonic for loops when you need a count and the value from an iterable. The big advantage of enumerate() is that it returns a tuple with the counter and value, so you don\u2019t have to increment the counter yourself. It also gives you the option to change the starting value for the counter.</p> <p>In this tutorial, you learned how to:</p> <p>Use Python\u2019s enumerate() in your for loops Apply enumerate() in a few real-world examples Get values from enumerate() using argument unpacking Implement your own equivalent function to enumerate() You also saw enumerate() used in some real-world code, including within the CPython code repository. You now have the superpower of simplifying your loops and making your Python code stylish!</p>"},{"location":"material/01_python/03_advanced/exceptions/","title":"1.6 - La gestione degli errori","text":"<p>Nella maggior parte dei linguaggi interpretati, l'esecuzione di un programma termina non appena viene individuato un errore.</p> <p>In Python, esistono due tipi di errore: il primo \u00e8 quello sintattico, mentre il secondo \u00e8 chiamato eccezione.</p>"},{"location":"material/01_python/03_advanced/exceptions/#161-errori-sintattici-ed-eccezioni","title":"1.6.1 - Errori sintattici ed eccezioni","text":"<p>Gli errori di sintassi avvengono qunado il parser individua un'istruzione scritta in maniera non corretta. Ad esempio:</p> <pre><code>&gt;&gt;&gt; print(0/0))\nFile \"&lt;stdin&gt;\", line 1\nprint(0/0))\n^\nSyntaxError: unmatched ')'\n</code></pre> <p>In questo caso, notiamo la presenza di una parentesi di chiusura di troppo. Di conseguenza, Python lancia un <code>SyntaxError</code>, indicandoci anche dove \u00e8 occorso l'errore (in questo caso, mediante l'informazione <code>unmatched ')'</code>).</p> <p>Proviamo adesso a rimuovere la parentesi.</p> <pre><code>&gt;&gt;&gt; print(0/0)\n</code></pre> <p>Se proviamo ad eseguire questa istruzione, avremo l'altro tipo di errore, ovvero l'eccezione. In questo caso, infatti, il codice risulta essere (sintatticamente) corretto, ma \u00e8 comunque occorso un evento ritenuto \"impossibile\", che viene adeguatamente descritto nel <code>Traceback</code>:</p> <pre><code>Traceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nZeroDivisionError: division by zero\n</code></pre> <p>In particolare, notiamo come il traceback ci dia diverse informazioni:</p> <ul> <li>il file dove \u00e8 stata generata l'eccezione. In questo caso, viene riportato <code>&lt;stdin&gt;</code> perch\u00e9 il codice precedente \u00e8 stato inserito mediante interprete;</li> <li>la riga dove \u00e8 occorsa l'eccezione. In questo caso, notiamo che \u00e8 riportato <code>line 1</code>;</li> <li>il tipo di eccezione occorsa, con una breve descrizione dell'errore. In questo caso, notiamo come venga lanciata una <code>ZeroDivisionError</code>, che occorre quando il secondo argomento della divisione \u00e8 pari a 0.</li> </ul> <p>Eccezioni built-in</p> <p>Notiamo come l'eccezione <code>ZeroDivisionError</code> sia una built-in exception, ovvero un'eccezione gi\u00e0 integrata nel linguaggio Python, che comunque ci offre la possibilit\u00e0 di definire da noi nuovi tipi di eccezione. Per una panoramica completa, consultare la reference.</p>"},{"location":"material/01_python/03_advanced/exceptions/#162-lanciare-uneccezione","title":"1.6.2 - Lanciare un'eccezione","text":"<p>Possiamo lanciare una specifica eccezione all'occorrenza di una condizione non voluta all'interno del nosro codice utilizzando l'istruzione <code>raise</code>. Ad esempio, possiamo verificare che il valore di una variabile non sia superiore ad un dato numero:</p> <pre><code>x = 10\nif x &gt; 5:\nraise Exception(f'x vale {x}. Non deve superare 5.')\n</code></pre> <p>Provando ad eseguire il codice precedente, avremo il seguente risultato:</p> <pre><code>Traceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 2, in &lt;module&gt;\nException: x vale 10. Non deve superare 5.\n</code></pre> <p>Dal traceback, notiamo come sia stata lanciata un'eccezione generica con il messaggio da noi elaborato.</p>"},{"location":"material/01_python/03_advanced/exceptions/#163-listruzione-assert","title":"1.6.3 - L'istruzione assert","text":"<p>Un altro modo di gestire situaizoni impreviste \u00e8 quello di utilizzare l'istruzione <code>assert</code>, che verifica la condizione passata come parametro. Se tale condizione risulta essere vera, il programma continuer\u00e0 la sua esecuzione; in alternativa, sar\u00e0 lanciata un'eccezione di tipo <code>AssertionError</code>.</p> <p>Possiamo, ad esempio, verificare che il nostro codice sia eseguito su un sistema Windows.</p> <pre><code>import sys\nassert ('win32' in sys.platform), 'Questo codice pu\u00f2 essere eseguito solo su una macchina Windows!'\n</code></pre> <p>Eseguendo questa istruzione su una macchina Windows, non sar\u00e0 lanciata alcuna eccezione, ed il programma continuer\u00e0 tranquillamente l'esecuzione. Eseguendo invece lo stesso codice su una macchina Unix, sar\u00e0 lanciata un'<code>AssertionError</code>, ed il programma terminer\u00e0:</p> <pre><code>Traceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nAssertionError: Questo codice pu\u00f2 essere eseguito solo su una macchina Windows!\n</code></pre>"},{"location":"material/01_python/03_advanced/exceptions/#164-gestione-delle-eccezioni-il-blocco-tryexcept","title":"1.6.4 - Gestione delle eccezioni: il blocco try/except","text":"<p>Abbiamo visto come le istruzioni <code>raise</code> ed <code>assert</code> permettano di verificare rispettivamente l'occorrenza di un errore o di una determinata condizione. Tuttavia, \u00e8 possibile gestire le situazioni in cui avviene un errore; per farlo, \u00e8 necessario utilizzare il blocco <code>try/except</code>.</p> <p>Nella pratica, durante l'esecuzione normale del programma, Python eseguir\u00e0 regolarmente le istruzioni contenute nella clausola <code>try</code>. Tuttavia, se viene riscontrata un'eccezione, il controllo passer\u00e0 direttamente alla clausola <code>except</code>, cui \u00e8 delegato il compito di gestirla. Questo funzionamento \u00e8 schematizzato nella figura successiva.</p> <pre><code>---\ntitle: Flusso in un blocco try/except\n---\nstateDiagram-v2\n    state if_state &lt;&lt;choice&gt;&gt;\n    state join_state &lt;&lt;join&gt;&gt;\n    \"Programma\" --&gt; \"Blocco try/except\"\n    \"Clausola try\" --&gt; if_state\n    if_state --&gt; \"Clausola except\": Eccezione\n    \"Clausola except\" --&gt; join_state\n    if_state --&gt; join_state\n    join_state --&gt; \"Programma\"</code></pre> <p>Notiamo come l'esecuzione del programma debba (idealmente) continuare, che la clausola <code>except</code> venga eseguita o meno. Proviamo a definire la funzione <code>controlla_sistema_operativo()</code>, che controlla se siamo su Windows:</p> <pre><code>def controlla_sistema_operativo():\nassert ('win32' in sys.platform), 'Questo codice pu\u00f2 essere eseguito solo su una macchina Windows!'\nprint('Il sistema operativo \u00e8 Windows!')\n</code></pre> <p>Nella funzione <code>controlla_sistema_operativo()</code>, l'istruzione <code>assert</code> controlla che si sia su una macchina Windows; in caso contrario, sar\u00e0 lanciata un'eccezione di tipo <code>AssertionError</code>. Proviamo ad integrare la funzione all'interno di un blocco <code>try/except</code>:</p> <pre><code>try:\ncontrolla_sistema_operativo()\nexcept:\npass\n</code></pre> <p>In questo caso, la gestione dell'errore sar\u00e0 delegata ad un'istruzione <code>pass</code> che, come sappiamo, non fa nulla. Eseguendo questo codice su una macchina Windows, sar\u00e0 mandato a schermo il messaggio <code>Il sistema operativo \u00e8 Windows!</code>, indice del fatto che l'<code>assert</code> non ha lanciato un'eccezione di tipo <code>AssertionError</code>. Se invece dovessimo eseguire questa funzione su una macchina Linux, non avremmo alcun risultato: infatti, la clausola <code>try</code> catturerebbe l'<code>AssertionError</code> e ne delegherebbe la gestione alla clausola <code>except</code>, che si limita ad eseguire un'istruzione <code>pass</code>.</p> <p>Proviamo a modificare il codice precedente come segue:</p> <pre><code>try:\ncontrolla_sistema_operativo()\nexcept:\nprint('Sembra che non siamo su Windows!')\n</code></pre> <p>Eseguendo questo codice su macchina Linux, avremo il seguente messaggio:</p> <pre><code>Sembra che non siamo su Windows!\n</code></pre>"},{"location":"material/01_python/03_advanced/exceptions/#1641-gestione-di-eccezioni-specifiche","title":"1.6.4.1 - Gestione di eccezioni specifiche","text":"<p>Come \u00e8 possibile verificare dal codice precedente, qualora venga lanciata un'eccezione, non sar\u00e0 pi\u00f9 disponibile il Traceback visto in precedenza, bens\u00ec il messaggio <code>Sembra che non siamo su Windows!</code>. Ci\u00f2 comporta un problema: infatti, non avremo informazioni a riguardo di quale eccezione sia stata lanciata. Per recuperare queste informazioni, dovremo fare una modifica all'istruzione <code>except</code>:</p> <pre><code>try:\ncontrolla_sistema_operativo()\nexcept AssertionError as error:\nprint(error)\nprint('Sembra che non siamo su Windows!')\n</code></pre> <p>Eseguendo questa funzione su macchina Linux, l'output sar\u00e0 stavolta il seguente:</p> <pre><code>Questo codice pu\u00f2 essere eseguito solo su una macchina Windows!\nSembra che non siamo su Windows!\n</code></pre> <p>Il primo messaggio, quindi, \u00e8 lanciato a valle della mancata verifica della condizione nella clausola <code>assert</code> specificata in <code>controlla_sistema_operativo()</code>, mentre il secondo \u00e8 direttamente specificato nella clausola <code>except</code>.</p> <p>Vediamo un altro esempio, nel quale proviamo ad aprire un file, gestendo l'eccezione lanciata quando questo non esiste:</p> <pre><code>try:\nwith open('file.log') as file:\nread_data = file.read()\nexcept:\nprint('Impossibile aprire il file specificato.')\n</code></pre> <p>Eseguendo questo codice, una volta appurato che <code>file.log</code> non esiste, avremo il seguente messaggio:</p> <pre><code>Impossibile aprire il file specificato.\n</code></pre> <p>Nonostante il messaggio sia abbastanza informativo, stiamo comunque gestendo tutte le possibili eccezioni all'interno della clausola <code>except</code>. Cerchiamo quindi di trovarne una pi\u00f9 adatta al nostro scopo tra quelle specificate nella reference Python. In particolare, scegliamo l'eccezione FileNotFoundError, e modifichiamo il codice come segue:</p> <pre><code>try:\nwith open('file.log') as file:\nread_data = file.read()\nexcept FileNotFoundError as error:\nprint(error)\n</code></pre> <p>In questo caso, se <code>file.log</code> non esiste, in output sar\u00e0 mandato il messaggio associato all'eccezione <code>FileNotFoundError</code>, ovvero:</p> <pre><code>[Errno 2] No such file or directory: 'file.log'\n</code></pre>"},{"location":"material/01_python/03_advanced/exceptions/#1642-eccezioni-multiple","title":"1.6.4.2 - Eccezioni multiple","text":"<p>A questo punto \u00e8 importante sottolineare come il blocco <code>try/except</code> sia in grado di gestire situazioni anche abbastanza complesse. Infatti, laddove \u00e8 evidente come la clausola <code>try</code> sia in grado di contenere diverse istruzioni, anche la clausola <code>except</code> pu\u00f2 gestire diverse tipologie di eccezione.</p> <p>In tal senso, proviamo a modificare il nostro codice, controllando dapprima il sistema operativo, e poi provando a leggere un file:</p> <pre><code>try:\ncontrolla_sistema_operativo()\nwith open('file.log') as file:\nread_data = file.read()\nexcept FileNotFoundError:\nprint('Il file specificato non esiste.')\nexcept AssertionError as error:\nprint(error)\nprint('Sembra che non siamo su Windows!')\n</code></pre> <p>Vediamo cosa succede in due diversi casi. Per prima cosa, eseguiamo il codice su macchina Linux, con <code>file.log</code> non esistente. In questo caso, il codice dar\u00e0 in output i seguenti messaggi:</p> <pre><code>Questo codice pu\u00f2 essere eseguito solo su una macchina Windows!\nSembra che non siamo su Windows!\n</code></pre> <p>In pratica, la prima istruzione del <code>try</code>, delegata al controllo del sistema operativo, riscontra un'eccezione, per cui viene chiamata la seconda clausola <code>except</code>. Nel caso invece si esegua il codice su macchina Windows, e supponendo sempre l'assenza di <code>file.log</code>, il risultato sar\u00e0 il seguente:</p> <pre><code>Siamo su Windows!\nIl file specificato non esiste.\n</code></pre> <p>In questo caso, la clausola <code>try</code> non ha riscontrato problemi nell'esecuzione della prima istruzione. Tuttavia, l'eccezione \u00e8 stata lanciata in corrispondenza della fase di lettura del file, lanciando un'eccezione gestita dalla prima clausola <code>except</code>.</p>"},{"location":"material/01_python/03_advanced/exceptions/#165-la-clausola-else","title":"1.6.5 - La clausola else","text":"<p>La clausola <code>else</code> pu\u00f2 essere usata in abbinamento al blocco <code>try/except</code> per eseguire un certo blocco di codice soltanto in assenza di eccezioni. Ad esempio:</p> <pre><code>try:\ncontrolla_sistema_operativo()\nexcept AssertionError as error:\nprint(error)\nelse:\nprint('Il sistema operativo \u00e8 Windows!')\n</code></pre> <p>Eseguendo questo codice su Windows, il programma non riscontrer\u00e0 alcuna eccezione, e l'output sar\u00e0 quello esplicitato nella clausola <code>else</code>:</p> <pre><code>Siamo su Windows!\nIl sistema operativo \u00e8 Windows!\n</code></pre> <p>Potremmo usare una clausola <code>else</code> per gestire ulteriori eccezioni. Ad esempio, proviamo ad eseguire questo blocco di codice su una macchina Windows (e senza il file <code>file.log</code>):</p> <pre><code>try:\ncontrolla_sistema_operativo()\nexcept AssertionError as error:\nprint(error)\nelse:\ntry:\nwith open('file.log') as file:\nread_data = file.read()\nexcept FileNotFoundError:\nprint('Il file specificato non esiste.')\n</code></pre> <p>Il risultato sar\u00e0:</p> <pre><code>Siamo su Windows!\nIl file specificato non esiste.\n</code></pre> <p>Suggerimento</p> <p>Ricordiamo sempre che la clausola <code>else</code> viene eseguita soltanto se non sono state trovate eccezioni. Se \u00e8 stata trovata un'eccezione, e gestita nell'<code>except</code>, il flusso del programma continuer\u00e0 comunque la sua regolare esecuzione, ma l'<code>else</code> non sar\u00e0 invocato.</p>"},{"location":"material/01_python/03_advanced/exceptions/#166-la-clausola-finally","title":"1.6.6 - La clausola finally","text":"<p>La clausola <code>finally</code> ci permette di eseguire delle istruzioni indipendentemente dal fatto che siano state riscontrate o meno eccezioni in un blocco <code>try/except</code> antecedente. Andiamo a modificare leggermente il codice relativo all'ultimo esempio:</p> <pre><code>try:\nsu_windows()\nexcept AssertionError as error:\nprint(error)\nelse:\ntry:\nwith open('file.log') as file:\nread_data = file.read()\nexcept FileNotFoundError:\nprint('Il file specificato non esiste.')\nfinally:\nprint('Istruzioni eseguite indipendentemente dal resto del programma.')\n</code></pre> <p>In questo caso, ci\u00f2 che viene inserito nella clausola <code>finally</code> sar\u00e0 sempre eseguito, indipendentemente da ci\u00f2 che \u00e8 accaduto nel codice precedente. Provando ad eseguire questo codice su macchina Windows in assenza di <code>file.log</code>, avremo il seguente output:</p> <pre><code>Siamo su Windows!\nIl file specificato non esiste.\nIstruzioni eseguite indipendentemente dal resto del programma.\n</code></pre> <p>L'utilit\u00e0 della clausola <code>finally</code></p> <p>La clausola <code>finally</code> trova utilit\u00e0 in tutte quelle situazioni nelle quali \u00e8 necessario effettuare delle operazioni a valle della gestione dell'eccezione. Queste operazioni sono spesso definite \"di pulizia\", perch\u00e9 prevedono l'eliminazione di stati o variabili che possono occupare memoria e che non sono pi\u00f9 utili ai fini dell'esecuzione del programma.</p>"},{"location":"material/01_python/03_advanced/exceptions/#166-per-ricapitolare","title":"1.6.6 - Per ricapitolare...","text":"<p>In questa lezione, abbiamo:</p> <ul> <li>visto la differenza tra errore sintattico ed eccezione;</li> <li>utilizzato l'istruzione <code>raise</code> per lanciare un'eccezione in qualsiasi momento;</li> <li>utilizzato l'istruzione <code>assert</code> per verificare il rispetto di una determinata condizione, lanciando in caso contrario un <code>AssertionError</code>;</li> <li>utilizzato la clausola <code>try</code> per verificare l'occorrenza di eccezioni all'interno di un blocco di istruzioni;</li> <li>utilizzato la clausola <code>except</code> per catturare e gestire una o pi\u00f9 delle eccezioni trovate nella clausola <code>try</code> corrispondente;</li> <li>utilizzato la clausola <code>else</code> per eseguire blocchi di codice esclusivamente nel caso non siano state individuate eccezioni nel <code>try</code> precedente;</li> <li>utilizzato la clausola <code>finally</code> per eseguire blocchi di codice indipendentemente dal fatto che siano state individuate o meno eccezioni.</li> </ul> <p>Nella prossima lezione andremo ad introdurre i principi alla base della programmazione funzionale.</p>"},{"location":"material/01_python/03_advanced/func_prog/","title":"1.7: La programmazione funzionale","text":"<p>La programmazione funzionale \u00e8 un paradigma di programmazione che definisce l'elaborazione del dato attraverso e concetti di funzione e stato immutabile.</p> <p>Per comprendere cosa questo comporti, \u00e8 utile pensare alla programmazione imperativa. In questo paradigma, infatti, l'elaborazione avviene mediante le singole istruzioni scritte nel codice sorgente, le quali consistono di una serie di comandi la cui esecuzione modifica il valore di una variabile e, conseguentemente, lo stato del programma. Ad esempio, un ciclo esegue ripetutamente una certa istruzione, cambiando di volta in volta il valore di una variabile:</p> <pre><code>contatore = 0\nfor i in range(10):\ncontatore += 1\n</code></pre> <p>Man mano che il valore di <code>contatore</code> aumenta, lo stato delle variabili varia di conseguenza. Di contro, la programmazione funzionale elimina il concetto di stato. Invece di modificare i valori delle variabili, questo tipo di programmazione lavora soltanto su tipi immutabili che, come sappiamo, non possono essere alterati. Di conseguenza, la programmazione funzionale lavora esclusivamente su copie della strutture dati originarie. Inoltre, mentre nella programmazione imperativa usiamo normalmente costrutti come sequenze, cicli ed iterazioni, nella programmazione funzionale usiamo esclusivamente funzioni per modificare i dati, il che risulta in soluzioni pi\u00f9 eleganti, maggiormente modulari, e potenzialmente pi\u00f9 efficienti.</p> <p>Prima di iniziare a parlare di programmazione funzionale in Python, tuttavia, \u00e8 necessario introdurre alcuni concetti fondamentali.</p>"},{"location":"material/01_python/03_advanced/func_prog/#171-le-funzioni-di-ordine-superiore","title":"1.7.1 - Le funzioni di ordine superiore","text":"<p>Le funzioni di ordine superiore sono ampiamente utilizzate nella programmazione funzionale, e non sono altro che funzioni che possono a loro volta accettare una funzione come argomento, o restituire una funzione in uscita. </p> <p>Le funzioni di ordine superiore sono lo strumento principale per definire l'elaborazione nella programmazione funzionale. Queste sono funzioni che possono accettare una funzione come argomento, o restituire una funzione in uscita. In Python, <code>reduce()</code>, <code>map()</code> e <code>filter()</code> sono alcune tra le pi\u00f9 importanti funzioni di ordine superiore. Quando combinate con funzioni pi\u00f9 semplici, possono essere usate epr eseguire operazioni complesse.</p> <p>Vediamo un esempio di funzione di ordine superiore. In particoalre, <code>stampa_saluto()</code> accetta una funzione <code>f</code> ed una stringa <code>n</code> come argomenti, e restituisce la chiamata alla funzione <code>f</code> con argomento <code>n</code>, ovvero <code>f(n)</code>.</p> <pre><code>&gt;&gt;&gt; def saluto(nome):\n...     return f'Buongiorno, {}!'\n...\n&gt;&gt;&gt; def stampa_saluto(f, n):\n...     print(f(n))\n...\n&gt;&gt;&gt; stampa_saluto(saluto, 'Mondo')\nBuongiorno, Mondo!\n</code></pre>"},{"location":"material/01_python/03_advanced/func_prog/#funzioni-anonime","title":"Funzioni anonime","text":"<p>Abbiamo visto un esempio di una funzione che accetta come argomento un'altra funzione. <code>map()</code>, <code>filter()</code> e <code>reduce()</code> funzionano allo stesso modo: ognuno di loro accetta una funzione ed una sequenza di elementi, restituendo il risutato dell'applicazione della funzi0one ricevuta ad ogni elemento della sequenza. Nei due esempi precedenti, abbiamo definito le nostre funzioni suando la parola chiave <code>def</code> di Python. Questo crea un oggetto Python chiamabile che esegue l'istruzione specificata all'interno della sua definizione ogni volta che lo chiamiamo.</p> <p>Tuttavia, nella programmazione funzionale, le funzioni anonime (anche chiamate funzioni lambda) sono preferite. Ne parleremo estesamente nella prossima lezione. Tuttavia, per ora ci basti sapere che sono chiamate anonime perch\u00e9 non sono \"collegate\" ad alcun nome, allineandosi quindi alla tendenza della programmaizone funzionale verso l'assenza di stato. In pratica, la differenza principale tra le funzioni lambda e le funzioni Python normali sta nel fatto che la funzione lambda valuta una singola espressione restituendo una funzione, mentre le funzioni normali non lo fanno (necessariamente). In altri termini, le funzioni lambda non possono usare delle istruzioni come le condizionali, o anche un semplice <code>return</code>. Ecco un esempio di funzione lambda:</p> <pre><code>&gt;&gt;&gt; (lambda x: x + 1)(5)\n6\n</code></pre> <p>Potremmo definire questa operazione usando la parola chiave <code>def</code> ed otterremmo lo stesso output:</p> <pre><code>&gt;&gt;&gt; def aggiungi_uno(x):\n...     return x + 1\n...\n&gt;&gt;&gt; aggiungi_uno(5)\n6\n</code></pre> <p>In pratica, nel primo snippet, abbiamo usato la keyword <code>lambda</code>per definire una funzione inline, chiamandola con argomento <code>x = 5</code>. La funzione \u00e8 stata immediatamente valutata, ed un output prodotto. A differenza del secondo snippet, la funzione lambda non era legata ad un nome, per cui, per utilizzarla nuovamente, dovremmo riscrivere l'istruzione.</p> <p>Le funzioni lambda sono importanti per <code>map()</code>, <code>filter()</code> e <code>reduce()</code> perch\u00e9 gli argomenti che passiamo a queste funzioni sono spesso funzioni brevi che devono essere usate soltanto una volta nei nostri programmi, per cui non vi \u00e8 alcun motivo per salvarle. A differenza delle funzioni regolari che devono essere definite e salvate in memoria, le funzioni anonime sono pi\u00f9 concise, e vengono eliminate dopo l'esecuzione.</p> <p>Ora che abbiamo visto i preliminari, diamo uno sguardo pi\u00f9 approfondito alle funzioni <code>map()</code>, <code>filter()</code> e <code>reduce()</code>.</p>"},{"location":"material/01_python/03_advanced/func_prog/#map","title":"map()","text":"<p>La funzione <code>map()</code> di Python ha la seguente sintassi:</p> <pre><code>map(function, *sequence)\n</code></pre> <p>In pratica, <code>map()</code> applica la funzione ricevuta al primo argomento ad ogni elemento nella sequenza <code>sequence</code>, restituendo la sequenza risultatnte. Nell'esempio successivo, creiamo una lista di interi ed usiamo <code>map()</code> e la funzione <code>str</code> di Python per convertire ogni intero in stringhe.</p> <pre><code>&gt;&gt;&gt; seq = list(range(10))\n&gt;&gt;&gt; list(map(str, seq))\n['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n</code></pre> <p>Notiamo come i risultati restituiti dalla funzione <code>map()</code> siano a loro volta racchiusi in una lista. Questo \u00e8 legato al fatto che, in realt\u00e0, la funzione <code>map()</code> restituisce un generator.</p> <pre><code>&gt;&gt;&gt; map(str, seq)\n&lt;map object at 0x000001BB7143F100&gt;\n</code></pre> <p>I generatori Python adottano una astrategia conosciutra come lazy evaluation, il che implica che Python non conosce il valore di un oggetto fino a che non lo usa. Anche se pu\u00f2 sembrare controintuitivo, valuter un oggetto in maniera \"lazy\" permette di aumentare l'efficienza del codice riducendo il numero di elabroazioni non necessarie. Questo \u00e8 il motivo per cui abbiamo racchiuso il generator creato da <code>map()</code> in una lista: farlo valuta l'espressione del generatore, e permette di inserire i risultati in un oggetto di tipo lista facilmente accessibile.</p> <p>Nota</p> <p>Le list comprehension hanno lo stesso scopo della funzione <code>map()</code>. Tuttavia, in questo caso, non abbiamo lazy evaluation.</p>"},{"location":"material/01_python/03_advanced/func_prog/#filter","title":"filter()","text":"<p>La funzione <code>filter()</code> di Python ha la seguente sintassi:</p> <pre><code>filter(function, *sequence)\n</code></pre> <p>In questo caso, filter() prende una funzione chiamata predicato che restituisce <code>True</code> se un elemento soddisfa la condizione definita nel predicato, e <code>Falso</code>altrimenti. L'output della funzione <code>filter()</code>consiste degli elementi della sequenza originaria che soddisfano il predicato.</p> <p>Nel codice seguente, usiamo una funzione <code>filter()</code> su una sequenza di nomi per individuare quelli che iniziano per <code>A</code>:</p> <pre><code>&gt;&gt;&gt; nomi = ['Angelo', 'Andrea', 'Giovanni', 'Paolo', 'Mario', 'Luca']\n&gt;&gt;&gt; list(filter(lambda x: x[0] == 'A', nomi))\n['Angelo', 'Andrea']\n</code></pre> <p>I nomi per i quali la funzione lambda restituisce <code>True</code> sono Angelo ed Andrea, come prevedibile. Il resto della sequenza viene quindi trascurato.</p> <p>Nota</p> <p>Anche in questo caso avremmo potuto utilizzare una list comprehension, ottenendo una soluzione sicuramente maggiormente pythonic.</p> <p>Potremmo anche concatenare le funzioni <code>map()</code> e <code>filter()</code> nella stessa chiamata. Se, ad esempio, volessimo ottenere i nomi che iniziano per <code>A</code> e convertirli in maiuscolo, potremmo usare la seguente istruzione:</p> <pre><code>&gt;&gt;&gt; list(map(lambda x: x.upper(), filter(lambda x: x[0] == 'A', nomi)))\n['ANGELO', 'ANDREA']\n</code></pre> <p>In pratica, stiamo mappando la funzione lambda <code>x: x.upper()</code>, che trasforma le stringhe in maiuscolo, sui risultati della <code>filter()</code> precedentemente considerata.</p>"},{"location":"material/01_python/03_advanced/func_prog/#reduce","title":"reduce()","text":"<p>La funzione <code>reduce()</code> non restituisce una nuova sequenza come <code>map()</code> o <code>filter()</code>. Invece, restituisce un singolo valreo. La sintassi \u00e8 simile a quella delle altre due funzioni:</p> <pre><code>reduce(function, *sequence)\n</code></pre> <p>In questo caso, <code>reduce()</code> applica la funzione agli elementi della sequenza, da sinsitra verso destra, iniziando con i primi due elementi della sequenza. Combiniamo quindi i risultati dell\u00ec'applciazione della funzione ai primi due elmeenti della sequezna con il terzo elemnto, passandolo ad un'altra chiamata alla stessa funzione. Questo processo si ripete fino a che non raggiungiamo la fine dell'iteratore, e questo viene ridotto ad un singolo valore.</p> <p>Vediamo un esempio dove <code>reduce()</code> prende come argomento una funzione lambda che moltiplica due numeri consecutivamente:</p> <pre><code>&gt;&gt;&gt; from functools import reduce\n&gt;&gt;&gt; numeri = list(range(1, 5))\n&gt;&gt;&gt; numeri\n[1, 2, 3, 4]\n&gt;&gt;&gt; reduce(lambda x, y: x*y, numeri)\n24\n</code></pre> <p>Nota</p> <p>Notiamo che, a differenza di <code>map()</code> e <code>filter()</code>, la funzione <code>reduce()</code> non \u00e8 integrata in Python, ma deve essere importata dalla libreria <code>functools</code>.</p> <p>Se volessimo scrivere questa stessa funzione ricorrendo ad un approccio classic, potremmo usare un iteratore, oppure una serie ricorsiva di chiamate a funzione. Ad esempio:</p> <pre><code>&gt;&gt;&gt; def moltiplica(x, y):\n...     return x*y\n...\n&gt;&gt;&gt; moltiplica(moltiplica(moltiplica(4, 3), 2), 1) \n24\n</code></pre>"},{"location":"material/01_python/03_advanced/lambda/","title":"1.8 - Il calcolo lambda e la programmazione funzionale","text":"<p>Le espressioni lambda, le quali saranno oggetto di questa lezione, affondano le loro origini nel calcolo lambda, modello computazionale inventato da Alonzo Church negli anni '30 del ventesimo secolo.</p> <p>Il calcolo lambda \u00e8 un linguaggio puramente basato sul concetto di astrazione, ed \u00e8 in grado di codificare ogni possibile algoritmo. Di conseguenza, risulta essere Turing-completo ma, contrariamente alla macchina di Turing, non mantiene al suo interno alcuna informazione sullo stato.</p> <p>Da quello che abbiamo visto nella lezione precedente, quindi, appare chiaro come la programmazione funzionale affondi le sue origini in questo tipo di calcolo. Contestualmente, possiamo dedurre come il modello computazionale basato sullo stato ed introdotto da Alan Turing sia alla base del paradigma imperativo.</p> <p>Tesi di Church-Turing</p> <p>I modelli basati sul calcolo lambda possono essere tradotti in quelli basati sulle macchine di Turing, e viceversa. Questa equivalenza \u00e8 anche conosciuta come ipotesi di Church-Turing.</p>"},{"location":"material/01_python/03_advanced/lambda/#181-le-funzioni-lambda","title":"1.8.1 - Le funzioni lambda","text":"<p>Le funzioni lambda, chiamate anche funzioni anonime, sono dei costrutti che permettono una sintassi pi\u00f9 concisa rispetto alle normali funzioni e, nonostante una serie di restrizioni, lavorano assieme ai concetti visti in precedenza per implementare meccanismi di programmazione funzionale.</p> <p>Le funzioni lambda e le best practice Python</p> <p>Alcuni degli esempi che faremo ignoreranno deliberatamente le best practice definite da Python. Tuttavia, ci saranno utili ad illustrare i concetti alla base delle funzioni lambda.</p>"},{"location":"material/01_python/03_advanced/lambda/#1811-le-prime-funzioni-lambda","title":"1.8.1.1 - Le prime funzioni lambda","text":"<p>Iniziamo con un banale esempio, definendo una funzione <code>identita()</code> che restituisce l'argomento passatogli.</p> <pre><code>def identita(x):\nreturn x\n</code></pre> <p>Proviamo a definire la stessa funzione usando le lambda:</p> <pre><code>lambda x: x\n</code></pre> <p>Notiamo quindi che l'espressione \u00e8 composta da:</p> <ul> <li>la keyword <code>lambda</code>, che indica l'inizio della funzione lambda;</li> <li>la variabile <code>x</code>, che rappresenta l'argomento in ingresso alla funzione lambda;</li> <li>il corpo della funzione, che segue l'operatore <code>:</code>, ed in questo caso \u00e8 semplicemente <code>x</code>.</li> </ul> <p>Possiamo definire la variabile <code>x</code> come dipendente, che si differenzia da una variabile indipendente a causa del fatto che quest'ultima non \u00e8 vincolata, e pu\u00f2 essere referenziata nel corpo dell'espressione. Proviamo in tal senso a scrivere un esempio leggermente pi\u00f9 elaborato, definendo una funzione <code>incrementa()</code> che aggiunge <code>1</code> al suo argomento, assieme alla corrispondente funzione lambda:</p> Funzione classicaFunzione lambda <pre><code>def incrementa(x):\nreturn x + 1\n</code></pre> <pre><code>lambda x: x + 1\n</code></pre>"},{"location":"material/01_python/03_advanced/lambda/#1812-argomenti-ed-identificativi","title":"1.8.1.2 - Argomenti ed identificativi","text":"<p>Proviamo adesso ad applicare la funzione lambda definita in precedenza. Per farlo, dovremo circondare sia la funzione, sia l'argomento che vogliamo passare, tra parentesi tonde:</p> <pre><code>&gt;&gt;&gt; (lambda x: x + 1)(2)\n3\n</code></pre> <p>Come funziona?</p> <p>I pi\u00f9 curiosi potranno interrogarsi sul funzionamento interno della funzione lambda. Uno dei possibili approcci in tal senso \u00e8 quello della riduzione: in pratica, andiamo a rimpiazzare la variabile dipendente, <code>x</code> con l'argomento, <code>2</code>, ottenendo il seguente risultato:</p> <pre><code>(lambda x: x + 1)(2) = lambda 2: 2 + 1\n                    = 2 + 1\n                    = 3\n</code></pre> <p>Possiamo anche associare un identificativo alla funzione lambda. Per farlo, possiamo usare una sintassi di questo tipo:</p> <pre><code>incrementa = lambda x: x + 1\n</code></pre> <p>Le funzioni che abbiamo definito finora accettano un unico argomento. Tuttavia, potremmo aver notato che, nella definizione delle funzioni lambda, gli argomenti non sono circondati da parentesi: per specificarne pi\u00f9 di uno, dovremo elencarli separandoli mediante una virgola. Ad esempio:</p> <pre><code>nome_cognome = lambda nome, cognome: f'{nome.title()} {cognome.title()}'\n</code></pre> <p>A questo punto, potremo invocare la funzione come segue:</p> <pre><code>&gt;&gt;&gt; nome_cognome('guido', 'van rossum')\nGuido Van Rossum\n</code></pre> <p>Ricapitolando, la funzione lambda con identificativo <code>nome_cognome</code> accetter\u00e0 due argomenti, rispettivamente <code>nome</code> e <code>cognome</code>, restituendo una stringa formattata. Come abbiamo gi\u00e0 sottolineato, nella definizione della funzione lambda gli argomenti sono elencati senza parentesi, mentre la chiamata alla funzione lambda \u00e8 fatta esattamente come se avessimo a che fare con una classica funzione Python, con delle parentesi che circondano gli argomenti utilizzati.</p>"},{"location":"material/01_python/03_advanced/lambda/#funzioni-anonime","title":"Funzioni anonime","text":"<p>I seguenti termini possono essere usati in maniera intercambiabile a seconda del tipo di linguaggio di programmazione: funzioni anonime, funzioni lambda, espressioni lambda, astrazioni lambda, e via dicendo.</p> <p>Prese letteralmente, una funzione anonima \u00e8 una funzione senza un nome. In Python, una funzione anonima viene creata mediante la parola chiave <code>lambda</code>. Blandamente, pu\u00f2 o meno avere un nome. Considerando una funzione anonima a due argomenti definita con la lambda ma non vincolata ad una variabile. La lambda non ha un nome:</p> <pre><code>&gt;&gt;&gt; lambda x, y: x + y\n</code></pre> <p>La funzione precedente definisce un'espressione lambda che rpende due argomenti e restituisce la loro somma.</p> <p>Oltre chje fornirci il feedback che Python \u00e8 perfettamente ok con questa forma, non ha alcun uso pratico. Possiamo invocare la funzione nell'interprete Python:</p> <pre><code>&gt;&gt;&gt; _(1, 2)\n3\n</code></pre> <p>L'esempio precedente sfrutta la feature interattiva dell'interprete mediante l'underscore. Tuttavia, non possiamo scrivere del codice simile in un modulo Python: qui, dovremmo assegnare un nome alla lambda, o passare la lambda ad una funzione. Vedremo in seguito come fare.</p> <p>Nota</p> <p>In una sessione interattiva con l'interprete Python, il singolo underscore \u00e8 collegato all'ultima espressione valutata. Nell'esempio precedente, quindi, il <code>_</code> putna alla funzione lambda.</p> <p>Un altro pattern usato in altri linguaggi come JavaScript \u00e8 quello di usare immediatamente una funzione lambda Python. Questo \u00e8 conosciuto come Immediately Invoked Function Expression (IIFE). Ecco un esempio</p> <pre><code>&gt;&gt;&gt; (lambda x, y: x + y)(2, 3)\n5\n</code></pre> <p>La funzione lambda precedente \u00e8 definita e quindi chiuamata immediatamente con due argomenti, ovvero 2 e 3. Restituisce il valore 5, che \u00e8 la somma degli argomenti.</p>"},{"location":"material/01_python/03_advanced/lambda/#lambda-e-higher-order-functions","title":"lambda e higher order functions","text":"<p>Le funzioni lambda sono di frequente usate con le higher-order functions, che prendono una o pi\u00f9 funzioni come argomenti e restituiscono una o pi\u00f9 funzioni.</p> <p>Una funzione lambda pu\u00f2 essere una higher-order function prendendo una funzione (normale o lambda) come argomento, come nell'esempio successivo.</p> <pre><code>&gt;&gt;&gt; high_ord_func = lambda x, func: x + func(x)\n&gt;&gt;&gt; high_ord_func(2, lambda x: x * x)\n6\n&gt;&gt;&gt; high_ord_func(2, lambda x: x + 3)\n7\n</code></pre> <p>Python espone le higher-order function come funzioni built-in, o nella libreria standard. Esempi includono map(), filter(), reduce(), cos\u00ec come funzioni chiave come sort(), sorted(), min(), e max(). </p>"},{"location":"material/01_python/03_advanced/lambda/#lambda-e-funzioni-regolari","title":"Lambda e funzioni regolari","text":"<p>A differenza delle forme lambda in altri linguaggi, dove aggiungono nuove funzionalit\u00e0, le lambda Python sono solo una notazione abbrievata se siamo troppo pigri per definire una funzione.</p> <p>Nonostante questo, non dobbiamo fare in modo che questa definizione ci faccia desistere dall'usare le lambda function in Python. Di primo acchitto, potremmo accettare che una funzione lambda sia una funzione che ci permetta semplicemente di ridurre il codice necessario a definire o invocare una funzione. Vedremo per\u00f2 a breve che ci sono delle sottili differenze tra le normali funzioni Python e le funzioni lambda.</p>"},{"location":"material/01_python/03_advanced/lambda/#funzioni","title":"Funzioni","text":"<p>A questo punto, potremmo chiederci cosa distingue fondamentalmente una funzione lambda vincolata ad una variabile da una regolare funzione con una singola riga di ritorno: sotto il cofano, praticamente niente. Verifichaimo \u00e8per\u00f2 come Python vede una funzione costruita con una singola istruzione di ritorno rispettoa d una funzione costrrita come un'espressione lambda.</p> <p>Il modulo dis espone delle funzioni per analizzare il bytecode Python generato dal compilatore.</p> <pre><code>&gt;&gt;&gt; import dis\n&gt;&gt;&gt; add = lambda x, y: x + y\n&gt;&gt;&gt; type(add)\n&lt;class 'function'&gt;\n&gt;&gt;&gt; dis.dis(add)\n1           0 LOAD_FAST                0 (x)\n2 LOAD_FAST                1 (y)\n4 BINARY_ADD\n6 RETURN_VALUE\n&gt;&gt;&gt; add\n&lt;function &lt;lambda&gt; at 0x7f30c6ce9ea0&gt;\n</code></pre> <p>Possiamo vedere che <code>dis()</code> mostra una versione leggibile del bytecode Python, permettendo l'ispezione delle istruzioni a basso livello che l'interprete Pythjon usa mentre esegue il programma.</p> <p>Ora vediamo una funzione classica:</p> <pre><code>&gt;&gt;&gt; import dis\n&gt;&gt;&gt; def add(x, y): return x + y\n&gt;&gt;&gt; type(add)\n&lt;class 'function'&gt;\n&gt;&gt;&gt; dis.dis(add)\n1           0 LOAD_FAST                0 (x)\n2 LOAD_FAST                1 (y)\n4 BINARY_ADD\n6 RETURN_VALUE\n&gt;&gt;&gt; add\n&lt;function add at 0x7f30c6ce9f28&gt;\n</code></pre> <p>Il bytecode interpretato da Python \u00e8 lo stesso per entrambe le funzioni. Tuttavia, possiamo notare che il nome \u00e8 differente: il nome della funzione \u00e8 add per la funzione definita mediante def, mentre la funzione lambda Python \u00e8 vista come lambda.</p>"},{"location":"material/01_python/03_advanced/lambda/#traceback","title":"traceback","text":"<p>ABbiamo visto che, nel contesto della funzione lambda, Python non ha fornito il nome della funzione, ma solo . Questa pu\u00f2 essere una limitazione da considerare quando vi \u00e8 un'eccezione, ed un traceback mostra soltanto :  <pre><code>&gt;&gt;&gt; div_zero = lambda x: x / 0\n&gt;&gt;&gt; div_zero(2)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"&lt;stdin&gt;\", line 1, in &lt;lambda&gt;\nZeroDivisionError: division by zero\n</code></pre> <p>Ecco la stessa eccezione lanciata da una funzione normale:</p> <pre><code>&gt;&gt;&gt; def div_zero(x): return x / 0\n&gt;&gt;&gt; div_zero(2)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"&lt;stdin&gt;\", line 1, in div_zero\nZeroDivisionError: division by zero\n</code></pre> <p>La funzione normale causa un errore simile, ma risulta in un traceback pi\u00f9 preceiso, perch\u00e9 d\u00e0 il nome della funzione (<code>div_zero</code>).</p>"},{"location":"material/01_python/03_advanced/lambda/#sintassi","title":"Sintassi","text":"<p>Come abbiamo visto nelle sezioni precedente, una funzione lambda presenta delle distinzioni sintattiche da una funzione normale. In particolare, una funzione lambda ha le seguenti caratteristiche:</p> <ul> <li>pu\u00f2 contenre soltanto espressioni e non include istruzioni nel suo corpo;</li> <li>\u00e8 scritta come una singola riga di esecuzione;</li> <li>non supporta il type hinting;</li> <li>pu\u00f2 essere invocata immedaitamente.</li> </ul>"},{"location":"material/01_python/03_advanced/lambda/#nessuna-istruzione","title":"Nessuna istruzione","text":"<p>Una funzione lambda non pu\u00f2 contenere alcuna istruzione. In una funzione lambda, le istruizoni come return, pass, assert o raise lanceranno un'eccezione SyntaxError. Ecco un esempio dell'aggiunta di assert al corpo di una lambda:</p> <pre><code>&gt;&gt;&gt; (lambda x: assert x == 2)(2)\nFile \"&lt;input&gt;\", line 1\n(lambda x: assert x == 2)(2)\n^\nSyntaxError: invalid syntax\n</code></pre> <p>Questo conciso esempio intendeva asserire che il parametro <code>x</code> ha un valore pari a 2. Tuttavia, l'interprete identifica un SyntaxError mentre effettua il parsing del codice che coinvolge l'assert nel corpo della lambda.</p>"},{"location":"material/01_python/03_advanced/lambda/#singola-espressione","title":"Singola espressione","text":"<p>Invece di una funzione normale, una funzione lambda Python \u00e8 una singola espressione. Tuttavia, nel corpo di una lambda, possiamo suddividere l'espressione in varie righe usando parentesi o stringhe multilinea; ci\u00f2nonostante, rimane una singola espressione:</p> <pre><code>&gt;&gt;&gt; (lambda x:\n... (x % 2 and 'odd' or 'even'))(3)\n'odd'\n</code></pre> <p>L'esempio precedente restituisce la stringa <code>odd</code> quando l'argomento della lambda \u00e8 dispari, e pari quando l'argomento \u00e8 pari. E' suddivisa tra due linee perch\u00e9 \u00e8 contenuta in un insieme di parentesi, ma rimane una singola espressione.</p>"},{"location":"material/01_python/03_advanced/lambda/#type-hinting","title":"Type hinting","text":"<p>Se abbiamo iniziato ad adottare il type hiunting, abbiamo un'altra ragione per preferire le funzioni normali alle lambda function Python. In una funzione lambda, infatti, questa espressione non ha equivalenti:</p> <pre><code>def full_name(first: str, last: str) -&gt; str:\nreturn f'{first.title()} {last.title()}'\n</code></pre> <p>Un qualsiasi errore di tipo pu\u00f2 essere catturato da strumetni come mypy o pyre, ed un SyntaxError con l'equivalente funzione lamb da viuene lanciato a runtime:</p> <pre><code>&gt;&gt;&gt; lambda first: str, last: str: first.title() + \" \" + last.title() -&gt; str\nFile \"&lt;stdin&gt;\", line 1\nlambda first: str, last: str: first.title() + \" \" + last.title() -&gt; str\nSyntaxError: invalid syntax\n</code></pre> <p>In pratica, provare ad inserire del type hinting risulta immedaitamente in un SyntaxError a runtime.</p>"},{"location":"material/01_python/03_advanced/lambda/#iife","title":"IIFE","text":"<p>Abbiamo gi\u00e0 visto degli esempi di IIFE:</p> <pre><code>&gt;&gt;&gt; (lambda x: x * x)(3)\n9\n</code></pre> <p>Al di furoi dell'interprete Pyuthon, questa feature non viene praticamente usata in pratica. E' infatti una conseguenza diretta del fatto che la funzione lambda \u00e8 chiamabile come viene definita. Per esempio, questo ci permette di apssare la definizione di una funzione lambda Python ad una higher-order function come map(), filter o reduec().</p>"},{"location":"material/01_python/03_advanced/lambda/#argomenti","title":"Argomenti","text":"<p>Come una normale funzione definita mediante def, le espressioni lambda in Python supportano tutti i diversi modi per passare degli argomenti, come argomenti posizionali, args e kwargs.</p> <p>Vediamo un esempio:</p> <pre><code>&gt;&gt;&gt; (lambda x, y, z: x + y + z)(1, 2, 3)\n6\n&gt;&gt;&gt; (lambda x, y, z=3: x + y + z)(1, 2)\n6\n&gt;&gt;&gt; (lambda x, y, z=3: x + y + z)(1, y=2)\n6\n&gt;&gt;&gt; (lambda *args: sum(args))(1,2,3)\n6\n&gt;&gt;&gt; (lambda **kwargs: sum(kwargs.values()))(one=1, two=2, three=3)\n6\n&gt;&gt;&gt; (lambda x, *, y=0, z=0: x + y + z)(1, y=2, z=3)\n6\n</code></pre>"},{"location":"material/01_python/03_advanced/lambda/#decorators","title":"Decorators","text":"<p>In Python, un decorator \u00e8 l'implemnentazione di un pattern che permette di aggiungere un dato comportamento ad una funzione o classe. Viene normalmente anteponendo una sintassi del tipo @nome_decorator alla funzione. Ecco un esempio:</p> <pre><code>def some_decorator(f):\ndef wraps(*args):\nprint(f\"Calling function '{f.__name__}'\")\nreturn f(args)\nreturn wraps\n@some_decorator\ndef decorated_function(x):\nprint(f\"With argument '{x}'\")\n</code></pre> <p>Nell'esempio precedente, somedecorator() \u00e8 una funzione che aggiunge un dato comporrtamento alla funzione decoratedfucntion(), in modo che chiamare decorated_fucntion('Python') restituisce il seguente output:</p> <pre><code>Calling function 'decorated_function'\nWith argument 'Python'\n</code></pre> <p>In pratica, decoratedfunction() manda a schermo soltanto \"With argument 'Python'\", ma il decorator aggiunge un ulteriorie comportamento che permette anche di mostrare a schermo \"Calling function 'decoratedfunction'\".</p> <p>Un decorator pu\u00f2 essere applicato ad una funzione lambda. Anche se non \u00e8 possibile decorare una funzione lambda con la sintassi @decorator, dato che il decorator \u00e8 semplicemente una funzione, questo pu\u00f2 chiamare  una funzione lambda:</p> <pre><code># Defining a decorator\ndef trace(f):\ndef wrap(*args, **kwargs):\nprint(f\"[TRACE] func: {f.__name__}, args: {args}, kwargs: {kwargs}\")\nreturn f(*args, **kwargs)\nreturn wrap\n# Applying decorator to a function\n@trace\ndef add_two(x):\nreturn x + 2\n# Calling the decorated function\nadd_two(3)\n# Applying decorator to a lambda\nprint((trace(lambda x: x ** 2))(3))\n</code></pre> <p>La funzione <code>add_two()</code>, decorata con <code>@trace</code> alla riga 11, viene invocata con l'argomento 3 alla riga 15. Di contro, alla riga 18, una funzione lambda viene immediatamente integrata in una chiamata a trace(), il decorator. Eseguendo il codice precedente, otteniamo il seguente output:</p> <pre><code>[TRACE] func: add_two, args: (3,), kwargs: {}\n[TRACE] func: &lt;lambda&gt;, args: (3,), kwargs: {}\n9\n</code></pre> <p>Vediamo che il nome della funzione lambda appare come <code>&lt;lambda&gt;</code>, mentre <code>add_two</code> viene chiaramente identificato come una funzione normale.</p> <p>Decorare la funzione lambda in questo modo pu\u00f2 essere utile a scopo di debugging, specialmente per analizzare il comportamento di una funzione almbda usata nel contesto di una higher-order function. Vediamo un esempio con <code>map()</code>:</p> <pre><code>list(map(trace(lambda x: x*2), range(3)))\n</code></pre> <p>The first argument of map() is a lambda that multiplies its argument by 2. This lambda is decorated with trace(). When executed, the example above outputs the following:</p> <p>[TRACE] Calling  with args (0,) and kwargs {} [TRACE] Calling  with args (1,) and kwargs {} [TRACE] Calling  with args (2,) and kwargs {} [0, 2, 4] The result [0, 2, 4] is a list obtained from multiplying each element of range(3). For now, consider range(3) equivalent to the list [0, 1, 2]. <p>You will be exposed to map() in more details in Map.</p> <p>A lambda can also be a decorator, but it\u2019s not recommended. If you find yourself needing to do this, consult PEP 8, Programming Recommendations.</p> <p>For more on Python decorators, check out Primer on Python Decorators.</p> <p>Remove ads Closure A closure is a function where every free variable, everything except parameters, used in that function is bound to a specific value defined in the enclosing scope of that function. In effect, closures define the environment in which they run, and so can be called from anywhere.</p> <p>The concepts of lambdas and closures are not necessarily related, although lambda functions can be closures in the same way that normal functions can also be closures. Some languages have special constructs for closure or lambda (for example, Groovy with an anonymous block of code as Closure object), or a lambda expression (for example, Java Lambda expression with a limited option for closure).</p> <p>Here\u2019s a closure constructed with a normal Python function:</p> <p>def outerfunc(x):     y = 4     def innerfunc(z):         print(f\"x = {x}, y = {y}, z = {z}\")         return x + y + z     return inner_func</p> <p>for i in range(3):     closure = outerfunc(i)     print(f\"closure({i+5}) = {closure(i+5)}\") outerfunc() returns inner_func(), a nested function that computes the sum of three arguments:</p> <p>x is passed as an argument to outerfunc(). y is a variable local to outerfunc(). z is an argument passed to innerfunc(). To test the behavior of outerfunc() and innerfunc(), outerfunc() is invoked three times in a for loop that prints the following:</p> <p>x = 0, y = 4, z = 5 closure(5) = 9 x = 1, y = 4, z = 6 closure(6) = 11 x = 2, y = 4, z = 7 closure(7) = 13 On line 9 of the code, innerfunc() returned by the invocation of outerfunc() is bound to the name closure. On line 5, inner_func() captures x and y because it has access to its embedding environment, such that upon invocation of the closure, it is able to operate on the two free variables x and y.</p> <p>Similarly, a lambda can also be a closure. Here\u2019s the same example with a Python lambda function:</p> <p>def outer_func(x):     y = 4     return lambda z: x + y + z</p> <p>for i in range(3):     closure = outer_func(i)     print(f\"closure({i+5}) = {closure(i+5)}\") When you execute the code above, you obtain the following output:</p> <p>closure(5) = 9 closure(6) = 11 closure(7) = 13 On line 6, outerfunc() returns a lambda and assigns it to to the variable closure. On line 3, the body of the lambda function references x and y. The variable y is available at definition time, whereas x is defined at runtime when outerfunc() is invoked.</p> <p>In this situation, both the normal function and the lambda behave similarly. In the next section, you\u2019ll see a situation where the behavior of a lambda can be deceptive due to its evaluation time (definition time vs runtime).</p> <p>Evaluation Time In some situations involving loops, the behavior of a Python lambda function as a closure may be counterintuitive. It requires understanding when free variables are bound in the context of a lambda. The following examples demonstrate the difference when using a regular function vs using a Python lambda.</p> <p>Test the scenario first using a regular function:</p> <p>def wrap(n): ...     def f(): ...         print(n) ...     return f ... numbers = 'one', 'two', 'three' funcs = [] for n in numbers: ...     funcs.append(wrap(n)) ... for f in funcs: ...     f() ... one two three In a normal function, n is evaluated at definition time, on line 9, when the function is added to the list: funcs.append(wrap(n)).</p> <p>Now, with the implementation of the same logic with a lambda function, observe the unexpected behavior:</p> <p>numbers = 'one', 'two', 'three' funcs = [] for n in numbers: ...     funcs.append(lambda: print(n)) ... for f in funcs: ...     f() ... three three three The unexpected result occurs because the free variable n, as implemented, is bound at the execution time of the lambda expression. The Python lambda function on line 4 is a closure that captures n, a free variable bound at runtime. At runtime, while invoking the function f on line 7, the value of n is three.</p> <p>To overcome this issue, you can assign the free variable at definition time as follows:</p> <p>numbers = 'one', 'two', 'three' funcs = [] for n in numbers: ...     funcs.append(lambda n=n: print(n)) ... for f in funcs: ...     f() ... one two three A Python lambda function behaves like a normal function in regard to arguments. Therefore, a lambda parameter can be initialized with a default value: the parameter n takes the outer n as a default value. The Python lambda function could have been written as lambda x=n: print(x) and have the same result.</p> <p>The Python lambda function is invoked without any argument on line 7, and it uses the default value n set at definition time.</p> <p>Remove ads Testing Lambdas Python lambdas can be tested similarly to regular functions. It\u2019s possible to use both unittest and doctest.</p> <p>unittest</p> <p>The unittest module handles Python lambda functions similarly to regular functions:</p> <p>import unittest</p> <p>addtwo = lambda x: x + 2</p> <p>class LambdaTest(unittest.TestCase):     def testaddtwo(self):         self.assertEqual(addtwo(2), 4)</p> <pre><code>def test_add_two_point_two(self):\n    self.assertEqual(addtwo(2.2), 4.2)\n\ndef test_add_three(self):\n    # Should fail\n    self.assertEqual(addtwo(3), 6)\n</code></pre> <p>if name == 'main':     unittest.main(verbosity=2) LambdaTest defines a test case with three test methods, each of them exercising a test scenario for addtwo() implemented as a lambda function. The execution of the Python file lambda_unittest.py that contains LambdaTest produces the following:</p> <p>$ python lambdaunittest.py testaddthree (main.LambdaTest) ... FAIL testaddtwo (main.LambdaTest) ... ok testaddtwopointtwo (main_.LambdaTest) ... ok</p> <p>====================================================================== FAIL: testaddthree (main.LambdaTest)</p> <p>Traceback (most recent call last):   File \"lambdaunittest.py\", line 18, in testadd_three     self.assertEqual(addtwo(3), 6) AssertionError: 5 != 6</p> <p>Ran 3 tests in 0.001s</p> <p>FAILED (failures=1) As expected, we have two successful test cases and one failure for testaddthree: the result is 5, but the expected result was 6. This failure is due to an intentional mistake in the test case. Changing the expected result from 6 to 5 will satisfy all the tests for LambdaTest.</p> <p>doctest</p> <p>The doctest module extracts interactive Python code from docstring to execute tests. Although the syntax of Python lambda functions does not support a typical docstring, it is possible to assign a string to the doc element of a named lambda:</p> <p>addtwo = lambda x: x + 2 addtwo.doc = \"\"\"Add 2 to a number.     &gt;&gt;&gt; addtwo(2)     4     &gt;&gt;&gt; addtwo(2.2)     4.2     &gt;&gt;&gt; addtwo(3) # Should fail     6     \"\"\"</p> <p>if name == 'main':     import doctest     doctest.testmod(verbose=True) The doctest in the doc comment of lambda addtwo() describes the same test cases as in the previous section.</p> <p>When you execute the tests via doctest.testmod(), you get the following:</p> <p>$ python lambda_doctest.py Trying:     addtwo(2) Expecting:     4 ok Trying:     addtwo(2.2) Expecting:     4.2 ok Trying:     addtwo(3) # Should fail Expecting:     6</p> <p>File \"lambdadoctest.py\", line 16, in _main.addtwo Failed example:     addtwo(3) # Should fail Expected:     6 Got:     5 1 items had no tests:     __main</p> <p>1 items had failures:    1 of   3 in main.addtwo 3 tests in 2 items. 2 passed and 1 failed. Test Failed 1 failures. The failed test results from the same failure explained in the execution of the unit tests in the previous section.</p> <p>You can add a docstring to a Python lambda via an assignment to doc to document a lambda function. Although possible, the Python syntax better accommodates docstring for normal functions than lambda functions.</p> <p>For a comprehensive overview of unit testing in Python, you may want to refer to Getting Started With Testing in Python.</p> <p>Lambda Expression Abuses Several examples in this article, if written in the context of professional Python code, would qualify as abuses.</p> <p>If you find yourself trying to overcome something that a lambda expression does not support, this is probably a sign that a normal function would be better suited. The docstring for a lambda expression in the previous section is a good example. Attempting to overcome the fact that a Python lambda function does not support statements is another red flag.</p> <p>The next sections illustrate a few examples of lambda usages that should be avoided. Those examples might be situations where, in the context of Python lambda, the code exhibits the following pattern:</p> <p>It doesn\u2019t follow the Python style guide (PEP 8) It\u2019s cumbersome and difficult to read. It\u2019s unnecessarily clever at the cost of difficult readability.</p> <p>Remove ads Raising an Exception Trying to raise an exception in a Python lambda should make you think twice. There are some clever ways to do so, but even something like the following is better to avoid:</p> <p>def throw(ex): raise ex (lambda: throw(Exception('Something bad happened')))() Traceback (most recent call last):     File \"\", line 1, in      File \"\", line 1, in      File \"\", line 1, in throw Exception: Something bad happened Because a statement is not syntactically correct in a Python lambda body, the workaround in the example above consists of abstracting the statement call with a dedicated function throw(). Using this type of workaround should be avoided. If you encounter this type of code, you should consider refactoring the code to use a regular function. <p>Cryptic Style As in any programming languages, you will find Python code that can be difficult to read because of the style used. Lambda functions, due to their conciseness, can be conducive to writing code that is difficult to read.</p> <p>The following lambda example contains several bad style choices:</p> <p>(lambda : list(map(lambda _: _ // 2, _)))([1,2,3,4,5,6,7,8,9,10]) [0, 1, 1, 2, 2, 3, 3, 4, 4, 5] The underscore () refers to a variable that you don\u2019t need to refer to explicitly. But in this example, three _ refer to different variables. An initial upgrade to this lambda code could be to name the variables:</p> <p>(lambda somelist: list(map(lambda n: n // 2,                                 somelist)))([1,2,3,4,5,6,7,8,9,10]) [0, 1, 1, 2, 2, 3, 3, 4, 4, 5] Admittedly, it\u2019s still difficult to read. By still taking advantage of a lambda, a regular function would go a long way to render this code more readable, spreading the logic over a few lines and function calls:</p> <p>def divitems(somelist):       divbytwo = lambda n: n // 2       return map(divbytwo, somelist) list(divitems([1,2,3,4,5,6,7,8,9,10]))) [0, 1, 1, 2, 2, 3, 3, 4, 4, 5] This is still not optimal but shows you a possible path to make code, and Python lambda functions in particular, more readable. In Alternatives to Lambdas, you\u2019ll learn to replace map() and lambda with list comprehensions or generator expressions. This will drastically improve the readability of the code.</p> <p>Python Classes You can but should not write class methods as Python lambda functions. The following example is perfectly legal Python code but exhibits unconventional Python code relying on lambda. For example, instead of implementing str as a regular function, it uses a lambda. Similarly, brand and year are properties also implemented with lambda functions, instead of regular functions or decorators:</p> <p>class Car:     \"\"\"Car with methods as lambda functions.\"\"\"     def init(self, brand, year):         self.brand = brand         self.year = year</p> <pre><code>brand = property(lambda self: getattr(self, '_brand'),\n                 lambda self, value: setattr(self, '_brand', value))\n\nyear = property(lambda self: getattr(self, '_year'),\n                lambda self, value: setattr(self, '_year', value))\n\n__str__ = lambda self: f'{self.brand} {self.year}'  # 1: error E731\n\nhonk = lambda self: print('Honk!')     # 2: error E731\n</code></pre> <p>Running a tool like flake8, a style guide enforcement tool, will display the following errors for str and honk:</p> <p>E731 do not assign a lambda expression, use a def Although flake8 doesn\u2019t point out an issue for the usage of the Python lambda functions in the properties, they are difficult to read and prone to error because of the usage of multiple strings like 'brand' and 'year'.</p> <p>Proper implementation of str would be expected to be as follows:</p> <p>def str(self):     return f'{self.brand} {self.year}' brand would be written as follows:</p> <p>@property def brand(self):     return self._brand</p> <p>@brand.setter def brand(self, value):     self._brand = value As a general rule, in the context of code written in Python, prefer regular functions over lambda expressions. Nonetheless, there are cases that benefit from lambda syntax, as you will see in the next section.</p> <p>Remove ads Appropriate Uses of Lambda Expressions Lambdas in Python tend to be the subject of controversies. Some of the arguments against lambdas in Python are:</p> <p>Issues with readability The imposition of a functional way of thinking Heavy syntax with the lambda keyword Despite the heated debates questioning the mere existence of this feature in Python, lambda functions have properties that sometimes provide value to the Python language and to developers.</p> <p>The following examples illustrate scenarios where the use of lambda functions is not only suitable but encouraged in Python code.</p> <p>Classic Functional Constructs Lambda functions are regularly used with the built-in functions map() and filter(), as well as functools.reduce(), exposed in the module functools. The following three examples are respective illustrations of using those functions with lambda expressions as companions:</p> <p>list(map(lambda x: x.upper(), ['cat', 'dog', 'cow'])) ['CAT', 'DOG', 'COW'] list(filter(lambda x: 'o' in x, ['cat', 'dog', 'cow'])) ['dog', 'cow'] from functools import reduce reduce(lambda acc, x: f'{acc} | {x}', ['cat', 'dog', 'cow']) 'cat | dog | cow' You may have to read code resembling the examples above, albeit with more relevant data. For that reason, it\u2019s important to recognize those constructs. Nevertheless, those constructs have equivalent alternatives that are considered more Pythonic. In Alternatives to Lambdas, you\u2019ll learn how to convert higher-order functions and their accompanying lambdas into other more idiomatic forms.</p> <p>Key Functions Key functions in Python are higher-order functions that take a parameter key as a named argument. key receives a function that can be a lambda. This function directly influences the algorithm driven by the key function itself. Here are some key functions:</p> <p>sort(): list method sorted(), min(), max(): built-in functions nlargest() and nsmallest(): in the Heap queue algorithm module heapq Imagine that you want to sort a list of IDs represented as strings. Each ID is the concatenation of the string id and a number. Sorting this list with the built-in function sorted(), by default, uses a lexicographic order as the elements in the list are strings.</p> <p>To influence the sorting execution, you can assign a lambda to the named argument key, such that the sorting will use the number associated with the ID:</p> <p>ids = ['id1', 'id2', 'id30', 'id3', 'id22', 'id100'] print(sorted(ids)) # Lexicographic sort ['id1', 'id100', 'id2', 'id22', 'id3', 'id30'] sortedids = sorted(ids, key=lambda x: int(x[2:])) # Integer sort print(sortedids) ['id1', 'id2', 'id3', 'id22', 'id30', 'id100'] UI Frameworks UI frameworks like Tkinter, wxPython, or .NET Windows Forms with IronPython take advantage of lambda functions for mapping actions in response to UI events.</p> <p>The naive Tkinter program below demonstrates the usage of a lambda assigned to the command of the Reverse button:</p> <p>import tkinter as tk import sys</p> <p>window = tk.Tk() window.grid_columnconfigure(0, weight=1) window.title(\"Lambda\") window.geometry(\"300x100\") label = tk.Label(window, text=\"Lambda Calculus\") label.grid(column=0, row=0) button = tk.Button(     window,     text=\"Reverse\",     command=lambda: label.configure(text=label.cget(\"text\")[::-1]), ) button.grid(column=0, row=1) window.mainloop() Clicking the button Reverse fires an event that triggers the lambda function, changing the label from Lambda Calculus to suluclaC adbmaL*:</p> <p>Animated TkInter Windows demonstrating the action of the button to the text Both wxPython and IronPython on the .NET platform share a similar approach for handling events. Note that lambda is one way to handle firing events, but a function may be used for the same purpose. It ends up being self-contained and less verbose to use a lambda when the amount of code needed is very short.</p> <p>To explore wxPython, check out How to Build a Python GUI Application With wxPython.</p> <p>Remove ads Python Interpreter When you\u2019re playing with Python code in the interactive interpreter, Python lambda functions are often a blessing. It\u2019s easy to craft a quick one-liner function to explore some snippets of code that will never see the light of day outside of the interpreter. The lambdas written in the interpreter, for the sake of speedy discovery, are like scrap paper that you can throw away after use.</p> <p>timeit In the same spirit as the experimentation in the Python interpreter, the module timeit provides functions to time small code fragments. timeit.timeit() in particular can be called directly, passing some Python code in a string. Here\u2019s an example:</p> <p>from timeit import timeit timeit(\"factorial(999)\", \"from math import factorial\", number=10) 0.0013087529951008037 When the statement is passed as a string, timeit() needs the full context. In the example above, this is provided by the second argument that sets up the environment needed by the main function to be timed. Not doing so would raise a NameError exception.</p> <p>Another approach is to use a lambda:</p> <p>from math import factorial timeit(lambda: factorial(999), number=10) 0.0012704220062005334 This solution is cleaner, more readable, and quicker to type in the interpreter. Although the execution time was slightly less for the lambda version, executing the functions again may show a slight advantage for the string version. The execution time of the setup is excluded from the overall execution time and shouldn\u2019t have any impact on the result.</p> <p>Monkey Patching For testing, it\u2019s sometimes necessary to rely on repeatable results, even if during the normal execution of a given software, the corresponding results are expected to differ, or even be totally random.</p> <p>Let\u2019s say you want to test a function that, at runtime, handles random values. But, during the testing execution, you need to assert against predictable values in a repeatable manner. The following example shows how, with a lambda function, monkey patching can help you:</p> <p>from contextlib import contextmanager import secrets</p> <p>def gentoken():     \"\"\"Generate a random token.\"\"\"     return f'TOKEN'</p> <p>@contextmanager def mocktoken():     \"\"\"Context manager to monkey patch the secrets.tokenhex     function during testing.     \"\"\"     defaulttokenhex = secrets.tokenhex     secrets.tokenhex = lambda : 'feedfacecafebeef'     yield     secrets.tokenhex = defaulttokenhex</p> <p>def testgenkey():     \"\"\"Test the random token.\"\"\"     with mocktoken():         assert gentoken() == f\"TOKEN_{'feedfacecafebeef'}\"</p> <p>testgenkey() A context manager helps with insulating the operation of monkey patching a function from the standard library (secrets, in this example). The lambda function assigned to secrets.token_hex() substitutes the default behavior by returning a static value.</p> <p>This allows testing any function depending on tokenhex() in a predictable fashion. Prior to exiting from the context manager, the default behavior of tokenhex() is reestablished to eliminate any unexpected side effects that would affect other areas of the testing that may depend on the default behavior of token_hex().</p> <p>Unit test frameworks like unittest and pytest take this concept to a higher level of sophistication.</p> <p>With pytest, still using a lambda function, the same example becomes more elegant and concise :</p> <p>import secrets</p> <p>def gentoken():     return f'TOKEN'</p> <p>def testgenkey(monkeypatch):     monkeypatch.setattr('secrets.tokenhex', lambda _: 'feedfacecafebeef')     assert gentoken() == f\"TOKEN{'feedfacecafebeef'}\" With the pytest monkeypatch fixture, secrets.tokenhex() is overwritten with a lambda that will return a deterministic value, feedfacecafebeef, allowing to validate the test. The pytest monkeypatch fixture allows you to control the scope of the override. In the example above, invoking secrets.token_hex() in subsequent tests, without using monkey patching, would execute the normal implementation of this function.</p> <p>Executing the pytest test gives the following result:</p> <p>$ pytest testtoken.py -v ============================= test session starts ============================== platform linux -- Python 3.7.2, pytest-4.3.0, py-1.8.0, pluggy-0.9.0 cachedir: .pytestcache rootdir: /home/andre/AB/tools/bpython, inifile: collected 1 item</p> <p>testtoken.py::testgen_key PASSED                                       [100%]</p> <p>=========================== 1 passed in 0.01 seconds =========================== The test passes as we validated that the gen_token() was exercised, and the results were the expected ones in the context of the test.</p> <p>Remove ads Alternatives to Lambdas While there are great reasons to use lambda, there are instances where its use is frowned upon. So what are the alternatives?</p> <p>Higher-order functions like map(), filter(), and functools.reduce() can be converted to more elegant forms with slight twists of creativity, in particular with list comprehensions or generator expressions.</p> <p>To learn more about list comprehensions, check out When to Use a List Comprehension in Python. To learn more about generator expressions, check out How to Use Generators and yield in Python.</p> <p>Map The built-in function map() takes a function as a first argument and applies it to each of the elements of its second argument, an iterable. Examples of iterables are strings, lists, and tuples. For more information on iterables and iterators, check out Iterables and Iterators.</p> <p>map() returns an iterator corresponding to the transformed collection. As an example, if you wanted to transform a list of strings to a new list with each string capitalized, you could use map(), as follows:</p> <p>list(map(lambda x: x.capitalize(), ['cat', 'dog', 'cow'])) ['Cat', 'Dog', 'Cow'] You need to invoke list() to convert the iterator returned by map() into an expanded list that can be displayed in the Python shell interpreter.</p> <p>Using a list comprehension eliminates the need for defining and invoking the lambda function:</p> <p>[x.capitalize() for x in ['cat', 'dog', 'cow']] ['Cat', 'Dog', 'Cow'] Filter The built-in function filter(), another classic functional construct, can be converted into a list comprehension. It takes a predicate as a first argument and an iterable as a second argument. It builds an iterator containing all the elements of the initial collection that satisfies the predicate function. Here\u2019s an example that filters all the even numbers in a given list of integers:</p> <p>even = lambda x: x%2 == 0 list(filter(even, range(11))) [0, 2, 4, 6, 8, 10] Note that filter() returns an iterator, hence the need to invoke the built-in type list that constructs a list given an iterator.</p> <p>The implementation leveraging the list comprehension construct gives the following:</p> <p>[x for x in range(11) if x%2 == 0] [0, 2, 4, 6, 8, 10] Reduce Since Python 3, reduce() has gone from a built-in function to a functools module function. As map() and filter(), its first two arguments are respectively a function and an iterable. It may also take an initializer as a third argument that is used as the initial value of the resulting accumulator. For each element of the iterable, reduce() applies the function and accumulates the result that is returned when the iterable is exhausted.</p> <p>To apply reduce() to a list of pairs and calculate the sum of the first item of each pair, you could write this:</p> <p>import functools pairs = [(1, 'a'), (2, 'b'), (3, 'c')] functools.reduce(lambda acc, pair: acc + pair[0], pairs, 0) 6 A more idiomatic approach using a generator expression, as an argument to sum() in the example, is the following:</p> <p>pairs = [(1, 'a'), (2, 'b'), (3, 'c')] sum(x[0] for x in pairs) 6 A slightly different and possibly cleaner solution removes the need to explicitly access the first element of the pair and instead use unpacking:</p> <p>pairs = [(1, 'a'), (2, 'b'), (3, 'c')] sum(x for x, _ in pairs) 6 The use of underscore (_) is a Python convention indicating that you can ignore the second value of the pair.</p> <p>sum() takes a unique argument, so the generator expression does not need to be in parentheses.</p> <p>Are Lambdas Pythonic or Not? PEP 8, which is the style guide for Python code, reads:</p> <p>Always use a def statement instead of an assignment statement that binds a lambda expression directly to an identifier. (Source)</p> <p>This strongly discourages using lambda bound to an identifier, mainly where functions should be used and have more benefits. PEP 8 does not mention other usages of lambda. As you have seen in the previous sections, lambda functions may certainly have good uses, although they are limited.</p> <p>A possible way to answer the question is that lambda functions are perfectly Pythonic if there is nothing more Pythonic available. I\u2019m staying away from defining what \u201cPythonic\u201d means, leaving you with the definition that best suits your mindset, as well as your personal or your team\u2019s coding style.</p> <p>Beyond the narrow scope of Python lambda, How to Write Beautiful Python Code With PEP 8 is a great resource that you may want to check out regarding code style in Python.</p> <p>Conclusion You now know how to use Python lambda functions and can:</p> <p>Write Python lambdas and use anonymous functions Choose wisely between lambdas or normal Python functions Avoid excessive use of lambdas Use lambdas with higher-order functions or Python key functions If you have a penchant for mathematics, you may have some fun exploring the fascinating world of lambda calculus.</p> <p>Python lambdas are like salt. A pinch in your spam, ham, and eggs will enhance the flavors, but too much will spoil the dish.</p>"},{"location":"material/01_python/03_advanced/pathlib/","title":"9 - Pathlib","text":"<p>In questa lezione, vedremo come lavorare in Python direttamente con i percorsi (in inglese, path) di cartelle e librerie. In particolare, vedremo come scrivere e leggere i file, iterando lungo le cartelle e manipolando il file system del nostro computer.</p>"},{"location":"material/01_python/03_advanced/pathlib/#91-python-e-la-gestione-del-path","title":"9.1 - Python e la gestione del path","text":"<p>Come abbiamo visto anche nella lezione relativa all'I/O, lavorare ed interagire con i file presenti sul nostro elaboratore \u00e8 estremamente importante. Nei casi pi\u00f9 semplici, ci limiteremo a scrivere su o leggere da un file ma, a volte, potremmo avere a che fare con task pi\u00f9 complessi, come elencare tutti i file con una certa estensione presenti in una data cartella, o creare un file che non esiste.</p>"},{"location":"material/01_python/03_advanced/pathlib/#912-i-path-come-stringhe","title":"9.1.2 - I path come stringhe","text":"<p>In passato, il percorso di un file Python \u00e8 sempre stato rappresentato usando degli oggetti di tipo stringa. Tuttavia, appare evidente come il percorso di un file non sia realmente una stringa: ci\u00f2 ha comportato la necessit\u00e0 di \"spargere\" diverse funzionalit\u00e0 in diversi package della libreria standard, in particolare <code>os</code>, <code>glob</code> e <code>shutil</code>, con conseguente aumento delle righe di codice e degli import da utilizzare.</p> <p>Ad esempio, se volessimo spostare tutti i file di testo presenti nella cartella di lavoro in un'altra cartella chiamata <code>archivio</code> avremmo bisogno di usare tre import:</p> <pre><code>import glob\nimport os\nimport shutil\nfor file_testo in glob.glob('*.txt'):\nnuovo_path = os.path.join('archivio', file_testo)\nshutil.move(file_testo, nuovo_path)\n</code></pre> <p>Rappresentare un path come una stringa favorisce inoltre la discutibile pratica dell'utilizzo dei metodi normalmente utilizzati su oggetti di questo tipo. Ad esempio, potremmo pensare di unire il percorso della cartella nella quale ci troviamo attualmente al percorso di una sottocartella utilizzando l'operatore <code>+</code>:</p> <pre><code>path_sottocartella = os.getcwd() + '/sottocartella'\n</code></pre> <p>Tuttavia, questa pratica \u00e8 estremamente sconsigliata, dato che la rappresentazione del percorso sotto forma di stringa varia tra sistemi Windows ed Unix-like. In particolare, ricordiamo che Windows utilizza il backslash <code>\\</code> per articolare il percorso di una cartella o file, mentre i sistemi Unix-like usano il forward slash <code>/</code>.</p> <p>La funzione join()</p> <p>Per ovviare a questo problema, prima dell'introduzione di pathlib passato si utilizzava il metodo <code>join()</code> di <code>os.path</code>, che permette di unire due path usando il separatore adatto al sistema operativo in analisi.</p>"},{"location":"material/01_python/03_advanced/pathlib/#913-i-path-in-pathlib","title":"9.1.3 - I path in pathlib","text":"<p>Il modulo <code>pathlib</code> \u00e8 stato introdotto per la prima volta in Python 3.4 proprio per porre rimedio a questa complicata situazione. L'obiettivo di <code>pathlib</code>, quindi, \u00e8 quello di raccogliere tutte le funzionalit\u00e0 necessarie alla gestione del path di un file in un unico componente della libreria standard, ed in particolare mediante un oggetto di classe <code>Path</code>.</p>"},{"location":"material/01_python/03_advanced/pathlib/#92-la-classe-path","title":"9.2 - La classe Path","text":""},{"location":"material/01_python/03_advanced/pathlib/#921-creazione-di-un-path","title":"9.2.1 - Creazione di un path","text":"<p>Come abbiamo gi\u00e0 detto, <code>pathlib</code> mette a disposizione la classe <code>Path</code> per la gestione del path di un file. Per utilizzare un oggetto di questa classe, dovremo innanzitutto crearlo; potremo in tal senso farlo in diversi modi.</p> <p>Innanzitutto, possiamo usare il metodo <code>cwd()</code>, che restituisce il path della cartella di lavoro. Supponendo di essere nella cartella <code>Documents</code> dell'utente <code>user</code>, avremo:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; Path.cwd()\nWindowsPath('C:/Users/user/Documents')\n</code></pre> <p>Il metodo <code>home()</code>, invece, restiuir\u00e0 la cartella base per l'utente attuale. Ad esempio, supponendo che l'utente <code>user</code> sia loggato:</p> <pre><code>&gt;&gt;&gt; Path.home()\nWindowsPath('C:/Users/user')\n</code></pre> <p>Possiamo anche creare un path in maniera esplicita utilizzando una stringa:</p> <pre><code>&gt;&gt;&gt; Path('C:/Users/user/Documents')\nWindowsPath('C:/Users/user/Documents')\n</code></pre> <p>Windows ed il backslash</p> <p>Abbiamo gi\u00e0 visto che il separatore dei path in Windows \u00e8 il backslash. Tuttavia, questo viene usato anche come escape character per rappresentare caratteri che non \u00e8 possibile stampare altrimenti. In tal senso, per evitare l'insorgere di errori, \u00e8 possibile l'uso di raw string literal per rappresentare i percorsi Python. Ad esempio, nel caso precedente, scriveremo:</p> <pre><code>&gt;&gt;&gt; Path(r'C:\\Users\\user\\Documents')  \nWindowsPath('C:/Users/user/Documents')\n</code></pre> <p>Un altro modo per costruire un path \u00e8 unire le varie parti dello stesso usando l'operatore <code>/</code>:</p> <pre><code>&gt;&gt;&gt; pathlib.Path.home() / 'Documents'\nWindowsPath('C:/Users/user/Documents')\n</code></pre> <p>Da notare che l'operatore <code>/</code> permette di unire anche pi\u00f9 di un path, oltre che un insieme di oggetti di tipo <code>Path</code> e stringhe (a patto che, ovviamente, vi sia almeno un oggetto di tipo <code>Path</code>). In alternativa, possiamo ottenere lo stesso effetto con il metodo <code>joinpath()</code>:</p> <pre><code>&gt;&gt;&gt; Path.home().joinpath('Documents')     \nWindowsPath('C:/Users/user/Documents')\n</code></pre> <p>Path, WindowsPath e PosixPath</p> <p>Negli esempi precedenti, utilizzare la classe <code>Path</code> ha sempre portato in output un <code>WindowsPath</code>. Ci\u00f2 \u00e8 legato al fatto che questi esempi sono stati scritti su un sistema Windows; se si fosse utilizzaton un sistema Unix-like, i path risultanti sarebbero stati dei <code>PosixPath</code>. In pratica, la classe vera e propria che caratterizza il path dipende dal sistema operativo su cui viene eseguito il nostro programma.</p>"},{"location":"material/01_python/03_advanced/pathlib/#922-io-su-file","title":"9.2.2 I/O su file","text":""},{"location":"material/01_python/03_advanced/pathlib/#apertura-di-un-file","title":"Apertura di un file","text":"<p>Per leggere da o scrivere su un file Python si \u00e8 utilizza il metodo <code>open()</code> che, convenientemente, pu\u00f2 essere usato direttamente con gli oggetti di classe <code>Path</code>. Ad esempio, se volessimo leggere tutti i commenti in un file Python, potremmo usare la seguente funzione:</p> <pre><code>def leggi_commenti(file_path):\nwith open(file_path, 'r') as f:\ncommenti = [line.strip() for line in f if line.startswith('#')]\nreturn '\\n'.join(commenti)\nleggi_commenti('test.py')\n</code></pre> <p>In realt\u00e0, possiamo anche chiamare la funzione <code>open()</code> messa a disposizione dall'oggetto <code>Path</code>:</p> <pre><code>with path.open(mode='r') as f:\n# ...\n</code></pre> <p>In pratica, <code>Path.open()</code> chiama internamente la <code>open()</code>. Di conseguenza, l'utilizzo dell'una o dell'altra funzione \u00e8 semplicemente una questione di preferenze personali.</p>"},{"location":"material/01_python/03_advanced/pathlib/#lettura-e-scrittura","title":"Lettura e scrittura","text":"<p>Per le operazioni di lettura e scrittura su file <code>pathlib</code> mette a disposizione i metodi mostrati nella tabella 9.1.</p> Metodo File aperto come... Tipo di interazione <code>.read_text()</code> File di testo Contenuti restituiti come stringa <code>.read_bytes()</code> File binario Contenuti restituiti come binario <code>.write_text()</code> File di testo Scrittura di contenuti come stringa <code>.write_bytes()</code> File binario Scrittura di contenuti come binari <p>Tutti i metodi gestiscono autonomamente l'apertura e l'interazione con il file. Ad esempio, per leggere i contenuti di un file di testo:</p> <pre><code>&gt;&gt;&gt; path = Path.cwd() / 'test.txt'\n&gt;&gt;&gt; path.read_text()\n&lt;contenuti del file test.txt&gt;\n</code></pre> <p>I path possono essere specificati anche come semplici nomi di file. In questo caso, ovviamente, Python assumer\u00e0 che siano all'interno dell'attuale cartella di lavoro. Ad esempio, un'altra forma di esprimere il codice precedente \u00e8 questa:</p> <pre><code>&gt;&gt;&gt; Path('test.txt').read_text()\n&lt;contenuti del file test.md&gt;\n</code></pre>"},{"location":"material/01_python/03_advanced/pathlib/#percorso-di-un-file","title":"Percorso di un file","text":"<p>Per avere il percorso completo (assoluto) di un file possiamo usare il metodo resolve():</p> <pre><code>&gt;&gt;&gt; path = Path('test.txt')\n&gt;&gt;&gt; path.resolve()\nWindowsPath('C:/Users/user/Documents/test.txt')\n</code></pre>"},{"location":"material/01_python/03_advanced/pathlib/#93-attributi-di-un-path","title":"9.3 - Attributi di un path","text":"<p>TODO DA QUI</p> <p>Le diverse parti di un path sono disponibili sotto forma di property. Deglie sempi basilari includono:</p> <ul> <li>.name: il nome del fiel senza alcuna directory</li> <li>.parent: la cartella che contiene il file, o la cartella padre se il path \u00e8 una cartella</li> <li>.stem: il nome del file senza l'estensione</li> <li>.suffix: l'estensione del file</li> <li>.anchor: la parte del path prima delle cartelle</li> </ul> <p>Ecco degli esempio:</p> <pre><code>&gt;&gt;&gt; path\nPosixPath('/home/gahjelle/realpython/test.md')\n&gt;&gt;&gt; path.name\n'test.md'\n&gt;&gt;&gt; path.stem\n'test'\n&gt;&gt;&gt; path.suffix\n'.md'\n&gt;&gt;&gt; path.parent\nPosixPath('/home/gahjelle/realpython')\n&gt;&gt;&gt; path.parent.parent\nPosixPath('/home/gahjelle')\n&gt;&gt;&gt; path.anchor\n'/'\n</code></pre> <p>Da notare che .parent restituisce un nuovo oggetto di tipo Path, metnre le altre propriet\u00e0 restituiscono delle stringhe. Questo significa ad esempio che .parent pu\u00f2 essere concatenato come nell'ultimo esempio, o anche combinato con / per creare dei nuovi path:</p> <pre><code>&gt;&gt;&gt; path.parent.parent / ('new' + path.suffix)\nPosixPath('/home/gahjelle/new.md')\n</code></pre>"},{"location":"material/01_python/03_advanced/pathlib/#spostare-e-cancellare-dei-file","title":"Spostare e cancellare dei file","text":"<p>Attraverso pathlib, avremo accesso anche ad operazioni base a livello di file system, come muovere, aggiornare ed anche cancellare i file. Per la maggior parte, questi metodi non ci danno un feedback prima di spostare o cancellare informazioni, quindi conviene fare attenzione.</p> <p>Per spostar eun file, usiamo .replace(). Notiamo che se la destinazione esiste gi\u00e0, .replace() la sovrascriuver\u00e0. Sfortunatamente, pathlib non supporta esplcitiamente lo spsotamenteo safe dei file. Per evitrare di sovrascirvere il path di destinazione, il modo pi\u00f9 semplice \u00e8 quello di testare se la destinazione esiste prima di rimpiazare:</p> <pre><code>if not destination.exists():\nsource.replace(destination)\n</code></pre> <p>Tuttavia, questo lascia aperta la porta ad una possibile race condition. Un altro processo potrebbe agigungere un path di destinazione tra l'esecuzione dell'istruzione if ed il metodo .replace(). Se questo \u00e8 un problema, un podo pi\u00f9 semplice \u00e8 quello di aprire il percorso di destinazione per la creazione esclusiva e copiare esplicitamente i dati sorgenti:</p> <pre><code>with destination.open(mode='xb') as fid:\nfid.write(source.read_bytes())\n</code></pre> <p>Questo codice lancer\u00e0 un <code>FileExistsError</code> se la destinazione esiste gi\u00e0. Tecnicamente, questo copia un file. Per effettuare lo spostamento, limitiamoci a cancellare il sorgente dopo che la copia \u00e8 stata fatta (vediamod i seguito). Assicuriamoci inoltre che non sia stata lanciata alcuna eccezione.</p> <p>Quando stiamo rinominando i file, dei meotdi utili potrebbero essere <code>.whit_name()</code> e <code>.with_suffix()</code>. Entrambi restituiscono il path originario ma con il noem o o il suffisso rimpiazzato, rispettivamente.</p> <p>Ad esempio:</p> <pre><code>&gt;&gt;&gt; path\nPosixPath('/home/gahjelle/realpython/test001.txt')\n&gt;&gt;&gt; path.with_suffix('.py')\nPosixPath('/home/gahjelle/realpython/test001.py')\n&gt;&gt;&gt; path.replace(path.with_suffix('.py'))\n</code></pre> <p>Le cartelle ed i file possono essere cancellati usando <code>.rmdir()</code> ed <code>.unlink()</code>, rispettivamente.</p>"},{"location":"material/01_python/03_advanced/pathlib/#esempi","title":"Esempi","text":"<p>Vediamo alcuni esempi di come usare <code>pathlib</code> per affrontare alcune semplici sfide.</p>"},{"location":"material/01_python/03_advanced/pathlib/#conteggio-dei-file","title":"Conteggio dei file","text":"<p>Ci sono alcuni modi differenti per elencare molti file. Il pi\u00f9 semplice \u00e8 il metodo <code>.iterdir()</code>, che itera su tutti i file in una data cartella. Il seguente esempio combina <code>.iterdir()</code> con la classe <code>collections.Counter</code> per contare quanti file ci sono di ogni tipo nella cartella attuale.</p> <pre><code>&gt;&gt;&gt; import collections\n&gt;&gt;&gt; collections.Counter(p.suffix for p in pathlib.Path.cwd().iterdir())\nCounter({'.md': 2, '.txt': 4, '.pdf': 2, '.py': 1})\n</code></pre> <p>Un elenco pi\u00f9 flessibile dei file pu\u00f2 essere creato con i metodi <code>.glob()</code> ed <code>.rglob()</code> (recursive glob). Ad esempio, <code>pathlib.Path.cwd().glob('*.txt')</code> restituisce tutti i file con estensione <code>.txt</code> nella cartella attuale. Il seguente codice conta soltanto i tipi di file che iniziano con <code>p</code>:</p> <pre><code>&gt;&gt;&gt; import collections\n&gt;&gt;&gt; collections.Counter(p.suffix for p in pathlib.Path.cwd().glob('*.p*'))\nCounter({'.pdf': 2, '.py': 1})\n</code></pre>"},{"location":"material/01_python/03_advanced/pathlib/#mostare-lalbero-di-una-cartella","title":"Mostare l'albero di una cartella","text":"<p>Il seguente esempio definisce una funzione, tree(), che mander\u00e0 a schermo un albero che rappresenta la gerarchia di file, con radice una certa cartella. Qui, vogliamo elencare le sottocartelle anche, per cui useremo il metodo <code>.rglob()</code>.</p> <pre><code>def tree(directory):\nprint(f'+ {directory}')\nfor path in sorted(directory.rglob('*')):\ndepth = len(path.relative_to(directory).parts)\nspacer = '    ' * depth\nprint(f'{spacer}+ {path.name}')\n</code></pre> <p>Notiamo che dobbiamo sapere quanto lontano dalla cartella radice \u00e8 collocato un file. Per falro, usiamo per prima cosa <code>.relative_to()</code> per rappresentare un eprocros relativamente alla cartella radice. Quindi, contiamo il numero di cartelle (usando la propriet\u00e0 <code>.parts</code>) nella rappresentazione. QUando eseguita, qeusta funzione crea un albero visu9ale come il seguente:</p> <pre><code>&gt;&gt;&gt; tree(pathlib.Path.cwd())\n+ /home/gahjelle/realpython\n+ directory_1\n+ file_a.md\n+ directory_2\n+ file_a.md\n+ file_b.pdf\n+ file_c.py\n+ file_1.txt\n+ file_2.txt\n</code></pre>"},{"location":"material/01_python/03_advanced/pathlib/#trovare-lultimo-file-modificato","title":"Trovare l'ultimo file modificato","text":"<p>Im metodi <code>.iterdir()</code>, <code>.glob()</code>, ed <code>.rglob</code> sono ottimi per i generator e le list comprehension. Per trovare il file in una cartella modificato per ultimo, possiamo usar eil metodo <code>.stat()</code> per ottenere informaizoni circa i file sottostanti. Per esempio, <code>.stat().st_mtime</code> ci d\u00e0 il momento dell'ultima modifica ad un file:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; time, file_path = max((f.stat().st_mtime, f) for f in directory.iterdir())\n&gt;&gt;&gt; print(datetime.fromtimestamp(time), file_path)\n2018-03-23 19:23:56.977817 /home/gahjelle/realpython/test001.txt\n</code></pre> <p>Possiamo anche ottenere i contenuti del file che \u00e8 stato modificato epr un'ultimo con una simile espressione:</p> <pre><code>&gt;&gt;&gt; max((f.stat().st_mtime, f) for f in directory.iterdir())[1].read_text()\n&lt;the contents of the last modified file in directory&gt;\n</code></pre> <p>Il timestamp restituito dalle diverse propriet\u00e0 <code>.stat().st_</code> rappresenta i secondi dal primo gennaio 1970. Oltre a <code>datetime.fromtimestamp</code>, <code>time.localtime</code> o <code>time.ctime</code> possono essere usati per convertire il timestamp in qualcosa di pi\u00f9 utilizzabile.</p>"},{"location":"material/01_python/03_advanced/pathlib/#creare-un-nome-del-file-univoco","title":"Creare un nome del file univoco","text":"<p>L'ultimo esempio ci mostra come costruire un file con numero univoco basato su una tempalte. Per prima cosa, specifichiamo un pattern per il nome del file, con spazio per un contatore. Quindi, controlliamo l'esistenza dle percorso del file creato unendo una cartella ed il nome del file (con un valore per il contatore). SE esiste gi\u00e0, aumentiamo il contatore e proviamo di nuovo:</p> <pre><code>def unique_path(directory, name_pattern):\ncounter = 0\nwhile True:\ncounter += 1\npath = directory / name_pattern.format(counter)\nif not path.exists():\nreturn path\npath = unique_path(pathlib.Path.cwd(), 'test{:03d}.txt')\n</code></pre> <p>Se la cartella contiene gi\u00e0 i file test001.txt e test002.txt, il codice precedente imposter\u00e0 il path a test003.txt.</p>"},{"location":"material/01_python/03_advanced/pathlib/#differenze-tra-sistemi-operativi","title":"Differenze tra sistemi operativi","text":"<p>In precedenza, abbiamo notato che abbiamo istanziato pathlib.Path, ed abbiamo ottenuto in ritorno un WindowsPath o un PosixPath. Il tipo di oggetto dipende dal sistema operativo utilizzato. Questa feature rende semplice scrivere del codice cross-platform. E' possibile richiedere esplcitiamente un WindowsPath o un PosixPath, ma staremmo limitando il codice a quel sistema, senza alcun beneficio. Un path concreto come questo non pu\u00f2 essere usato su un sistema differente:</p> <pre><code>&gt;&gt;&gt; pathlib.WindowsPath('test.md')\nNotImplementedError: cannot instantiate 'WindowsPath' on your system\n</code></pre> <p>Ci sono delle volte dove abbiamo bisogno della rappresentazione di un path senza accedere al file system sottostante (nel qual caso potrebbe aver senso rappresentare un percorso Windows su un sistema non-Windows, o viceversa). Questo pu\u00f2 essere fatto con degli oggetti di tipo PurePath. Questi oggetti supportano le operazioni discusse nella sezione sui Path Components, ma non i metodi che accedono al file system.</p> <pre><code>&gt;&gt;&gt; path = pathlib.PureWindowsPath(r'C:\\Users\\gahjelle\\realpython\\file.txt')\n&gt;&gt;&gt; path.name\n'file.txt'\n&gt;&gt;&gt; path.parent\nPureWindowsPath('C:/Users/gahjelle/realpython')\n&gt;&gt;&gt; path.exists()\nAttributeError: 'PureWindowsPath' object has no attribute 'exists'\n</code></pre> <p>Possiamo istanziare direttaqmente un <code>PureWindowsPath</code>o un PurePosixPath su ttutti i sistemi. Istanziare un PurePath restituir\u00e0 uno di questi oggetti a seconda del sistema operativo utilizzato.</p>"},{"location":"material/01_python/03_advanced/pathlib/#path-come-oggetti-veri-e-propri","title":"Path come oggetti veri e propri","text":"<p>Nell'introduzione, abbiamo notato brevemente che i path non sono stringhe, ed una motivazione dietro a questo \u00e8 che pathlib rappresenta il file system cond egli oggetti veri e propri. Infatti, la documenbtazione ufficiale di pathlib \u00e8 intitolata \"pathlib - Object-oriented filesystem paths\". L'approccio orientato agli oggetti \u00e8 abbastanza visibile negli esempi precedenti (specialmente se lo mettiamo a confronto con la vecchia maniera usatga da <code>os.path</code>). Tuyttavia, vediamo qualche ultimo spunto.</p> <p>Indipendentemente dal sistema operativo utilizzato, i path sono rappresentati in stile Posix, con lo slash come separatore del path. Su Windows, vedremo qualcosa come questo:</p> <pre><code>&gt;&gt;&gt; pathlib.Path(r'C:\\Users\\gahjelle\\realpython\\file.txt')\nWindowsPath('C:/Users/gahjelle/realpython/file.txt')\n</code></pre> <p>Quando il path viene convertito in stringa, user\u00e0 la forma nativa, per esempio con delle backslash su Windows:</p> <pre><code>&gt;&gt;&gt; str(pathlib.Path(r'C:\\Users\\gahjelle\\realpython\\file.txt'))\n'C:\\\\Users\\\\gahjelle\\\\realpython\\\\file.txt'\n</code></pre> <p>Questo risulta essere particolarmente utile se stiamo usando una libreria che non sa come usare gli oggetti pathlib.Path. Qeusto \u00e8 un grosso problema sulle versioni di Python antecedendi la 3.6. Ad esempio, in Python 3.5, la libreria standard configparser pu\u00f2 usare solo dei path sotto forma di stringa per leggere dei file. Il modo di gestire questi casi \u00e8 fare la conversione ad una stringa in maniera esplcitia.</p> <pre><code>&gt;&gt;&gt; from configparser import ConfigParser\n&gt;&gt;&gt; path = pathlib.Path('config.txt')\n&gt;&gt;&gt; cfg = ConfigParser()\n&gt;&gt;&gt; cfg.read(path)                     # Error on Python &lt; 3.6\nTypeError: 'PosixPath' object is not iterable\n&gt;&gt;&gt; cfg.read(str(path))                # Works on Python &gt;= 3.4\n['config.txt']\n</code></pre> <p>In Python 3.6 e successovo \u00e8 raccomandabile usare <code>os.fpath()</code> invece di <code>str()</code> se dobbiamo fare una conversione esplciita. Questo \u00e8 pi\u00f9 sicuro, in quando lancer\u00e0 un errore se proviamo a convertire accidentalmente un oggetto che non \u00e8 un path.</p> <p>Probabilmente, la parte pi\u00f9 inusuale della libreria pathlibe \u00e8 data dall'uso dell'operatore <code>/</code>. Vediamo come \u00e8 implementato. Questo \u00e8 un esempio di un overloading di operatore: il comportamento di un operatore cambia a seconda del contesto. Python implementa l'overloading di operatori attraverso l'uso dei dunder metrhods, ovvero dei metodi circondati da un doppio underscore.</p> <p>L'operatore <code>/</code> \u00e8 definito dal metodo <code>.__truediv__()</code>. Infatti, se diamo un'occhiata al codice sorgente di <code>pathlib</code>, vedremo qualcosa come:</p> <pre><code>class PurePath(object):\ndef __truediv__(self, key):\nreturn self._make_child((key,))\n</code></pre>"},{"location":"material/01_python/03_advanced/pathlib/#conclusion","title":"Conclusion","text":"<p>Da Python 3.4 in poi, pathlib \u00e8 stato reso disponibile nella libreria standard. Con pathlib, i path dei file possono essere rappresentati da oggetti Path veri e propri, invece di stringhe come in precedenza. Questi oggetti rendono l'uso dei path:</p> <ul> <li>pi\u00f9 facile da leggere, specie perch\u00e9 <code>/</code> \u00e8 usato per unire tra loro i path;</li> <li>pi\u00f9 potente, con la maggior parte dei metodi necessari e delle propriet\u00e0 disponibili direttamente sull'oggetto;</li> <li>pi\u00f9 consistenti tra sistemi operativi, in quanto le peculariet\u00e0 dei diversi sistemi sono nascoste dall'oggetto <code>Path</code>.</li> </ul>"},{"location":"material/01_python/03_advanced/reference/","title":"Passaggio per reference","text":"<p>Dopo aver guadagnato un po' di familiarit\u00e0 con Python, potremmo notare dei casi nei quali le nostre funzioni non modificano degli argometni come atteso. Specialmente se veniamo d aaltri linguaggi, vedremo che alcuni di questi gestiscono gli argometni di una funzione come dei riferimenti a variabili esistenti, il che \u00e8 conosciuto come passaggio per riferimento. Altri linguaggi, invece, trattano le due variabili come valori indipendenti, un approccio conosciuto come passaggio per valore.</p> <p>In questa lezione, vedremo:</p> <ul> <li>cosa significa passare per reference, e perch\u00e9 dovremmo volerlo fare;</li> <li>come il passaggio per refrence differisce sia dal passaggio per valore, sia dall'approccio unico di Python;</li> <li>come si comportano i funciton arguments in Python</li> <li>come possiamo usare certi tipi mutabili per effettuare il passaggio per reference in Python</li> <li>quali sono le best practice per replicare il passaggio per reference in Python</li> </ul>"},{"location":"material/01_python/03_advanced/reference/#cosa-e-il-passaggio-per-reference","title":"Cosa \u00e8 il passaggio per reference?","text":"<p>Prima di addentrarci nei dettagli tecnici del passaggio per reference, pu\u00f2 esserci d'aiuto dare uno sguardo ravvicinato al termine stesso \"rompendolo\" in pi\u00f9 componenti:</p> <ul> <li>passaggio significa fornire un arogmento ad una funzione;</li> <li>reference indca che l'argomento che stiamo passando alla funzione \u00e8 un riferimento ad una variabile che esiste gi\u00e0 in memoria, e non una copia indipendente di quella stessa variabile.</li> </ul> <p>Dal momento che stiamo dando alla funzione un riferimento ad una variabile esistente, tutte le operazioni effettuate su questo riferimento influenzeranno direttamente la variabile a cui si riferisce.</p> <p>Vediamo alcuni esempi di come questo funziona nella pratica.</p> <p>Vediamo come passare una variabile per reference in C#. NOtiamo l'uso della parola chiave ref nelle righe evidenziate:</p> <pre><code>using System;\n// Source:\n// https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/passing-parameters\nclass Program\n{\nstatic void Main(string[] args)\n{\nint arg;\n// Passing by reference.\n// The value of arg in Main is changed.\narg = 4;\nsquareRef(ref arg);\nConsole.WriteLine(arg);\n// Output: 16\n}\nstatic void squareRef(ref int refParameter)\n{\nrefParameter *= refParameter;\n}\n}\n</code></pre> <p>Come possiamo vedere, il <code>refParameter</code> di <code>squareRef()</code> deve essere dichiarato usando la parola chaive <code>ref</code>, e dobbiamo anche usare la parola chiave quando chiamiamo la funzione. Quindi, l'argomento sar\u00e0 passato per reference, e potr\u00e0 essere modificato in place.</p> <p>Python non ha una parola chiave <code>ref</code>, o un suo equivalente. SE provassimo a replicare l'esempio precedente in Python, avremmo risultati differenti:</p> <pre><code>&gt;&gt;&gt; def main():\n...     arg = 4\n...     square(arg)\n...     print(arg)\n...\n&gt;&gt;&gt; def square(n):\n...     n *= n\n...\n&gt;&gt;&gt; main()\n4\n</code></pre> <p>In questo caso, la variabile <code>arg</code> non viene alterata in place. Sembra che Python tratti l'argomento passato come valore singolo piuttosto che una reference ad una variabile esistente. Questo singifica che Python passa gli argomenti per valore piuttosto che per reference?</p> <p>Non proprio. Python passa gli argomenti n\u00e9 per reference n\u00e9 per valore, ma per assegnazione (assignment). Vedremo a breve rapidamente i dettalgi del passaggio per valore e per reference prima di guardare pi\u00f9 da vicino l'approccio di Python. Dopo questo, vedremo alcune delle best practice epr ottenere l'equivalente del passaggiuo per reference in Python.</p>"},{"location":"material/01_python/03_advanced/reference/#passaggio-per-valore-vs-passaggio-per-reference","title":"passaggio per valore vs. passaggio per reference","text":"<p>Quando passiamo degli argomenti di una funzione per reference, questi argomenti sono riferiti soltanto a valori gi\u00e0 esistenti. Di contro, quando passaimo gli argomenti per valore, questi diventano copie indipendenti dei valori originari.</p> <p>Torniamo brevemente all'esempio in C#, questa volta togliendo la parola chiave <code>ref</code>. Questo far\u00e0 s\u00ec che il programma usi il comportamento di default, ovvero il passaggio per valore:</p> <pre><code>using System;\n// Source:\n// https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/passing-parameters\nclass Program\n{\nstatic void Main(string[] args)\n{\nint arg;\n// Passing by value.\n// The value of arg in Main is not changed.\narg = 4;\nsquareVal(arg);\nConsole.WriteLine(arg);\n// Output: 4\n}\nstatic void squareVal(int valParameter)\n{\nvalParameter *= valParameter;\n}\n}\n</code></pre> <p>Qui, possiamo vedere che <code>squareVal()</code> non modifica la variabile originaria. Piuttosto, <code>valParameter</code> \u00e8 una copia indipendente della variabile originaria <code>arg</code>. Anche se questo combacia con il comportamento che vedremmo in Python, ricordiamo che Python non passa esattamente per valore. Proviamo ci\u00f2.</p> <p>La funzione integrata <code>id()</code> di Python restituisce un intero che rappresenta l'indirizzo di memoria dell'oggetto desiderato. Usando <code>id()</code>, possiamo verificare che:</p> <ul> <li>gli argomenti della funzione si riferiscono inizialmente allo stesso indirizzo delle loro variabili originarie</li> <li>riassegnare l'argomento nella funzione gli d\u00e0 un nuovo indirizzo, mentre la variabile originaria rimane immutata</li> </ul> <p>Nell'esempio successivo, notiamo che l'idnirizzo di <code>x</code> combacia inizialmente con quello di <code>n</code>, ma cambia dopo la riassegnazione, mentre l'indirizzo di <code>n</code> non cambia:</p> <pre><code>&gt;&gt;&gt; def main():\n...     n = 9001\n...     print(f\"Initial address of n: {id(n)}\")\n...     increment(n)\n...     print(f\"  Final address of n: {id(n)}\")\n...\n&gt;&gt;&gt; def increment(x):\n...     print(f\"Initial address of x: {id(x)}\")\n...     x += 1\n...     print(f\"  Final address of x: {id(x)}\")\n...\n&gt;&gt;&gt; main()\nInitial address of n: 140562586057840\nInitial address of x: 140562586057840\nFinal address of x: 140562586057968\nFinal address of n: 140562586057840\n</code></pre> <p>Il fatto che l'indirizzo iniziale di <code>n</code> ed <code>x</code> siano gli stessi quando invochiamo <code>increment()</code> prova che l'argomento <code>x</code> non sta venendo passato per valore. Altrimetni, <code>n</code> ed <code>x</code> avrebbero avuto indirizzi di memoria distinti.</p> <p>Prima di apprendere i dettagli di come Python gestisce gli argomenti, vediamo alcuni casi d'uso pratici del passaggio per reference.</p>"},{"location":"material/01_python/03_advanced/reference/#utilizzare-dei-costrutti-di-passaggio-per-referecne","title":"Utilizzare dei costrutti di passaggio per referecne","text":"<p>Passare variabili per reference \u00e8 una delle tante strategie che possiamo usare per implementare determianti pattern di programmazione. Anche se non \u00e8 sempre necessario, il passaggio per reference pu\u00f2 comunque essere utile.</p> <p>In questa sezione, vedremo tre dei pattern pi\u00f9 comuni per i quali il passaggio per reference \u00e8 un approccio pratico. Vedremo quindi come implementare ciascuno di questi pattern in Python.</p>"},{"location":"material/01_python/03_advanced/reference/#evitare-oggetti-duplicati","title":"Evitare oggetti duplicati","text":"<p>Come abbiamo visto, passare una variabile per valore casuer\u00e0 la creazione e memorizzazione di una copia di quel valore, Nei linguaggi in cui il comportamento di default \u00e8 il passaggio per valore, potremmo avere dei benefici in termini di performance nel passaggio per reference, specialmente qunado la variabile ha molti dati. Questo sar\u00e0 abbastanza evidente quando il codice gira su macchine con risorse limitate.</p> <p>In Python, tuttavia, questo non \u00e8 mai un problema. Veddemo il perch\u00e9 nella sezione successiva.</p>"},{"location":"material/01_python/03_advanced/reference/#restiture-valori-multipli","title":"Restiture valori multipli","text":"<p>Una delle applicazioni pi\u00f9 comuni del passaggio per reference \u00e8 creare auna funzione che alteri il valore dei parametri di riferimento restituendo un valore distinto. Possiamo modificare l'esempio del passaggio per reference in C# per illustrare questa tecnica:</p> <pre><code>using System;\nclass Program\n{\nstatic void Main(string[] args)\n{\nint counter = 0;\n// Passing by reference.\n// The value of counter in Main is changed.\nConsole.WriteLine(greet(\"Alice\", ref counter));\nConsole.WriteLine(\"Counter is {0}\", counter);\nConsole.WriteLine(greet(\"Bob\", ref counter));\nConsole.WriteLine(\"Counter is {0}\", counter);\n// Output:\n// Hi, Alice!\n// Counter is 1\n// Hi, Bob!\n// Counter is 2\n}\nstatic string greet(string name, ref int counter)\n{\nstring greeting = \"Hi, \" + name + \"!\";\ncounter++;\nreturn greeting;\n}\n}\n</code></pre> <p>Nell'esempio precedente, <code>greet()</code> restituisce una stringa di benvenuto e modifica contestualmente il valore del contatore. Ora, proviamo a riprodurre questo quanto pi\u00f9 possibile in Python:</p> <pre><code>&gt;&gt;&gt; def main():\n...     counter = 0\n...     print(greet(\"Alice\", counter))\n...     print(f\"Counter is {counter}\")\n...     print(greet(\"Bob\", counter))\n...     print(f\"Counter is {counter}\")\n...\n&gt;&gt;&gt; def greet(name, counter):\n...     counter += 1\n...     return f\"Hi, {name}!\"\n...\n&gt;&gt;&gt; main()\nHi, Alice!\nCounter is 0\nHi, Bob!\nCounter is 0\n</code></pre> <p>Counter non viene incrementato nell'esempio precedente perch\u00e9, come abbiamo appreso in precedenza, Python non ha modo di passare i valori per reference. Quindi, come possiamo ottenere lo stesso risultato ottenuto in C#?</p> <p>In pratica, i parametri passati per riferimento in C# permettono alla funzione non solo di restituire un valore, ma anche di operare su parametri aggiuntivi. QUesto equivale a restituire valori multipli.</p> <p>Fortunatamente, Python supporta gi\u00e0 la restituzione di valori multipli. In senso stretto, una funzione Python che restituisce valori multipli restituisce in effetti una tupla che contiene ogni valore.</p> <pre><code>&gt;&gt;&gt; def multiple_return():\n...     return 1, 2\n...\n&gt;&gt;&gt; t = multiple_return()\n&gt;&gt;&gt; t  # A tuple\n(1, 2)\n&gt;&gt;&gt; # You can unpack the tuple into two variables:\n&gt;&gt;&gt; x, y = multiple_return()\n&gt;&gt;&gt; x\n1\n&gt;&gt;&gt; y\n2\n</code></pre> <p>Come possiamo vedere, per restiturie valori multipli, possiamo semplicemente usare la parola chiave <code>return</code>seguita da valori separati da virgole, o variabili.</p> <p>Grazie a questa tecnica, posisamo modificare l'istruzione di ritorno in <code>greet()</code> dal codice Python precedente per restituire sia un messaggio di benvenuto sia un contatore:</p> <pre><code>&gt;&gt;&gt; def main():\n...     counter = 0\n...     print(greet(\"Alice\", counter))\n...     print(f\"Counter is {counter}\")\n...     print(greet(\"Bob\", counter))\n...     print(f\"Counter is {counter}\")\n...\n&gt;&gt;&gt; def greet(name, counter):\n...     return f\"Hi, {name}!\", counter + 1\n...\n&gt;&gt;&gt; main()\n('Hi, Alice!', 1)\nCounter is 0\n('Hi, Bob!', 1)\nCounter is 0\n</code></pre> <p>Tuttavia, questo ancora non sembra giusto. Anche se adesso <code>greet()</code> restituisce pi\u00f9 valori, questi stanno venendo stampati come una tupla, il che non \u00e8 nostra intenzione. Inoltre, la variabile contatore originaria rimane a 0.</p> <p>Per pulire il nostro output ed ottenere i risutlati desiderati, dobbiamo reassegnare la variabile <code>counter</code> con ogni chiamata a <code>greet()</code>.</p> <pre><code>&gt;&gt;&gt; def main():\n...     counter = 0\n...     greeting, counter = greet(\"Alice\", counter)\n...     print(f\"{greeting}\\nCounter is {counter}\")\n...     greeting, counter = greet(\"Bob\", counter)\n...     print(f\"{greeting}\\nCounter is {counter}\")\n...\n&gt;&gt;&gt; def greet(name, counter):\n...     return f\"Hi, {name}!\", counter + 1\n...\n&gt;&gt;&gt; main()\nHi, Alice!\nCounter is 1\nHi, Bob!\nCounter is 2\n</code></pre> <p>Ora, dopo aver riassegnato ogni variabile con una chiamata a <code>greet()</code>, potremo vedere i risultati desiderati.</p> <p>Assegnare i valori di ritorno alle variabili \u00e8 il miglior modo di ottenere gli stessi risultati del passaggio per reference in Python. Vedremo il perch\u00e9, tra le altre cose, nella sezione sulle best pracitce.</p>"},{"location":"material/01_python/03_advanced/reference/#creazione-di-funzioni-condizionali-con-piu-valori-di-ritorno","title":"Creazione di funzioni condizionali con pi\u00f9 valori di ritorno","text":"<p>Questo \u00e8 un caso d'uso specifico di restituire pi\u00f9 valori nel quale la funzione pu\u00f2 essere usata in un'istruzione condizionale ed ha dei side effect aggiuntivi, come modificare una variabile esterna passata come argomento.</p> <p>Consideriamo la funzione standard <code>Int32.TryParse</code> in C#, che restituisce un valore booleano edmopera su una reference ad un argomento intero allo stesso tempo:</p> <pre><code>public static bool TryParse (string s, out int result);\n</code></pre> <p>Questa funzione prova a convertire una stringa in un intero a 32 bit cons egno usando la parola chiave <code>out</code>. Ci sono due possibili risultati:</p> <ul> <li>se il parsing ha successo, il parametro di output sar\u00e0 impostato all'intero risultatnte, e la funzione restituir\u00e0 <code>true</code></li> <li>se il parsing fallisce, allora il parmaetro di output sar\u00e0 impostato a <code>0</code>, e la funzione restituir\u00e0 falso</li> </ul> <p>Possiamo vedere questo nella pratica nel seguente esempio, che prova a convertire un certo numero di stringhe differenti:</p> <pre><code>using System;\n// Source:\n// https://docs.microsoft.com/en-us/dotnet/api/system.int32.tryparse?view=netcore-3.1#System_Int32_TryParse_System_String_System_Int32__\npublic class Example {\npublic static void Main() {\nString[] values = { null, \"160519\", \"9432.0\", \"16,667\",\n\"   -322   \", \"+4302\", \"(100);\", \"01FA\" };\nforeach (var value in values) {\nint number;\nif (Int32.TryParse(value, out number)) {\nConsole.WriteLine(\"Converted '{0}' to {1}.\", value, number);\n}\nelse {\nConsole.WriteLine(\"Attempted conversion of '{0}' failed.\",\nvalue ?? \"&lt;null&gt;\");\n}\n}\n}\n}\n</code></pre> <p>Il codice precedente, che prova a convertrire delle stringhe formattate differentemente in interi mediante <code>TryParse()</code>, manda in output il seguente:</p> <pre><code>Attempted conversion of '&lt;null&gt;' failed.\nConverted '160519' to 160519.\nAttempted conversion of '9432.0' failed.\nAttempted conversion of '16,667' failed.\nConverted '   -322   ' to -322.\nConverted '+4302' to 4302.\nAttempted conversion of '(100);' failed.\nAttempted conversion of '01FA' failed.\n</code></pre> <p>Per implementare una funzione simile in Python, possiamo usare molteplici valori di ritorno come visto in precedenza:</p> <pre><code>def tryparse(string, base=10):\ntry:\nreturn True, int(string, base=base)\nexcept ValueError:\nreturn False, None\n</code></pre> <p>Questa funzione <code>tryparse()</code> restituisce due valori. Il primo valore indica se la conversione ha avuto successo, ed il secondo contiene il risultato (o <code>None</code>, in caso di fallimento).</p> <p>Tuttavia, l'uso di questa funzione \u00e8 un po' CLUNKY, perch\u00e9 dobbiamo spacchettare il valore di ritorno ad ogni chiamata. Questo significa che non possiamo usare la funzione all'interno di un'istruzione if:</p> <pre><code>&gt;&gt;&gt; success, result = tryparse(\"123\")\n&gt;&gt;&gt; success\nTrue\n&gt;&gt;&gt; result\n123\n&gt;&gt;&gt; # We can make the check work\n&gt;&gt;&gt; # by accessing the first element of the returned tuple,\n&gt;&gt;&gt; # but there's no way to reassign the second element to `result`:\n&gt;&gt;&gt; if tryparse(\"456\")[0]:\n...     print(result)\n...\n123\n</code></pre> <p>Anche se in linea generale questo funziona restituendo pi\u00f9 valori, <code>tryparse()</code> non pu\u00f2 essere usato in un check condizionale. Questo significa che abbiamo dell'ulteriore lavoro da fare.</p> <p>Possiamo sfruttare la flessibilit\u00e0 di Python e semplificare la funzione per restituire un singolo valore di diversi tipi a seconda del fatto che la conversione abbia successo:</p> <pre><code>def tryparse(string, base=10):\ntry:\nreturn int(string, base=base)\nexcept ValueError:\nreturn None\n</code></pre> <p>Grazie al fatto che le funzioni Python possono restituire diversi tipi di dato, possiamo usare questa funzione all'interno di un'istruzione condizionale. Ma come? Non dovremmo chiamare per prima la funzione, assegnare il suo valore di ritorno, e quindi controllare il valore stesso?</p> <p>Sfruttando la flessibilit\u00e0 di Python sui tipi degli oggetti, cos\u00ec come le nuove espressioni di assegnazione in Python 3.8, possiamo chiamare questa funzione semplificata all'interno di un'istruzione if ed ottenere il valore di ritorno se il controllo passa:</p> <pre><code>&gt;&gt;&gt; if (n := tryparse(\"123\")) is not None:\n...     print(n)\n...\n123\n&gt;&gt;&gt; if (n := tryparse(\"abc\")) is None:\n...     print(n)\n...\nNone\n&gt;&gt;&gt; # You can even do arithmetic!\n&gt;&gt;&gt; 10 * tryparse(\"10\")\n100\n&gt;&gt;&gt; # All the functionality of int() is available:\n&gt;&gt;&gt; 10 * tryparse(\"0a\", base=16)\n100\n&gt;&gt;&gt; # You can also embed the check within the arithmetic expression!\n&gt;&gt;&gt; 10 * (n if (n := tryparse(\"123\")) is not None else 1)\n1230\n&gt;&gt;&gt; 10 * (n if (n := tryparse(\"abc\")) is not None else 1)\n10\n</code></pre> <p>Notiamo che questa versione di <code>tryparse()</code> risulta essere anche pi\u00f9 potente della versione C#, permettendoci di suarla all'interno di istruzioni condizionali ed in espressioni aritmetiche.</p> <p>Con un po' di ingenuit\u00e0, abbiamo replicato un pattern specifico ed utile di passaggio per reference senza passare gli argomenti per reference. Infatti, dobbiamo di nuovo assegnare i valori di ritorno quando usiamo l'operatore di assegnazione (:=) ed usando il valore di ritorno direttamente nelle espressioni Python.</p> <p>Finora, abbiamo appreso quello che significa passaggio per reference, come differisce dal passaggio per valore, e come l'approccio di Python differisca da entrambi. Ora siamo pronti a dare un'occhiata ravvicinata a come Python gestisce gli argomenti di una funzione.</p>"},{"location":"material/01_python/03_advanced/reference/#passare-gli-argomenti-in-python","title":"Passare gli argomenti in Python","text":"<p>Python passa gli argomenti per assegnazione. Ci\u00f2 significa che quando chiamiamo una funzione Python, ogni argomento diventa una variabile alla quale viene assegnato il valore passato.</p> <p>Quindi, possiamo apprendere dettagli importanti su come Python gestisce gli argomenti della funzione comprendendo come il meccanismo di assegnazione stesso funziona, anche al di fuori delle funzioni.</p>"},{"location":"material/01_python/03_advanced/reference/#comprendere-lassegnazione-in-python","title":"Comprendere l'assegnazione in Python","text":"<p>La documentazione di Python per le istruzioni di assegnazione fornisce i seguenti dettagli:</p> <ul> <li>se l'obiettivo dell'assegnazione \u00e8 un identificatore, o il nome di una variabile, questo nome \u00e8 collegato all'oggetto. Per esempio, in <code>x = 2</code>, <code>x</code> \u00e8 il nome e <code>2</code> \u00e8 l'oggetto.</li> <li>se il nome \u00e8 gi\u00e0 collegato ad un oggetto separato, viene quindi ri-collegato al nuovo oggetto. Ad esempio, se <code>x</code> \u00e8 gi\u00e0 <code>2</code> ed abbiamo scritto <code>x = 3</code>, allora il nome della variabile <code>x</code> viene ri-assegnato a <code>3</code>.</li> </ul> <p>Tutti gli oggetti Python sono implementati secondo una certa struttura. UNa delle propriet\u00e0 di qeusta struttura \u00e8 un contatore che tiene traccia di qunati nomi sono stati collegati a questo oggetto.</p> <p>Nota</p> <p>Questo contatore \u00e8 chiamato reference counter perch\u00e9 tiene traccia di quante reference, o nomi, puntano allo stesso oggetto. Non confondiamo il reference counter con il concetto di passaggio per reference, in quanto i due sono incorrelati.</p> <p>La documentazione Python fornisce ulteriori dettagli sui reference counts.</p> <p>Rimaniamo all'esempio <code>x = 2</code> ed esaminiamo quello che accade quando assegnamo un valore ad una nuova varibile:</p> <ul> <li>se un oggetto rappresentativo del valore <code>2</code> esiste gi\u00e0, viene recuperato. Altrimenti, \u00e8 creato.</li> <li>il reference counter di questo oggetto viene incrementato</li> <li>un'entrata \u00e8 aggiunta nell'attuale namespace per collegare l'identificatore <code>x</code> all'oggetto che rappresenta <code>2</code>. Questa entrata \u00e8 nei fatti una coppia chiave-valore memorizzata in un dizionario. Una rappresentazione di questo dizionario \u00e8 restituita da <code>locals()</code> o <code>globals()</code>.</li> </ul> <p>Ecco quello chea ccade se riassegnamo <code>x</code> ad un diverso valore:</p> <ul> <li>il reference counter dell'oggetto rappresentante <code>2</code> viene decrementato</li> <li>il reference counter dell'oggetto che rappresenta il nuovo valore \u00e8 incrementato</li> <li>il dizionario per l'attuale namespace \u00e8 aggiornato per correlare <code>x</code> all'oggetto rappresentante il nuovo valore</li> </ul> <p>Python ci permette di ottenre il reference counter per valori arbitrari con la funzione <code>sys.getrefcount()</code>. Possiamo usarla per illustrare come l'assegnazione incemenrta e decrementa questi reference counter. Notiamo che l'interprete interattivo sfrutta il comportamento che dar\u00e0 risultati differenti, per cui dovremo eseguire il seguente codice da un file:</p> <pre><code>from sys import getrefcount\nprint(\"--- Before  assignment ---\")\nprint(f\"References to value_1: {getrefcount('value_1')}\")\nprint(f\"References to value_2: {getrefcount('value_2')}\")\nx = \"value_1\"\nprint(\"--- After   assignment ---\")\nprint(f\"References to value_1: {getrefcount('value_1')}\")\nprint(f\"References to value_2: {getrefcount('value_2')}\")\nx = \"value_2\"\nprint(\"--- After reassignment ---\")\nprint(f\"References to value_1: {getrefcount('value_1')}\")\nprint(f\"References to value_2: {getrefcount('value_2')}\")\n</code></pre> <p>Questo script mostrer\u00e0 il conteggio delle reference per ogni valore prima dell'assegnazione, dopo l'assegnazione, e dopo la riassegnazione:</p> <pre><code>--- Before  assignment ---\nReferences to value_1: 3\nReferences to value_2: 3\n--- After   assignment ---\nReferences to value_1: 4\nReferences to value_2: 3\n--- After reassignment ---\nReferences to value_1: 3\nReferences to value_2: 4\n</code></pre> <p>Questi risultai illustrano la relazione tra gli identificatori (nomi delle variabili) e gli oggetti Python che rapprentano valori distinti. Quando assegnamo pi\u00f9 variabili allo stesso valore, Python aumenta il reference counter per l'oggetto esistente ed aggiorna il namespace attuale piuttosto che creare oggetti duplicati in memroia.</p> <p>Vediamo adesso di esplorare come Python gestisce gli argomenti di una funzione.</p>"},{"location":"material/01_python/03_advanced/reference/#esplorazione-degli-argomenti-di-una-funzione","title":"Esplorazione degli argomenti di una funzione","text":"<p>Gli argomenti di una funzione in Python sono variabili locali. Cosa significa? Quello locale \u00e8 uno degli ambiti definiti in Python (ed in ogni linguaggio di programmazione). Questi ambiti sono rappresentati dai namespace dictionary menizioanti nella sezione precedente. Possiamo usare <code>locals()</code> e <code>globals()</code> per recuperare i namespace dictionary locali e globali, rispettivamnete.</p> <p>All'esecuzione, ogni funzione ha il suo proprio namespace locale:</p> <pre><code>&gt;&gt;&gt; def show_locals():\n...     my_local = True\n...     print(locals())\n...\n&gt;&gt;&gt; show_locals()\n{'my_local': True}\n</code></pre> <p>Usando <code>locals()</code>, possiamo dimostrare che gli argomenti della funzione diventano variabili regolai nel namespace locale della funzione. Aggiungiamo un argomento, <code>my_arg</code>, alla funzione:</p> <pre><code>&gt;&gt;&gt; def show_locals(my_arg):\n...     my_local = True\n...     print(locals())\n...\n&gt;&gt;&gt; show_locals(\"arg_value\")\n{'my_arg': 'arg_value', 'my_local': True}\n</code></pre> <p>Possiamo anche usare <code>sys.getrefcount()</code> per mostrare come gli argomenti di funzioni aumentano il conteggio delle reference per un oggetto:</p> <pre><code>&gt;&gt;&gt; from sys import getrefcount\n&gt;&gt;&gt; def show_refcount(my_arg):\n...     return getrefcount(my_arg)\n...\n&gt;&gt;&gt; getrefcount(\"my_value\")\n3\n&gt;&gt;&gt; show_refcount(\"my_value\")\n5\n</code></pre> <p>Lo script precedente scrive il conteggio delle reference per <code>my_value</code> per prima cosa all'esterno, poi all'interno di <code>show_refcount()</code>, mostrando un aumento del reference count non di uno, ma di due!</p> <p>Questo perch\u00e9, oltre a <code>show_refcount()</code> stesso, la chiamata a <code>sys.getrefcount()</code> all'interno di <code>show_refcount()</code> riceve anche <code>my_arg</code> come argomento. Questo piazza <code>my_arg</code> nel namespace locale per <code>sys.getrefcount()</code>, aggiungendo una reference extra a <code>my_value</code>.</p> <p>By examining namespaces and reference counts inside functions, you can see that function arguments work exactly like assignments: Python creates bindings in the function\u2019s local namespace between identifiers and Python objects that represent argument values. Each of these bindings increments the object\u2019s reference counter.</p> <p>Now you can see how Python passes arguments by assignment!</p> <p>Remove ads Replicating Pass by Reference With Python Having examined namespaces in the previous section, you may be asking why global hasn\u2019t been mentioned as one way to modify variables as if they were passed by reference:</p> <p>def square(): ...     # Not recommended! ...     global n ...     n *= n ... n = 4 square() n 16 Using the global statement generally takes away from the clarity of your code. It can create a number of issues, including the following:</p> <p>Free variables, seemingly unrelated to anything Functions without explicit arguments for said variables Functions that can\u2019t be used generically with other variables or arguments since they rely on a single global variable Lack of thread safety when using global variables Contrast the previous example with the following, which explicitly returns a value:</p> <p>def square(n): ...     return n * n ... square(4) 16 Much better! You avoid all potential issues with global variables, and by requiring an argument, you make your function clearer.</p> <p>Despite being neither a pass-by-reference language nor a pass-by-value language, Python suffers no shortcomings in that regard. Its flexibility more than meets the challenge.</p> <p>Best Practice: Return and Reassign You\u2019ve already touched on returning values from the function and reassigning them to a variable. For functions that operate on a single value, returning the value is much clearer than using a reference. Furthermore, since Python already uses pointers behind the scenes, there would be no additional performance benefits even if it were able to pass arguments by reference.</p> <p>Aim to write single-purpose functions that return one value, then (re)assign that value to variables, as in the following example:</p> <p>def square(n):     # Accept an argument, return a value.     return n * n</p> <p>x = 4 ...</p>"},{"location":"material/01_python/03_advanced/reference/#later-reassign-the-return-value","title":"Later, reassign the return value:","text":"<p>x = square(x) Returning and assigning values also makes your intention explicit and your code easier to understand and test.</p> <p>For functions that operate on multiple values, you\u2019ve already seen that Python is capable of returning a tuple of values. You even surpassed the elegance of Int32.TryParse() in C# thanks to Python\u2019s flexibility!</p> <p>If you need to operate on multiple values, then you can write single-purpose functions that return multiple values, then (re)assign those values to variables. Here\u2019s an example:</p> <p>def greet(name, counter):     # Return multiple values     return f\"Hi, {name}!\", counter + 1</p> <p>counter = 0 ...</p>"},{"location":"material/01_python/03_advanced/reference/#later-reassign-each-return-value-by-unpacking","title":"Later, reassign each return value by unpacking.","text":"<p>greeting, counter = greet(\"Alice\", counter) When calling a function that returns multiple values, you can assign multiple variables at the same time.</p> <p>Best Practice: Use Object Attributes Object attributes have their own place in Python\u2019s assignment strategy. Python\u2019s language reference for assignment statements states that if the target is an object\u2019s attribute that supports assignment, then the object will be asked to perform the assignment on that attribute. If you pass the object as an argument to a function, then its attributes can be modified in place.</p> <p>Write functions that accept objects with attributes, then operate directly on those attributes, as in the following example:</p> <p>It\u2019s worth repeating that you should make sure the attribute supports assignment! Here\u2019s the same example with namedtuple, whose attributes are read-only:</p> <p>from collections import namedtuple NS = namedtuple(\"NS\", \"n\") def square(instance): ...     instance.n *= instance.n ... ns = NS(4) ns.n 4 square(ns) Traceback (most recent call last):   File \"\", line 1, in    File \"\", line 2, in square AttributeError: can't set attribute Attempts to modify attributes that don\u2019t allow modification result in an AttributeError. <p>Additionally, you should be mindful of class attributes. They will remain unchanged, and an instance attribute will be created and modified:</p> <p>class NS: ...     n = 4 ... ns = NS() def square(instance): ...     instance.n *= instance.n ... ns.n 4 square(ns)</p>"},{"location":"material/01_python/03_advanced/reference/#for-the-purpose-of-this-example-lets-use-simplenamespace","title":"For the purpose of this example, let's use SimpleNamespace.","text":"<p>from types import SimpleNamespace</p>"},{"location":"material/01_python/03_advanced/reference/#simplenamespace-allows-us-to-set-arbitrary-attributes","title":"SimpleNamespace allows us to set arbitrary attributes.","text":""},{"location":"material/01_python/03_advanced/reference/#it-is-an-explicit-handy-replacement-for-class-x-pass","title":"It is an explicit, handy replacement for \"class X: pass\".","text":"<p>ns = SimpleNamespace()</p> <p>Remove ads Best Practice: Use Dictionaries and Lists Dictionaries in Python are a different object type than all other built-in types. They\u2019re referred to as mapping types. Python\u2019s documentation on mapping types provides some insight into the term:</p> <p>A mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only one standard mapping type, the dictionary. (Source)</p> <p>This tutorial doesn\u2019t cover how to implement a custom mapping type, but you can replicate pass by reference using the humble dictionary. Here\u2019s an example using a function that operates directly on dictionary elements:</p> <p>While lists aren\u2019t mapping types, you can use them in a similar way to dictionaries because of two important characteristics: subscriptability and mutability. These characteristics are worthy of a little more explanation, but let\u2019s first take a look at best practices for mimicking pass by reference using Python lists.</p> <p>To replicate pass by reference using lists, write a function that operates directly on list elements:</p> <p>Now let\u2019s explore subscriptability. An object is subscriptable when a subset of its structure can be accessed by index positions:</p> <p>subscriptable = [0, 1, 2]  # A list subscriptable[0] 0 subscriptable = (0, 1, 2)  # A tuple subscriptable[0] 0 subscriptable = \"012\"  # A string subscriptable[0] '0' notsubscriptable = {0, 1, 2}  # A set notsubscriptable[0] Traceback (most recent call last):   File \"\", line 1, in  TypeError: 'set' object is not subscriptable Lists, tuples, and strings are subscriptable, but sets are not. Attempting to access an element of an object that isn\u2019t subscriptable will raise a TypeError. <p>Mutability is a broader topic requiring additional exploration and documentation reference. To keep things short, an object is mutable if its structure can be changed in place rather than requiring reassignment:</p> <p>mutable = [0, 1, 2]  # A list mutable[0] = \"x\" mutable ['x', 1, 2]</p> <p>notmutable = (0, 1, 2)  # A tuple notmutable[0] = \"x\" Traceback (most recent call last):   File \"\", line 1, in  TypeError: 'tuple' object does not support item assignment <p>notmutable = \"012\"  # A string notmutable[0] = \"x\" Traceback (most recent call last):   File \"\", line 1, in  TypeError: 'str' object does not support item assignment <p>mutable = {0, 1, 2}  # A set mutable.remove(0) mutable.add(\"x\") mutable {1, 2, 'x'} Lists and sets are mutable, as are dictionaries and other mapping types. Strings and tuples are not mutable. Attempting to modify an element of an immutable object will raise a TypeError.</p> <p>Conclusion Python works differently from languages that support passing arguments by reference or by value. Function arguments become local variables assigned to each value that was passed to the function. But this doesn\u2019t prevent you from achieving the same results you\u2019d expect when passing arguments by reference in other languages.</p> <p>In this tutorial, you learned:</p> <p>How Python handles assigning values to variables How function arguments are passed by assignment in Python Why returning values is a best practice for replicating pass by reference How to use attributes, dictionaries, and lists as alternative best practices You also learned some additional best practices for replicating pass-by-reference constructs in Python. You can use this knowledge to implement patterns that have traditionally required support for passing by reference.</p> <p>To continue your Python journey, I encourage you to dive deeper into some of the related topics that you\u2019ve encountered here, such as mutability, assignment expressions, and Python namespaces and scope.</p> <p>Stay curious, and see you next time!</p>"},{"location":"material/01_python/03_advanced/reference/#define-a-function-to-operate-on-an-objects-attribute","title":"Define a function to operate on an object's attribute.","text":"<p>def square(instance): ...     instance.n *= instance.n ... ns.n = 4 square(ns) ns.n 16 Note that square() needs to be written to operate directly on an attribute, which will be modified without the need to reassign a return value.</p>"},{"location":"material/01_python/03_advanced/reference/#instance-attribute-is-modified","title":"Instance attribute is modified.","text":"<p>ns.n 16</p>"},{"location":"material/01_python/03_advanced/reference/#class-attribute-remains-unchanged","title":"Class attribute remains unchanged.","text":"<p>NS.n 4 Since class attributes remain unchanged when modified through a class instance, you\u2019ll need to remember to reference the instance attribute.</p>"},{"location":"material/01_python/03_advanced/reference/#dictionaries-are-mapping-types","title":"Dictionaries are mapping types.","text":"<p>mt = {\"n\": 4}</p>"},{"location":"material/01_python/03_advanced/reference/#define-a-function-to-operate-on-a-key","title":"Define a function to operate on a key:","text":"<p>def square(numdict): ...     numdict[\"n\"] *= num_dict[\"n\"] ... square(mt) mt {'n': 16} Since you\u2019re reassigning a value to a dictionary key, operating on dictionary elements is still a form of assignment. With dictionaries, you get the added practicality of accessing the modified value through the same dictionary object.</p>"},{"location":"material/01_python/03_advanced/reference/#lists-are-both-subscriptable-and-mutable","title":"Lists are both subscriptable and mutable.","text":"<p>sm = [4]</p>"},{"location":"material/01_python/03_advanced/reference/#define-a-function-to-operate-on-an-index","title":"Define a function to operate on an index:","text":"<p>def square(numlist): ...     numlist[0] *= num_list[0] ... square(sm) sm [16] Since you\u2019re reassigning a value to an element within the list, operating on list elements is still a form of assignment. Similar to dictionaries, lists allow you to access the modified value through the same list object.</p>"},{"location":"material/02_libs/01_jupyter/lecture/","title":"1 - iPython e Jupyter Lab","text":"<p>Notebook di accompagnamento</p> <p>Per questa lezione esiste un notebook di accompagnamento, reperibile a questo indirizzo.</p> <p>Fino a questo momento ci siamo limitati a lanciare script Python direttamente da riga di comando. Tuttavia, \u00e8 evidente come questo approccio sia limitato, specialmente in applicazioni in ambito data science.</p> <p>Per ovviare a queste problematiche, all'interno del framework SciPy viene proposto Jupyter Lab,  che introduce uno tra gli strumenti pi\u00f9 utilizzati dai data analyst al giorno d'oggi, ovvero i notebook.</p>"},{"location":"material/02_libs/01_jupyter/lecture/#anatomia-di-un-notebook","title":"Anatomia di un notebook","text":"<p>Un notebook \u00e8, in poche parole, un ambiente interattivo che permette di scrivere e testare il nostro codice. In particolare, ptoremo scrivere una o pi\u00f9 istruzioni, ed eseguirle in maniera separata dalle altre mediante il meccanismo delle celle, che altro non sono se non dei singoli \"blocchi\" di codice.</p> <p>Suggerimento</p> <p>I notebook Jupyter ci permettono di inserire anche commenti, descrizioni ed equazioni utilizzando due linguaggi di markup molto noti, ovvero Markdown e Latex.</p> <p>Vediamo adesso come creare ed utilizzare il nostro primo notebook.</p>"},{"location":"material/02_libs/01_jupyter/lecture/#installazione-e-lancio-di-jupyter-lab","title":"Installazione e lancio di Jupyter Lab","text":"<p>Installazione di una libreria</p> <p>Ricordiamo che le diverse opzioni utilizzabili per installare una libreria sono descritte nel dettaglio nell'appendice B.</p> <p>Per installare Jupyter Lab, ricorriamo all'utilizzo di <code>pip</code>, preferibilmente all'interno di un ambiente virtuale:</p> <pre><code>workon my-virtual-env\n(my-virtual-env) pip install jupyterlab\n</code></pre> <p>A differenza delle altre librerie, Jupyter non andr\u00e0 (necessariamente) importato; infatti, \u00e8 possibile lanciare un ambiente interattivo utilizzando la seguente istruzione da riga di comando:</p> <pre><code>jupyter lab\n</code></pre> <p>Importare iPython</p> <p>In teoria \u00e8 possibile importare iPython ed utilizzare i metodi e le classi messe a disposizione come una qualsiasi libreria. Nei fatti, per\u00f2, molto spesso ci si limita ad utilizzare l'ambiente interattivo offerto dai notebook.</p>"},{"location":"material/02_libs/01_jupyter/lecture/#il-primo-notebook","title":"Il primo notebook","text":"<p>A questo punto ci troveremo davanti ad una schermata simile a quella mostrata in figura 1.</p> <p> </p> Figura 1 - La schermata introduttiva di Jupyter Lab <p>Creiamo il nostro primo notebook premendo il pulsante Python 3 nel menu Notebook. Una volta terminata la procedura, potremo iniziare ad interagire con l'ambiente. Prima di procedere, per\u00f2, definiamo il nome del nostro notebook dal menu a sinistra.</p> <p>Proviamo a fare qualcosa di semplice: creiamo una funzione che sommi due variabili di tipo numerico, restituendo il risultato, e chiamiamola su due diversi valori.</p> <p>Per prima cosa, scriviamo il codice della funzione all'interno della prima cella:</p> <pre><code>def somma(a, b):\nsomma = a + b\nreturn somma\n</code></pre> <p>Per eseguire il codice all'interno della cella, premiamo il tasto <code>Play</code>, oppure la combinazione di tasti <code>Shift+Invio</code>. Una volta eseguita la prima cella, Jupyter ne creer\u00e0 in automatico un'altra; al suo interno, potremo scrivere le istruzioni necessarie a chiamare la funzione <code>somma()</code> su due diversi valori.</p> <pre><code>somma(5, 7)\n</code></pre> <p>Eseguiamo l'istruzione; noteremo che al di sotto della cella apparir\u00e0 il valore assunto dalla funzione.</p>"},{"location":"material/02_libs/01_jupyter/lecture/#altre-operazioni-utili","title":"Altre operazioni utili","text":"<p>Jupyter ci permette di effettuare una serie di operazioni utili, tra cui:</p> <ul> <li>cancellare un'intera cella;</li> <li>inserire una cella al di sopra o al di sotto di quella attualmente selezionata;</li> <li>stoppare il kernel;</li> <li>riavviare il kernel.</li> </ul> <p>Soffermiamoci per un attimo sulle ultime due operazioni. Pu\u00f2 capitare, infatti, che ci sia la necessit\u00e0 di interrompere il flusso attuale dell'esecuzione delle istruzioni, oppure ancora che sia necessario riavviare il notebook. Dato che Jupyter si basa sul concetto di kernel, il quale \u00e8 il responsabile per l'esecuzione del notebook, diremo in gergo che possiamo interrompere, o stoppare, il kernel, oppure ancora che possiamo riavviarlo.</p> <p>L'interruzione del kernel si limita a fermare l'esecuzione della cella attuale: ci\u00f2 non comporta alcuna perdita di dati, e potremo riprendere ad eseguire il codice nel notebook in ogni momento, sia dall'inizio di quella cella, sia dall'interno di un'altra. Il riavvio del kernel, invece, \"blocca\" completamente l'esecuzione, andando a cancellare anche le variabili presenti in memoria: si tratta, quindi, di un vero e proprio \"reset\", da utilizzare quando, ad esempio, abbiamo la necessit\u00e0 di riorganizzare il codice, oppure quando abbiamo effettuato un numero eccessivo di modifiche per le quali i risultati iniziano a non essere coerenti con le nostre attese.</p>"},{"location":"material/02_libs/01_jupyter/lecture/#colab","title":"Colab","text":"<p>Sempre pi\u00f9 spesso il codice per il calcolo scientifico e la data science richiede l'uso di risorse computazionali estese che, talvolta, non sono disponibili sui PC che utilizziamo. Per ovviare a questo problema, e permettere a chiunque di sperimentare con le librerie che vedremo in questo corso, esiste uno strumento chiamato Colab messo a disposizione da Google che ci permette di eseguire gratuitamente i nostri notebook Jupyter.</p> <p>Ovviamente, la versione gratuita comporta una serie di limitazioni, che tuttavia risultano essere pi\u00f9 che sufficienti per i nostri scopi.</p>"},{"location":"material/02_libs/02_numpy/01_intro/","title":"2.1 Introduzione a NumPy","text":"<p>La libreria NumPy, nome derivante dalla crasi tra Numerical Python, \u00e8 una tra le pi\u00f9 utilizzate nelle applicazioni di calcolo scientifico in Python.</p> <p>Nella pratica, possiamo pensare a NumPy come ad uno standard de facto: infatti, le classi ed i metodi messi a disposizione dalla libreria sono estensivamente utilizzate nella quasi totalit\u00e0 degli altri tool Python per le scienze matematiche, chimiche e fisiche, oltre che per l'ingegneria.</p> <p>Partiamo nella nostra disamina dalla procedura di installazione della libreria.</p>"},{"location":"material/02_libs/02_numpy/01_intro/#installare-numpy","title":"Installare NumPy","text":"<p>Installazione di una libreria</p> <p>Al solito, ricordiamo che le diverse opzioni utilizzabili per installare una libreria sono descritte nel dettaglio nell'appendice B.</p> <p>Per installare NumPy, ricorriamo all'utilizzo di <code>pip</code>, preferibilmente all'interno di un ambiente virtuale:</p> <pre><code>workon my-virtual-env\n(my-virtual-env) pip install numpy\n</code></pre>"},{"location":"material/02_libs/02_numpy/01_intro/#introduzione-a-numpy","title":"Introduzione a NumPy","text":""},{"location":"material/02_libs/02_numpy/01_intro/#gli-ndarray","title":"Gli <code>ndarray</code>","text":"<p>Abbiamo visto in precedenza che per usare un package o un modulo Python all'interno dei nostri programmi dovremo per prima cosa importarlo:</p> <pre><code>import numpy as np\n</code></pre> <p>Una volta importato NumPy, potremo passare ad utilizzare la struttura dati \"principe\" della libreria, ovvero l'array, analogo a quelli descritti dalla classica formulazione matematica.</p> <p>Nello specifico, NumPy ci mette a disposizione gli <code>ndarray</code>, ovvero delle strutture dati in grado di rappresentare array ad \\(n\\) dimensioni, contenenti dati di tipo omogeneo.</p> <p>Nota</p> <p>Anche <code>ndarray</code> \u00e8 un'abbreviazione che sta per n-dimensional array.</p> <p>Il metodo pi\u00f9 semplice per creare un array \u00e8 usare il costruttore <code>array</code> a cui viene passata una lista:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2, 3])\n</code></pre>"},{"location":"material/02_libs/02_numpy/01_intro/#array-vs-liste","title":"Array vs liste","text":"<p>Sono diverse le differenze che intercorrono tra un array ed una classica lista; le principali sono riassunte nella seguente tabella.</p> Caratteristica <code>ndarray</code> Lista Dimensione Fissa Non fissa Elementi Omogenei (stesso tipo) Eterogenei (qualsiasi tipo) Ambito Operazioni algebriche General-purpose <p>In pratica:</p> <ul> <li>un array ha dimensione fissa, a differenza della lista. Cambiarne la dimensione comporter\u00e0 quindi la creazione di un nuovo array, e la cancellazione di quello originario;</li> <li>gli elementi di un array devono essere dello stesso tipo (tale limitazione non vale ovviamente per le liste);</li> <li>gli array sono pensati specificamente per le operazioni algebriche, laddove le liste sono pensate per degli scopi generici.</li> </ul>"},{"location":"material/02_libs/02_numpy/01_intro/#numpy-e-le-operazioni-algebriche","title":"NumPy e le operazioni algebriche","text":"<p>Abbiamo detto che gli array NumPy sono progettati specificamente per le operazioni algebriche. Ovviamente, ci\u00f2 assume una notevole rilevanza ai nostri fini. Per capirlo, facciamo un esemplice esempio, nel quale moltiplichiamo tra loro due vettori riga elemento-per-elemento.</p> <p>Per effettuare l'operazione appena descritta potremmo usare un ciclo <code>for</code> o una list comprehension:</p> <pre><code># ciclo for\nc = []\nfor i in range(len(a)):\nc.append(a[i]*b[i])\n# list comprehension\nc = [a[i] * b[i] for i in range(len(a))]\n</code></pre> <p>Il risultato dell'operazione sar\u00e0 in entrambi i casi corretto. Tuttavia, i cicli sono computazionalmente costosi: ci\u00f2 significa che, specialmente all'aumentare del numero di elementi contenuti nei vettori, sar\u00e0 necessario pagare un costo crescente.</p> <p>Questo potrebbe essere in qualche modo arginato dal ricorso ad un linguaggio pi\u00f9 efficiente, come ad esempio il C; tuttavia, provando ad estendere il calcolo a due dimensioni, il codice diverr\u00e0:</p> <pre><code>for i in range(len(a)):\nfor j in range(len(b)):\nc.append(a[i][j]*b[i][j])\n</code></pre> <p>Il numero di cicli annidati aumenter\u00e0 ovviamente in maniera direttamente proporzionale alla dimensionalit\u00e0 degli array coinvolti. Ci\u00f2 implica che per un array ad \\(m\\) dimensioni avremo altrettanti cicli annidati, con tutto ci\u00f2 che ne consegue in termini di complessit\u00e0 di codice.</p> <p>Ed \u00e8 proprio in questa situazione che NumPy ci viene in aiuto. Infatti, per moltiplicare due array di qualsiasi dimensionalit\u00e0 ci basta usare la seguente istruzione:</p> <pre><code>c = a * b\n</code></pre> <p>Evidentemente, una sintassi di questo tipo risulta essere molto pi\u00f9 concisa e semplice rispetto all'uso dei cicli annidati, ed \u00e8 inoltre molto simile a quella che possiamo trovare sulle formule \"reali\" usate nei libri di testo.</p> <p>L'uso di questa sintassi si esplicita in due concetti fondamentali sui quali risulta essere basato NumPy:</p> <ul> <li>la vettorizzazione del codice, ovvero la possibilit\u00e0 di scrivere istruzioni matriciali senza usare esplicitamente dei cicli;</li> <li>il broadcasting, che riguarda la possibilit\u00e0 di usare una sintassi comune ed indipendente dalla dimensionalit\u00e0 degli array coinvolti nelle operazioni.</li> </ul>"},{"location":"material/02_libs/02_numpy/01_intro/#tipi-di-dato","title":"Tipi di dato","text":"<p>NumPy mette a disposizione una serie di tipi di dato primitivi che vanno a sovrapporsi a quelli built-in di Python, e che trovano una corrispondenza praticamente perfetta con quelli messi a disposizione dal linguaggio C.</p> <p>Questi sono riassunti nella tabella presente sulla reference.</p> <p>E' importante sottolineare due aspetti:</p> <ul> <li>la dimensione di ciascun dato dipende dalla piattaforma (ovvero, sistema operativo e processore) utilizzata;</li> <li>\u00e8 disponibile una serie di tipi la cui dimensione \u00e8 indipendente dalla piattaforma, definiti a questo indirizzo. In generale, il consiglio \u00e8 di far riferimento proprio a questi ultimi.</li> </ul>"},{"location":"material/02_libs/02_numpy/02_array/","title":"2.2 - Gli array","text":"<p>Nella lezione precedente abbiamo introdotto il concetto gli array, ovvero la struttura dati \"centrale\" nell'ecosistema di NumPy. In questa lezione ne approfondiremo aspetti e caratteristiche principali.</p>"},{"location":"material/02_libs/02_numpy/02_array/#array-e-liste","title":"Array e liste","text":"<p>Di primo acchito, l'impressione che si pu\u00f2 avere osservando gli array \u00e8 che questi siano molto simili alle classiche liste. Tuttavia, come abbiamo gi\u00e0 visto, esistono diverse differenze notevoli, riassumibili in linea di massima affermando che \u00e8 preferibile usare un array quando si devono svolgere operazioni di tipo matematico su dati omogenei.</p> <p>Gli array NumPy sono istanze della classe <code>ndarray</code>, crasi che sta per \\(n\\)-dimensional array. Mediante questa classe possiamo rappresentare strutture dati con un numero arbitrario di dimensioni, ovvero vettori, matrici e tensori.</p> <p>Il primo passo per utilizzare un array \u00e8, come accennato in precedenza, crearlo. In tal senso, ci sono diversi metodi, ma ricordiamo di seguito quello pi\u00f9 \"semplice\", che prevede l'uso del costruttore <code>array()</code> a cui passare una lista di elementi dello stesso tipo:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2, 3, 4, 5, 6])\n&gt;&gt;&gt; a\narray([1, 2, 3, 4, 5, 6])\n</code></pre> <p>Passando invece una lista i cui elementi sono a loro volta delle liste, potremo ottenere in uscita un array multidimensionale:</p> <pre><code>&gt;&gt;&gt; b = np.array([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; b\narray([[1, 2, 3],\n[4, 5, 6]])\n</code></pre> <p>Notiamo infine che gli array non sono necessariamente numerici. Possiamo, ad esempio, creare un array di stringhe:</p> <pre><code>&gt;&gt;&gt; c = np.array([\"s1\", \"s2\"])\n&gt;&gt;&gt; c\narray(['s1', 's2'], dtype='&lt;U2')\n</code></pre>"},{"location":"material/02_libs/02_numpy/02_array/#array-eterogenei","title":"Array eterogenei","text":"<p>In precedenza si \u00e8 accennato al fatto che gli array, a differenza delle liste, debbano contenere dati omogenei. Cosa succederebbe quindi se provassimo a passare al metodo <code>array()</code> una lista composta da dati di tipo eterogeneo? Partiamo verificando cosa accade ad esempio usando un intero ed un float.</p> <pre><code>&gt;&gt;&gt; d = np.array([1, 1.])\n&gt;&gt;&gt; d\narray([1., 1.])\n</code></pre> <p>Notiamo subito che \u00e8 stata effettuata in maniera implicita ed automatica un'operazione di conversione di tipo, e tutti i valori passati sono stati convertiti in formato float.</p> <p>Interessante \u00e8 anche valutare cosa accade se proviamo a passare una lista contenente un numero ed una stringa:</p> <pre><code>&gt;&gt;&gt; e = np.array([1, \"s3\"])\n&gt;&gt;&gt; e\narray(['1', 's3'], dtype='&lt;U11')\n</code></pre> <p>Notiamo come anche in questo caso sia stata effettuata una conversione di tipo, passando stavolta da intero a stringa.</p> <p>Upcasting</p> <p>La regola da tenere a mente \u00e8 che NumPy (e, in generale, Python) seguono il principio dell'upcasting: in altre parole, quando deve essere fatta una conversione tra diversi tipi di dati, si fa in modo di scegliere il tipo a pi\u00f9 alta precisione, minimizzando i rischi di perdita di informazioni.</p>"},{"location":"material/02_libs/02_numpy/02_array/#il-numero-di-elementi-di-un-array","title":"Il numero di elementi di un array","text":"<p>Gli array NumPy hanno dimensione prefissata, e sono quindi in grado di contenere un numero fisso di oggetti di un certo tipo. Per definire (o conoscere) questo valore si utilizza una propriet\u00e0 chiamata <code>shape</code> che, a grandi linee, rappresenta la forma dell'array. La shape di un array \u00e8 in pratica una tupla di numeri interi, ovviamente non negativi, ciascuno dei quali determina il numero di elementi per ciascuna delle dimensioni dell'array.</p> <p>Creiamo ad esempio un array che rappresenti una matrice \\(2 \\times 3\\), ovvero a due righe e tre colonne:</p> <pre><code>&gt;&gt;&gt; a = np.array([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; a\narray([[1, 2, 3],\n[4, 5, 6]])\n</code></pre> <p>Vediamo che valore assume la propriet\u00e0 <code>shape</code> di questo array:</p> <pre><code>&gt;&gt;&gt; a.shape\n(2, 3)\n</code></pre> <p>Come ci aspettavamo, il nostro array ha cardinalit\u00e0 due sulla prima dimensione (ovvero il numero di righe) e tre sulla seconda (ovvero il numero di colonne).</p>"},{"location":"material/02_libs/02_numpy/02_array/#altri-metodi-per-creare-un-array","title":"Altri metodi per creare un array","text":"<p>Oltre al metodo visto in precedenza, possiamo creare un array utilizzando direttamente il costruttore della classe <code>ndarray</code>:</p> <pre><code>&gt;&gt;&gt; a = np.ndarray([3, 3])       # oppure a = np.ndarray(shape=(3, 3))\n&gt;&gt;&gt; a\narray([[0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n[0.00000000e+000, 0.00000000e+000, 3.02368175e-321],\n[6.69431255e+151, 1.68534231e+246, 6.69431467e+151]])\n</code></pre> <p>Notiamo che il costruttore accetta una lista contenente la shape dell'array, che in questo caso diverr\u00e0 un \\(3 \\times 3\\).</p> <p>Nota</p> <p>Notiamo come i numeri con cui viene \"riempito\" l'array sono al momento casuali.</p> <p>Oltre a questa tecnica base, esistono diversi modi per creare array di un certo tipo. Vediamoli in breve.</p>"},{"location":"material/02_libs/02_numpy/02_array/#array-con-valori-zero-ed-unitari","title":"Array con valori zero ed unitari","text":"<p>Possiamo creare un array di dimensioni arbitrarie in cui tutti gli elementi sono pari ad 1. Per farlo, usiamo la funzione <code>ones()</code>:</p> <pre><code>&gt;&gt;&gt; u = np.ones(shape=(3, 3))\n&gt;&gt;&gt; u\narray([[1., 1., 1.],\n[1., 1., 1.],\n[1., 1., 1.]])\n</code></pre> <p>In modo simile, possiamo creare array di dimensioni arbitrarie in cui tutti gli elementi sono pari a zero mediante la funzione <code>zeros()</code>:</p> <pre><code>&gt;&gt;&gt; z = np.zeros(shape=(3, 3))\n&gt;&gt;&gt; z\narray([[0., 0., 0.],\n[0., 0., 0.],\n[0., 0., 0.]])\n</code></pre>"},{"location":"material/02_libs/02_numpy/02_array/#array-vuoti","title":"Array vuoti","text":"<p>Possiamo creare un array vuoto mediante la funzione <code>empty()</code>:</p> <pre><code>&gt;&gt;&gt; e = np.empty(shape=(3, 3))\n&gt;&gt;&gt; e\narray([[0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n[0.00000000e+000, 0.00000000e+000, 1.67982320e-321],\n[5.96555652e-302, 1.14188703e-104, 9.91401238e-278]])\n</code></pre> <p>Questa funzione pu\u00f2 risultare utile quando vogliamo preallocare spazio per un array.</p> <p>Nota</p> <p>I pi\u00f9 attenti avranno notato che, in realt\u00e0, l'array generato da <code>empty()</code> non \u00e8 vuoto, ma contiene valori casuali. In tal senso, d\u00e0 risultati equivalenti all'uso diretto del costruttore <code>ndarray()</code>.</p>"},{"location":"material/02_libs/02_numpy/02_array/#matrice-identita","title":"Matrice identit\u00e0","text":"<p>Possiamo creare una matrice identit\u00e0 usando la funzione <code>eye()</code>:</p> <pre><code>&gt;&gt;&gt; i = np.eye(3)\n&gt;&gt;&gt; i\narray([[1., 0., 0.],\n[0., 1., 0.],\n[0., 0., 1.]])\n</code></pre> <p>Attenzione</p> <p>In questo caso, notiamo come non si possa passare una tupla o una lista per indicare le dimensioni dell'array. Tuttavia, possiamo specificare sia il numero delle righe (con il primo parametro) che il numero delle colonne (con il secondo parametro).</p>"},{"location":"material/02_libs/02_numpy/02_array/#matrici-diagonali","title":"Matrici diagonali","text":"<p>La funzione <code>diag()</code> viene usata sia per creare una matrice diagonale a partire da un vettore (che, ovviamente, sar\u00e0 poi la diagonale della matrice), sia per estrarre la diagonale di una matrice. Per capire questa dualit\u00e0, immaginiamo per prima cosa di avere a disposizione un vettore riga a tre elementi, che vogliamo trasformare in modo tale che si comporti come la diagonale di una matrice.</p> <pre><code>&gt;&gt;&gt; x = np.array([5, 2, 3])\n&gt;&gt;&gt; x\narray([5, 2, 3])\n</code></pre> <p>Potremo creare una matrice diagonale a partire da questo vettore passandolo come parametro alla funzione <code>diag()</code>:</p> <pre><code>&gt;&gt;&gt; d = np.diag(x)\n&gt;&gt;&gt; d\narray([[5, 0, 0],\n[0, 2, 0],\n[0, 0, 3]])\n</code></pre> <p>Vediamo invece come affrontare il problema duale. Immaginiamo di avere quindi un array, e volerne estrarre la diagonale:</p> <pre><code>&gt;&gt;&gt; x = np.array([[5, 5, 5], [2, 1, 3], [4, 3, 6]])\n&gt;&gt;&gt; x\narray([[5, 2, 2],\n[2, 1, 3],\n[4, 3, 6]])\n</code></pre> <p>Per farlo, dovremo anche questa volta usare la funzione <code>diag()</code>:</p> <pre><code>&gt;&gt;&gt; d = np.diag(x)\n&gt;&gt;&gt; d\narray([5, 1, 6])\n</code></pre> <p>Suggerimento</p> <p>Il fatto che la funzione <code>diag()</code> sia usata per operazioni duali pu\u00f2, a ragione, causare confusione. Basta per\u00f2 ricordare che passando un vettore si ottiene una matrice, mentre passando una matrice si ottiene un vettore, ed il gioco \u00e8 fatto.</p> <p>Attenzione</p> <p>Ovviamente, la funzione <code>diag()</code> accetta solo input monodimensionali (vettori) e bidimensionali (matrici)!</p>"},{"location":"material/02_libs/02_numpy/02_array/#matrici-triangolari","title":"Matrici triangolari","text":"<p>Concludiamo questa breve carrellata mostrando due metodi in grado di estrarre la matrice triangolare, rispettivamente superiore ed inferiore.</p> <p>Supponiamo di avere la matrice x definita in precedenza. Per estrarre la matrice triangolare superiore, dovremo usare la funzione <code>triu()</code>:</p> <pre><code>&gt;&gt;&gt; tu = np.triu(x)\n&gt;&gt;&gt; tu\narray([[5, 2, 2],\n[0, 1, 3],\n[0, 0, 6]])\n</code></pre> <p>Per estrarre invece la matrice triangolare inferiore, dovremo usare la funzione <code>tril()</code>:</p> <pre><code>&gt;&gt;&gt; tl = np.tril(x)\n&gt;&gt;&gt; tl\narray([[5, 0, 0],\n[2, 1, 0],\n[4, 3, 6]])\n</code></pre> <p>Suggerimento</p> <p>In questo caso, le funzioni <code>tril()</code> e <code>triu()</code> possono tranquillamente essere applicate agli array n-dimensionali. Inoltre, non \u00e8 richiesto le diverse dimensioni dell'array abbiano la stessa cardinalit\u00e0.</p>"},{"location":"material/02_libs/02_numpy/02_array/#accesso-agli-elementi-di-un-array","title":"Accesso agli elementi di un array","text":"<p>Cos\u00ec come per le liste, il modo pi\u00f9 immediato per accedere al valore di un elemento in un array \u00e8 usare l'operatore <code>[]</code>, specificando contestualmente l'indice dell'elemento cui si vuole accedere. Ad esempio, per selezionare il primo elemento di un vettore:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2, 3, 4])\n&gt;&gt;&gt; a[0]\n1\n</code></pre> <p>Nel caso di array ad \\(n\\) dimensioni, \u00e8 necessario indicare l'indice per ciascuna delle dimensioni dell'array. Ad esempio, per un array bidimensionale potremmo selezionare l'elemento alla prima riga e prima colonna con una sintassi di questo tipo:</p> <pre><code>&gt;&gt;&gt; b = np.array([[1, 2], [3, 4]])\n&gt;&gt;&gt; b[0][0]\n1\n</code></pre>"},{"location":"material/02_libs/02_numpy/02_array/#maschere-booleane","title":"Maschere booleane","text":"<p>Possiamo accedere ad un sottoinsieme di elementi dell'array mediante una \"maschera\", ovvero un altro array, di dimensioni uguali a quelle di partenza, al cui interno sono presenti esclusivamente dei valori booleani. Cos\u00ec facendo, estrarremo soltanto gli elementi la cui corrispondente posizione all'interno della maschera ha valore <code>True</code>. Ad esempio, possiamo selezionare tutti gli elementi appartenenti alla prima colonna dell'array <code>b</code>:</p> <pre><code>&gt;&gt;&gt; mask = np.array([[True, False], [True, False]])\n&gt;&gt;&gt; b[mask]\narray([1, 3])\n</code></pre> <p>Ancora, possiamo scegliere tutti gli elementi che soddisfano una certa condizione logico/matematica:</p> <pre><code>&gt;&gt;&gt; mask = (b &gt; 2)\n&gt;&gt;&gt; mask\narray([[False, False],\n[ True,  True]])\n&gt;&gt;&gt; b[mask]\narray([3, 4])\n</code></pre> <p>Interessante notare come la precedente notazione possa essere ulteriormente sintetizzata usando delle relazioni logiche:</p> <pre><code>&gt;&gt;&gt; b[b &gt; 2]\narray([3, 4])\n</code></pre> <p>Volendo, possiamo adattare la forma precedente all'uso di espressioni arbitrariamente complesse:</p> <pre><code>&gt;&gt;&gt; b[b%2 == 0]\narray([2, 4])\n&gt;&gt;&gt; b[(b &gt; 1) &amp; (b &lt; 4)]\narray([2, 3])\n</code></pre>"},{"location":"material/02_libs/02_numpy/02_array/#slicing-degli-array","title":"Slicing degli array","text":"<p>Cos\u00ec come le liste, anche gli array consentono le operazioni di slicing:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2, 3, 4])\n&gt;&gt;&gt; a[0:2]\narray([1, 2])\n</code></pre> <p>Per gli array multidimensionali, lo slicing si intende sulla \\(n\\)-ma dimensione dell'array. Questo concetto \u00e8 facile da comprendere se si visualizza l'array ad \\(n\\)-dimensioni come un array di array:</p> <pre><code>&gt;&gt;&gt; b\narray([[1, 2],\n[3, 4]])\n&gt;&gt;&gt; b[0:1]              # Lo slicing avviene sulla seconda dimensione\narray([[1, 2]])\n</code></pre>"},{"location":"material/02_libs/02_numpy/02_array/#la-funzione-nonzero","title":"La funzione <code>nonzero()</code>","text":"<p>Possiamo usare la funzione <code>nonzero()</code> per selezionare gli elementi e gli indici di un array il cui valore non sia pari a zero. Ad esempio:</p> <pre><code>&gt;&gt;&gt; x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]])\n&gt;&gt;&gt; x\narray([[3, 0, 0],\n[0, 4, 0],\n[5, 6, 0]])\n&gt;&gt;&gt; np.nonzero(x)\n(array([0, 1, 2, 2], dtype=int64), array([0, 1, 0, 1], dtype=int64))\n</code></pre> <p>La funzione <code>nonzero()</code> restituisce una tupla con gli indici per riga e colonna degli elementi diversi da zero. In particolare, la tupla risultante avr\u00e0 un numero di elementi pari a ciascuna delle dimensioni dell'array <code>x</code> di ingresso, e l'\\(i\\)-mo vettore individuer\u00e0 gli indici relativi alla \\(i\\)-ma dimensione. Ad esempio, in questo caso, il primo array rappresenta gli indici relativi alla prima dimensione dei valori non nulli (in questo caso, gli indici di riga), mentre il secondo gli indici relativi alla seconda dimensione (indici di colonna). Notiamo quindi che avremo i seguenti elementi diversi da zero:</p> Indice di riga Indice di colonna Valore 0 0 3 1 1 4 2 0 5 2 1 6 <p>Ottenere una lista di tuple</p> <p>Possiamo ottenere una lista di tuple rappresentative delle coppie di indici per gli elementi non nulli sfruttando la funzione <code>zip</code>:</p> <pre><code>&gt;&gt;&gt; s = np.nonzero(tarry)\n&gt;&gt;&gt; s\n(array([0, 1, 2, 2], dtype=int64), array([0, 1, 0, 1], dtype=int64))\n&gt;&gt;&gt; coords = list(zip(s[0], s[1]))\n&gt;&gt;&gt; coords\n[(0, 0), (1, 1), (2, 0), (2, 1)]\n</code></pre>"},{"location":"material/02_libs/02_numpy/02_array/#fancy-indexing","title":"Fancy indexing","text":"<p>Chiudiamo questa lezione parlando di una tecnica molto interessante chiamata fancy indexing, consistente nell'usare un array di indici per accedere a pi\u00f9 elementi contemporaneamente. Ad esempio:</p> <pre><code>&gt;&gt;&gt; rand = np.random.RandomState(42)\n&gt;&gt;&gt; x = rand.randint(100, size=10)\n&gt;&gt;&gt; indexes = np.array([[1, 4],[5, 2]])\n&gt;&gt;&gt; x\narray([51, 92, 14, 71, 60, 20, 82, 86, 74, 74])\n&gt;&gt;&gt; x[indexes]\narray([[92, 60],\n[20, 14]])\n</code></pre> <p>Nel codice precedente, stiamo:</p> <ol> <li>usando la funzione <code>randint()</code> per generare un array di numeri interi casuali compresi tra 0 e 100;</li> <li>generando un array bidimensionale <code>indexes</code>;</li> <li>restituendo, mediante il fancy indexing, un array con le dimensioni di <code>indexes</code> e gli elementi di <code>x</code> presi nelle posizioni indicate da <code>indexes</code>.</li> </ol> <p>La potenza del fancy indexing sta proprio in questo: non solo siamo in grado di accedere facilmente a pi\u00f9 elementi di un array mediante un'unica operazione, ma possiamo anche ridisporre questi elementi come pi\u00f9 ci aggrada!</p>"},{"location":"material/02_libs/02_numpy/03_fundamentals/","title":"2.3 - Operazioni fondamentali sugli array","text":"<p>Dopo averli introdotti nella lezione precedente, proseguiamo nella nostra trattazione sugli array andando a vedere tutta quella serie di operazioni fondamentali che \u00e8 possibile effettuarvi.</p>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#operazioni-algebriche-di-base","title":"Operazioni algebriche di base","text":"<p>Partiamo dalle operazioni algebriche di base. Ad esempio, possiamo sommare elemento per elemento due array mediante l'operatore <code>+</code>:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2])\n&gt;&gt;&gt; b = np.array([3, 4])\n&gt;&gt;&gt; a + b\narray([4, 6])\n</code></pre> <p>Contestualmente, l'utilizzo degli operatori matematici di sottrazione, moltiplicazione e divisione ci permetter\u00e0 di effettuare le omologhe operazioni, sempre elemento per elemento.</p> <pre><code>&gt;&gt;&gt; a - b\narray([-2, -2])\n&gt;&gt;&gt; a * b\narray([3, 8])\n&gt;&gt;&gt; a / b\narray([0.33333333, 0.5])\n&gt;&gt;&gt; b / a\narray([3., 2.])\n</code></pre>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#la-funzione-numpysum","title":"La funzione <code>numpy.sum()</code>","text":"<p>La funzione <code>numpy.sum()</code> ci permette di sommare tutti gli elementi di un array. Ad esempio, per sommare tutti gli elementi di un vettore:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2, 3, 4])\n&gt;&gt;&gt; a.sum()\n10\n</code></pre> <p>In caso di array multidimensionale, potremo specificare il parametro <code>axis</code>, che indica l'asse lungo il quale gli elementi vengono sommati. In particolare, il valore passato pu\u00f2 essere un intero a valore \\(i\\), nel qual caso si andr\u00e0 ad effettuare la somma lungo la dimensione \\(i\\)-ma, o una tupla di interi, in qual caso la somma sar\u00e0 effettuata su ognuna delle dimensioni specificate. Facciamo alcuni esempi.</p> <p>Supponiamo di avere un array bidimensionale di dimensioni \\(2 \\times 3\\) (ovvero, a due righe e tre colonne).</p> <pre><code>&gt;&gt;&gt; b = np.array([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; b\narray([[1, 2, 3],\n[4, 5, 6]])\n</code></pre> <p>Cerchiamo di capire a quale dimensione sono associate le righe, ed a quale le colonne. Per farlo, usiamo l'attributo <code>shape</code>.</p> <pre><code>&gt;&gt;&gt; b.shape\n(2, 3)\n</code></pre> <p>Nella tupla associata a <code>shape</code>, notiamo come il primo elemento sia associato al numero di righe, mentre il secondo al numero di colonne. Proviamo quindi a sommare l'array per righe, passando il parametro <code>axis=0</code>:</p> <pre><code>&gt;&gt;&gt; b.sum(axis=0)\narray([5, 7, 9])\n</code></pre> <p>Intuitivamente, dato che il secondo elemento \u00e8 associato al numero di colonne, la somma per colonne avr\u00e0 luogo valorizzando <code>axis</code> ad <code>1</code>:</p> <pre><code>&gt;&gt;&gt; b.sum(axis=1)\narray([6, 15])\n</code></pre> <p>Proviamo a vedere cosa accade in pi\u00f9 dimensioni. Creiamo un array tridimensionale:</p> <pre><code>&gt;&gt;&gt; c = np.random.rand(2, 3, 4)\n&gt;&gt;&gt; c\narray([[[0.92287179, 0.46394039, 0.87332474, 0.74359334],\n[0.52656447, 0.6055654 , 0.74493945, 0.9349442 ],\n[0.90911935, 0.01961204, 0.66304527, 0.3025307 ]],\n[[0.86562763, 0.37544415, 0.4984404 , 0.74486371],\n[0.10910642, 0.24617353, 0.6237486 , 0.26432378],\n[0.37713232, 0.08804626, 0.21283048, 0.41133527]]])\n&gt;&gt;&gt; c.shape\n(2, 3, 4)\n</code></pre> <p>Proviamo adesso ad effettuare la somma di tutti gli elementi per riga e colonna:</p> <pre><code>&gt;&gt;&gt; c.sum(axis=(0, 1))\narray([3.71042197, 1.79878176, 3.61632893, 3.401591  ])\n</code></pre> <p>Abbiamo quindi visto la versatilit\u00e0 della funzione <code>sum()</code>, e la capacit\u00e0 della stessa di operare su array a qualsiasi dimensionalit\u00e0.</p> <p>Il parametro <code>axis</code></p> <p>Ritroveremo il parametro <code>axis</code> in ogni applicazione che coinvolge NumPy e le librerie basate su di essa.</p>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#la-funzione-dot","title":"La funzione <code>dot()</code>","text":"<p>La funzione <code>dot()</code> ci permette di effettuare l'operazione di moltiplicazione matriciale riga per colonna. In particolare, la funzione sar\u00e0 invocata sulla matrice a sinistra nella moltiplicazione, mentre il parametro passato sar\u00e0 la matrice a destra.</p> <p>Ad esempio, possiamo provare a moltiplicare un vettore riga per un vettore colonna, ottenendo un intero:</p> <pre><code>&gt;&gt;&gt; a = np.array([[1, 2]])\n&gt;&gt;&gt; b = np.array([[3], [4]])\n&gt;&gt;&gt; a.dot(b)\narray([11])\n</code></pre> <p>Al contrario, moltiplicando un vettore colonna per un vettore riga, otterremo una matrice:</p> <pre><code>&gt;&gt;&gt; b.dot(a)\narray([[3, 6],\n[4, 8]])\n</code></pre>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#la-funzione-numpysort","title":"La funzione <code>numpy.sort()</code>","text":"<p>La funzione <code>numpy.sort()</code> permette di ordinare gli elementi di un array. Ad esempio:</p> <pre><code>&gt;&gt;&gt; arr = np.array([2, 1, 5, 3, 7, 4, 6, 8])\n&gt;&gt;&gt; np.sort(arr)\narray([1, 2, 3, 4, 5, 6, 7, 8])\n</code></pre> <p>L'ordine avviene maniera ascendente (ovvero dall'elemento pi\u00f9 piccolo al pi\u00f9 grande). In caso di array \\(n\\)-dimensionale, possiamo anche specificare l'asse lungo il quale avviene l'ordinamento, specificando il parametro axis. Ad esempio:</p> <pre><code>&gt;&gt;&gt; mat = np.array([[2, 3, 1], [4, 2, 6], [7, 5, 1]])\n&gt;&gt;&gt; mat\narray([[2, 3, 1],\n[4, 2, 6],\n[7, 5, 1]])\n</code></pre> <p>Per ordinare lungo le righe:</p> <pre><code>&gt;&gt;&gt; np.sort(mat, axis=0)\narray([[2, 2, 1],\n[4, 3, 1],\n[7, 5, 6]])\n</code></pre> <p>Mentre per ordinare lungo le colonne:</p> <pre><code>&gt;&gt;&gt; np.sort(mat, axis=1)\narray([[1, 2, 3],\n[2, 4, 6],\n[1, 5, 7]])\n</code></pre> <p>Possiamo anche specificare diversi algoritmi di ordinamento mediante l'argomento <code>kind</code>, che ci permette di scegliere tra il quick sort, il merge sort e l'heap sort.</p> <p>Ordinamento inplace</p> <p>I pi\u00f9 attenti noteranno che la funzione <code>sort()</code> pu\u00f2 essere chiamata direttamente sull'oggetto <code>mat</code> (<code>mat.sort()</code>) oppure da NumPy (<code>np.sort()</code>). Nel primo caso, la matrice viene modificata inplace, mentre nel secondo caso non lo \u00e8, e ne viene modificata una copia.</p> <p>Altre funzioni per l'ordinamento</p> <p>Esistono anche altre funzioni per l'ordinamento di un array, come <code>argsort()</code>, <code>lexsort()</code>, <code>searchsorted()</code> e <code>partition()</code>.</p>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#concatenazione-di-due-array","title":"Concatenazione di due array","text":"<p>Per concatenare due array \u00e8 necessario usare la funzione <code>concatenate()</code>:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2, 3, 4])\n&gt;&gt;&gt; b = np.array([5, 6, 7, 8])\n&gt;&gt;&gt; np.concatenate((a, b))\narray([1, 2, 3, 4, 5, 6, 7, 8])\n</code></pre> <p>Si pu\u00f2 anche in questo caso usare il parametro <code>axis</code> per specificare l'asse lungo quale concatenare due diversi array:</p> <pre><code>&gt;&gt;&gt; x = np.array([[1, 2], [3, 4]])\n&gt;&gt;&gt; y = np.array([[5, 6], [7, 8]])\n&gt;&gt;&gt; np.concatenate((x, y), axis=0)\narray([[1, 2],\n[3, 4],\n[5, 6],\n[7, 8]])\n&gt;&gt;&gt; np.concatenate((x, y), axis=1)\narray([[1, 2, 5, 6],\n[3, 4, 7, 8]])\n</code></pre> <p>Ovviamente, le dimensioni degli array devono essere coerenti affinch\u00e9 vengano concatenati. Ad esempio:</p> <pre><code>&gt;&gt;&gt; z = np.array([[9, 10]])\n</code></pre> <p>la concatenazione per righe \u00e8 ammissibile:</p> <pre><code>&gt;&gt;&gt; np.concatenate((x, z), axis=0)\narray([[ 1,  2],\n[ 3,  4],\n[ 9, 10]])\n</code></pre> <p>mentre la concatenazione per colonne lancer\u00e0 un errore:</p> <pre><code>&gt;&gt;&gt; np.concatenate((x, z), axis=1)\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"&lt;__array_function__ internals&gt;\", line 5, in concatenate\nValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 2 and the array at index 1 has size 1\n</code></pre>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#rimozione-ed-inserimento-di-elementi-in-un-array","title":"Rimozione ed inserimento di elementi in un array","text":"<p>Vediamo brevemente come aggiungere o rimuovere un elemento in un array.</p>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#la-funzione-numpydelete","title":"La funzione <code>numpy.delete()</code>","text":"<p>La funzione <code>numpy.delete()</code> ci permette di rimuovere uno o pi\u00f9 elementi di un array specificandone gli indici. La funzione accetta i seguenti parametri:</p> <ul> <li><code>arr</code>: l'array sul quale vogliamo effettuare l'operazione di rimozione;</li> <li><code>obj</code>: gli indici degli elementi da rimuovere;</li> <li><code>axis</code>: l'asse su cui vogliamo operare.</li> </ul> <p>Ad esempio, immaginiamo di voler rimuovere il primo elemento di un vettore:</p> <pre><code>&gt;&gt;&gt; arr = np.array([1, 2, 3, 4])\n&gt;&gt;&gt; np.delete(arr, 0)\narray([2, 3, 4])\n</code></pre> <p>La funzione pu\u00f2 essere anche applicata su pi\u00f9 indici usando una sequenza:</p> <pre><code>&gt;&gt;&gt; np.delete(arr, range(2))\narray([3, 4])\n</code></pre> <p>Possiamo anche usare lo slicing:</p> <pre><code>&gt;&gt;&gt; idx = range(4)\n&gt;&gt;&gt; np.delete(arr, idx[0:2])\narray([3, 4])\n</code></pre> <p>Modifiche inplace</p> <p>Nei casi precedenti la modifica non avviene inplace, per cui <code>arr</code> non sar\u00e0 modificato.</p>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#array-multidimensionali-e-delete","title":"Array multidimensionali e <code>delete()</code>","text":"<p>La funzione <code>delete()</code> pu\u00f2 essere usata anche su array multidimensionali. In questo caso, \u00e8 opportuno specificare l'asse su cui operare.</p> <p>Ad esempio, se vogliamo rimuovere la prima riga dal seguente array, dobbiamo dare il valore <code>0</code> al parametro <code>axis</code>:</p> <pre><code>&gt;&gt;&gt; mat = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n&gt;&gt;&gt; np.delete(mat, 0, 0)\narray([[4, 5, 6],\n[7, 8, 9]])\n</code></pre> <p>Invece, se vogliamo rimuovere la prima colonna, dobbiamo passare il valore <code>1</code>:</p> <pre><code>&gt;&gt;&gt; np.delete(mat, 0, 1)\narray([[2, 3],\n[5, 6],\n[8, 9]])\n</code></pre> <p>Se non specificassimo alcun valore per il parametro <code>axis</code>, otterremmo questo risultato:</p> <pre><code>&gt;&gt;&gt; np.delete(mat, 0)\narray([2, 3, 4, 5, 6, 7, 8, 9])\n</code></pre> <p>In altre parole, non specificando un valore per <code>axis</code>, rimuoveremmo il primo elemento dell'array \"vettorizzato\".</p> <p>Altre tecniche di rimozione elementi</p> <p>Esistono altri modi di rimuovere elementi da un array. Ad esempio, si potrebbe usare la funzione <code>slice(start, stop, step)</code>, che crea un oggetto di classe <code>slice</code> sugli indici che vanno da <code>start</code> a <code>stop</code> con passo <code>step</code>. Questo pu\u00f2 essere usato per scopi analoghi ai precedenti; ad esempio:</p> <pre><code>&gt;&gt;&gt; np.delete(a, slice(0, 2, 1))\narray([3, 4])\n</code></pre> <p>Un altro modo \u00e8 usare una maschera booleana:</p> <pre><code>&gt;&gt;&gt; mask = np.array([[True, False, True], [False, False, True], [False, True, True]])\n&gt;&gt;&gt; mtrx[mask]\narray([1, 3, 6, 8, 9])\n</code></pre>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#la-funzione-numpyinsert","title":"La funzione <code>numpy.insert()</code>","text":"<p>La funzione <code>numpy.insert()</code> permette di inserire un elemento all'interno di un array. I parametri accettati dalla funzione sono:</p> <ul> <li><code>arr</code>: l'array sul quale vogliamo effettuare l'operazione di inserzione;</li> <li><code>obj</code>: gli indici su cui inserire i nuovi valori;</li> <li><code>values</code>: i valori da inserire agli indici specificati da <code>obj</code>;</li> <li><code>axis</code>: l'asse su cui vogliamo operare.</li> </ul> <p>Ad esempio, per inserire una nuova riga nella matrice precedente, dovremo specificare l'indice di riga (<code>3</code>), gli elementi della riga da inserire (<code>[10, 11, 12]</code>) e l'asse (<code>0</code>):</p> <pre><code>&gt;&gt;&gt; np.insert(mat, 3, [10, 11, 12], 0)\narray([[ 1,  2,  3],\n[ 4,  5,  6],\n[ 7,  8,  9],\n[10, 11, 12]])\n</code></pre> <p>Cambiando l'asse in <code>1</code>, si effettua l'inserzione sulle colonne:</p> <pre><code>&gt;&gt;&gt; np.insert(mat, 3, [10, 11, 12], 1)\narray([[ 1,  2,  3, 10],\n[ 4,  5,  6, 11],\n[ 7,  8,  9, 12]])\n</code></pre> <p>Non specificando alcun asse, infine, si inserisce l'elemento specificato nella matrice vettorizzata:</p> <pre><code>&gt;&gt;&gt; np.insert(mat, 9, 10)\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n</code></pre>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#la-funzione-numpyappend","title":"La funzione <code>numpy.append()</code>","text":"<p>La funzione <code>numpy.append()</code> permette di inserire in coda ad un array i valori specificati. I parametri accettati dalla funzione sono:</p> <ul> <li><code>arr</code>: l'array sul quale vogliamo effettuare l'operazione di inserzione;</li> <li><code>values</code>: i valori da inserire in coda all'array;</li> <li><code>axis</code>: l'asse su cui vogliamo operare.</li> </ul> <p>Al solito, non specificando l'asse effettuiamo la concatenazione sulla matrice vettorizzata:</p> <pre><code>&gt;&gt;&gt; np.append(mat, [[10, 11, 12]])\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n</code></pre> <p>Se specifichiamo il valore 0 sul parametro <code>axis</code>, effettuiamo la concatenazione per righe:</p> <pre><code>&gt;&gt;&gt; np.append(mat, [[10, 11, 12]], axis=0)\narray([[ 1,  2,  3],\n[ 4,  5,  6],\n[ 7,  8,  9],\n[10, 11, 12]])\n</code></pre> <p>Se specifichiamo il valore 1 sul parametro <code>axis</code>, invece, effettuiamo la concatenazione per colonne:</p> <pre><code>&gt;&gt;&gt; np.append(mat, [[10], [11], [12]], axis=1)\narray([[ 1,  2,  3, 10],\n[ 4,  5,  6, 11],\n[ 7,  8,  9, 12]])\n</code></pre> <p>Attenzione</p> <p>Nell'ultima istruzione, abbiamo usato un vettore colonna, mentre nella penultima un vettore riga.</p>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#dimensioni-e-forma-di-un-array","title":"Dimensioni e forma di un array","text":"<p>Esistono diverse propriet\u00e0 di un array che ne descrivono dimensioni e forma.</p> <p>Tornando alla nostra matrice <code>mat</code>, possiamo conoscere il numero di assi mediante l'attributo <code>ndarray.ndim</code>:</p> <pre><code>&gt;&gt;&gt; mat.ndim\n2\n</code></pre> <p>Il numero di elementi \u00e8 invece definito dall'attributo <code>ndarray.size</code>:</p> <pre><code>&gt;&gt;&gt; mat.size\n9\n</code></pre> <p>L'attributo <code>ndarray.shape</code>, che abbiamo brevemente visto in precedenza, restituisce invece una tupla di interi che indica il numero di elementi per ciascuno degli assi dell'array:</p> <pre><code>&gt;&gt;&gt; mat.shape\n(3, 3)\n</code></pre>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#modificare-le-dimensioni-di-un-array","title":"Modificare le dimensioni di un array","text":"<p>Possiamo modificare le dimensioni di un array mediante la funzione <code>numpy.reshape()</code>. I parametri passati alla funzione sono:</p> <ul> <li><code>arr</code>: l'array di cui modificare le dimensioni;</li> <li><code>new_shape</code>: le nuove dimensioni dell'array.</li> </ul> <p>Se volessimo modificare le dimensioni di una matrice da \\(4 \\times 4\\) a \\(2 \\times 8\\), potremmo usare la funzione <code>reshape()</code> come segue:</p> <pre><code>&gt;&gt;&gt; mat = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])\n&gt;&gt;&gt; np.reshape(mat, (2, 8))\narray([[ 1,  2,  3,  4,  5,  6,  7,  8],\n[ 9, 10, 11, 12, 13, 14, 15, 16]])\n</code></pre> <p>Suggerimento</p> <p>Una forma alternativa \u00e8 la seguente:</p> <pre><code>&gt;&gt;&gt; mat.reshape((2, 8))\narray([[ 1,  2,  3,  4,  5,  6,  7,  8],\n[ 9, 10, 11, 12, 13, 14, 15, 16]])\n</code></pre> <p>Ci\u00f2 significa che la funzione <code>reshape()</code> \u00e8 sia disponibile nella libreria NumPy, sia come metodo sugli oggetti di classe <code>ndarray</code>.</p> <p>Attenzione</p> <p>Le nuove dimensioni dell'array devono essere coerenti con quelle dell'array di partenza!</p>"},{"location":"material/02_libs/02_numpy/03_fundamentals/#flattening-di-un-array","title":"Flattening di un array","text":"<p>Abbiamo gi\u00e0 visto in precedenza la vettorizzazione di un array, effettuata in automatico in alcune situazioni (come ad esempio la chiamata di <code>delete()</code> o <code>insert()</code> senza specificare il parametro <code>axis</code>). Tuttavia, possiamo usare la funzione <code>numpy.flatten()</code> per effettuare manualmente questa operazione:</p> <pre><code>&gt;&gt;&gt; mat.flatten()\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])\n</code></pre> <p>Un altro modo per effettuare la vettorizzazione \u00e8 utilizzare la funzione <code>numpy.ravel()</code>.</p> <p>Le funzioni <code>ravel()</code> e <code>flatten()</code> possono apparentemente sembrare analoghe. Tuttavia, vi \u00e8 una differenza fondamentale: infatti, <code>flatten()</code> restituir\u00e0 sempre una copia dell'array originario, mentre <code>ravel()</code>, laddove possibile, restituir\u00e0 una vista, ovvero una variabile che punta allo stesso indirizzo di memoria dell'oggetto originario.</p>"},{"location":"material/02_libs/02_numpy/04_algebra/","title":"2.4 - Operazioni algebriche in NumPy","text":"<p>Notebook di accompagnamento</p> <p>Per questa lezione esiste un notebook di accompagnamento, reperibile a questo indirizzo.</p> <p>Dopo aver trattato le operazioni fondamentali in NumPy, facciamo un breve approfondimento sulle operazioni di algebra lineare, alcune delle quali sono integrate nel package <code>linalg</code>.</p> <p>Gli esempi che vedremo nel seguito prevederanno tutti l'uso di questo package, per cui \u00e8 necessario importarlo prima di procedere nella lezione.</p> <pre><code>from numpy import linalg\n</code></pre>"},{"location":"material/02_libs/02_numpy/04_algebra/#matrice-trasposta","title":"Matrice trasposta","text":"<p>In realt\u00e0, la prima operazione che descriveremo non richiede l'uso del modulo <code>linalg</code>, ed \u00e8 quella che ci permette di effettuare la trasposta di una matrice. </p> <p>Ricordiamo che la trasposta \\(A^T\\) di una matrice \\(A\\) \u00e8 definita come la matrice in cui il generico elemento con indice \\((i,j)\\) \u00e8 l'elemento con indici \\((j,i)\\) della matrice originaria. In pratica:</p> \\[ (A^T)_{ij} = A_{ji} \\forall A \\in \\mathbb{R}^{m,n}, 1 \\leq i \\leq m, 1 \\leq j \\leq n \\] <p>Per farlo, dovremo semplicemente usare la funzione <code>numpy.transpose()</code>.</p> <pre><code>&gt;&gt;&gt; x = np.array([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; np.transpose(x)\narray([[1, 4],\n[2, 5],\n[3, 6]])\n</code></pre>"},{"location":"material/02_libs/02_numpy/04_algebra/#matrice-inversa","title":"Matrice inversa","text":"<p>Il calcolo della matrice inversa, invece, prevede l'utilizzo della funzione <code>linalg.inv()</code>, che accetta come parametro la matrice da invertire. </p> <p>Ricordiamo che la matrice inversa \\(A_{inv}\\) di una matrice invertibile \\(A\\) \u00e8 quella matrice per cui vale la seguente relazione:</p> \\[ A_{inv}A=AA_{inv}=I \\] <p>In altri termini, il prodotto matriciale tra \\(A\\) e la sua inversa \u00e8 commutativo e pari alla matrice identit\u00e0 di eguale rango.</p> <p>Ad esempio:</p> <pre><code>&gt;&gt;&gt; mat = np.array([[5, 0, 0], [0, 2, 0], [0, 0, 4]])\n&gt;&gt;&gt; linalg.inv(mat)\narray([[0.2 , 0.  , 0.  ],\n[0.  , 0.5 , 0.  ],\n[0.  , 0.  , 0.25]])\n</code></pre> <p>Ovviamente, la matrice <code>mat</code> deve essere invertibile, ovvero quadrata e a rango massimo. Nel caso passassimo una matrice rettangolare, infatti, verrebbe lanciato un errore di tipo <code>LinAlgError</code>:</p> <pre><code>&gt;&gt;&gt; mat = np.array([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; linalg.inv(mat)\nTraceback (most recent call last):\nnumpy.linalg.LinAlgError: Last 2 dimensions of the array must be square\n</code></pre> <p>Lo stesso accade se <code>mat</code> \u00e8 singolare:</p> <pre><code>&gt;&gt;&gt; mat = np.array([[1, 1, 1], [2, 2, 2], [0, 0, 1]])\n&gt;&gt;&gt; linalg.inv(mat)\nTraceback (most recent call last):\nnumpy.linalg.LinAlgError: Singular matrix\n</code></pre>"},{"location":"material/02_libs/02_numpy/04_algebra/#prodotti-vettoriali-e-matriciali","title":"Prodotti vettoriali e matriciali","text":""},{"location":"material/02_libs/02_numpy/04_algebra/#la-funzione-dot","title":"La funzione <code>dot()</code>","text":"<p>Nella scorsa lezione abbiamo visto un esempio di utilizzo della funzione <code>dot(a, b)</code> utilizzata per calcolare il prodotto matriciale tra gli array <code>a</code> e <code>b</code>. A questa funzione si applicano tutte le regole del calcolo matriciale, cos\u00ec come riassunto nella seguente tabella.</p> Dimensionalit\u00e0 <code>a</code> Dimensionalit\u00e0 <code>b</code> Risultato Monodimensionale (vettore) Monodimensionale (vettore) Prodotto scalare Bidimensionale (matrice) Bidimensionale (matrice) Prodotto matriciale Scalare \\(n\\)-dimensionale Prodotto scalare per array \\(n\\)-dimensionale \\(n\\)-dimensionale Scalare Prodotto scalare per array \\(n\\)-dimensionale <p>Notiamo che:</p> <ul> <li>in caso di moltiplicazione di due vettori, il risultato sar\u00e0 il prodotto scalare;</li> <li>in caso di moltiplicazione di due matrici, il risultato sar\u00e0 il prodotto matriciale e, di conseguenza, si consiglia di preferire la funzione <code>matmul()</code>;</li> <li>in caso di prodotto tra scalare e matrice, si consiglia di utilizzare la funzione <code>multiply()</code> o, in alternativa, l'operatore <code>*</code>.</li> </ul> <p>Nel notebook della lezione vedremo alcuni esempi di prodotti matriciali.</p> <p>Moltiplicazione di array multidimensionali</p> <p>Nel caso entrambi gli array da moltiplicare siano \\(n\\)-dimensionali, si applicano altre regole, che \u00e8 possibile recuperare a questo indirizzo.</p>"},{"location":"material/02_libs/02_numpy/04_algebra/#prodotto-interno","title":"Prodotto interno","text":"<p>Ricordiamo che per due generici vettori monodimensionali \\(a = [a_{1}, \\ldots, a_{j}], b = [b_{1}, \\ldots, b_{j}]\\), entrambi a \\(j\\) elementi, il prodotto scalare, o prodotto interno, \u00e8 dato da:</p> \\[ p = \\sum_{i=1}^j a_{i} \\cdot b_{i} \\] <p>Per calcolare il prodotto scalare tra i vettori <code>a</code> e <code>b</code> possiamo usare la funzione <code>numpy.inner(a, b)</code>:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2, 3])\n&gt;&gt;&gt; b = np.array([4, 5, 6])\n&gt;&gt;&gt; np.inner(a, b)\n32\n</code></pre>"},{"location":"material/02_libs/02_numpy/04_algebra/#le-funzioni-inner-e-dot","title":"Le Funzioni <code>inner()</code> e <code>dot()</code>","text":"<p>Un lettore attento avr\u00e0 notato che, nella pratica, per vettori monodimensionali, le funzioni <code>inner()</code> e <code>dot()</code> restituiscono lo stesso risultato:</p> <pre><code>np.inner(a, b)      # Output: 32\na.dot(b)            # Output: 32, stesso di b.dot()\n</code></pre> <p>La differenza tra le due funzioni \u00e8 visibile quando si utilizzano array a dimensionalit\u00e0 maggiore di 1:</p> <pre><code>&gt;&gt;&gt; a = np.array([[1, 2], [3, 4]])\n&gt;&gt;&gt; b = np.array([[5, 6], [7, 8]])\n&gt;&gt;&gt; np.inner(a, b)   # Risultato con inner()\narray([[17, 23],\n[39, 53]])\n&gt;&gt;&gt; a.dot(b)   # Risultato con dot()\narray([[19, 22],\n[43, 50]])\n</code></pre> <p>In pratica, riprendendo la documentazione:</p> <ul> <li>per quello che riguarda la funzione <code>dot()</code>, questa \u00e8 equivalente a <code>matmul()</code>, e quindi rappresenta una moltiplicazione matriciale che, nel caso di vettori monodimensionali, equivale al prodotto vettoriale, mentre per \\(n\\) dimensioni \u00e8 la somma dei prodotti tra l'ultima dimensione del primo vettore e delle dimensioni che vanno da \\(2\\) ad \\(n\\) del secondo;</li> <li>per quello che riguarda la funzione <code>inner()</code>, rappresenta il prodotto vettoriale nel caso ad una dimensione, mentre nel caso di \\(n\\) dimensioni rappresenta la somma dei prodotti lungo l'ultima dimensione.</li> </ul> <p>In altri termini:</p> <pre><code>a.dot(b) == sum(a[i, :] * b[:, j])\nnp.inner(a, b) == sum(a[i, :] * b[j, :])\n</code></pre> <p>Andando a rapportare il tutto all'esempio precedente:</p> \\[ dot = \\left(\\begin{array}{cc} 1 &amp; 2\\\\ 3 &amp; 4 \\end{array}\\right) \\left(\\begin{array}{cc} 5 &amp; 6\\\\ 7 &amp; 8 \\end{array}\\right) = \\\\ = \\left(\\begin{array}{cc} 1 \\cdot 5 + 2 \\cdot 7 &amp; 1 \\cdot 6 + 2 \\cdot 8   \\\\ 3 \\cdot 5 + 4 \\cdot 7 &amp; 1 \\cdot 6 + 4 \\cdot 8 \\end{array}\\right) = \\left(\\begin{array}{cc} 19 &amp; 22\\\\ 43 &amp; 50 \\end{array}\\right) \\] \\[ inner = \\left(\\begin{array}{cc} 1 &amp; 2\\\\ 3 &amp; 4 \\end{array}\\right) \\left(\\begin{array}{cc} 5 &amp; 6\\\\ 7 &amp; 8 \\end{array}\\right) = \\\\ = \\left(\\begin{array}{cc} 17 &amp; 23\\\\ 39 &amp; 53 \\end{array}\\right) \\]"},{"location":"material/02_libs/02_numpy/04_algebra/#prodotto-esterno","title":"Prodotto esterno","text":"<p>Il prodotto esterno tra due vettori \\(a = [a_1, a_2, \\ldots, a_j]\\) e \\(b = [b_1, b_2, \\ldots, b_j]\\) \u00e8 definito come la matrice \\(P\\) tale per cui:</p> \\[ P = \\left[     \\begin{array}{ccc}         a_1 \\cdot b_1 &amp; \\ldots &amp; a_1 \\cdot b_n \\\\         \\vdots        &amp; \\ddots &amp; \\vdots        \\\\         a_n \\cdot b_1 &amp; \\ldots &amp; a_n \\cdot b_n     \\end{array} \\right] \\] <p>Per calcolarlo, NumPy ci mette a disposizione la funzione <code>numpy.outer(a, b)</code>.</p> <p>Ad esempio:</p> <pre><code>a = np.array([1, 2])\nb = np.array([3, 4])\nnp.outer(a, b)\n</code></pre>"},{"location":"material/02_libs/02_numpy/04_algebra/#la-funzione-matmul","title":"La funzione <code>matmul</code>","text":"<p>Quando abbiamo parlato della funzione <code>dot()</code> abbiamo visto come sia possibile usarla per effettuare il prodotto matriciale tra le matrici <code>mat_1</code> e <code>mat_2</code>. Tuttavia, esiste un'altra possibilit\u00e0, che \u00e8 anche quella consigliata, ovvero usare la funzione <code>numpy.matmul()</code>:</p> <pre><code>&gt;&gt;&gt; a = np.array([[1, 2], [3, 4]])\n&gt;&gt;&gt; b = np.array([[5, 6], [7, 8]])\n&gt;&gt;&gt; np.matmul(a, b)\narray([[19, 22],\n[43, 50]])\n</code></pre> <p>La funzione <code>matmul()</code> ha una differenza fondamentale rispetto alla funzione <code>dot()</code>, in quanto non accetta scalari come parametro (anche se \u00e8 possibile passare vettori ed array \\(n\\)-dimensionali). Esiste in realt\u00e0 un'altra differenza importante, che riguarda le operazioni \\(n\\)-dimensionali, ma che non tratteremo in questa sede.</p> <p>L'operatore <code>@</code></p> <p>L'operatore <code>@</code> \u00e8 delegato alla moltiplicazione diretta di array bidimensionali, ed \u00e8 utilizzato \"sotto al cofano\" dalla funzione <code>matmul()</code>.</p>"},{"location":"material/02_libs/02_numpy/04_algebra/#potenza-di-matrice","title":"Potenza di matrice","text":"<p>La funzione <code>np.linalg.matrix_power(a, n)</code> permette di elevare a potenza <code>n</code> della matrice <code>a</code>. Ad esempio:</p> <pre><code>&gt;&gt;&gt; linalg.matrix_power(a, 5)\narray([[1069, 1558],\n[2337, 3406]])\n</code></pre>"},{"location":"material/02_libs/02_numpy/04_algebra/#autovalori-ed-autovettori","title":"Autovalori ed autovettori","text":"<p>Per calcolare gli autovalori e gli autovettori di una matrice, NumPy ci mette a disposizione la funzione <code>np.linalg.eig()</code>, che restituisce gli autovalori e gli autovettori destri di una matrice quadrata:</p> <pre><code>&gt;&gt;&gt; (v, w) = linalg.eig(a)\n&gt;&gt;&gt; v\narray([-0.37228132,  5.37228132])\n&gt;&gt;&gt; w\narray([[-0.82456484, -0.41597356],\n[ 0.56576746, -0.90937671]])\n</code></pre> <p>Esistono anche altre funzioni per il calcolo degli autovalori ed autovettori. In particolare:</p> <ul> <li><code>np.linalg.eigh()</code> calcola gli autovettori e gli autovettori di una matrice simmetrica a valori reali o complessi;</li> <li><code>np.linalg.eigvals()</code> calcola gli autovalori di una matrice quadrata;</li> <li><code>np.linalg.eigvalsh()</code> calcola gli autovalori di una matrice simmetrica a valori reali o complessi.</li> </ul>"},{"location":"material/02_libs/02_numpy/04_algebra/#norma-rango-determinante-e-traccia","title":"Norma, rango, determinante e traccia","text":"<p>La funzione <code>np.linalg.norm(a)</code> ci permette di calcolare la norma di una matrice. Opzionalmente, possiamo specificare tre parametri, ovvero:</p> <ul> <li><code>ord</code>, che rappresenta l'ordine della norma da calcolare (di default, viene calcolata la norma di Frobenius);</li> <li><code>axis</code>, che indica l'asse (o gli assi, in caso di array multidimensionale) su cui operare;</li> <li><code>keepdims</code>, usata per restituire, opzionalmente, l'asse su cui viene calcolata la norma.</li> </ul> <p>Per calcolare la norma di Frobenius della matrice <code>mat</code> possiamo usare questa sintassi:</p> <pre><code>&gt;&gt;&gt; linalg.norm(a)\n5.477225575051661\n</code></pre> <p>Per calcolare determinante, rango e traccia di una matrice mediante le funzioni <code>np.linalg.det()</code>, <code>np.linalg.matrix_rank()</code> e <code>np.trace()</code>. Ad esempio:</p> <pre><code>&gt;&gt;&gt; linalg.det(a)\n-2.0000000000000004\n&gt;&gt;&gt; linalg.matrix_rank(a)\n2\n&gt;&gt;&gt; np.trace(a)\n5\n</code></pre> <p>La <code>trace()</code> pu\u00f2 anche essere usata per calcolare la sommatoria delle sovra/sotto diagonali specificando il parametro <code>offset</code>. Ad esempio:</p> <pre><code>&gt;&gt;&gt; mtrx = np.array([[ 5,  2,  9], [ 2,  3,  1], [ 4, -2, 12]])\n&gt;&gt;&gt; np.trace(mtrx, offset=1)\n3\n&gt;&gt;&gt; np.trace(mtrx, offset=-1)\n0\n</code></pre>"},{"location":"material/02_libs/02_numpy/04_algebra/#risoluzione-di-sistemi-di-equazioni-lineari","title":"Risoluzione di sistemi di equazioni lineari","text":"<p>Chiudiamo questa (necessariamente breve!) carrellata sulle operazioni di algebra lineare con la funzione <code>np.linalg.solve(a, b)</code>, che permette di risolvere un sistema di equazioni lineari nel quale la matrice <code>a</code> \u00e8 la matrice dei coefficienti, mentre il vettore <code>b</code> \u00e8 il vettore dei termini noti. Ad esempio:</p> <pre><code>&gt;&gt;&gt; b = np.array([3, 2, 3])\n&gt;&gt;&gt; linalg.solve(mat, b)\narray([-7.5,  4.5,  3.5])\n</code></pre> <p>Ovviamente, la matrice <code>a</code> deve essere quadrata, mentre il vettore <code>b</code> deve avere esattamente <code>n</code> elementi, con <code>n</code> ordine di <code>a</code>!</p> <p>Operazioni su tensori</p> <p>NumPy mette a disposizione la versione per tensori ad \\(N\\) dimensioni di alcune funzioni. In particolare, ricordiamo la funzione per il prodotto tensoriale (<code>np.tensordot()</code>) e quella per risolvere equazioni tensoriali (<code>np.linalg.tensorsolve()</code>).</p>"},{"location":"material/02_libs/02_numpy/04_algebra/#reference","title":"Reference","text":"<p>Come detto pi\u00f9 volte, la nostra carrellata \u00e8 stata inevitabilmente molto breve e limitata. Per una panoramica pi\u00f9 completa, il consiglio \u00e8 sempre quello di riferirsi all'ottima documentazione di NumPy.</p>"},{"location":"material/02_libs/02_numpy/05_polynomials/","title":"2.5 - Operazioni polinomiali in NumPy","text":"<p>Notebook di accompagnamento</p> <p>Per questa lezione esiste un notebook di accompagnamento, reperibile a questo indirizzo.</p> <p>Come abbiamo visto nella scorsa lezione, NumPy ci offre un'ampia gamma di funzioni per il calcolo matriciale. Tuttavia, \u00e8 anche possibile utilizzarlo per altri scopi, non ultimo il calcolo polinomiale, mediante il modulo <code>numpy.polynomial</code>. Vediamo quindi alcuni tra i principali utilizzi di questo modulo.</p>"},{"location":"material/02_libs/02_numpy/05_polynomials/#la-classe-polynomial","title":"La classe <code>Polynomial</code>","text":"<p>Immaginiamo di avere due diversi polinomi, cui non associamo alcun significato fisico. I due sono espressi dalle seguenti equazioni:</p> \\[ \\begin{cases} p_1: y = 2x + 1 \\\\ p_2: y = x^2 + 3x + 2 \\end{cases} \\] <p>NumPy ci permette di rappresentare il polinomio mediante gli oggetti di classe <code>Polynomial</code>. In particolare, un oggetto di questo tipo pu\u00f2 essere istanziato a partire dai coefficienti del polinomio (ma non solo). Ad esempio, considerando i polinomi visti in precedenza, assieme ai loro coefficienti, possiamo scrivere:</p> <pre><code>&gt;&gt;&gt; from numpy.polynomial import Polynomial\n&gt;&gt;&gt; p_1_coef = [2, 1]       # lista dei coefficienti per p_1\n&gt;&gt;&gt; p_2_coef = [1, 3, 2]    # lista dei coefficienti per p_2\n&gt;&gt;&gt; p_1 = Polynomial(p_1_coef[::-1])\n&gt;&gt;&gt; p_2 = Polynomial(p_2_coef[::-1])\n</code></pre> <p>Ordine dei coefficienti</p> <p>La caratteristica pi\u00f9 importante (e controintuitiva) della classe <code>Polynomial</code> (e di tutti i metodi di gestione dei polinomi in NumPy) \u00e8 che i coefficienti vengono trattati in ordine crescente. In pratica, viene considerato innanzitutto il termine noto (ovvero il termine per \\(x^0\\)), poi il coefficiente di primo grado, quello di secondo, e cos\u00ec via. Per questo motivo, nel codice precedente viene considerata la lista dei coefficienti in ordine inverso.</p>"},{"location":"material/02_libs/02_numpy/05_polynomials/#somma-di-polinomi","title":"Somma di polinomi","text":"<p>Per sommare due polinomi, \u00e8 possibile utilizzare il metodo <code>polyadd()</code>, il quale accetta come parametri due vettori <code>c1</code> e <code>c2</code> rappresentativi dei coefficienti dei due polinomi da sommare. Ad esempio, volendo sommare due polinomi, potremo scrivere:</p> <pre><code>&gt;&gt;&gt; from numpy.polynomial import polynomial as P\n&gt;&gt;&gt; c1 = [1, 2, 3]\n&gt;&gt;&gt; c2 = [2, 5, 1]\n&gt;&gt;&gt; poly_sum = P.polyadd(c1, c2)\n</code></pre> <p>Il risultato di questa operazione sar\u00e0 un array numpy a valori <code>[3, 7, 4]</code>, equivalente al polinomio \\(4x^2 + 7x + 3\\).</p>"},{"location":"material/02_libs/02_numpy/05_polynomials/#sottrazione-di-polinomi","title":"Sottrazione di polinomi","text":"<p>La sottrazione tra due polinomi \u00e8 possibile mediante la funzione <code>polysub()</code>, il cui funzionamento \u00e8 molto simile a quello di <code>polyadd()</code>, con l'ovvia differenza che il risultato sar\u00e0 il polinomio risultante dalla differenza tra i coefficienti di <code>c1</code> e <code>c2</code>.</p> <pre><code>&gt;&gt;&gt; poly_sub = P.polysub(c1, c2)\n</code></pre>"},{"location":"material/02_libs/02_numpy/05_polynomials/#moltiplicazione-di-polinomi","title":"Moltiplicazione di polinomi","text":"<p>Le considerazioni precedenti possono essere estese alla moltiplicazione tra polinomi mediante la funzione <code>polymul()</code>:</p> <pre><code>&gt;&gt;&gt; poly_mul = P.polymul(c1, c2)\n</code></pre> <p>Nel caso si debba moltiplicare un polinomio per una variabile indipendente \\(x\\), andr\u00e0 utilizzata la funzione <code>polymulx()</code>.</p>"},{"location":"material/02_libs/02_numpy/05_polynomials/#divisione-tra-polinomi","title":"Divisione tra polinomi","text":"<p>La divisione tra polinomi \u00e8 un'operazione leggermente pi\u00f9 complessa delle altre, e prevede l'uso della funzione <code>polydiv()</code>, che restituir\u00e0 stavolta due array: il primo rappresenta i coefficienti del polinomio quoziente, mentre il secondo i coefficienti del polinomio resto. Ad esempio:</p> <pre><code>&gt;&gt;&gt; poly_q, poly_r = P.polydiv(c1, c2)\n</code></pre> <p>Anche in questo caso, i coefficienti sono ordinati da quello a grado pi\u00f9 basso a quello a grado pi\u00f9 alto.</p>"},{"location":"material/02_libs/02_numpy/05_polynomials/#elevazione-a-potenza","title":"Elevazione a potenza","text":"<p>Per elevare a potenza un polinomio, possiamo usare la funzione <code>polypow()</code>, la quale accetta due parametri: un vettore dei coefficienti <code>c</code> al primo argomento, ed uno scalare <code>pow</code> al secondo, rappresentativo della potenza alla quale effettuare l'elevazione. Ad esempio:</p> <pre><code>&gt;&gt;&gt; poly_pow = P.polypow(c1, 2)\narray([0., 0., 4., 4., 1.])\n</code></pre>"},{"location":"material/02_libs/02_numpy/05_polynomials/#valore-assunto-da-un-polinomio","title":"Valore assunto da un polinomio","text":"<p>Il valore \\(y\\) assunto da un polinomio \\(p\\) ad un certo valore di \\(x\\) pu\u00f2 essere determinato mediante la funzione <code>polyval()</code>, che accetta come argomento un intero (o una lista di interi) <code>x</code> ed un polinomio <code>p</code>. Ad esempio, volendo valutare il valore assunto da \\(y\\) per \\(x \\in [1, 2]\\) sulla retta rappresentata dal polinomio <code>c1</code>:</p> <pre><code>&gt;&gt;&gt; P.polyval([1, 2], c1.coef)\n</code></pre> <p>Coefficienti e polinomio</p> <p>E' molto importante notare come non stiamo usando un oggetto di classe <code>Polynomial</code>, ma i coefficienti dello stesso, estraibili accedendo alla propriet\u00e0 <code>coef</code>.</p> <p>Operazioni a dimensionalit\u00e0 2 e 3</p> <p>Nel caso occorra valutare i polinomi nei casi a due e tre dimensioni, NumPy ci mette a disposizione le funzioni <code>polyval2d()</code> e <code>polyval3d()</code>.</p>"},{"location":"material/02_libs/02_numpy/05_polynomials/#derivata-ed-integrale-di-funzioni-polinomiali","title":"Derivata ed integrale di funzioni polinomiali","text":"<p>Concludiamo questa breve carrellata con due metodi in grado di calcolare, rispettivamente, la derivata e l'integrale di una funzione polinomiale.</p> <p>La funzione <code>numpy.polyder()</code>, infatti, permette di calcolare la derivata di ordine <code>m</code> (passato come secondo argomento, di default pari ad <code>1</code>) dei coefficienti del polinomio <code>p</code> (passati come primo argomento). Ad esempio, per calcolare la derivata di <code>c1</code>:</p> <pre><code>&gt;&gt;&gt; P.polyder(c1.coef)\n</code></pre> <p>Il metodo duale \u00e8 <code>numpy.polyint()</code>, che (prevedibilmente) calcola l'integrale di ordine <code>m</code> dei coefficienti del polinomio <code>p</code>:</p> <pre><code>&gt;&gt;&gt; P.polyint(c1.coef)\n</code></pre>"},{"location":"material/02_libs/02_numpy/06_statistics/","title":"2.6 - Statistica in NumPy","text":"<p>Notebook di accompagnamento</p> <p>Per questa lezione esiste un notebook di accompagnamento, reperibile a questo indirizzo.</p> <p>Oltre ai polinomi ed alle operazioni algebriche, NumPy ci mette a disposizione varie funzioni utili per i calcoli statistici; in questa lezione ne vedremo alcune.</p>"},{"location":"material/02_libs/02_numpy/06_statistics/#minimo-e-massimo-di-un-array","title":"Minimo e massimo di un array","text":"<p>Per prima cosa, vediamo due funzioni utili a deterinare il valore massimo e minimo per un array, in particolare <code>numpy.amax()</code> e <code>numpy.amin()</code>, che permettono di individuare il massimo lungo una particolare direzione di un array.</p> <p>Ad esempio, se volessimo trovare il minimo ed il massimo di un vettore generato casualmente usando la funzione <code>default_rng()</code>:</p> <pre><code>&gt;&gt;&gt; rng = np.random.default_rng(42)\n&gt;&gt;&gt; a = rng.integers(low=0, high=10, size=5)\n&gt;&gt;&gt; np.amin(a)\n&gt;&gt;&gt; np.amax(a)\n</code></pre> <p>Per una matrice, ed in generale per ogni array \\(N\\)-dimensionale, il procedimento da seguire \u00e8 analogo:</p> <pre><code>&gt;&gt;&gt; b = rng.integers(low=0, high=10, size=(3, 3))\n&gt;&gt;&gt; np.amin(b)\n&gt;&gt;&gt; np.amax(b)\n</code></pre> <p>Se volessimo individuare il massimo ed il minimo sulle colonne di <code>b</code>, dovremmo specificare il parametro <code>axis</code>, che assumer\u00e0 valore pari a <code>0</code>:</p> <pre><code>&gt;&gt;&gt; np.amin(b, axis=0)\n&gt;&gt;&gt; np.amax(b, axis=0)\n</code></pre> <p>Ovviamente, per trovare il minimo ed il massimo per riga, dovremo cambiare il valore di <code>axis</code> in <code>1</code>:</p> <pre><code>&gt;&gt;&gt; np.amin(b, axis=1)\n&gt;&gt;&gt; np.amax(b, axis=1)\n</code></pre> <p>Possiamo anche specificare una tupla per il valore del parametro <code>axis</code>; in tal caso, la ricerca del massimo o del minimo avverr\u00e0 lungo tutti gli assi specificati dalla tupla. Ad esempio, specificando <code>(0, 1)</code>, effettueremo la ricerca del minimo (o del massimo) elemento nella matrice:</p> <pre><code>&gt;&gt;&gt; np.amin(b, axis=(0, 1))\n&gt;&gt;&gt; np.amax(b, axis=(0, 1))\n</code></pre> <p>Le funzioni <code>argmax</code> ed <code>argmin</code></p> <p>Le funzioni [<code>numpy.argmax()</code>] e [<code>numpy.argmin()</code>] permettono di individuare l'indice del valore massimo e minimo, rispettivamente.</p>"},{"location":"material/02_libs/02_numpy/06_statistics/#percentile-quantile-e-quartili","title":"Percentile, quantile, e quartili","text":"<p>Con il termine percentile definiamo un valore che indica la posizione di un dato all'interno di una distribuzione o, in altre parole, la percentuale di dati che si trovano al di sotto di un determinato valore all'interno della distribuzione stessa. </p> <p>Per calcolare il percentile per un dato valore \\(p\\), dovremo seguire questi passaggi:</p> <ol> <li>Ordinare gli \\(n\\) valori della distribuzione in ordine crescente.</li> <li>Se \\(p\\) \u00e8 il percentile, calcolare il prodotto \\(k = n \\cdot p \\cdot \\frac{1}{100}\\).</li> <li>Se \\(k\\) \u00e8 un intero, il percentile \u00e8 dato dalla media tra il \\(k\\)-esimo ed il \\(k+1\\)-esimo valore dei dati ordinati.</li> <li>Se \\(k\\) non \u00e8 un intero, si arrotonda \\(k\\) per eccesso al primo intero successivo, scegliendo il corrispondente valore dei dati ordinati.</li> </ol> <p>Facciamo un esempio. Supponiamo di avere la seguente distribuzione di valori:</p> \\[ D = [20, 30, 10, 50, 40, 100, 90, 60, 80, 70] \\] <p>Vogliamo calcolare il \\(30\\)-percentile, quindi \\(p=30\\). Proviamo a seguire i passaggi sopra descritti.</p> <ol> <li>Ordiniamo i dati, ottenendo il vettore \\(D_{ord} = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\\).</li> <li>Il valore di \\(k\\) \u00e8 pari ad \\(n * p\\), con \\(n=10\\) e \\(p=0.30\\), per cui \\(k=3\\).</li> <li>Dato che \\(k\\) \u00e8 un intero, il \\(30\\)-percentile \u00e8 dato dalla media tra \\(30\\) e \\(40\\), ovvero \\(35\\).</li> </ol> <p>Il concetto di quantile \u00e8 collegato a quello di percentile, che in qualche modo generalizza. In particolare, quando si parla di quantile, si definisce una suddivisione della distribuzione dei valori in un certo numero di intervalli: appare chiaro che se questi intervalli sono \\(100\\) il quantile coincide con il percentile.</p> <p>Una suddivisione notevole \u00e8 quella che prevede la ripartizione della distribuzione dei valori in quattro parti, dette quartili, ripartiti come segue:</p> <ul> <li>il primo quartile \u00e8 quello che raccoglie tutti gli elementi che vanno al di sotto del \\(25\\)-percentile (indicato con \\(Q_1\\));</li> <li>il secondo quartile \u00e8 quello che raccoglie gli elementi che vanno dal \\(25\\)-percentile al \\(50\\)-percentile (indicato con \\(Q_2\\));</li> <li>il terzo quartile \u00e8 quello che contiene gli elementi che vanno dal \\(50\\)-percentile al \\(75\\)-percentile (indicato con \\(Q_3\\));</li> <li>l'ultimo quartile racchidue gli elementi che sono oltre \\(Q_3\\).</li> </ul> <p>In altri termini, se \\(n\\) \u00e8 il numero totale di dati nella distribuzione, allora:</p> \\[ \\begin{align} &amp; Q_1 = \\frac{n + 1}{4}\\\\ &amp; Q_2 = \\frac{n + 1}{2}\\\\ &amp; Q_3 = \\frac{n + 1}{4} \\cdot 3 \\end{align} \\] <p>I quartili sono importanti soprattutto quando si va a caratterizzate una distribuzione non parametrica, ovvero non rappresentabile in termini di semplici parametri statistici come, ad esempio, una distribuzione normale. In questi casi, infatti, la distribuzione pu\u00f2 essere caratterizzata in maniera non parametrica mediante la mediana (ovvero, il \\(50\\)-percentile), la deviazione standard, ed il range interquartile, dato da \\(Q3-Q1\\).</p>"},{"location":"material/02_libs/02_numpy/06_statistics/#le-funzioni-numpypercentile-e-numpyquantile","title":"Le funzioni <code>numpy.percentile()</code> e <code>numpy.quantile()</code>","text":"<p>Per fare un esempio, supponiamo di avere un vettore ordinato di elementi che vanno da \\(1\\) a \\(10\\), e di calcolare il \\(50\\)-percentile mediante la funzione <code>numpy.percentile()</code> di NumPy.</p> <pre><code>&gt;&gt;&gt; a = np.arange(1, 11)\n&gt;&gt;&gt; np.percentile(a, 50)\n</code></pre> <p>Esistono diversi modi di calcolare il q-percentile; in tal senso, \u00e8 opportuno consultare la reference e l'articolo Sample quantiles in statistical packages di Hyndman, R. J., &amp; Fan, Y.</p> <p>In realt\u00e0, la funzione <code>percentile()</code> usa, per il \\(50\\)-percentile, il calcolo della mediana, per cui \u00e8 equivalente alla funzione <code>median()</code>. In questo caso specifico, avremo un discostamento dal risultato atteso, dovuto ad errori di interpolazione introdotti da NumPy:</p> <pre><code>np.percentile(a, 50)\n</code></pre> <p>Il concetto di quantile \u00e8 analogo a quello di percentile; tuttavia, in questo caso, non abbiamo a che fare con valori percentuali, bens\u00ec con valori normalizzati tra \\(0\\) e \\(1\\). Per cui, se usassimo la funzione <code>numpy.quantile()</code> come in precedenza:</p> <pre><code>&gt;&gt;&gt; np.quantile(a, .5)\n</code></pre> <p>Anche le funzioni <code>percentile()</code> e <code>quantile()</code> prevedono come argomento opzionale il parametro <code>axis</code>. Ad esempio:</p> <pre><code>&gt;&gt;&gt; np.percentile(b, 50, axis=0)\n&gt;&gt;&gt; np.percentile(b, 50, axis=1)\n</code></pre> <p>Come previsto, dando il valore <code>0</code> al parametro <code>axis</code> avremo il calcolo del percentile su ciascuna colonna, mentre passando il valore <code>1</code> avremo il calcolo del percentile su ciascuna riga.</p>"},{"location":"material/02_libs/02_numpy/06_statistics/#media-aritmetica-e-media-pesata","title":"Media aritmetica e media pesata","text":"<p>Per il calcolo del valore medio di un array NumPy ci mette a disposizione due metodi. Il primo \u00e8 la funzione <code>numpy.average(a, weights)</code>, che viene usata per calcolare una media pesata degli elementi di <code>a</code> ponderati per gli elementi di <code>weights</code> (a patto che, ovviamente, le dimensioni dei due array siano coerenti).</p> <p>Il calcolo che viene effettuato da NumPy con la funzione <code>average()</code> \u00e8 quindi il seguente:</p> <pre><code>&gt;&gt;&gt; avg = sum(a * weights) / sum(weights)\n</code></pre> <p>Per cui, se volessimo assegnare un peso maggiore al primo ed al quarto elemento di un array <code>a</code> generato casualmente, potremmo fare come segue:</p> <pre><code>&gt;&gt;&gt; w = np.array([3, 1, 1, 3, 1])\n&gt;&gt;&gt; np.average(a, weights=w)\n3.2222222222222223\n</code></pre> <p>Il risultato si discosta leggermente dalla semplice media, calcolata come:</p> <pre><code>&gt;&gt;&gt; np.average(a)\n4.2\n</code></pre> <p>Suggerimento</p> <p>Teniamo sempre a mente che la media \u00e8 ponderata per la sommatoria dei valori assunti dai pesi!</p> <p>La funzione <code>numpy.mean(a)</code> \u00e8 invece rappresentativa della media aritmetica degli elementi di un array, ed equivale alla funzione <code>average(a)</code> senza la specifica del vettore dei pesi. Ad esempio:</p> <pre><code>&gt;&gt;&gt; np.mean(a)\n4.2\n</code></pre> <p>Concludiamo ricordando che anche in questo caso possiamo specificare il valore del parametro <code>axis</code>:</p> <pre><code>&gt;&gt;&gt; np.mean(b, axis=0)\narray([6.33333333, 2.33333333, 6.        ])\n&gt;&gt;&gt; np.mean(b, axis=1)\narray([4.66666667, 2.33333333, 7.66666667])\n</code></pre>"},{"location":"material/02_libs/02_numpy/06_statistics/#varianza-e-deviazione-standard","title":"Varianza e deviazione standard","text":"<p>Non possono mancare le funzioni <code>numpy.std(a)</code> e <code>numpy.var(a)</code>, dedicate al calcolo della deviazione standard e della varianza di un vettore:</p> <pre><code>&gt;&gt;&gt; np.std(a)\n2.4\n&gt;&gt;&gt; np.var(a)\n5.76\n</code></pre> <p>Anche in questo caso, possiamo specificare gli assi lungo i quali effettuare l'operazione desiderata:</p> <pre><code>&gt;&gt;&gt; np.var(b, axis=0)\narray([ 9.55555556, 10.88888889,  0.66666667])\n&gt;&gt;&gt; np.var(b, axis=1)\narray([11.55555556,  4.22222222,  0.88888889])\n</code></pre>"},{"location":"material/02_libs/02_numpy/06_statistics/#istogramma","title":"Istogramma","text":"<p>Un istogramma offre una visualizzazione grafica dei valori contenuti in un vettore, raggruppandoli all'interno di un certo numero di partizioni (bin).</p> <p>Ad esempio, una possibile rappresentazione a due partizioni del vettore \\(A = [1, 2, 3, 4]\\) \u00e8 data dal vettore \\([2, 2]\\). Questo si spiega col fatto che le due partizioni suddividono il range di valori assunti da \\(A\\) in due parti, con la prima inerente gli elementi \\(1\\) e \\(2\\), e la seconda gli elementi \\(3\\) e \\(4\\). Una volta calcolate le partizioni, queste andranno \"riempite\" contando il numero di elementi presenti in ciascuna partizione, il che ci riporta al vettore \\([2, 2]\\).</p> <p>Nota</p> <p>Ovviamente, \u00e8 possibile specificare, oltre al numero di partizioni, anche gli estremi delle stesse, che potrebbero non coincidere con quelli del vettore.</p> <p>NumPy ci permette di ottenere l'istogramma di un vettore mediante l'insieme di funzioni <code>numpy.histogram(a, bins, range)</code>, che ci permette di calcolare l'istogramma (monodimensionale) dell'array <code>a</code> in funzione del numero di partizioni (opzionale) e del range (opzionale). Ad esempio:</p> <pre><code>&gt;&gt;&gt; h, b = np.histogram(a)\n</code></pre> <p>In questo caso, abbiamo lasciato il valore di default di <code>bins</code>, ovvero 10.</p> <p>Notiamo che la funzione <code>histogram()</code> restituisce due valori: il primo \u00e8 dato dai valori assunti dall'istogramma (ovvero dal numero di elementi che ricade in ciascun bin), mentre il secondo \u00e8 dato dai limiti di ogni bin.</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/","title":"Esercitazione 3 - NumPy","text":""},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizi-sugli-array","title":"Esercizi sugli array","text":""},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-31","title":"Esercizio 3.1","text":"<p>Scrivere una funzione che restituisca il prodotto riga per colonna di due vettori <code>v1</code> e <code>v2</code>. Utilizzare in primis una list comprehension, verificando anche che la lunghezza dei due vettori sia coerente. Valutare inoltre il tempo necessario all'esecuzione utilizzando la libreria <code>time</code>.</p> <p>Effettuare la stessa operazione in NumPy, valutando contestualmente il tempo necessario in entrambi i casi.</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-32","title":"Esercizio 3.2","text":"<p>Scrivere la funzione <code>crea_array(dim_1, dim_2, val_min, val_max)</code> che crea array di dimensione arbitraria <code>dim_1</code> \\(\\times\\) <code>dim_2</code> composti da numeri interi casuali compresi tra <code>val_min</code> e <code>val_max</code>. Di default, la funzione dovr\u00e0 creare dei vettori riga. Utilizzare il package <code>random</code>.</p> <p>Provare ad effettuare la stessa operazione in NumPy.</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-33","title":"Esercizio 3.3","text":"<p>Scrivere la funzione <code>rettifica(array)</code> che restituisce un array analogo a quello in ingresso, ma con tutti i valori negativi \"rettificati\" a \\(0\\).</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizi-sulle-operazioni-algebriche","title":"Esercizi sulle operazioni algebriche","text":""},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-34","title":"Esercizio 3.4","text":"<p>Verificare che il prodotto tra una matrice invertibile e la sua inversa sia la matrice identit\u00e0.</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-35","title":"Esercizio 3.5","text":"<p>Scrivere la funzione <code>calcola_determinante()</code> che accetta come parametro in ingresso una matrice \\(2 \\times 2\\) e ne calcola il determinante. Gestire opportunamente il caso in cui la matrice in ingresso sia difforme dalle indicazioni fornite in precedenza, o che non la matrice non sia invertibile.</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-36","title":"Esercizio 3.6","text":"<p>Scrivere la funzione <code>inverti_se_invertibile(mat)</code> che, data una matrice bidimensionale, restituisca l'inversa soltanto se <code>mat</code> \u00e8 bidimensionale, quadrata, e il determinante \u00e8 diverso da zero. Utilizzare un'unica istruzione condizionale.</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizi-sulle-operazioni-polinomiali-in-numpy","title":"Esercizi sulle operazioni polinomiali in NumPy","text":""},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-37","title":"Esercizio 3.7","text":"<p>Scrivere la funzione <code>somma_polinomi()</code> che accetta come parametri due polinomi di grandezza arbitraria, sommandoli tra loro. Trattiamo i polinomi come liste; in particolare, all'\\(i\\)-mo elemento della lista corrisponder\u00e0 il coefficiente di \\(i\\)-mo grado del polinomio.</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-38","title":"Esercizio 3.8","text":"<p>Usare una lista per scrivere la funzione <code>calcola_media(array, pesi)</code> che restituisce il valor medio di un array. Il valore di default del parametro <code>pesi</code> dovr\u00e0 essere una lista vuota. Nel caso che <code>pesi=[]</code>, dovr\u00e0 essere calcolata una media aritmetica; in caso contrario, si dovr\u00e0 verificare la coerenza delle dimensioni di <code>array</code> e <code>pesi</code>, e restituire la media pesata.</p>"},{"location":"material/02_libs/02_numpy/exercises/exercises/#esercizio-39","title":"Esercizio 3.9","text":"<p>Scrivere la funzione <code>descrivi(array)</code> che permette di descrivere un array in termini non parametrici, individuando mediana, deviazione standard e range interquartile (ovvero tra il 25-percentile ed il 75-percentile).</p>"},{"location":"material/02_libs/02_numpy/exercises/solutions/","title":"Esercitazione 3 - NumPy (Soluzioni)","text":"<p>Soluzioni</p> <p>L'implementazione delle soluzioni \u00e8 disponibile questo notebook.</p>"},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizi-sugli-array","title":"Esercizi sugli array","text":""},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizio-31","title":"Esercizio 3.1","text":"<p>Definiamo innanzitutto la funzione <code>riga_per_colonna</code>, la quale accetta due array in ingresso e, se le dimensioni sono coerenti, effettua la moltiplicazione riga per colonna.</p> <p>Una possibile forma per la funzione \u00e8 la seguente:</p> <pre><code>def riga_per_colonna(v1, v2):\ntic = time()\nif v1.shape[0] == 1:\nif v2.shape[1] == 1 and v1.shape[1] == v2.shape[0]:\nprod = sum([v1[0][i] * v2[i] for i in range(v2.shape[0])])\nelif v2.shape[0] == 1:\nif v1.shape[1] == 1 and v2.shape[1] == v1.shape[0]:\nprod = sum([v1[i] * v2[0][i] for i in range(v1.shape[0])])\nelse:\nreturn 'Le dimensioni non sono coerenti!'\ntoc = time()\nreturn prod, toc - tic\n</code></pre> <p>In particolare:</p> <ul> <li>alla riga 2, lanciamo il timer di inizio chiamata a funzione;</li> <li>alle righe 3-4, se il vettore <code>v1</code> \u00e8 un vettore riga, allora andiamo a controllare che il vettore <code>v2</code> sia un vettore colonna;</li> <li>alla riga 5, se il controllo precedente \u00e8 andato per il verso giusto, usiamo una list comprehension per fare il prodotto riga per colonna;</li> <li>alle righe 6-8, effettuiamo le operazioni duali alle precedenti;</li> <li>alla riga 11, lanciamo il timer di fine chiamata a funzione;</li> <li>alla riga 12, restituiamo il prodotto ed il tempo trascorso.</li> </ul> <p>Proviamo la nostra funzione:</p> <pre><code>v1 = np.array([[1,2,3,4]])\nv2 = np.array([[1],[2],[3],[4]])\nres, elapsed = riga_per_colonna(v1, v2)\nprint(elapsed)\n</code></pre> <p>L'equivalente operazione in NumPy \u00e8 data da:</p> <pre><code>res = np.dot(v1, v2)\n</code></pre>"},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizio-32","title":"Esercizio 3.2","text":"<p>Una possibile soluzione \u00e8 la seguente:</p> <pre><code>def crea_array(dim_1, dim_2=1, val_min=0, val_max=100):\nrows = [[randint(val_min, val_max) for i in range(dim_2)] for j in range(dim_1)]\nreturn np.array(rows)\n</code></pre> <p>Alla riga 2 utilizziamo due list comprehension, l'una annidata nell'altra. In particolare, nella list comprehension pi\u00f9 interna, andremo a generare <code>dim_2</code> valori interi casuali compresi tra <code>val_min</code> e <code>val_max</code>, mentre in quella pi\u00f9 esterna ripeteremo l'operazione definita dalla lista pi\u00f9 interna <code>dim_1</code> volte. Il valore ottenuto \u00e8 quindi restituito alla riga 3.</p> <p>Con NumPy potremo ovviamente utilizzare il metodo <code>randint</code>:</p> <pre><code>from numpy import random\na_1 = random.randint(0, 100, (4, 1))\na_2 = random.randint(0, 100, (2, 2))\n</code></pre>"},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizio-33","title":"Esercizio 3.3","text":"<p>Per risolvere questo problema, possiamo sfruttare il concetto di maschera booleana. In particolare, se provassimo a scrivere un'espressione del tipo:</p> <pre><code>&gt;&gt;&gt; a = np.array([1, 2, -1, 2])\n&gt;&gt;&gt; [a &lt; 0]\n</code></pre> <p>l'interprete ci restituirebbe una maschera fatta di soli booleani:</p> <pre><code>[array([False, False,  True, False])]\n</code></pre> <p>Questa maschera pu\u00f2 essere utilizzata per accedere agli elementi dell'array <code>a</code> il cui corrispondente elemento nella maschera \u00e8 a <code>True</code>. In pratica, nell'esempio precedente, accederemo esclusivamente all'elemento in posizione \\(3\\):</p> <pre><code>&gt;&gt;&gt; a[a &lt; 0]\narray([-1])\n</code></pre> <p>Ovviamente, possiamo utilizzare questa maschera anche per assegnare dei nuovi valori agli elementi acceduti. Quindi, scrivendo:</p> <pre><code>&gt;&gt;&gt; a[a &lt; 0] = 0\n</code></pre> <p>andremo a modificare l'array <code>a</code> come segue:</p> <pre><code>array([1, 2, 0, 2])\n</code></pre> <p>Di conseguenza, potremo scrivere la funzione rettifica come segue:</p> <pre><code>def rettifica(array):\narray[array &lt; 0] = 0\nreturn array\n</code></pre>"},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizi-sulle-operazioni-algebriche","title":"Esercizi sulle operazioni algebriche","text":""},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizio-34","title":"Esercizio 3.4","text":"<p>Per verificare questo assunto ci basta utilizzare la funzione <code>inv</code> per calcolare la matrice inversa:</p> <pre><code>mat = np.array([[5, 0, 1], [0, 2, 2], [0, 0, 3]])\nmat_inv = np.linalg.inv(mat)\n</code></pre> <p>Conseguentemente, utilizzando la funzione <code>dot</code>, potremo fare il prodotto matriciale tra <code>mat</code>e <code>mat_inv</code>, verificando che sia pari alla matrice identit\u00e0 (in questo caso di ordine 3):</p> <pre><code>np.eye(3) == mat.dot(mat_inv)\n</code></pre>"},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizio-35","title":"Esercizio 3.5","text":"<p>Ricordiamo che il calcolo del determinante di una matrice \\(2 \\times 2\\) \u00e8 dato dalla differenza tra il prodotto degli elementi sulla diagonale e quello dei restanti elementi.</p> <p>Per cui, la funzione <code>calcola_determinante()</code> potr\u00e0 essere scritta come segue:</p> <p>```py linenums=1\" def calcola_determinante(mat):     if len(mat.shape) == 2 and mat.shape[0] == mat.shape[1] and mat.shape[0] == 2:         return mat[0][0] * mat[1][1] - mat[0][1] * mat[1][0]     raise ValueError('La matrice non ha le dimensioni attese.') <pre><code>In particolare:\n\n* alla riga 2, verifichiamo che la matrice sia bidimensionale ed abbia dimensioni $2 \\times 2$;\n* alla riga 3, calcoliamo il determinante;\n* alla riga 4, lanciamo un errore nel caso la matrice non abbia dimensioni $2 \\times 2$.\n\n### Esercizio 3.6\n\nIn questo caso, potremo utilizzare i metodi messi a disposizione da NumPy. Tuttavia, dovremo verificare contemporaneamente che:\n\n* `shape` di `mat` sia pari a `2` (e, quindi, la matrice sia bidimensionale);\n* la prima dimensione sia uguale alla seconda;\n* che il determinante sia diverso da zero (e, quindi, la matrice risulti essere invertibile).\n\nDi seguito, una possibile soluzione:\n\n```py\ndef inverti_se_invertibile(mat):\n    if len(mat.shape) == 2 \\\n        and mat.shape[0] == mat.shape[1] \\\n        and linalg.det(mat) != 0:\n        return linalg.inv(mat)\n    raise ValueError('La matrice passata non \u00e8 invertibile.')\n</code></pre></p>"},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizi-sulle-operazioni-polinomiali-in-numpy","title":"Esercizi sulle operazioni polinomiali in NumPy","text":""},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizio-37","title":"Esercizio 3.7","text":"<p>Per prima cosa, dovremo verificare le lunghezze dei polinomi e, qualora queste non siano coerenti, andare ad inserire un numero di coefficienti adeguato.</p> <pre><code>def somma_polinomi(pol_1, pol_2):\nif len(pol_1) &lt; len(pol_2):\nwhile len(pol_1) &lt; len(pol_2):\npol_1.insert(0, 0)\nelif len(pol_2) &lt; len(pol_1):\nwhile len(pol_2) &lt; len(pol_1):\npol_2.insert(0, 0)\nreturn [(pol_1[i] + pol_2[i]) for i in range(len(pol_1))]\n</code></pre> <p>In pratica:</p> <ul> <li>alle righe 2 - 5, verifichiamo se la lunghezza di pol1 \u00e8 inferiore a quella di pol2 e, se questo \u00e8 vero, andiamo ad inserire tanti zeri quanti sono i coefficienti \"mancanti\";</li> <li>alle righe 6 - 8, effettuiamo la stessa operazione a polinomi invertiti;</li> <li>alla riga 9, andiamo a restituire la somma elemento per elemento dei coefficienti del polinomio.</li> </ul>"},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizio-38","title":"Esercizio 3.8","text":"<p>Una possibile soluzione \u00e8 la seguente:</p> <pre><code>def calcola_media(array, pesi=[]):\nif len(pesi) == 0:\nreturn sum(array) / len(array)\nelse:\nif len(pesi) == len(array):\nreturn sum([(pesi[i] * array[i]) for i in range(len(array))]) / len(array)\nraise ValueError('La lunghezza dei pesi non corrisponde a quella degli array.')\ncalcola_media([5, 4, 5])\ncalcola_media([5, 4, 5], [0, 1, 0])\ncalcola_media([5, 4, 5], [0, 1])\n</code></pre> <p>In pratica:</p> <ul> <li>alla riga 2, verifichiamo che <code>pesi</code> sia una lista vuota;</li> <li>alla riga 3, calcoliamo la media aritmetica come somma degli elementi di <code>array</code> diviso la lunghezza dello stesso;</li> <li>nel caso <code>pesi</code> non sia una lista vuota, alla riga 5 viene verificato che <code>pesi</code> ed <code>array</code> abbiano la stessa lunghezza;</li> <li>se ci\u00f2 avviene, alla riga 6 viene creata una list comprehension moltiplicando l'\\(i\\)-mo elemento di <code>pesi</code> per il corrispondente elemento di <code>array</code>; questa sar\u00e0 quindi suddiviso per il numero di elementi di <code>array</code>.</li> </ul>"},{"location":"material/02_libs/02_numpy/exercises/solutions/#esercizio-39","title":"Esercizio 3.9","text":"<p>La funzione <code>descrivi</code> pu\u00f2 essere definita come segue:</p> <pre><code>def descrivi(array):\nreturn (\nnp.median(array),\nnp.std(array),\nnp.percentile(array, 25) - np.percentile(array, 75))\ndescrivi(np.array([3, 5, 3, 2, 1, 8]))\n</code></pre> <p>In pratica, la funzione restituisce mediana, deviazione standard e range interquartile usando le rispettive funzioni NumPy, e restituendo il tutto in una tupla.</p>"},{"location":"material/02_libs/03_pandas/01_intro/","title":"3.1 - Introduzione a Pandas","text":"<p>Notebook di accompagnamento</p> <p>Per questa lezione esiste un notebook di accompagnamento, reperibile a questo indirizzo.</p> <p>Pandas viene usata per la lettura ed elaborazione dei dati provenienti da sorgenti di vario tipo, come ad esempio file CSV o Excel, ma anche file di testo e database. Vediamo quindi brevemente come usare la libreria, tenendo presente che ne approfondiremo il funzionamento anche durante le lezioni successive.</p>"},{"location":"material/02_libs/03_pandas/01_intro/#installazione-e-configurazione-di-pandas","title":"Installazione e configurazione di Pandas","text":"<p>Al solito, il primo passo \u00e8 sempre quello di installare la libreria nel nostro ambiente di lavoro:</p> <pre><code>pip install pandas\n</code></pre> <p>Possiamo quindi importare la libreria all'interno dei nostri script o notebook:</p> <pre><code>import pandas as pd\n</code></pre>"},{"location":"material/02_libs/03_pandas/01_intro/#pandas-e-la-gestione-dei-dati","title":"Pandas e la gestione dei dati","text":"<p>Pandas gestisce prevalentemente dati strutturati sotto forma tabellare, ossia simili a quelli comunemente contenuti all'interno dei fogli di calcolo o nei database. Questi dati sono sicuramente tra i pi\u00f9 diffusi ed utilizzati nel contesto dell'analisi dei dati, ovviamente escludendo le immagini: in tal senso, per modellarli, Pandas ci mette a disposizione un'apposita struttura denominata <code>DataFrame</code>.</p> <p>I dataframe sono quindi delle strutture atte a contenere dati di ogni tipo. Questi sono normalmente organizzati in righe e colonne, in maniera del tutto analoga a quella in cui sono organizzati i fogli di calcolo ed i database. Importante anche sottolineare come, per convenzione, le singole righe rappresentino i campioni del dataset, mentre le colonne siano associati ai valori assunti dalle diverse caratteristiche, o feature, di ciascun campione.</p> <p>Facciamo un esempio usando il dataset Titanic, che \u00e8 uno tra i pi\u00f9 utilizzati a scopi di sperimentazione. Per prima cosa, generiamo un dataframe rappresentativo dei dati contenuti nel dataset, leggendo il file <code>titanic.csv</code>, che possiamo scaricare a questo link. Per leggere i dati, dovremo utilizzare il metodo <code>read_csv()</code>, cui passeremo il percorso relativo del file:</p> <pre><code>df = pd.read_csv('titanic.csv')\n</code></pre> <p>Usiamo il metodo <code>head()</code> per mostrare a schermo le prime cinque righe del dataframe.</p> <pre><code>&gt;&gt;&gt; df.head()\n</code></pre> <pre><code>   PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked\n0            1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500   NaN        S\n1            2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C\n2            3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S\n3            4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S\n4            5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500   NaN        S\n</code></pre> <p>Vediamo rapidamente che ad ogni passeggero sono associate delle feature, di cui possiamo inferire il tipo (lo verificheremo a breve):</p> Feature Descrizione Tipo PassengerId Identificativo univoco del passeggero. Intero Survived Stabilisce se il passeggero \u00e8 sopravvissuto. Intero/booleano Pclass Rappresenta la classe del passeggero Intero Name Nome completo del passeggero Stringa Sex Genere del passeggero Stringa Age Et\u00e0 del passeggero Decimale SibSp Crasi di \"Siblings/Spouses\", rappresenta il numero di fratelli/sorelle/coniugi a bordo per ogni passeggero Intero Parch Crasi di \"Parents/Children\", rappresenta il numero di genitori/figli a bordo per ogni passeggero Intero Ticket Rappresenta l'identificativo per il ticket del passeggero. Stringa Tariffa Rappresenta la tariffa pagata dal passeggero. Decimale Cabin Rappresenta la cabina in cui allogiava il passeggero. Stringa Embarked Rappresenta il punto di imbarco del passeggero. Stringa <p>Verifichiamo che le nostre ipotesi sul tipo di dato siano corrette; per farlo, possiamo usare la propriet\u00e0 <code>dtypes</code> del dataframe:</p> <pre><code>&gt;&gt;&gt; df.dtypes\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n</code></pre> <p>Notiamo subito la presenza di tre tipi di colonna, ovvero <code>int64</code>, <code>float64</code> e <code>object</code>. Laddove i primi due sono autoesplicativi, merita una particolare menzione il tipo <code>object</code>, che viene associato automaticamente a tutte le stringhe.</p> <p>Suggerimento</p> <p>Normalmente, usare il tipo <code>object</code> comporta diversi problemi nella successiva fase di analisi dei dati. Potrebbe quindi essere una buona idea parametrizzare la funzione <code>read_csv()</code> mediante il parametro <code>dtype</code>, che accetta un dizionario che specifica il tipo di una o pi\u00f9 colonne. Ad esempio, se volessimo specificare che i nomi sono delle stringhe, potremmo usare il tipo <code>string</code>:</p> <pre><code>&gt;&gt;&gt; types = {'Name': 'string'}\n&gt;&gt;&gt; df = pd.read_csv('train.csv', dtype=types)\n&gt;&gt;&gt; df.dtypes\n# ...\nName            string\n# ...\n</code></pre> <p>Appare chiaro come il dataset ci illustri numerose propriet\u00e0 per ogni passeggero imbarcato. Queste potranno quindi essere utilizzate per un'analisi approfondita della struttura dei dati sotto diversi aspetti e punti di vista; ne parleremo pi\u00f9 estesamente nel seguito.</p>"},{"location":"material/02_libs/03_pandas/02_series/","title":"3.2 - Le Series","text":""},{"location":"material/02_libs/03_pandas/02_series/#le-series","title":"Le Series","text":"<p>Nella lezione precedente abbiamo visto come ogni DataFrame sia in realt\u00e0 composto da diverse colonne, ciascuna rappresentativa di una feature specifica. Nella pratica, Pandas ci offre un modo per estrarre singolarmente ciascuna di queste colonne mediante la classe <code>Series</code>. Ad esempio, potremmo estrarre la serie relativa agli identificativi numerici dei passeggeri:</p> <pre><code>names = df['Name']\nnames.head()\n# Output restituito\n0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\nName: Name, dtype: object\n</code></pre>"},{"location":"material/02_libs/03_pandas/02_series/#accesso-agli-elementi-di-una-serie","title":"Accesso agli elementi di una serie","text":"<p>Possiamo accedere ad un singolo elemento di una serie mediante una classica procedura di indicizzazione. Notiamo infatti come ogni campione all'interno della serie sia associato ad un indice numerico crescente il cui valore iniziale \u00e8 pari a 0; pertanto, possiamo accedere all'\\(i\\)-mo elemento della serie richiamando l'\\(i-1\\)-mo indice, esattamente come accade per le liste o le sequenze.</p> <pre><code>&gt;&gt;&gt; names[0]\n'Braund, Mr. Owen Harris'\n</code></pre> <p>Nota</p> <p>L'indicizzazione pu\u00f2 essere anche usata per impostare il valore associato ad uno specifico indice della serie.</p>"},{"location":"material/02_libs/03_pandas/02_series/#accesso-agli-elementi-del-dataframe","title":"Accesso agli elementi del dataframe","text":"<p>L'accesso agli elementi del dataframe pu\u00f2 avvenire attraverso diverse modalit\u00e0. In primo luogo, possiamo accedere allo specifico valore di una feature di un dato campione mediante il chained indexing:</p> <pre><code>&gt;&gt;&gt; df['Age'][1]\n38\n</code></pre> <p>In alternativa, \u00e8 possibile usare la funzione <code>loc(row_idx, col)</code> che, se chiamata su un oggetto di tipo <code>DataFrame</code>, ci permette di accedere al valore assunto dalla feature <code>col</code> per l'elemento in posizione <code>row_idx</code>:</p> <pre><code>&gt;&gt;&gt; df.loc[1, ('Age')]\n38.0\n</code></pre> <p>La funzione <code>loc()</code> pu\u00f2 operare anche su delle slice di dati:</p> <pre><code>&gt;&gt;&gt; df.loc[1:5, ('Age')]\n1    38.0\n2    26.0\n3    35.0\n4    35.0\n5     NaN\n</code></pre> <p>o su insiemi di feature:</p> <pre><code>&gt;&gt;&gt; df.loc[1:5, ('Age', 'Sex')]\nAge     Sex\n1  38.0  female\n2  26.0  female\n3  35.0  female\n4  35.0    male\n5   NaN    male\n</code></pre> <p>Sottolineamo che la funzione <code>loc()</code> opera sugli indici di riga. In questo caso, il nostro dataframe ha degli indici di riga interi, assegnati automaticamente in fase di lettura del dataframe. Nel caso decidessimo di usare una colonna del dataframe come indice, potremmo usare il metodo <code>set_index()</code>:</p> <pre><code>df = df.set_index('Ticket')\n</code></pre> <p>Notiamo che, come al solito, le funzioni lavorano sul valore, e non sulla reference. Di conseguenza, se omettessimo l'assegnazione, <code>df</code> rimarrebbe invariato. Un modo per evitare di usare ogni volta l'operazione di assegnazione \u00e8 quello di impostare il parametro <code>inplace</code> a <code>True</code>:</p> <pre><code>df.set_index('Ticket', inplace=True)\n</code></pre> <p>In alternativa, possiamo decidere di impostare l'indice direttamente nel metodo <code>read_csv()</code> impostando il parametro <code>index_col</code>:</p> <pre><code>df = pd.read_csv('titanic.csv', index_col='Ticket')\n</code></pre> <p>In questo caso, la funzione <code>loc()</code> dovr\u00e0 essere utilizzata usando come parametri di lettura per righe i nuovi indici. Ad esempio:</p> <pre><code>&gt;&gt;&gt; df.loc['STON/O2. 3101282', 'Name']\n'Heikkinen, Miss. Laina'\n</code></pre> <p>Oltre alla funzione <code>loc()</code> Pandas ci mette a disposizione la funzione <code>iloc()</code>, la quale ci offre la possibilit\u00e0 di selezionare un sottoinsieme di campion del dataframe mediante indici interi (da cui la <code>i</code>):</p> <pre><code>&gt;&gt;&gt; df.iloc[2:5, 2:4]\nPclass                                          Name\nTicket                                                                \nSTON/O2. 3101282       3                        Heikkinen, Miss. Laina\n113803                 1  Futrelle, Mrs. Jacques Heath (Lily May Peel)\n373450                 3                      Allen, Mr. William Henry\n</code></pre>"},{"location":"material/02_libs/03_pandas/02_series/#maschere-booleane","title":"Maschere booleane","text":"<p>Supponiamo di voler selezionare soltanto gli uomini maggiorenni presenti nel dataset del Titanic. Per farlo, possiamo usare un'istruzione che implementi delle logiche di tipo booleano:</p> <pre><code>&gt;&gt;&gt; men = df[(df['Age'] &gt; 18) &amp; (df['Sex'] == 'male')]\n&gt;&gt;&gt; men.head()\nPassengerId  Survived  Pclass                            Name   Sex   Age\n0             1         0       3         Braund, Mr. Owen Harris  male  22.0   \n4             5         0       3        Allen, Mr. William Henry  male  35.0   \n6             7         0       1         McCarthy, Mr. Timothy J  male  54.0   \n12           13         0       3  Saundercock, Mr. William Henry  male  20.0   \n13           14         0       3     Andersson, Mr. Anders Johan  male  39.0   \n</code></pre> <p>Nella pratica, stiamo filtrando il dataset in base all'<code>AND</code> logico tra due condizioni:</p> <ul> <li><code>df['Age'] &gt; 18</code>: questa condizione genera una maschera booleana che \u00e8 <code>True</code> soltanto se l'et\u00e0 per quel passeggero \u00e8 maggiore di 18 anni;</li> <li><code>df['Sex'] == 'male'</code>: questa condizione genera una maschera booleana che \u00e8 vera soltanto se il genere del passeggero \u00e8 maschile.</li> </ul>"},{"location":"material/02_libs/03_pandas/02_series/#la-funzione-groupby","title":"La funzione <code>groupby</code>","text":"<p>Possiamo sfruttare la funzione <code>groupby</code> per raggruppare insiemi di dati (normalmente pertinenti a categorie).</p> <p>Ad esempio, potremmo raggruppare i passeggeri per genere:</p> <pre><code>&gt;&gt;&gt; df.groupby(['Sex'])\n</code></pre> <p>Possiamo ovviamente estrarre delle statistiche a partire da questi raggruppamenti. Vediamo, ad esempio, l'et\u00e0 media dei passeggeri di sesso femminile e maschile:</p> <pre><code>&gt;&gt;&gt; df.groupby(['Sex'])['Age'].mean()\nSex\nfemale    27.915709\nmale      30.726645\nName: Age, dtype: float64\n</code></pre>"},{"location":"material/02_libs/03_pandas/03_io/","title":"3.3 - I/O in Pandas","text":""},{"location":"material/02_libs/03_pandas/03_io/#lettura-di-dati-da-sorgenti-eterogenee","title":"Lettura di dati da sorgenti eterogenee","text":"<p>Nel nostro primo esempio abbiamo usato la funzione <code>read_csv</code> per creare un dataframe partendo dai dati memorizzati in un file in formato CSV. Tuttavia, Pandas supporta molti altri formati.</p> <p>Ad esempio, potremmo provare a leggere un file Excel:</p> <pre><code>df = pd.read_excel('dati.xlsx')\n</code></pre> <p>Attenzione</p> <p>Per leggere (e scrivere) da (su) Excel \u00e8 necessario installare la libreria <code>openpyxl</code> (<code>pip install openpyxl</code>).</p> <p>In alternativa, pu\u00f2 essere letto un file in formato JSON, oppure ancora direttamente un database:</p> <pre><code>df = pd.read_json('dati.json')\ndf = pd.read_sql(SQL_QUERY)\n</code></pre> <p>Esiste un elenco completo delle (numerose) funzioni disponibili, che possono essere individuate sulla reference. In generale, comunque, la sintassi \u00e8 sempre <code>read_*(data_source)</code>, con <code>*</code> da sostituire con il tipo di sorgente dati (<code>csv</code>, <code>excel</code>, etc.).</p>"},{"location":"material/02_libs/03_pandas/03_io/#scrittura-di-dati-su-destinazioni-eterogenee","title":"Scrittura di dati su destinazioni eterogenee","text":"<p>Possiamo anche scrivere un dataframe su file mediante le funzioni duali alle <code>read_</code>, che usano il suffisso <code>to_</code> seguito dall'estensione del file destinazione. Ad esempio, potremmo scrivere un file CSV con il metodo <code>to_csv</code>:</p> <pre><code>df.to_csv('train.xlsx')\n</code></pre>"},{"location":"material/02_libs/03_pandas/03_io/#aggiunta-di-feature-e-dati","title":"Aggiunta di feature e dati","text":"<p>Immaginiamo adesso di voler aggiungere una nuova feature ad un dataframe gi\u00e0 esistente. Per farlo, iniziamo creando un dataframe da zero:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame([1,2,3,4,5], columns=['one'])\none\n0    1\n1    2\n2    3\n3    4\n4    5\n</code></pre> <p>Possiamo aggiungere una nuova colonna semplicemente usando l'operatore di assegnazione e specificandone il nome:</p> <pre><code>&gt;&gt;&gt; df['two'] = df['one'] * 2\none  two\n0    1    2\n1    2    4\n2    3    6\n3    4    8\n4    5   10\n</code></pre> <p>Possiamo poi inserire nuovi campioni in coda al dataframe. Per farlo, dovremo prima creare un nuovo dataframe dalle dimensioni coerenti con quello gi\u00e0 esistente, e poi usare la funzione <code>concat()</code>:</p> <pre><code>&gt;&gt;&gt; df_add = pd.DataFrame([[6,7]], columns=['one', 'two'])\n&gt;&gt;&gt; df = pd.concat([df, df_add])\none  two\n0    1    2\n1    2    4\n2    3    6\n3    4    8\n4    5   10\n0    6    7\n</code></pre> <p>Notiamo che la funzione <code>concat()</code> accetta, tra gli altri, il parametro <code>axis</code>. Se questo \u00e8 uguale a zero (come lo \u00e8 di default), la <code>concat()</code> effettua la concatenazione per righe; se \u00e8 pari ad 1, invece, la concatenazione avviene per colonne. Tuttavia, \u00e8 importante sottolineare come la concatenazione avvenga anche nel caso le misure non siano completamente coerenti: infatti, se provassimo ad effettuare una concatenazione per colonne, avremmo un risultato del tipo:</p> <pre><code>&gt;&gt;&gt; pd.concat([df, df_add], axis=1)\none  two  one  two\n0    1    2  6.0  7.0\n1    2    4  NaN  NaN\n2    3    6  NaN  NaN\n3    4    8  NaN  NaN\n4    5   10  NaN  NaN\n</code></pre> <p>I valori relativi alle righe con indice che va da 1 a 4, che ovviamente non saranno presenti, saranno automaticamente impostati a NaN, acronimo di Not a Number.</p>"},{"location":"material/02_libs/03_pandas/04_functions/","title":"3.4 - Manipolazione dei DataFrame","text":""},{"location":"material/02_libs/03_pandas/04_functions/#visualizzazione-dei-dataframe","title":"Visualizzazione dei DataFrame","text":"<p>Pandas ci offre un supporto nativo a Matplotlib per permettere la visualizzazione dei dati contenuti all'interno di un dataframe.</p> <p>In tal senso, possiamo usare la funzione <code>plot()</code> su una serie o su un intero dataframe; ad esempio, potremmo plottare le et\u00e0 dei passeggeri:</p> <pre><code>df['Age'].plot()\nplt.show()\n</code></pre> <p>ottenendo il risultato mostrato in figura 1:</p> <p> </p> Figura 1 - Le et\u00e0 dei passeggeri nel dataset Titanic <p>Possiamo anche fare il plot dell'intero <code>DataFrame</code>:</p> <pre><code>df.plot()\nplt.show()\n</code></pre> <p>che risulter\u00e0 nella figura 2:</p> <p> </p> Figura 2 - Il dataset Titanic (in grafico) <p>Ovviamente, \u00e8 possibile usare Pandas anche per fare il plot di altri tipi di grafico, come ad esempio gli istogrammi. Per farlo, si usano le apposite sotto-funzioni di <code>plot</code>:</p> <pre><code>df['Age'].plot.hist()\nplt.show()\n</code></pre> <p>Il risultato \u00e8 mostrato in figura 3.</p> <p> </p> Figura 3 - Istogramma delle et\u00e0 dei passeggeri <p>Pandas e Seaborn</p> <p>Pandas si integra in maniera naturale anche con la libreria Seaborn, di cui tratteremo in una delle prossime lezioni.</p>"},{"location":"material/02_libs/03_pandas/04_functions/#gestione-dei-valori-mancanti","title":"Gestione dei valori mancanti","text":"<p>Chiunque abbia provato almeno una volta ad effettuare una campagna di acquisizione dati sa bene come questa non sia (quasi) mai una procedura in cui va tutto per il verso giusto. Ad esempio, potremmo avere un guasto ad un sensore, il quale comporterebbe la perdita di un determinato insieme di dati per un certo periodo; oppure, un utente del nostro sistema potrebbe omettere la sua et\u00e0, che quindi non risulterebbe poi nell'insieme di dati finali.</p> <p>Queste evenienze ci pongono di fronte ad una situazione \"spinosa\", legata alla gestione di dataset con al loro interno uno o pi\u00f9 valori mancanti. Ad esempio, riprendiamo le prime sei righe del dataset Titanic:</p> <pre><code>   PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked\n0            1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500   NaN        S\n1            2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C\n2            3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S\n3            4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S\n4            5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500   NaN        S\n5            6         0       3                                   Moran, Mr. James    male   NaN      0      0            330877   8.4583   NaN        Q\n</code></pre> <p>Notiamo come, per la feature <code>Cabin</code>, sia associato ai passeggeri <code>1</code>, <code>3</code>, <code>5</code> e <code>6</code> il valore <code>NaN</code>, cos\u00ec come per il parametro <code>Age</code> del passeggero <code>6</code>. Questo indica che, nel dataset originario, il valore corrispondente risulta essere assente: <code>NaN</code>, infatti, \u00e8 un acronimo che sta per Not a Number, e viene per convenzione utilizzato come placeholder per tutte le feature di cui non \u00e8 possibile leggere il valore a partire dal dataset iniziale.</p> <p>La presenza (o, per meglio dire assenza) di questi valori comporta l'impossibilit\u00e0 di utilizzare alcuni degli algoritmi che vedremo successivamente, in quanto questi prevedono la valorizzazione integrale di ciascun campione presente nel dataset. Per ovviare a questa problematica, Pandas ci mette a disposizione principalmente due alternative.</p>"},{"location":"material/02_libs/03_pandas/04_functions/#opzione-1-rimozione-dei-dati-mancanti","title":"Opzione 1: rimozione dei dati mancanti","text":"<p>La prima alternativa offerta da Pandas sta nella rimozione dei dati mancanti usando la funzione <code>dropna()</code>, che ci permette di eliminare i campioni o le feature dove sono presenti valori mancanti.</p> <p>In particolare, per eliminare i campioni che presentano dei valori mancanti, dovremo impostare il parametro <code>axis</code> a <code>0</code> (e, quindi, lavorare sulle righe):</p> <pre><code>&gt;&gt;&gt; df.dropna(axis=0)\nPassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch    Ticket     Fare        Cabin Embarked\n1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0  PC 17599  71.2833          C85        C\n3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0    113803  53.1000         C123        S\n6              7         0       1                            McCarthy, Mr. Timothy J    male  54.0      0      0     17463  51.8625          E46        S\n10            11         1       3                    Sandstrom, Miss. Marguerite Rut  female   4.0      1      1   PP 9549  16.7000           G6        S\n11            12         1       1                           Bonnell, Miss. Elizabeth  female  58.0      0      0    113783  26.5500         C103        S\n</code></pre> <p>Per eliminare invece una feature che presenta uno o pi\u00f9 dati mancanti nella sua interezza, agiamo per colonne, impostando <code>axis=1</code>:</p> <pre><code>&gt;&gt;&gt; df.dropna(axis=1)\nPassengerId  Survived  Pclass                                               Name     Sex  SibSp  Parch            Ticket     Fare\n0              1         0       3                            Braund, Mr. Owen Harris    male      1      0         A/5 21171   7.2500\n1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female      1      0          PC 17599  71.2833\n2              3         1       3                             Heikkinen, Miss. Laina  female      0      0  STON/O2. 3101282   7.9250\n3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female      1      0            113803  53.1000\n4              5         0       3                           Allen, Mr. William Henry    male      0      0            373450   8.0500\n</code></pre> <p>Soglie per l'eliminazione di un campione o di una feature</p> <p>Eliminare interamente un campione (o addirittura una feature) per la presenza di un unico valore mancante potrebbe risultare una misura draconiana. Per evitare di far questo, possiamo decidere di impostare il parametro <code>how</code> ad <code>all</code>, nel qual caso il campione/feature sar\u00e0 eliminato solo se tutti i valori risultano essere mancanti:</p> <pre><code>&gt;&gt;&gt; df.dropna(axis=1, how='all')\n</code></pre> <p>In alternativa, possiamo impostare il parametro <code>thresh</code>, che ci permette di impostare una soglia minima di valori mancanti per eliminare il campione o la feature. Ad esempio, se volessimo eliminare tutte quelle feature che presentano almeno il \\(50\\%\\) di valori mancanti, dovremmo scrivere:</p> <pre><code>&gt;&gt;&gt; df.dropna(axis=1, thresh=0.5)\n</code></pre>"},{"location":"material/02_libs/03_pandas/04_functions/#opzione-2-riempimento-dei-dati-mancanti","title":"Opzione 2: riempimento dei dati mancanti","text":"<p>L'altra opzione messa a disposizione da Pandas \u00e8 quella del riempimento dei dati mancanti. Questa strada \u00e8 percorribile usando la funzione <code>fillna()</code>.</p> <p>Nell'interpretazione base, possiamo usare <code>fillna()</code> parametrizzandolo con il valore che vogliamo utilizzare. Ad esempio:</p> <pre><code>&gt;&gt;&gt; df.fillna(0) \nPassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked\n0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500     0        S\n1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C\n2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250     0        S\n3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S\n4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500     0        S\n</code></pre> <p>In questo caso, andremo ad associare il valore <code>0</code> a tutti i <code>NaN</code>. Un utilizzo pi\u00f9 raffinato prevede la specifica di un metodo di riempimento dei dati. Ad esempio, potremmo indicare a Pandas di riempire i <code>NaN</code> con i valori immediatamente precedenti:</p> <pre><code>&gt;&gt;&gt; df.fillna(method='ffill')\nPassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked\n0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500   NaN        S\n1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C\n2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250   C85        S\n3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S\n4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500  C123        S\n</code></pre> <p>In questo caso, notiamo come il valore di <code>Cabin</code> per la prima riga non venga riempito, perch\u00e9 non vi sono dati \"precedenti\" da cui attingere. Potremmo per\u00f2 porvi rimedio utilizzando in cascata due chiamate a <code>fillna()</code>:</p> <pre><code>&gt;&gt;&gt; df.fillna(method='ffill').fillna(method='bfill')\nPassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked\n0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500   C85        S\n1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C\n2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250   C85        S\n3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S\n4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500  C123        S\n</code></pre> <p>Questa volta, al primo indice, <code>Cabin</code> diventa pari al valore del secondo indice, grazie alla chiamata in cascata di un <code>ffill</code> e di un <code>bfill</code> (ovvero, un riempimento \"all'indietro\"). Da notare anche l'influenza del parametro <code>axis</code>. Negli esempi precedenti, infatti, abbiamo ragionato per colonne; tuttavia, possiamo anche ragionare per righe, specificando <code>axis=1</code>:</p> <pre><code>&gt;&gt;&gt; df.fillna(method='ffill', axis=1)\nPassengerId Survived Pclass                                               Name     Sex     Age SibSp Parch            Ticket     Fare  Cabin Embarked\n0             1        0      3                            Braund, Mr. Owen Harris    male    22.0     1     0         A/5 21171     7.25   7.25        S\n1             2        1      1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female    38.0     1     0          PC 17599  71.2833    C85        C\n2             3        1      3                             Heikkinen, Miss. Laina  female    26.0     0     0  STON/O2. 3101282    7.925  7.925        S\n3             4        1      1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female    35.0     1     0            113803     53.1   C123        S\n4             5        0      3                           Allen, Mr. William Henry    male    35.0     0     0            373450     8.05   8.05        S\n</code></pre> <p>Vediamo come la feature <code>Cabin</code> venga stavolta valorizzata con il valore di <code>Fare</code>.</p> <p>Suggerimento</p> <p>Va da s\u00e9 che la precedente trattazione sia a meno scopo illustrativo. Non ha infatti senso andare ad assegnare a <code>Cabin</code> un valore numerico, o far propagare i valori delle cabine precedenti/successive. In questo caso, infatti, potrebbe essere conveniente eliminare del tutto la feature o il campione. Come vedremo quando parleremo di Scikit Learn, l'assegnazione dei valori mancanti ha significato soprattutto quando vi sono delle relazioni, dirette o indirette, tra i diversi campioni presenti nel dataset.</p>"},{"location":"material/02_libs/03_pandas/04_functions/#operazioni-statistiche-sui-dataframe","title":"Operazioni statistiche sui dataframe","text":"<p>Pandas ci mette a disposizione delle funzioni, simili a quelle offerte da NumPy, per calcolare delle statistiche per ciascuna delle colonne presenti in un DataFrame. Ad esempio, possiamo calcolare la media usando la funzione <code>mean()</code>:</p> <pre><code>&gt;&gt;&gt; df.mean()\nPassengerId    446.000000\nSurvived         0.383838\nPclass           2.308642\nAge             29.699118\nSibSp            0.523008\nParch            0.381594\nFare            32.204208\ndtype: float64\n</code></pre> <p>Ovviamente, esistono funzioni anche per calcolare varianza (<code>var()</code>), mediana (<code>median()</code>), deviazione standard (<code>std()</code>), e via discorrendo.</p> <p>Particolarmente interessante \u00e8 la funzione <code>describe()</code>, che ci mosta tutte le statistiche pi\u00f9 significative per ognuna delle feature considerate.</p> <pre><code>&gt;&gt;&gt; df.describe()\nPassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\ncount   891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\nmean    446.000000    0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\nstd     257.353842    0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\nmin       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n25%     223.500000    0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n50%     446.000000    0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n75%     668.500000    1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\nmax     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n</code></pre>"},{"location":"material/02_libs/04_visualization/01_matplotlib/","title":"4.1 - Matplotlib","text":"<p>Notebook di accompagnamento</p> <p>Per questa lezione esiste un notebook di accompagnamento, reperibile a questo indirizzo.</p> <p>Nelle lezioni precedenti, ci siamo limitati a visualizzare i risultati ottenuti usando l'output fornito dalla riga di comando o dal notebook Jupyter/Colab. Tuttavia, \u00e8 chiaro come questo modo di procedere sia giocoforza limitante: cosa ne \u00e8 di tutti i coloratissimi grafici che possiamo ammirare in siti ed articoli scientifici? Saranno per caso relegati esclusivamente al mondo di Excel?</p> <p>In realt\u00e0, per ottenerli dovremo necessariamente integrare il nostro ambiente di lavoro con altre librerie. Ne esistono diverse, ma la pi\u00f9 utilizzata \u00e8 senza dubbio Matplotlib, cui si pu\u00f2 affiancare Seaborn, che tratteremo in una delle prossime lezioni.</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#setup-della-libreria","title":"Setup della libreria","text":"<p>Prima di utilizzare Matplotlib, dovremo ovviamente installare la libreria. Per farlo, abbiamo al solito le opzioni mostrate in appendice; di seguito, riportiamo l'opzione di installazione tramite <code>pip</code>:</p> <pre><code>pip install matplotlib\n</code></pre> <p>Passiamo poi ad importare la libreria all'interno del nostro programma. In particolare, il package pi\u00f9 utilizzato \u00e8 <code>pyplot</code> che, come dice la documentazione, altro non \u00e8 che un insieme di funzioni (palesemente) ispirate a MATLAB. Useremo quindi un alias per questo package:</p> <pre><code>import matplotlib.pylot as plt\n</code></pre> <p>Saremo a questo punto pronti per utilizzare le funzioni messe a disposizione da Matplotlib.</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#il-primo-plot","title":"Il primo plot","text":"<p>Per creare il nostro primo plot, utilizziamo il seguente codice:</p> <pre><code>rng = np.random.default_rng(42)\nx = np.arange(1, 6)\ny = rng.integers(low=0, high=10, size=5)\nfig, ax = plt.subplots()\nax.plot(x, y)\nplt.show()\n</code></pre> <p>In particolare:</p> <ul> <li>alla riga 1, creiamo un generatore di numeri casuali;</li> <li>alla riga 2, definiamo tutti i valori di <code>x</code> compresi nell'intervallo tra 1 e 5 usando la funzione <code>numpy.arange()</code>;</li> <li>alla riga 3, definiamo tutti i valori di <code>y</code> come valori interi casuali compresi tra <code>0</code> e <code>10</code>;</li> <li>alla riga 4, creiamo una <code>figure</code> ed un <code>axes</code> mediante il metodo <code>subplots()</code>;</li> <li>alla riga 5, effettuiamo il plot su <code>ax</code>, mettendo come ascissa i valori di <code>x</code>, e come ordinata quelli di <code>y</code>;</li> <li>alla riga 6, chiamiamo il metodo <code>show()</code> per mostrare a schermo il grafico ottenuto.</li> </ul> <p>Se tutto \u00e8 andato per il verso giusto, dovremmo vedere a schermo l'immagine mostrata nella figura 1.</p> <p> </p> Figura 1 - Un semplice plot in Matplotlib <p>Suggerimento</p> <p>Se avete seguito pedissequamente il tutorial, a schermo dovrebbe essere visualizzata esattamente l'immagine mostrata nella figura 1. Questo perch\u00e9 al generatore di numeri (pseudo) casuali viene passato il parametro <code>seed</code>, usato come base per la generazione degli stessi, che risulteranno quindi essere sempre gli stessi, indipendentemente dall'iterazione.</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#figure-ed-assi","title":"Figure ed assi","text":"<p>L'esempio precedente ci permette di illustrare in poche righe di codice tutti i concetti su cui si basa Matplotlib. Tuttavia, \u00e8 opportuno scendere maggiormente nel dettaglio.</p> <p>In particolare, alla base del funzionamento di Matplotlib ci sono quattro classi fondamentali.</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#la-classe-figure","title":"La classe <code>Figure</code>","text":"<p>Per prima cosa, ci sono le <code>Figure</code>, rappresentative dell'intera area mostrata a schermo da Matplotlib. Un oggetto di questa classe conterr\u00e0 un numero arbitrario di elementi, permettendone visualizzazione e contestuale manipolazione.</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#la-classe-axes","title":"La classe <code>Axes</code>","text":"<p>Gli oggetti di classe <code>Axes</code>, rappresentano l'area della <code>Figure</code> all'interno della quale saranno visualizzati i dati. La relazione tra <code>Figure</code> ed <code>Axes</code> \u00e8 strettamente gerarchica: in pratica, una <code>Figure</code> pu\u00f2 avere diversi <code>Axes</code>, ma ogni <code>Axes</code> appartiene esclusivamente ad una <code>Figure</code>.</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#la-classe-axis","title":"La classe <code>Axis</code>","text":"<p>All'interno di un oggetto <code>Axes</code> troviamo poi due o tre oggetti di tipo <code>Axis</code>, ognuno dei quali rappresenta l'asse vero e proprio. In altri termini, avremo due <code>Axis</code> per i plot bidimensionali, rappresentativi degli assi \\(x\\) ed \\(y\\), ed un terzo <code>Axis</code> per i plot tridimensionali, rappresentativo ovviamente dell'asse \\(z\\). Gli oggetti <code>Axis</code> ci permettono quindi di definire gli intervalli dati, l'eventuale griglia, e via discorrendo.</p> <p><code>Axes</code> ed <code>Axis</code></p> <p>Fate attenzione a non confondere gli <code>Axes</code> con gli <code>Axis</code>! In pratica: gli <code>Axes</code> sono i singoli plot, mentre gli <code>Axis</code> sono gli assi contenuti in ciascun plot.</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#la-classe-artist","title":"La classe <code>Artist</code>","text":"<p>L'ultimo concetto fondamentale di Matplotlib \u00e8 quello degli artist, oggetti derivati dalla classe base <code>Artist</code>, delegata al rendering vero e proprio dei plot.</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#rivisitazione-dellesempio-precedente","title":"Rivisitazione dell'esempio precedente","text":"<p>Torniamo brevemente al precedente snippet. La funzione <code>subplots()</code> ci servir\u00e0 quindi a creare un oggetto di tipo <code>Figure</code> assieme agli <code>Axes</code> desiderati:</p> <pre><code>fig, ax = plt.subplots()\n</code></pre> <p>A questo punto, possiamo plottare i valori di <code>x</code> ed <code>y</code> su nostro oggetto <code>Axes</code>, che conterr\u00e0 a sua volta due <code>Axis</code>, uno per l'asse delle \\(x\\), e l'altro per l'asse delle \\(y\\):</p> <pre><code>ax.plot(x, y)\n</code></pre> <p>Vediamo adesso qualche esempio pi\u00f9 significativo</p>"},{"location":"material/02_libs/04_visualization/01_matplotlib/#esempio-1-plot-di-piu-funzioni","title":"Esempio 1: Plot di pi\u00f9 funzioni","text":"<p>L'obiettivo di questo esempio \u00e8 mostrare su uno stesso <code>Axes</code> due diverse funzioni. In particolare, scegliamo come funzioni da rappresentare una retta ed una funzione seno.</p> <p>Per prima cosa, definiamo i nostri dati:</p> <pre><code>x = np.arange(0., 10., 0.01)\ny_1 = 1 + 2 * x\ny_2 = np.sin(x)\n</code></pre> <p>Alla riga 1, definiamo l'intervallo sull'asse \\(x\\) come quello compreso tra \\(0\\) e \\(10\\) e campionato a passo \\(0.01\\). Cos\u00ec facendo, avremo un campionamento molto fitto, con un totale di \\(1000\\) punti considerati. Alla riga 2 definiamo la nostra retta, la cui equazione sar\u00e0 \\(y = 2x + 1\\), mentre alla riga 3 andremo a definire la funzione seno.</p> <p>Adesso, creiamo la nostra <code>Figure</code> con relativo <code>Axes</code>, ed effettuiamo il plot di entrambe le funzioni.</p> <pre><code>fig, ax = plt.subplots()\nax.plot(x, y_1, label='Retta')\nax.plot(x, y_2, label='Funzione sinusoidale')\n</code></pre> <p>Notiamo la presenza del parametro <code>label</code> che indica l'etichetta assegnata ai due plot; questa sar\u00e0 utilizzata successivamente per generare la legenda. Passiamo adesso ad impostare il titolo e le label sugli assi \\(x\\) e \\(y\\) usando rispettivamente le funzioni <code>set_title()</code>, <code>set_xlabel()</code> e <code>set_ylabel()</code>:</p> <pre><code>ax.set_title('Plot di due funzioni matematiche')\nax.set_xlabel('Asse x')\nax.set_ylabel('Asse y')\n</code></pre> <p>Usiamo adesso la funzione <code>grid()</code> per mostrare una griglia sulla figura, e la funzione <code>legend()</code> per far apparire la legenda che descrive le funzioni visualizzate.</p> <pre><code>ax.legend()\nax.grid()\n</code></pre> <p>In ultimo, mostriamo a schermo la figura con la funzione <code>show()</code>:</p> <pre><code>plt.show()\n</code></pre> <p>Il risultato ottenuto \u00e8 mostrato in figura 2.</p> <p> </p> Figura 2 - Plot di due funzioni"},{"location":"material/02_libs/04_visualization/01_matplotlib/#esempio-2-subplot-multipli","title":"Esempio 2: Subplot multipli","text":"<p>Alle volte, pu\u00f2 essere conveniente affiancare pi\u00f9 subplot all'interno di un unico plot principale. In tal senso, abbiamo in precedenza detto che possiamo definire pi\u00f9 <code>Axes</code> per un'unica <code>Figure</code>; per farlo, possiamo parametrizzare la funzione <code>subplots(i, j)</code>, in maniera tale che vengano creati \\(i \\times j\\) plot all'interno della stessa figura.</p> <p>Per creare 2 subplot in \"riga\", ad esempio, parametrizzeremo <code>subplots()</code> come segue:</p> <pre><code>fig, (ax_1, ax_2) = plt.subplots(2, 1)\n</code></pre> <p>Notiamo la presenza di due <code>Axes</code>, rispettivamente <code>ax_1</code> ed <code>ax_2</code>. Ognuno di questi potr\u00e0 essere trattato come descritto in precedenza.</p> <p>Per prima cosa, usiamo la funzione <code>suptitle()</code> sulla <code>Figure</code> <code>fig</code> per dare un titolo all'intero plot:</p> <pre><code>fig.suptitle('Due subplot di pi\u00f9 funzioni matematiche')\n</code></pre> <p>A questo punto, procediamo ad effettuare i plot sui relativi assi:</p> <pre><code># Primo subplot\nax_1.plot(x, y_1, label='Retta')\nax_1.set_xlabel('Asse x')\nax_1.set_ylabel('Asse y')\nax_1.legend()\nax_1.grid()\n# Secondo subplot\nax_2.plot(x, y_2, label='Funzione sinusoidale')\nax_2.set_xlabel('Asse x')\nax_2.set_ylabel('Asse y')\nax_2.legend()\nax_2.grid()\n</code></pre> <p>Mostriamo quindi a schermo il plot:</p> <pre><code>plt.show()\n</code></pre> <p>Il risultato sar\u00e0 simile a quello mostrato in figura 3:</p> <p> </p> Figura 3 - Subplot multipli"},{"location":"material/02_libs/04_visualization/01_matplotlib/#esempio-3-istogramma","title":"Esempio 3: Istogramma","text":"<p>Abbiamo gi\u00e0 parlato degli istogrammi in NumPy. Tuttavia, un istogramma raggiunge la massima espressivit\u00e0 possibile quando ne si utilizza la rappresentazione visiva. In tal senso, Matplotlib ci offre una funzione apposita chiamata <code>hist()</code>.</p> <p>Proviamo ad utilizzarla. Per farlo, creiamo in primis un vettore di \\(1000\\) numeri interi casuali compresi tra \\(0\\) e \\(100\\).</p> <pre><code>x = rng.integers(low=0, high=100, size=1000)\n</code></pre> <p>Al solito, creiamo la nostra figura, ed usiamo la funzione <code>hist()</code> passandogli il vettore <code>x</code> creato in precedenza e il parametro <code>density</code>, che ci permetter\u00e0 di normalizzare l'istogramma (ovvero, fare in modo tale che la sommatoria dei singoli bin sia esattamente pari ad 1).</p> <pre><code>fig, ax = plt.subplots()\nax.hist(x, edgecolor='black', linewidth=1.2, density=True)\n</code></pre> <p>Notiamo anche l'uso dei parametri <code>edgecolor</code>, che permette di impostare il colore del bordo di ciascuna barra dell'istogramma, e <code>linewidth</code>, che consente di specificarne lo spessore.</p> <p>Al solito, usiamo i metodi opportuni per impostare titolo e label degli assi, e mostriamo la figura.</p> <pre><code>ax.set_xlabel('Bin')\nax.set_ylabel('Conteggio dei singoli elementi')\nax.set_title('Esempio di istogramma')\nplt.show()\n</code></pre> <p>Il risultato sar\u00e0 simile a quello mostrato nella figura 4.</p> <p> </p> Figura 4 - Istogramma"},{"location":"material/02_libs/04_visualization/01_matplotlib/#esempio-4-scatter-plot","title":"Esempio 4: Scatter plot","text":"<p>Lo scatter plot \u00e8 una modalit\u00e0 alternativa di mostrare la distribuzione dei dati lungo gli assi \\(x\\), \\(y\\) ed, opzionalmente, \\(z\\). In particolare, questo tipo di visualizzazione differisce dal normale plot in quanto i singoli punti dati non sono collegati da una linea, ma rappresentati in modo discreto, ed \u00e8 particolarmente utile quando si vuole valutare visivamente la distribuzione di una serie di dati in due o tre dimensioni. Ovviamente, Matplotlib ci mette a disposizione un'apposita funzione per la visualizzazione di questo tipo di plot, chiamata <code>scatter()</code>.</p> <p>Il funzionamento \u00e8 totalmente analogo al <code>plot()</code>. Ad esempio, considerando i valori di <code>x</code> ed <code>y</code> utilizzati nel primo esempio del tutorial, potremmo generare uno scatter plot come segue:</p> <pre><code>rng = np.random.default_rng(42)\nx = np.arange(1, 6)\ny = rng.integers(low=0, high=10, size=5)\nfig, ax = plt.subplots()\nax.set_xlabel('Asse x')\nax.set_ylabel('Asse y')\nax.set_title('Esempio di scatter plot')\nax.plot(x, y)\nplt.show()\n</code></pre> <p>Il risultato sar\u00e0 simile a quello mostrato in figura 5.</p> <p> </p> Figura 5 - Scatter plot"},{"location":"material/02_libs/04_visualization/01_matplotlib/#note-finali-salvataggio-e-chiusura-di-una-figura","title":"Note finali: salvataggio e chiusura di una figura","text":"<p>Chiudiamo questa breve carrellata specificando che, per salvare una figura, \u00e8 necessario usare la funzione <code>savefig()</code>, che accetta come primo parametro il nome del file su cui salveremo l'immagine:</p> <pre><code>plt.savefig('file_name.png')\n</code></pre> <p>Oltre a questo, dei parametri molto utili da utilizzare sono <code>dpi</code>, che ci permette di specificare la risoluzione della figura, e <code>bbox_inches</code>, per il quale il suggerimento \u00e8 di impostarlo a <code>tight</code> per evitare eccessivi spazi bianchi attorno alla figura (o, al contrario, il taglio di parti delle label).</p> <p>Infine, facciamo un cenno alla funzione <code>close()</code>, delegata alla chiusura di un oggetto di tipo <code>Figure</code>:</p> <pre><code>plt.close()\n</code></pre> <p>La funzione <code>close()</code> assume particolare rilevanza nel momento in cui vogliamo, ad esempio, plottare diverse figure al variare di alcune condizioni, come ad esempio in un ciclo. Infatti, se non chiudessimo la figura attuale al termine di ciascuna iterazione, Matplotlib andrebbe a disegnare la nuova funzione sempre sulla stessa figura. Ad esempio:</p> <pre><code>for i in range(5):\nplt.plot(x, y*i)\nplt.show()\n</code></pre> <p>In questo caso, dato che non stiamo chiudendo la figura, avremo un risultato come visto in figura 6.</p> <p> </p> Figura 6 - Plot senza l'invocazione di `close()` <p>Se invece chiamassimo sempre la <code>close()</code>, all'ultima iterazione avremmo il plot mostrato in figura 7.</p> <pre><code>for i in range(5):\nplt.plot(x, y*i)\nplt.show()\nplt.close()\n</code></pre> <p> </p> Figura 7 - Plot con l'invocazione di `close()` <p>Nella prossima lezione, approfondiremo l'utilizzo di una libreria discendente da Matplotlib, ovvero Seaborn.</p>"},{"location":"material/02_libs/04_visualization/02_seaborn/","title":"4.2 - Seaborn","text":"<p>Notebook di accompagnamento</p> <p>Per questa lezione esiste un notebook di accompagnamento, reperibile a questo indirizzo.</p> <p>Seaborn \u00e8 una libreria che estende Matplotlib aggiungendone diverse funzionalit\u00e0, tutte nell'ottica della data analysis, e sulla scia di quello che abbiamo presentato in Pandas in una delle precedenti lezioni. Ci\u00f2 permette quindi di mantenere un'interfaccia molto simile a quella di Matplotlib, estendendone al contempo le possibilit\u00e0. Vediamo qualche esempio.</p>"},{"location":"material/02_libs/04_visualization/02_seaborn/#setup-della-libreria","title":"Setup della libreria","text":"<p>Come in ogni altro caso, partiamo dall'installazione della libreria, che potr\u00e0 essere fatta usando il seguente comando:</p> <pre><code>pip install seaborn\n</code></pre> <p>Una volta completata l'installazione, potremo importare Seaborn mediante un alias:</p> <pre><code>import seaborn as sns\n</code></pre>"},{"location":"material/02_libs/04_visualization/02_seaborn/#analisi-esplorativa-dei-dati","title":"Analisi esplorativa dei dati","text":"<p>Come abbiamo detto in precedenza, Seaborn risulta utile in diverse situazioni collegate alla data analysis.</p> <p>In tal senso, supponiamo di voler effettuare un'analisi dei dati esplorativa (Exploratory Data Analysis, o EDA), visualizzando le relazioni che intercorrono tra le diverse feature presenti all'interno di un certo dataset. Nel nostro esempio, utilizzeremo il dataset tips, contenuto all'interno di Seaborn, il quale descrive le caratteristiche dei clienti di un generico ristorante, ed in particolare:</p> <ul> <li>total_bill: il conto totale;</li> <li>tip: la mancia lasciata dal cliente pagante;</li> <li>sex: il genere del cliente pagante;</li> <li>smoker: il fatto che il tavolo sia o meno in zona fumatori;</li> <li>day: la giornata nella quale il pasto \u00e8 stato consumato;</li> <li>time: la parte della giornata nella il pasto \u00e8 stato consumato (in particolare, pranzo o cena);</li> <li>size: il numero di clienti seduti al tavolo.</li> </ul> <p>Partiamo caricando il dataset. Per farlo, utilizziamo il metodo <code>load_dataset()</code>, che ci permette di scaricare rapidamente il dataset passato come parametro, salvandolo in un apposito <code>DataFrame</code>:</p> <pre><code>tips = sns.load_dataset('tips')\n</code></pre> <p>I dataset</p> <p>L'elenco dei dataset integrati in Seaborn \u00e8 presente a questo indirizzo.</p> <p>Partiamo ispezionando il <code>DataFrame</code> appena scaricato mediante il comando <code>head()</code>. Vediamo che gli elementi precedentemente descritti sono organizzati in questo modo:</p> <pre><code>  total_bill   tip     sex smoker  day    time  size\n0       16.99  1.01  Female     No  Sun  Dinner     2\n1       10.34  1.66    Male     No  Sun  Dinner     3\n2       21.01  3.50    Male     No  Sun  Dinner     3\n3       23.68  3.31    Male     No  Sun  Dinner     2\n4       24.59  3.61  Female     No  Sun  Dinner     4\n</code></pre> <p>La struttura del <code>DataFrame</code> \u00e8 quindi la seguente:</p> <ul> <li>ogni riga \u00e8 associata ad una specifica ordinazione;</li> <li>le colonne sono associate rispettivamente a conto (<code>total_bill</code>), mancia (<code>tip</code>), genere (<code>sex</code>), fumatore (<code>smoker</code>), giorno (<code>day</code>), orario (<code>time</code>) e numero di attendenti (<code>size</code>), come descritto in precedenza.</li> </ul>"},{"location":"material/02_libs/04_visualization/02_seaborn/#visualizzare-le-relazioni-tra-dati","title":"Visualizzare le relazioni tra dati","text":"<p>La prima funzione che andremmo ad utilizzare \u00e8 la <code>relplot()</code>, la quale ci permette di analizzare rapidamente le relazioni intercorrenti tra le diverse feature del dataset. Ad esempio, possiamo vedere come cambiano il conto e la mancia al variare della giornata:</p> <pre><code>sns.relplot(\ndata=tips,\nx='total_bill',\ny='tip',\ncol='day')\n</code></pre> <p>In particolare:</p> <ul> <li>il parametro <code>data</code> viene valorizzato con <code>tips</code>, ovvero il <code>DataFrame</code> che contiene i dati che vogliamo analizzare;</li> <li>il parametro <code>x</code>, che definisce i dati visualizzati sull'asse delle ascisse, sar\u00e0 parametrizzato a <code>total_bill</code>, ovvero il nome della feature che vogliamo visualizzare sul suddetto asse;</li> <li>in maniera simile al precedente, <code>y</code>, che definisce i dati visualizzati sull'asse delle ordinate, sar\u00e0 parametrizzato a <code>tip</code>;</li> <li>il parametro <code>col</code>, invece, generer\u00e0 tanti grafici quante sono le possibili valorizzazioni della colonna <code>day</code>, ognuno dei quali corrispondente all'andamento dei parametri indicati su <code>x</code> ed <code>y</code> per quello specifico giorno.</li> </ul> <p>I risultati sono mostrati nella figura 1.</p> <p> </p> Figura 1 - Comparazione tra conto e mance al variare del giorno in Seaborn <p>Proviamo adesso a valutare come cambia il rapporto conto/mance in base al sesso:</p> <pre><code>sns.relplot(\ndata=tips,\nx='total_bill',\ny='tip',\ncol='sex',\nsize='tip')\n</code></pre> <p>I risultati sono mostrati in figura 2. Notiamo come, impostando il parametro <code>size</code>, potremo modificare la dimensione di ciascun punto, rendendola direttamente proporzionale alla mancia data.</p> <p> </p> Figura 2 - Comparazione tra conto e mance al variare del sesso. La dimensione di ciascun punto \u00e8 data dall'entit\u00e0 della mancia <p>Una funzione simile alla <code>relplot()</code> \u00e8 la <code>lmplot()</code>, la quale offre anche un'approssimazione ai minimi quadrati dei dati impostati sugli assi cartesiani. Ad esempio, proviamo a mostrare lo stesso rapporto illustrato in figura 2 con la <code>lmplot()</code>:</p> <pre><code>sns.lmplot(\ndata=tips,\nx='total_bill',\ny='tip',\ncol='time',\nhue='day')\n</code></pre> <p>Da notare come in questo caso abbiamo specificato il parametro <code>hue</code>, che regola la tinta dei punti dati. I risultati sono mostrati in figura 3.</p> <p> </p> Figura 3 - Comparazione tra conto e mance con approssimazione dei dati ai minimi quadrati"},{"location":"material/02_libs/04_visualization/02_seaborn/#analisi-della-distribuzione-dati","title":"Analisi della distribuzione dati","text":"<p>Seaborn ci permette di effettuare un'analisi della distribuzione delle variabili all'interno del dataset sotto analisi. Per farlo, usiamo la funzione <code>displot()</code>, che ci permette di visualizzare la distribuzione dei dati sulla base di determinate condizioni sfruttando un istogramma.</p> <p>Ad esempio, potremmo visualizzare la distribuzione dei clienti in base al loro genere ed al momento della giornata in cui effettuano la consumazione:</p> <pre><code>sns.displot(\ndata=tips,\nx='sex',\ncol='time',\nkde=True)\n</code></pre> <p>Il risultato \u00e8 mostrato in figura 4:</p> <p> </p> Figura 4 - Distribuzione dei clienti in base al loro genere ed al momento della giornata in cui viene effettuata la consumazione <p>Specificando il parametro <code>kde</code>, \u00e8 possibile ottenere un'approssimazione della distribuzione mediante kernel density estimation, come mostrato in figura 5.</p> <p> </p> Figura 5 - Distribuzione dei clienti in base al loro genere ed al momento della giornata in cui viene effettuata la consumazione. La visualizzazione sfrutta la KDE"},{"location":"material/02_libs/04_visualization/02_seaborn/#plot-di-dati-categorici","title":"Plot di dati categorici","text":"<p>Seaborn offre anche dei plot specializzati per la creazione e visualizzazione di dati (o feature) di tipo categorico, ovvero dati appartenenti ad una tra diverse possibili categorie. In tal senso, un esempio di feature categorica \u00e8 il genere dei clienti del ristorante, che nel dataset sono soltanto uomini o donne.</p> <p>Dati categorici e numerici</p> <p>Oltre ai dati categorici, esistono i dati numerici che, ovviamente, rappresentano dei numeri.</p> <p>I plot di questo tipo possono essere generati mediante la funzione <code>catplot()</code>, delegata alla definizione di plot a diversi livelli di granularit\u00e0, come ad esempio i violin plot.</p> <pre><code>sns.catplot(\ndata=tips,\nkind='violin',\nx='day',\ny='tip',\nhue='sex',\nsplit=True)\n</code></pre> <p>In particolare, il grafico mostrato in figura 6 descrive la distribuzione delle mance giorno per giorno al variare del genere del cliente.</p> <p> </p> Figura 6 - *Violin plot* descrivente la distribuzione delle mance giorno per giorno al variare del sesso dell'avventore <p>Catplot con dati non categorici</p> <p>In realt\u00e0, \u00e8 possibile usare la <code>catplot()</code> con dati numerici. Tuttavia, vi \u00e8 un elevato rischio che il risultato non sia interpretabile, in quanto la funzione assegner\u00e0 una categoria ad ogni possibile valore assunto dalla feature di riferimento, il che ovviamente comporter\u00e0 l'illeggibilit\u00e0 del grafico nel caso di valori reali.</p>"},{"location":"material/02_libs/04_visualization/02_seaborn/#heatmap","title":"Heatmap","text":"<p>Un'ultima funzione che vale la pena menzionare \u00e8 quella che ci permette di visualizzare le heatmap, ovvero delle strutture grafiche che ci permettono di visualizzare gli intervalli in cui ricadono i valori di diversi tipi di matrici. Questa funzione \u00e8, per l'appunto, chiamata <code>heatmap()</code>, e richiede in ingresso almeno il parametro relativo alla matrice da cui sar\u00e0 estratta la figura. Ad esempio:</p> <pre><code>ar = np.array([[5, 12], [4, 3]])\nsns.heatmap(\nar,\ncmap='jet',\nannot=True,\nxticklabels=False,\nyticklabels=False)\n</code></pre> <p>Nella precedente invocazione della funzione <code>heatmap()</code> specifichiamo i parametri indicati in modo da passare un array (o similari) come primo argomento, seguito da una colormap, ovvero i colori da utilizzare. Specifichiamo inoltre che vogliamo inserire i valori dell'array su ciascuna delle celle dell'heatmap (mediante il parametro <code>annot</code>) e che non vogliamo visualizzare i label sugli assi \\(x\\) e \\(y\\) (<code>xticklabels</code> ed <code>yticklabels</code> rispettivamente). Otterremo il risultato mostrato in figura 7:</p> <p> </p> Figura 7 - Un esempio di heatmap <p>Usi delle heatmap</p> <p>Le heatmap sono molto utili in diverse situazioni, tra cui la descrizione dei risultati degli algoritmi di machine learning mediante le matrici di confusione, l'analisi di correlazione, e la visualizzazione delle mappe di attivazione in caso di interpretabilit\u00e0 delle reti neurali.</p>"},{"location":"material/02_libs/04_visualization/exercises/exercises/","title":"Esercitazione 4 - Visualizzazione dei dati in Python","text":""},{"location":"material/02_libs/04_visualization/exercises/exercises/#esercizio-41","title":"Esercizio 4.1","text":"<p>Utilizzare Seaborn per visualizzare come si distribuisce l'et\u00e0 dei diversi passeggeri del Titanic sulla base del loro genere. Visualizzare inoltre il rapporto tra l'et\u00e0 ed il numero di familiari, sempre sulla base del genere.</p>"},{"location":"material/02_libs/04_visualization/exercises/exercises/#esercizio-42","title":"Esercizio 4.2","text":"<p>Effettuiamo un'analisi esplorativa del dataset Titanic. In particolare, partiamo da una serie di domande di ricerca, e sfruttiamo Pandas e Seaborn per rispondere in maniera qualitativa.</p>"},{"location":"material/02_libs/04_visualization/exercises/exercises/#esercizio-43","title":"Esercizio 4.3","text":"<p>Effettuiamo un'analoga analisi sul dataset Tips.</p>"},{"location":"material/02_libs/04_visualization/exercises/solutions/","title":"Esercitazione 4 - Visualizzazione dei dati in Python (Soluzioni)","text":"<p>Soluzioni</p> <p>L'implementazione delle soluzioni \u00e8 disponibile questo notebook.</p>"},{"location":"material/02_libs/04_visualization/exercises/solutions/#esercizio-41","title":"Esercizio 4.1","text":"<p>Per prima cosa, leggiamo il dataframe:</p> <pre><code>df = pd.read_csv('titanic.csv')\n</code></pre> <p>Per visualizzare la distribuzione dell'et\u00e0 dei diversi passeggeri del Titanic in base al loro genere usiamo un <code>displot()</code>:</p> <pre><code>sns.displot(\ndata=df,\nx='Age',\ncol='Sex')\n</code></pre> <p>Per visualizzare inoltre il rapporto tra et\u00e0 e numero di fratelli/sorelle/coniugi in base al genere del passeggero usiamo un <code>catplot()</code>:</p> <pre><code>sns.catplot(\ndata=df,\nkind='violin',\nx='SibSp',\ny='Age',\nhue='Sex',\nsplit=True)\n</code></pre>"},{"location":"material/02_libs/05_scipy/exercises/","title":"E11 - Introduzione a SciPy","text":""},{"location":"material/02_libs/05_scipy/exercises/#esercizio-e111","title":"Esercizio E11.1","text":"<p>Scrivere una funzione che restituisca <code>True</code> se la matrice passata in ingresso \u00e8 invertibile, <code>False</code> altrimenti. Usare SciPy.</p>"},{"location":"material/02_libs/05_scipy/exercises/#soluzione-s101","title":"Soluzione S10.1","text":"<p>Ecco una possibile soluzione:</p> <pre><code>from scipy import linalg\ndef invertibile(mat):\n\"\"\" Usiamo un operatore ternario.\n    Il risultato \u00e8 analogo alla seguente:\n    if linalg.det(mat) != 0.:\n        return True\n    else:\n        return False\n    \"\"\"\nreturn True if linalg.det(mat) != 0. else False\n</code></pre>"},{"location":"material/02_libs/05_scipy/exercises/#esercizio-e112","title":"Esercizio E11.2","text":"<p>Scrivere una classe che, incorporando la funzione precedente, permetta di invertire una matrice.</p>"},{"location":"material/02_libs/05_scipy/exercises/#soluzione-s112","title":"Soluzione S11.2","text":"<p>Ecco una possibile soluzione:</p> <pre><code>from scipy import linalg\nimport warnings\nclass InversoreMatrici():\ndef __init__(self, mat):\nself.mat = mat\nself.invertibilita = mat\n@property\ndef mat(self):\nreturn self.__mat\n@mat.setter\ndef mat(self, value):\nif value is None:\nraise ValueError('La matrice non pu\u00f2 essere nulla')\nself.__mat = value\n@property\ndef inv(self):\nreturn self.__inv\n@inv.setter\ndef inv(self, value):\nif value is None:\nraise ValueError(\"L'inversa non pu\u00f2 essere nulla\")\nself.__inv = value\n@property\ndef invertibilita(self):\nreturn self.__invertibilita\n@invertibilita.setter\ndef invertibilita(self, value):\nif value is None:\nraise ValueError(\"La determinazione dell'invertibilit\u00e0 non pu\u00f2 essere nulla\")\nself.__invertibilita = True if linalg.det(value) != 0. else False\ndef inverti(self):\nif self.invertibilita:\nself.inv = linalg.inv(self.mat)\nelse:\nwarnings.warn('La matrice non \u00e8 invertibile')\na = np.array([[1, 2], [2, 5]])\ni = InversoreMatrici(a)\ni.inverti()\ni.inv\n</code></pre>"},{"location":"material/02_libs/05_scipy/lecture/","title":"6 - L'ecosistema SciPy","text":"<p>Ai lettori pi\u00f9 attenti pu\u00f2 apparire evidente come tutte le librerie viste finora facciano parte di una sorta di \"ecosistema\" pensato per permettere un'interazione tra tipi e classi il quanto pi\u00f9 possibile \"semplice\" e coesa.</p> <p>Questo \u00e8 dovuto al fatto che librerie come NumPy, Matplotlib, Pandas e Seaborn fanno tutte parte di un unico ecosistema chiamato SciPy, pensato per dare delle fondamenta comuni su cui costruire l'intera disciplina del calcolo scientifico in Python.</p> <p>Tuttavia, abbiamo omesso una delle librerie fondamentali di questo ecosistema, talmente importante che prende il nome del framework stesso: ovviamente, stiamo parlando della libreria SciPy.</p>"},{"location":"material/02_libs/05_scipy/lecture/#la-libreria-scipy","title":"La libreria SciPy","text":"<p>La libreria SciPy presenta un vastissimo insieme di algoritmi e funzioni matematiche costruite a partire dagli oggetti definiti da NumPy.</p> <p>Al solito, la libreria va installata usando, ad esempio <code>pip</code>:</p> <pre><code>pip install scipy\n</code></pre> <p>In questa giocoforza brevissima introduzione, vedremo alcune delle potenzialit\u00e0 di SciPy, basandoci su un paio di casi d'uso (pi\u00f9 o meno) reali.</p>"},{"location":"material/02_libs/05_scipy/lecture/#validazione-empirica-di-due-distribuzioni","title":"Validazione empirica di due distribuzioni","text":"<p>Proviamo a vedere come viene visualizzato il valore (teorico) assunto da due distribuzioni di probabilit\u00e0 \"classiche\", ovvero la distribuzione uniforme e quella normale.</p> <p>Vediamo come comparare visivamente il valore teorico assunto da due distribuzioni di probabilit\u00e0 \"standard\" (ovvero la uniforme e la normale) e l'istogramma ottenuto a partire da un elevato numero di elementi generati casualmente ma appartenenti a quella distribuzione.</p> <p>In primis, iniziamo importando i moduli <code>norm</code> ed <code>uniform</code> dal package <code>stats</code>, atti a modellare tutte le istruzioni riguardanti le distribuzioni normali ed uniformi:</p> <pre><code>from scipy.stats import norm, uniform\n</code></pre> <p>Generiamo adesso 100 campioni equidistanziati e compresi tra l'1 ed il 99 percentile delle distribuzioni:</p> <pre><code>x_1 = np.linspace(norm.ppf(0.01), norm.ppf(0.99), 100)\nx_2 = np.linspace(uniform.ppf(0.01), uniform.ppf(0.99), 100)\n</code></pre> <p>Stiamo usando la funzione <code>linspace()</code> per generare dei campioni equidistanti tra loro, compresi tra <code>dist.ppf(0.01)</code> e <code>dist.ppf(0.99)</code>. L'oggetto <code>dist</code> pu\u00f2 essere sia <code>norm</code> che <code>uniform</code>, mentre <code>ppf(0.01)</code> rappresenta l'1-percentile della distribuzione (e, analogamente, <code>ppf(0.99)</code> rappresenta il 99-percentile). In parole povere, stiamo generando cento campioni equidistanti tra l'1-percentile ed il 99-percentile della distribuzione <code>dist</code>.</p> <p>Successivamente, utilizziamo la funzione <code>rvs()</code> per generare casualmente un \"gran\" numero di valori che per\u00f2 siano distribuiti secondo le due distribuzioni considerate:</p> <pre><code>r_1 = norm.rvs(size=1000)\nr_2 = uniform.rvs(size=1000)\n</code></pre> <p>A questo punto, possiamo plottare l'istogramma dei valori <code>r_i</code>, e verificare che segua la distribuzione di probabilit\u00e0 <code>pdf(x)</code> per ciascuno dei due tipi di distribuzione. Ricordiamo di inserire il valore <code>density=True</code> per normalizzare l'istogramma.</p> <p>Il risultato dovrebbe essere simile a quello mostrato in figura:</p> <p></p>"},{"location":"material/02_libs/05_scipy/lecture/#calcolo-del-determinante-e-dellinversa","title":"Calcolo del determinante e dell'inversa","text":"<p>SciPy offre anche la possibilit\u00e0 di effettuare calcoli algebrici grazie ad un numero di funzioni molto pi\u00f9 elevato rispetto a quelle presenti in NumPy.</p> <p>Per fare un rapido esempio, vediamo come \u00e8 possibile calcolare il determinante e l'inversa di una matrice.</p> <pre><code>from scipy import linalg\n# ... matrice mat creata sotto forma di array NumPy\n# Determinante\nd = linalg.det(mat)\n# Inversa\ni = linalg.inv(mat)\n</code></pre> <p>Nota</p> <p>E' molto semplice notare come la sintassi richiami quella di NumPy e, in realt\u00e0, anche il funzionamento sia il medesimo, per cui \u00e8 possibile usare indifferentemente entrambe le librerie. Dove SciPy \"spicca\" \u00e8 in tutte quelle funzioni che non sono presenti in NumPy.</p>"},{"location":"material/02_libs/05_scipy/lecture/#filtraggio-di-un-segnale","title":"Filtraggio di un segnale","text":"<p>SciPy ha al suo interno diverse librerie per l'elaborazione dei segnali a diverse dimensionalit\u00e0.</p> <p>Per fare un esempio, proviamo ad utilizzare un filtro di Savitzky-Golay su un array monodimensionale mediante la funzione <code>savgol_filter()</code>.</p> <p>Creiamo un array casuale mediante NumPy:</p> <pre><code>noisy = np.random.normal(0, 1, size=(100,))\n</code></pre> <p>Filtriamo questo segnale usando un filtro di Savitzky-Golay con finestra di lunghezza pari a 7 campioni e mediante un polinomio approssimante di secondo grado:</p> <pre><code>from scipy.signal import savgol_filter\nfiltered = savgol_filter(noisy, 7, 2)\n</code></pre> <p>Creiamo il plot:</p> <pre><code>plt.plot(np.arange(100), noisy, alpha=0.5, label='Segnale originale')\nplt.plot(np.arange(100), filtered, label='Segnale filtrato')\nplt.grid()\nplt.legend()\nplt.show()\n</code></pre> <p>Otterremo un risultato simile a quello mostrato in figura:</p> <p></p>"},{"location":"material/03_ml/01_intro/","title":"1 - Introduzione al machine learning","text":"<p>Il machine learning \u00e8 l'insieme di approcci alla base di alcune tra le pi\u00f9 importanti e diffuse tecnologie odierne. Le sue applicazioni sono molteplici: si va dagli strumenti di traduzione automatica, che tutti utilizziamo pi\u00f9 o meno spesso, ai chatbot, ormai estremamente evoluti, passando per sistemi di videosorveglianza e riconoscimento facciale, e tanto altro ancora. In altre parole, la pervasiva diffusione del machine learning ha offerto un'alternativa pi\u00f9 efficace alla risoluzione di problemi che, un tempo, venivano trattati esclusivamente mediante complessi modelli di equazioni matematiche.</p> <p>Volendo riassumere quello che \u00e8 il \"flusso di lavoro\" di un algoritmo di machine learning, possiamo dire che questo \u00e8 il procedimento che permette ad un modello di imparare a fare predizioni significative a partire da un insieme di dati. In altri termini:</p> <p>Modello di machine learning</p> <p>Un modello di machine learning rappresenta la relazione matematica intercorrente tra i dati che il sistema derivante utilizza per effettuare predizioni.</p> <p>Come esempio, immaginiamo di creare un software che effettui la predizione del quantitativo di pioggia che cadr\u00e0 in una zona. Per farlo, possiamo usare due approcci:</p> <ul> <li>nell'approccio tradizionale, creeremo una rappresentazione fisica dell'atmosfera e della superficie terrestre, risolvendo equazioni estremamente complesse come le Navier-Stokes;</li> <li>nell'approccio basato sul machine learning, daremo ad un modello un quantitativo adeguato (e, molto spesso, enorme) di dati riguardanti le condizioni meteorologiche, fino a che il modello stesso non apprender\u00e0 le relazioni sottostanti i diversi pattern di feature meteorologiche che permettono di produrre diversi quantitativi di pioggia.</li> </ul> <p>In entrambi i casi, una volta completata l'implementazione (per l'approccio tradizionale) o l'addestramento (per l'approccio basato su machine learning) passeremo al software i dati sulla condizione meteorologica attuale, per poi predire il quantitativo di pioggia previsto.</p> <p>Perch\u00e9, dunque, preferire il machine learning agli approcci tradizionali? Per rispondere a questa domanda, ci viene in aiuto il principio di indeterminazione discendente dal paradosso del demone di Laplace, il quale afferma che l'unico modo di predire lo stato di un sistema chiuso, pur conoscendone ogni dettaglio, \u00e8 quello di essere esterno al sistema stesso. Ci\u00f2 comporta che, per complesso che sia, nessun modello a scatola trasparente \u00e8 in grado di modellare con precisione la realt\u00e0: di conseguenza, i modelli fisici sono giocoforza limitati sia dal numero di variabili da considerare, sia dalla natura dell'universo fisico.</p> <p>Un modello di machine learning, ovviamente, \u00e8 soggetto agli stessi vincoli dei modelli tradizionali. Tuttavia, il modello non deriva le sue predizioni da complesse equazioni matematiche, bens\u00ec deriva la relazione dai dati sotto osservazione. Di conseguenza, con un numero adeguato di dati, e rispettando le opportune ipotesi di funzionamento, un modello di machine learning questo offre una rappresentazione della realt\u00e0 pi\u00f9 \"vera\" di quella offerta da qualsiasi modello classico.</p> <p>Statistica e machine learning</p> <p>Potremmo essere tentati di mettere sullo stesso piano la statistica ed il machine learning. Infatti, pensandoci bene, entrambi gli approcci possono essere usati per fare inferenza (ovvero, creare un modello matematico del processo di generazione dei dati che formalizzi il comportamento del sistema) e predizione (ovvero, predire il comportamento futuro del sistema). Tuttavia, la statistica \u00e8 maggiormente incentrata sull'inferire dettagli sulla distribuzione cui sottende una popolazione, mentre il machine learning si concentra sull'aspetto predittivo. Per approfondire, date un'occhiata a questo articolo.</p>"},{"location":"material/03_ml/01_intro/#tipi-di-sistemi-di-machine-learning","title":"Tipi di sistemi di machine learning","text":"<p>I sistemi di machine learning ricadono in tre diverse categorie, distinte sulla base di come \"apprendono\" a fare determinate predizioni.</p>"},{"location":"material/03_ml/01_intro/#sistemi-ad-apprendimento-supervisionato","title":"Sistemi ad apprendimento supervisionato","text":"<p>I sistemi ad apprendimento supervisionato (supervised learning) effettuano una predizione dopo aver appreso le relazioni intercorrenti tra un numero pi\u00f9 o meno grande di dati ed i corrispondenti valori da predire. Per intenderci, un sistema di questo tipo \u00e8 un po' come uno studente di matematica che, dopo aver appreso i metodi per la risoluzione di un problema di analisi mediante la risoluzione di un gran numero degli stessi, si prepara a sostenere l'esame.</p> <p>Perch\u00e9 supervisionato?</p> <p>L'appellativo supervisionato deriva dal fatto che \u00e8 (di solito) un esperto di dominio a fornire al sistema i dati con i risultati corretti.</p> <p>I pi\u00f9 importanti approcci all'apprendimento supervisionato sono la regressione e la classificazione.</p>"},{"location":"material/03_ml/01_intro/#modelli-di-regressione","title":"Modelli di regressione","text":"<p>Un modello di regressione predice un valore numerico. Ad esempio, un modello meteorologico di regressione potrebbe predire il quantitativo di pioggia in millimetri, mentre un altro modello di regressione potrebbe valutare l'andamento dei prezzi delle propriet\u00e0 immobiliari sulla base di dati come i metri quadri, la posizione e le caratteristiche della casa, nonch\u00e9 la situazione attuale dei mercati finanziario ed immobiliare.</p>"},{"location":"material/03_ml/01_intro/#modelli-di-classificazione","title":"Modelli di classificazione","text":"<p>A differenza dei modelli di regressione, il cui output \u00e8 rappresentato da un numero, i modelli di classificazione restituiscono in uscita un valore che stabilisce la possibilit\u00e0 che un certo campione appartenga ad una data categoria. Ad esempio, un modello di classificazione potrebbe essere usato per predire se un'email \u00e8 un messaggio di spam, o se una foto contiene invece un gatto o un cane.</p> <p>Esistono due macrocategorie di modelli di classificazione, ovvero quelli binari e quelli multiclasse. In particolare, i modelli di classificazione binaria distinguono esclusivamente tra due valori: ad esempio, un modello di classificazione delle email potrebbe indicare se il messaggio \u00e8 di spam o meno. I modelli di classificazione multiclasse invece riescono a distinguere tra pi\u00f9 classi: ad esempio, il nostro modello di riconoscimento delle foto potrebbe riconoscere oggetti di \"classe\" gatto, cane, gallina ed oca.</p>"},{"location":"material/03_ml/01_intro/#sistemi-ad-apprendimento-non-supervisionato","title":"Sistemi ad apprendimento non supervisionato","text":"<p>I sistemi di apprendimento non supervisionato compiono delle predizioni a partire da dati che non contengono alcuna informazione sulla classe di appartenenza o sul valore di regressione. In pratica, i modelli non supervisionati hanno il compito di identificare pattern significativi direttamente nei dati, senza alcun \"indizio\" a priori, ma limitandosi ad inferire automaticamente le proprie regole.</p> <p>Algoritmi comunemente utilizzati in tal senso sono quelli di clustering, nei quali il modello individua come i dati vanno a \"disporsi\" utilizzando delle regole basate su distanze o capacit\u00e0 di \"agglomerarsi\".</p> <p>Il clustering differisce dagli algoritmi supervisionati, ed in particolare dalla classificazione, principalmente perch\u00e9 le categorie non sono definite a priori da un esperto di dominio. Ad esempio, un algoritmo di clustering potrebbe raggruppare i campioni in un dataset meteo sulla base esclusivamente delle temperature, rivelando delle suddivisioni che definiscono le diverse stagioni, oppure ancora gli orari del giorno. Sar\u00e0 poi nostro compito \"provare\" a dare un nome a questi cluster sulla base della nostra interpretazione del dataset.</p>"},{"location":"material/03_ml/01_intro/#sistemi-di-reinforcement-learning","title":"Sistemi di reinforcement learning","text":"<p>I sistemi di reinforcement learning effettuano delle predizioni a partire da ricompense o penalit\u00e0 basate sulle azioni effettuate da un agente all'interno di un ambiente. Sulla base di queste osservazioni, il sistema di reinforcement learning genera una policy che definisce la strategia migliore per raggiungere lo scopo prefissato.</p> <p>Le applicazioni dei sistemi di questo tipo sono varie, e spaziano dall'addestramento dei robot per svolgere task anche complessi, alla creazione di programmi come Alpha Go che sfidino (e battano) gli umani al gioco del Go.</p>"},{"location":"material/03_ml/02_framing/","title":"2 - Definizione del problema","text":"<p>La definizione di un problema \u00e8, come prevedibile, il primo passo per la sua risoluzione. Pensiamoci un attimo: se non abbiamo una chiara idea del problema da affrontare, come possiamo pensare di risolverlo?</p> <p>Il primo step per affrontare il problema \u00e8 quindi analizzarlo, isolando gli elementi essenziali da utilizzare nella sua risoluzione: andr\u00e0 fatto uno studio di fattibilit\u00e0, determinando se il problema \u00e8 risolvibile o meno; saranno poi forniti un chiaro insieme di obiettivi, assieme ai criteri ed ai vincoli da rispettare nella risoluzione. Approfondiamo questi aspetti.</p>"},{"location":"material/03_ml/02_framing/#analisi-del-problema","title":"Analisi del problema","text":"<p>Partiamo analizzando il problema, definendo quindi sia i dati in ingresso, sia quello che vogliamo ottenere a valle della risoluzione. Facciamo un paio di esempi concreti:</p> <ul> <li>Predittore di precipitazioni: il nostro primo problema prevede la predizione delle precipitazioni orarie. In questo caso, l'obiettivo \u00e8 quello di creare un software/hardware che, data la collezione storica delle precipitazioni, sia in grado di predire l'entit\u00e0 delle stesse, a partire dalla zona e dal periodo dell'anno, con un buon grado di confidenza.</li> <li>Spam detector: il nostro secondo problema ci chiede di capire se una mail \u00e8 di spam. L'obiettivo sar\u00e0 quindi la creazione di un software che, una volta ricevuta una mail, sia in grado di estrapolarne le informazioni che permettano di classificarla come legittima (o meno).</li> </ul> <p>Una possibile schematizzazione \u00e8 nella seguente tabella.</p> Applicazione Obiettivo del problema Output atteso Input Previsioni meteo Calcolare le precipitazioni orarie in una determinata zona Predizione delle precipitazione orarie Storico delle precipitazioni, localit\u00e0, situazione attuale Spam detector Individuare lo spam Alert per un possibile spam Mail sotto analisi, esempi di mail di spam e legittime <p>Una volta individuati obiettivo, input ed output, dovremo verificare che il problema sia risolvibile mediante un algoritmo di machine learning. In particolare, dovremo verificare la presenza di un'adeguata quantit\u00e0 di dati rappresentativi del fenomeno osservato, e decidere quale approccio utilizzare tra classificazione, regressione e clustering. In questa nostra analisi, inoltre, dovremo tenere conto del cosiddetto rasoio di Occam: infatti, alle volte, potrebbe non essere necessario utilizzare un algoritmo di machine learning per risolvere il problema sotto analisi.</p> <p>Machine learning? No, grazie!</p> <p>Ad eempio, nonostante un semplice sistema massa - molla - smorzatore possa essere modellato tramite il machine learning, \u00e8 decisamente pi\u00f9 produttivo usare delle semplici relazioni fisiche.</p> <p>Una volta analizzato il problema, e verificata la necessit\u00e0 (e possibilit\u00e0) di usare il machine learning, dovremo passare alla fase successiva, che prevede l'analisi e lo studio dei dati a nostra disposizione.</p>"},{"location":"material/03_ml/02_framing/#comprensione-dei-dati","title":"Comprensione dei dati","text":"<p>La disponibilit\u00e0 di un'adeguata quantit\u00e0 di dati caratterizzanti il fenomeno sotto analisi sono alla base del corretto funzionamento degli algoritmi di machine learning. Per effettuare delle predizioni efficaci, infatti, abbiamo bisogno di usare dati di quantit\u00e0 e qualit\u00e0 adeguate, in grado quindi di garantire un elevato potere predittivo. In particolare, i nostri dati dovranno essere:</p> <ul> <li>abbondanti: pi\u00f9 esempi rilevanti abbiamo a disposizione, maggiori saranno gli aspetti che potremo caratterizzare e, di conseguenza, migliore sar\u00e0 il potere risolutivo del nostro modello;</li> <li>consistenti: raccogliere dati usando criteri e strumenti ben determinati e coerenti permetter\u00e0 una migliore campagna di acquisizione. Ad esempio, il modello meteorologico ottenuto usando dati raccolti ogni giorno per cento anni sar\u00e0 pi\u00f9 preciso di quello ottenuto raccogliendo dati una volta l'anno per lo stesso periodo di tempo;</li> <li>affidabili: la sorgente dei nostri dati dovr\u00e0 essere affidabile. Ad esempio, l'igrometro ed il barometro dovranno essere ben tarati ed accessibili, mentre l'insieme di email usate per caratterizzare lo spam dovr\u00e0 essere acquisita da utenti verificati;</li> <li>disponibili: dovremo verificare che non vi siano parti del nostro dataset completamente omesse e, qualora queste siano presenti, che non riguardino aspetti fondamentali e non trascurabili del fenomeno sotto analisi. Ad esempio, un dataset nel quale i valori di temperatura, umidit\u00e0 e pressione sono presi soltanto nei giorni soleggiati avr\u00e0 ben poca utilit\u00e0 nella predizione delle precipitazioni;</li> <li>corretti: i dati andrebbero verificati in termini sia di valori delle feature, che potrebbero essere errati a causa di starature o malfunzionamenti dei sensori, oppure ancora in caso di perdita di dettagli del testo analizzato, sia di label assegnate. In quest'ultimo caso, infatti, un esperto di dominio potrebbe erroneamente contrassegnare come spam una mail legittima, o viceversa, e ci\u00f2 andrebbe ovviamente ad inficiare le performance del nostro modello;</li> <li>rappresentativi: il dataset dovrebbe descrivere in maniera completa il fenomeno sottostante, riflettendone accuratamente aspetti e caratteristiche. Utilizzare un dataset non rappresentativo inficier\u00e0 negativamente le performance predittive del modello.</li> </ul>"},{"location":"material/03_ml/02_framing/#scelta-il-modello","title":"Scelta il modello","text":"<p>L'ultimo step \u00e8 la scelta del tipo di modello da utilizzare, valutando ad esempio tra classificatore, regressore ed algoritmo di clustering.</p> <p>Per la nostra applicazione meteo, ad esempio, predire il quantitativo di pioggia che cadr\u00e0 in un determinato luogo \u00e8 un chiaro problema di regressione, nel senso che date \\(n\\) variabili indipendenti cercheremo di predire una variabile dipendente in uscita.</p> <p>Regressione univariata e multivariata</p> <p>In questo caso, la regressione si dice univariata a causa del fatto che si sta predicendo un'unica variabile dipendente. Se provassimo a predire (ad esempio) anche la temperatura, avremmo a che fare con una regressione multivariata.</p> <p>Nel caso dell'applicazione mail, dato che stiamo cercando di valutare se un messaggio \u00e8 classificabile o meno come spam, avremo a che fare con un problema di classificazione binaria.</p> <p>Una volta determinato il tipo di problema, dovremo scegliere l'algoritmo da utilizzare sulla base dei dati, oltre che la metrica con la quale valutare i risultati ottenuti (in accordo al modello scelto). In particolare, la metrica, ed il valore da essa assunto, dipendono strettamente dall'ambito applicativo: se, ad esempio, un errore del \\(10\\%\\) potrebbe non essere estremamente importante nell'applicazione mail, questo diventerebbe estremamente rilevante (e potenzialmente pericoloso) nella stima dei millimetri di pioggia che cadranno in una certa zona.</p>"},{"location":"material/03_ml/03_data_prep/","title":"3 - Preparazione dei dati","text":"<p>Nella lezione precedente abbiamo evidenziato come uno dei passi fondamentali nella definizione di un algoritmo di machine learning sia la definizione dei dati sui quali il modello deve essere addestrato. Infatti, per ottenere delle buone predizioni, dovremo opportunamente costruire un dataset; questa operazione avviene in due step, ovvero campionamento e preparazione dei dati.</p>"},{"location":"material/03_ml/03_data_prep/#campionamento-del-dataset","title":"Campionamento del dataset","text":"<p>Il primo problema da affrontare \u00e8 quello relativo al campionamento, ovvero alla raccolta dei dati che andranno a comporre il nostro dataset. In particolare, dovremo tenere conto di due aspetti, ovvero il numero dei dati e la loro qualit\u00e0.</p>"},{"location":"material/03_ml/03_data_prep/#dimensione-del-dataset","title":"Dimensione del dataset","text":"<p>Il primo aspetto di cui tenere conto riguarda il numero dei dati da raccogliere, che influenza direttamente la dimensione del dataset. In tal senso, non esiste una regola vera e propria per deteterminare il quantitativo di dati sufficiente ad addestrare un modello in modo adeguato; in generale, tuttavia, potremo dire che questa quantit\u00e0 deve essere almeno un ordine di grandezza superiore rispetto al numero dei parametri utilizzati dal modello. A scopo puramente esemplificativo, usare una rete neurale con \\(100\\) neuroni implicher\u00e0 la presenza di almeno \\(100\\) pesi e \\(100\\) bias, per cui dovremo avere indicativamente almeno \\(2000\\) campioni a disposizione.</p>"},{"location":"material/03_ml/03_data_prep/#qualita-del-dataset","title":"Qualit\u00e0 del dataset","text":"<p>Parafrasando una vecchia pubblicit\u00e0 degli anni '90, la quantit\u00e0 (potenza) \u00e8 niente senza qualit\u00e0 (controllo). In altri termini, avere a disposizione grandi quantit\u00e0 di dati non basta se questi non sono anche significativi nella caratterizzazione del fenomeno sotto osservazione.</p> <p>Per comprendere questo concetto, cerchiamo di usare un approccio empirico. Riprendiamo il nostro modello di predizione delle precipitazioni, ed immaginiamo di doverlo addestrare scegliendo tra due dataset. In particolare:</p> <ul> <li>il dataset A contiene un dato relativo ai valori di temperatura e pressione campionato ogni \\(15\\) minuti negli ultimi \\(100\\) anni esclusivamente per il mese di luglio;</li> <li>il dataset B contiene un unico dato giornaliero per i valori di temperatura e pressione per ciascun giorno degli ultimi \\(100\\) anni.</li> </ul> <p>Possiamo quindi facilmente verificare che il dataset A contiene \\(297.600\\) campioni (pari a \\(4 \\cdot 24 \\cdot 31 \\cdot 100\\), ovvero il numero di campioni per ora moltiplicati per il numero di ore e per il numero di giorni presenti a luglio), mentre il dataset B contiene solo \\(365 \\cdot 100 = 36.500\\) campioni.</p> <p>Tuttavia, la qualit\u00e0 del dataset B risulta essere migliore rispetto a quella del dataset A: infatti, nonostante quest'ultimo abbia quasi dieci volte pi\u00f9 campioni del primo, non potr\u00e0 essere utilizzato per stimare le precipitazioni in mesi differenti da luglio.</p>"},{"location":"material/03_ml/03_data_prep/#preparazione-dei-dati","title":"Preparazione dei dati","text":"<p>Una volta acquisito in maniera appropriata il dataset, dovremo preparare i dati in esso contenuto. </p> <p>Anonimizzazione dei dati</p> <p>Lo step \"zero\" della preparazione del dataset \u00e8 quello legato all'anonimizzazione dei dati, che assume fondamentale importanza in taluni contesti, come ad esempio quello medico o finanziario. Presupporremo, nel prosieguo, che questo passo venga effettuato di default.</p> <p>Questa preparazione prevede gli step riassunti nel prosieguo.</p>"},{"location":"material/03_ml/03_data_prep/#step-1-data-cleaning","title":"Step 1: Data cleaning","text":"<p>Abbiamo visto come la qualit\u00e0 ed affidabilit\u00e0 del dataset siano essenziali per garantire adeguate performance del modello addestrato. In tal senso, \u00e8 necessario determinare diversi fattori, ad esempio:</p> <ul> <li>presenza di errori nel labelling: il lavoro svolto dall'esperto di dominio nel labeling pu\u00f2, alle volte, essere subottimale, e presentare errori grossolani ed evidenti. In questo caso, potrebbe essere necessario effettuare un'ulteriore procedura di etichettatura;</li> <li>presenza di rumore: \u00e8 importante valutare se i dati sono affetti da rumore o da trend evidenti. Per esempio, potremmo notare che tutte le letture di un sensore sono affette da un certo punto in avanti da un certo offset, legato magari ad una staratura dello stesso;</li> <li>assenza di dati: immaginando che un sensore risulti danneggiato, potrebbe verificarsi la situazione per cui le letture per lo stesso non siano disponibili da un certo istante in avanti. Questo fenomeno, che abbiamo gi\u00e0 analizzato quando abbiamo parlato della manipolazione dei DataFrame in Pandas, va adeguatamente affrontato;</li> <li>valori contrastanti o duplicati: data la dinamicit\u00e0 delle campagne di acquisizione, specialmente se lunghe, potrebbero esserci delle incoerenze nei dati campionati. Ad esempio, lungo l'arco della campagna, un sensore di temperatura non funzionante potrebbe essere stato sostituito con un altro che, per\u00f2, a differenza del primo effettua le letture in gradi Kelvin.</li> </ul> <p>Se si presenta una di queste occorrenza, \u00e8 necessario valutare una strategia di data cleaning. Ne abbiamo brevemente parlato in precedenza analizzando le funzioni <code>dropna()</code> e <code>fillna()</code>; ne vedremo delle altre nel proseguo.</p>"},{"location":"material/03_ml/03_data_prep/#step-2-bilanciamento-del-dataset","title":"Step 2: Bilanciamento del dataset","text":"<p>Quando si affronta un problema di classificazione, esiste la (tutt'altro che remota) possibilit\u00e0 che il dataset acquisito presenti diverse proporzioni nel raggruppamento delle classi. In altre parole, supponendo la presenza di due classi \\(X\\) ed \\(Y\\), potremmo avere il \\(70\\%\\) di campioni appartenenti alla classe \\(X\\), ed il restante \\(30\\%\\) appartenenti alla classe \\(Y\\).</p> <p>Ci\u00f2 comporta che avremo una classe maggioritaria, ovvero \\(X\\), che avr\u00e0 un maggior numero di campioni rispetto alla minoritaria \\(Y\\), la quale, prevedibilmente, sar\u00e0 rappresentata da un numero limitato di campioni. Un dataset in cui si verifica questo fenomeno \u00e8 detto sbilanciato.</p> <p>Possiamo quantificare, in maniera approssimativa, l'entit\u00e0 dello sbilanciamento del dataset, rifacendoci alla seguente tabella.</p> Grado di sbilanciamento \\(\\%\\) di campioni di classi minoritarie Leggero 20-40 \\(\\%\\) del datset Moderato 1-20 \\(\\%\\) del dataset Estremo &lt; 1 \\(\\%\\) del dataset <p>Per comprendere a fondo quali siano gli effetti dello sbilanciamento del dataset, possiamo tornare al nostro spam detector. Per addestrarlo, usiamo un dataset di qeusto tipo:</p> Mail non spam Mail spam Numero di mail \\(5\\) \\(995\\) Percentuale \\(0.5 \\%\\) \\(99.5 \\%\\) <p>Notiamo subito che abbiamo un numero molto limitato di mail di spam. Di conseguenza, l'addestramento avverr\u00e0 per la maggior parte su mail \"normali\"; inoltre, un numero cos\u00ec esiguo di mail di spam non potr\u00e0 descrivere adeguatamente tutti i casi in cui ci si trova di fronte a questo fenomeno.</p>"},{"location":"material/03_ml/03_data_prep/#data-balancing","title":"Data balancing","text":"<p>Una maniera efficace per trattare situazioni di questo tipo \u00e8 quella di adottare una tecnica di data balancing (ovvero, bilanciamento dei dati). Ne esistono diverse, pi\u00f9 o meno efficaci; tra queste, la pi\u00f9 semplice riguarda la rimozione di un certo numero di campioni della classe maggioritaria (downsampling), dando agli esempi sottocampionati un peso maggiore nell'addestramento (upweighting).</p> <p>Facciamo un esempio. Scegliendo di mantenere soltanto il \\(10 \\%\\) delle mail non-spam, avremmo circa \\(99\\) campioni. Ci\u00f2 porter\u00e0 il rapporto tra le mail di spam e quelle non di spam a circa il \\(5 \\%\\), passando da una situazione di sbilanciamento estremo ad una di sbilanciamento moderato.</p> <p>A valle di questa operazione, dovremo dare maggior peso ai campioni delle mail non-spam, usando un fattore tendenzialmente pari a quello che abbiamo usato in fase di downsampling. Nella pratica, ogni mail non-spam avr\u00e0 un peso dieci volte superiore a quello che avrebbe avuto se si fosse utilizzato il dataset iniziale.</p>"},{"location":"material/03_ml/03_data_prep/#trasformazione-dei-dati","title":"Trasformazione dei dati","text":"<p>Il passo successivo nella preparazione dei dati \u00e8 quello di trasformare un insieme (o la totalit\u00e0) dei valori. Ci\u00f2 avviene principalmente per due motivi.</p> <p>Il primo \u00e8 legato alla necessit\u00e0 di trasformazioni obbligatorie volte a garantire la compatibilit\u00e0 dei dati. Alcuni esempi:</p> <ul> <li>conversione di feature non numeriche in numeriche: in pratica, non possiamo effettuare operazioni sensate tra interi e stringhe, per cui dovremmo trovarci ad individuare un modo per permettere tale confronto;</li> <li>ridimensionamento degli input ad una dimensione fissa: alcuni modelli, come ad esempio le reti neurali, prevedono un numero fisso di nodi di input, per cui i dati in ingresso devono avere sempre la stessa dimensione.</li> </ul> <p>Il secondo motivo \u00e8 legato a delle trasformazioni opzionali che ottimizzino i risultati ottenuti durante l'addestramento. Ad esempio, potremmo dover portarli tutti i valori numerici all'interno di una stessa scala di valori (rescaling), oppure trasformarli in modo tale che ricordino una distribuzione normale (normalizzazione).</p> <p>Per comprendere al meglio il motivo alla base di questa necessit\u00e0, immaginiamo di avere un dataset che comprende due feature: l'et\u00e0 (che assume valori da \\(0\\) a \\(100\\)) e reddito annuo (che supponiamo assuma valori da \\(10.000\\) a \\(100.000\\) \u20ac). Dando in pasto queste feature ad algoritmi che le combinano in qualche modo, l'et\u00e0 diventer\u00e0 presto trascurabile rispetto al reddito, dato che quest'ultimo risulta essere di due o tre ordini di grandezza superiore. Di conseguenza, il modello trascurer\u00e0 l'et\u00e0 in fase di analisi, utilizzando esclusivamente lo stipendio.</p> <p>Da questa considerazione appare evidente come sia necessario portare tutti i dati ad una \"base comune\" prima di effettuare un addestramento. Per farlo, abbiamo a disposizione quattro tipi di trasformazione.</p>"},{"location":"material/03_ml/03_data_prep/#scaling","title":"Scaling","text":"<p>Lo scaling prevede la conversione dei valori assunti da una feature in un range che va di solito tra \\([0, 1]\\) o \\([-1, 1]\\). La formula dello scaling \u00e8 la seguente:</p> \\[ y = \\frac{(x - x_{min})}{(x_{max} - x_{min})} \\]"},{"location":"material/03_ml/03_data_prep/#clipping","title":"Clipping","text":"<p>La tecnica del clipping viene usata quando il dataset contiene degli outlier, ovvero alcuni campioni che divergono notevolmente dalle caratteristiche statistiche del resto dei dati. In questo caso, potremmo limitarci a rimuovere completamente tali valori mediante soglie statistiche, come i range interquartili in caso di distribuzione parametrica, o i classici \\(3 \\sigma\\) in caso di distribuzione normale.</p>"},{"location":"material/03_ml/03_data_prep/#trasformazione-logaritmica","title":"Trasformazione logaritmica","text":"<p>Un'altra possibilit\u00e0 \u00e8 quella di convertire i nostri valori in scala logaritmica, comprimendo un range ampio in uno pi\u00f9 piccolo usando la funzione logaritmo:</p> \\[ y = Log(x) \\]"},{"location":"material/03_ml/03_data_prep/#z-score","title":"Z-score","text":"<p>Un ultimo tipo di trasformazione prevede l'uso dello z-score, che prevede una riformulazione dei valori assunti dalla feature per fare in modo che questi aderiscano ad una distribuzione a media nulla e deviazione tandard unitaria. Per calcolarlo, si usa la seguente formula:</p> \\[ y = \\frac{x - \\mu}{\\sigma} \\] <p>dove \\(\\mu\\) \u00e8 la media della distribuzione dei nostri dati, mentre \\(\\sigma\\) ne \u00e8 chiaramente la varianza.</p>"},{"location":"material/03_ml/03_data_prep/#trasformazione-dei-dati-categorici","title":"Trasformazione dei dati categorici","text":"<p>Alcune delle nostre feature possono assumere esclusivamente valori discreti. Ad esempio, la feature \"localit\u00e0\" associato alle precipitazioni potrebbe riportare il CAP, mentre la feature \"spam\" nel nostro dataset di email potrebbe avere al suo interno un booleano. Queste feature sono dette categoriche, ed i valori ad esse associate possono essere sia stringhe sia numeri.</p> <p>Le feature categoriche di tipo numerico</p> <p>Spesso, dobbiamo trattare feature categoriche che contengono valori numerici. Consideriamo ad esempio il CAP: rappresentandolo come un tipo numerico, il nostro modello potrebbe interpretare la distanza tra Bari (\\(70126\\)) e Taranto (\\(74121\\)) come pari a \\(3.995\\), il che non avrebbe ovviamente senso.</p> <p>Le feature categoriche devono per\u00f2 essere convertite in valori numerici, mantenendo contestualmente il riferimento al significato originario. Immaginiamo ad esempio di avere a che fare con una feature categorica che descrive il giorno della settimana. Il modo pi\u00f9 semplice per passare da una rappresentazione puramente categorica ad una numerica \u00e8 quella di usare un numero:</p> Giorno Rappresentazione numerica Luned\u00ec 1 Marted\u00ec 2 Mercoled\u00ec 3 Gioved\u00ec 4 Venerd\u00ec 5 Sabato 6 Domenica 7 <p>In questa maniera creeremo un dizionario, nel quale potremo accedere ad una chiave (la rappresentazione numerica) che rappresenter\u00e0 un determinato valore (il giorno).</p> <p>Sulle feature categoriche trasformate</p> <p>A valle di questa trasformazione, la differenza aritmetica tra domenica e sabato continua ad avere un senso alquanto limitato, e comunque relativo ad un generico concetto di distanza.</p> <p>Un altro modo di rappresentare le feature categoriche \u00e8 mediante una rappresentazione sparsa, detta anche one-hot encoding, nella quale ogni valore \u00e8 rappresentato da un vettore \\(V\\) di lunghezza \\(m\\), con \\(m\\) numero di categorie possibili. In questo caso, tutti i valori di \\(V\\) saranno pari a \\(0\\), tranne quello rappresentativo del valore attualmente assunto dalla feature, che sar\u00e0 pari ad \\(1\\). Ad esempio, la rappresentazione sparsa del luned\u00ec \u00e8 data da:</p> <pre><code>lunedi = np.array([1 0 0 0 0 0 0])\n</code></pre> <p>mentre quella del gioved\u00ec:</p> <pre><code>giovedi = np.array([0 0 0 1 0 0 0])\n</code></pre>"},{"location":"material/03_ml/03_data_prep/#dati-di-training-test-e-validazione","title":"Dati di training, test e validazione","text":"<p>L'ultimo passo nella preparazione del dataset \u00e8 quello della suddivisione dei dati. In particolare, si destinano un certo quantitativo di dati per l'addestramento del modello, delegando la restante parte alla validazione dei risultati ottenuti; ci\u00f2 \u00e8 legato alla volont\u00e0 di verificare la capacit\u00e0 di generalizzazione del modello, ovvero a quanto \u00e8 in grado di \"funzionare\" il nostro algoritmo in caso di analisi di dati su cui non \u00e8 stato addestrato.</p> <p>Un rapporto molto usato in tal senso \u00e8 quello che prevede che il \\(60\\%\\) dei dati sia usato per l'addestramento, un altro \\(20\\%\\) per il test del modello, ed il restante \\(20\\%\\) per la validazione dei risultati ottenuti.</p>"},{"location":"material/03_ml/04_lin_reg/lecture/","title":"4 - La regressione lineare","text":"<p>Nelle lezioni precedenti abbiamo visto come esistano fondamentalmente due tipi di tecniche di apprendimento supervisionato, ovvero regressione e classificazione. In questa lezione, approfondiremo il caso pi\u00f9 semplice di regressione, ovvero quello lineare.</p>"},{"location":"material/03_ml/04_lin_reg/lecture/#cosa-e-la-regressione","title":"Cosa \u00e8 la regressione?","text":"<p>Non occorre essere esperti di meteorologia per sapere che i millimetri di pioggia caduti durante una precipitazione sono correlata a fattori quali temperatura, venti, umidit\u00e0, posizione geografica, ed altri ancora. Immaginiamo quindi di avere un insieme di dati che, al loro interno, descrivano la condizione meteorologica ad un dato istante di tempo (supponiamo, per semplicit\u00e0, giornaliero), oltre che i millimetri di pioggia caduti nello stesso periodo. Supponiamo di effettuare un'analisi esplorativa dei dati, i cui risultati sono (parzialmente) riportati in figura 1.</p> <p> </p> Figura 1 - Relazione tra millimetri di pioggia (sulle ordinate) e temperatura in gradi (sulle ascisse). <p>La nostra analisi esplorativa ci porta subito ad intuire l'esistenza di una relazione tra la quantit\u00e0 di pioggia caduta e la temperatura: in particolare, a valor di temperatura pi\u00f9 elevati corrisponde una minore quantit\u00e0 di pioggia, e viceversa.</p> <p>Proviamo adesso a tracciare la retta ai minimi quadrati, ovvero quella che minimizza la somma quadratica dello scarto tra il valore \\((\\hat{x}_i, \\hat{y}_i)\\) da essa \"attraversato\" ed il valore \\((x_i, y_i)\\) \"vero\" associato ai dati, per ciascun punto \\(i\\) nell'insieme considerato. Il risultato \u00e8 mostrato in figura 2.</p> <p> </p> Figura 2 - Retta ai minimi quadrati relativa al rapporto tra precipitazioni e gradi."},{"location":"material/03_ml/04_lin_reg/lecture/#rappresentazione-analitica-del-modello","title":"Rappresentazione analitica del modello","text":"<p>Come gi\u00e0 detto, notiamo come i millimetri di pioggia attesi diminuiscano all'aumentare della temperatura, secondo una relazione (pi\u00f9 o meno) lineare, riconducibile ad una forma del tipo:</p> \\[ y = mx + b \\] <p>dove:</p> <ul> <li>\\(y\\) sono i millimetri di pioggia medi caduti nell'arco di tutte le giornate con un dato valore medio di temperatura;</li> <li>\\(x\\) \u00e8 il valore medio di temperatura;</li> <li>\\(m\\) \u00e8 il coefficiente angolare della retta di regressione;</li> <li>\\(b\\) \u00e8 l'incercetta della retta di regressione.</li> </ul> <p>Nota</p> <p>Ovviamente, la retta di regressione non tocca tutti i punti, ma approssima l'andamento di \\(x\\) in funzione di \\(y\\).</p> <p>Possiamo riscrivere l'equazione precedente come segue:</p> \\[ \\hat{y} = b + w_1 x_1 \\] <p>dove:</p> <ul> <li>\\(\\hat{y}\\) \u00e8 l'output predetto dal modello, detto anche variabile dipendente;</li> <li>\\(b\\) \u00e8 il bias, equivalente al concetto analitico di intercetta;</li> <li>\\(w_1\\) \u00e8 il peso della prima feature, equivalente al concetto analitico di coefficiente angolare;</li> <li>\\(x_1\\) \u00e8 il valore di ingresso assunto dalla prima ed unica feature considerata, detta anche variabile indipendente.</li> </ul> <p>Per inferire un nuovo valore di \\(\\hat{y}\\) ci baster\u00e0 quindi cambiare il valore assunto da \\(x_1\\). In pratica, proprio come accade per una retta, se poniamo \\(x_1 = 8\\) (ovvero assumendo un valore di temperatura di 8 gradi), avremo un corrispondente valore per le precipitazioni pari ad \\(\\hat{y} = 25\\) mm, mentre se \\(x_1 = 32\\) il valore predetto per i millimetri di pioggia sar\u00e0 \\(\\hat{y}=0\\).</p> <p>Regressione multivariata</p> <p>In questo caso, abbiamo presupposto che vi sia un'unica variabile indipendente a determinare il valore di un'unica variabile dipendente. Esistono ovviamente casi pi\u00f9 complessi, con diverse variabili dipendenti il cui valore \u00e8 determinato da pi\u00f9 feature secondo formule del tipo \\(b + w_1 x_1 + \\ldots + w_n x_n\\).</p>"},{"location":"material/03_ml/04_lin_reg/lecture/#addestramento-e-funzione-di-costo","title":"Addestramento e funzione di costo","text":"<p>Addestrare un modello significa determinarne i valori ottimali per pesi e bias a partire dai dati che, nel caso della regressione, sono etichettati. Per far questo, i modelli ad apprendimento supervisionato esaminano iterativamente tutti i campioni presenti nel set di addestramento alla ricerca di un modo per minimizzare un costo (o, in inglese, loss) direttamente proporzionale alla differenza intercorrente tra la predizione del modello ed il valore vero. In altri termini, la loss \u00e8 una misura dell'errore delle predizioni effettuate dal modello.</p>"},{"location":"material/03_ml/04_lin_reg/lecture/#interpretazione-grafica-della-funzione-di-costo","title":"Interpretazione grafica della funzione di costo","text":"<p>Nel caso ideale, la loss sarebbe pari a \\(0\\). Ovviamente, nel caso reale, la loss \u00e8 sempre maggiore di questo valore, e sar\u00e0 tanto maggiore quanto pi\u00f9 il valore predetto diverger\u00e0 da quello atteso. Proviamo ad interpretare al meglio questo concetto aiutandoci con la figura 3.</p> <p> </p> Figura 3 - Interpretazione della funzione di costo <p>In particolare, le frecce schematizzano l'entit\u00e0 della differenza intercorrente tra il valore vero \\(y\\) ed il valore predetto \\(\\hat{y}\\). Come evidente, la loss complessiva \u00e8 maggiore nella situazione a sinistra; ci\u00f2 significa che l'addestramento dovr\u00e0 necessariamente prediligere una retta di regressione come quella mostrata a destra.</p>"},{"location":"material/03_ml/04_lin_reg/lecture/#calcolo-della-funzione-di-costo","title":"Calcolo della funzione di costo","text":"<p>Per calcolare la loss complessiva del modello a partire da un dato insieme di campioni dobbiamo utilizzare una funzione di costo, o loss function. Ne esistono molteplici esempi, alcuni dei quali saranno approfonditi nel prosieguo. Tuttavia, uno dei pi\u00f9 semplici \u00e8 dato dall'errore quadratico medio, o mean squared error (MSE), rappresentabile secondo la seguente formula:</p> \\[ MSE = \\frac{1}{N} \\sum_{(x, y) \\in D} (y - \\hat{y})^2 \\] <p>In particolare:</p> <ul> <li>\\((x, y)\\) rappresenta l'insieme di feature \\(x\\) con la corrispondente label \\(y\\);</li> <li>\\(\\hat{y}\\) \u00e8 il valore predetto della label a partire dall'applicazione del modello;</li> <li>\\(D\\) \u00e8 il nostro dataset etichettato;</li> <li>\\(N\\) \u00e8 il numero di campioni prensenti in \\(D\\).</li> </ul> <p>In pratica, l'MSE \u00e8 dato dalla media delle differenze tra il valore predetto dal modello e quello vero calcolata sull'intero dataset. Come prevedibile, l'errore sar\u00e0 tanto pi\u00f9 alto quanto maggiore \u00e8 la distanza complessiva tra le label e le predizioni; nell'esempio visto in figura 3, appare chiaro come l'MSE sia maggiore per la prima approssimazione rispetto alla seconda.</p> <p>Perch\u00e9 quadratico?</p> <p>I pi\u00f9 attenti avranno notato che stiamo utilizzando il quadrato dell'errore. Se non lo facessimo, gli errori \"positivi\" annullerebbero i \"negativi\", il che ovviamente non \u00e8 il nostro obiettivo, in quanto ci interessa soltanto il modulo dello scarto quadratico.</p>"},{"location":"material/03_ml/04_lin_reg/lecture/#addestramento-iterativo","title":"Addestramento iterativo","text":"<p>Gli algoritmi di machine learning sono normalmente addestrati seguendo un approccio iterativo che prevede, al termine di ogni singola iterazione, l'aggiornamento del valore dei pesi, allo scopo di ridurre il costo complessivo associato alle predizioni dell'algoritmo. Possiamo riassumere questo comportamento mediante il seguente schema:</p> <pre><code>flowchart TB\n    A[Dataset] --&gt; B[Feature] &amp; C[Label];\n    B &amp; C --&gt; D[Prediction];\n    D --&gt; E[Loss evaluation];\n    E --&gt; F[Parameters update];\n    F --&gt; D;</code></pre> <p>Nella pratica, alla prima iterazione, il modello stabilisce in maniera casuale i valori dei parametri da utilizzare per la predizione; nel caso della regressione lineare, abbiamo visto come questi siano \\(w_1\\) e \\(b\\). A questo punto, viene calcolato il valore predetto \\(\\hat{y}\\)</p> <p>Nella pratica, ad ogni iterazione, il modello effettua una predizione a partire dai campioni a disposizione. Il risultato viene comparato con la label, ed il costo complessivo calcolato secondo la funzione scelta. I pesi sono quindi aggiornati seguendo una certa regola di ottimizzazione, ed il ciclo si ripete.</p> <p>Quante iterazioni?</p> <p>Le iterazioni non sono infinite: normalmente, si imposta un numero preciso di epoche di training, oppure si aspetta che l'algoritmo arrivi ad una sorta di \"convergenza\", nella quale il valore della loss non decresce ulteriormente.</p> <p>Quanti dati?</p> <p>Come vedremo anche nel seguito, il calcolo della loss non avviene considerando il dataset nella sua interezza, ma soltanto dei sottoinsiemi di dati per ogni iterazione.</p>"},{"location":"material/03_ml/04_lin_reg/lecture/#ottimizzazione-della-funzione-di-costo","title":"Ottimizzazione della funzione di costo","text":"<p>Come gi\u00e0 accennato, l'aggiornamento dei pesi segue una ben precisa regola di ottimizzazione, volta a minimizzare il valore complessivo assunto dal costo. In altre parole, durante l'addestramento, l'algoritmo cerca di trovare quella combinazione di pesi per la quale il costo legato all'approssimazione dei valori predetti ai valori veri \u00e8 minimo.</p> <p>Esistono diversi tipi di algoritmi di ottimizzazione, ma la maggior parte si rif\u00e0 al concetto di discesa del gradiente, schematizzto in figura 4.</p> <p> </p> Figura 4 - La discesa di gradiente <p>In questa sede, daremo un'interpretazione puramente qualitativa dei concetti alla base dell'algoritmo, che andremo poi ad approfondire in un'altra lezione. Per farlo, osserviamo brevemente cosa accade in figura 4, guardando da sinistra verso destra.</p> <p>Per prima cosa, dobbiamo immaginare che la funzione che modella la nostra loss sia una sorta di paraboloide, dotato di un valore minimo (sull'asse delle ordinate) che viene raggiunto in corrispondenza di una determinata combinazione dei pesi (mostrata sull'asse delle ascisse). Nel nostro esempio, presupponiamo un unico peso; tuttavia, nei casi reali, il numero dei pesi \u00e8 molto pi\u00f9 elevato, per cui lo spazio considerato sar\u00e0 \\(n\\) dimensionale, con \\(n\\) numero dei pesi da ottimizzare.</p> <p>L'immagine pi\u00f9 a sinistra rappresenta la situazione iniziale: abbiamo dei pesi nel ramo sinistro del paraboloide e, conseguentemente, l'obiettivo sar\u00e0 quello di spostarci verso il minimo globale assunto dalla funzione (ovvero, verso destra). Per farlo, possiamo utilizzare la derivata o, nel caso di funzioni \\(n\\)-dimensionali, il gradiente della funzione di costo, aggiornando i pesi in maniera che questo assuma, all'iterazione successiva, un valore inferiore. Questo ci porta alla figura centrale, in cui notiamo che il gradiente si muove dal punto rosso a quello blu; a seguito di questo spostamento, dovremo ancora aumentare il valore dei pesi, allo scopo di far diminuire la loss, portandoci quindi nella situazione raffigurata nella figura a destra.</p> <p>In quest'ultima situazione, vedremo che il segno del gradiente sar\u00e0 diventato positivo, in quanto ci troveremo nella parte ascendente del paraboloide. Di conseguenza, la convergenza dell'algoritmo si otterr\u00e0 diminuendo il valore assunto dai pesi.</p> <p>Learning rate</p> <p>Il \"quantitativo\" di cui sono aggiornati i pesi \u00e8 spesso denotato come learning rate. Un learning rate troppo basso porta ad una convergenza molto lenta dell'algoritmo, che potrebbe \"esaurire\" le iterazioni prima di arrivare al minimo della funzione di costo. Un learning rate eccessivamente altro potrebbe invece fare in modo che l'algoritmo \"salti\" da una parte all'altra del minimo, non arrivando neanche in questo caso a convergenza.</p> <p>Minimi locali</p> <p>Il nostro banale esempio presuppone che la funzione di costo non abbia alcun minimo locale. Ci\u00f2 non \u00e8 ovviamente vero, e delle scelte sbagliate in termini di punto di partenza o learning rate potrebbero farci finire all'interno di un minimo locale, impedendoci di arrivare a convergenza.</p>"},{"location":"material/03_ml/04_lin_reg/lecture/#overfitting-e-regolarizzazione","title":"Overfitting e regolarizzazione","text":"<p>Alle volte, accade che il nostro modello sia in grado di arrivare ad una loss estremamente bassa sui dati di training, ma che tuttavia inizia ad aumentare sui dati di validazione, un po' come mostrato in figura 5:</p> <p> </p> Figura 5 - Andamento della funzione di costo in training e validazione <p>Ci\u00f2 pu\u00f2 accadere per diversi motivi, come errori nei parametri di addestramento o dati non ben bilanciati. Ad ogni modo, questo fenomeno prende il nome di overfitting, e comporta che il modello, che si comporta molto bene sui dati di training, non riesca a generalizzare, comportandosi in maniera meno egregia su quelli di validazione. L'overfitting si manifesta all'aumentare delle epoche di training, quando il nostro modello diventa sempre pi\u00f9 \"complesso\", ed apprende sempre meglio a caratterizzare relazioni di complessit\u00e0 crescente intercorrenti tra feature e label.</p> <p>Per arginare il fenomeno dell'overfitting, oltre ad agire sui dati e sui parametri del modello, si inserisce spesso un termine di regolarizzazione, che tende a penalizzare un modello in grado di caratterizzare relazioni eccessivamente complesse. Il termine di regolarizzazione interviene direttamente sul valore trattato dall'ottimizzatore, che non avr\u00e0 pi\u00f9 come unico obiettivo quello di minimizzare la loss, ma quello di minimizzare congiuntamente la loss e la complessit\u00e0 del modello ottenuto.</p> <p>Una funzione di regolarizzazione molto usata \u00e8 la regolarizzazione \\(L_2\\), definita come la somma dei quadrati dei pesi associati alle feature:</p> \\[ L_2 = ||w||_2^2 = w_1^2 + w_2^2 + \\ldots + w_n^2 \\] <p>Minimizzare questo termine significa dare meno \"importanza\" ad alcuni pesi che inficiano la complessit\u00e0 totale del modello. Se, ad esempio, avessimo i seguenti pesi:</p> \\[ \\begin{aligned} &amp; w_1 = 0.1 \\\\ &amp; w_2 = 0.025 \\\\ &amp; w_3 = 0.4 \\\\ &amp; w_4 = 10 \\end{aligned} \\] <p>il termine di regolarizzazione \\(L_2\\) diverrebbe pari a:</p> \\[ L_2 = 0.01 + 0,000625 + 0.16 + 100 \\sim 100.17 \\] <p>E' evidente come la maggior parte del contributo sia data dal quarto peso, per cui risulta essere necessario diminuirne l'influenza nel modello allo scopo di bilanciare l'overfitting.</p>"},{"location":"material/03_ml/04_lin_reg/sgd/","title":"Gradient-Based Optimization","text":"<p>4.3 del libro \"DEEP LEARNING BOOK\"</p> <p>La maggior parte degli algoritmi di deeep learning prevede un qualche tipo di ottimizzazione. Questa si riferisce al compito di minimizzare o massimizzare una funzione \\(f(x)\\) modificando \\(x\\). Normalmente, la maggior parte dei problemi di ottimizzazione sono posti in termini di minimizzazione di \\(f(x)\\).</p> <p>!!!note \"Massimizzare f(x)$     Se il problema \u00e8 posto in termini di minimizzazione, ovviamente, la massimizzazione della funzione pu\u00f2 essere fatta minimizzando \\(-f(x)\\).</p>"},{"location":"material/03_ml/04_lin_reg/sgd/#stochastic-gradient-descent","title":"Stochastic Gradient Descent","text":"<p>5.9 del libro</p>"},{"location":"material/03_ml/05_log_reg/lecture/","title":"5 - La regressione logistica","text":"<p>Nella lezione precedente abbiamo introdotto l'algoritmo di regressione lineare, il cui comito \u00e8 quello di \"tracciare\" la relazione intercorrente tra una serie di variabili indipendenti (le feature) ed una variabile dipendente che, come abbiamo visto, \u00e8 continua e di tipo numerico. La regressione logistica, invece, ed a discapito del nome, \u00e8 il pi\u00f9 semplice dei classificatori, e viene usata quando abbiamo a che fare con variabili di tipo categorico.</p> <p>A scopo di esempio, supponiamo di creare un modello che predica la probabilit\u00e0 che una mail ricevuta da un mittente a noi sconosciuto rappresenti uno spam. Indicheremo questa probabilit\u00e0 come \\(p(mail|unknown)\\).</p> <p>In pratica, se il modello afferma che \\(p(mail|unknown) = 0.05\\), allora, in media, su \\(100\\) mail ricevute da indirizzi sconosciuti, \\(5\\) saranno di spam:</p> \\[ \\begin{align} spam &amp;= p(mail|unknown) \\cdot mail_{rec} \\\\ &amp;= 0.05 * 100 \\\\ &amp;= 5 \\end{align} \\] <p>Questo \u00e8 un esempio di utilizzo della probabilit\u00e0 as is. In molti casi, tuttavia, mapperemo l'output della soluzione su un problema di classificazione binario, nel quale l'obiettivo \u00e8 predire correttamente uno di due possibili label (in questo caso, spam o non spam).</p>"},{"location":"material/03_ml/05_log_reg/lecture/#la-funzione-sigmoidale","title":"La funzione sigmoidale","text":"<p>Ci si potrebbe chiedere come un modello per la regressione logistica sia in grado di asicurarsi che l'uscita ricada sempre nell'intervallo tra \\(0\\) ed \\(1\\). In tal senso, questo \u00e8 assicurato dall'uso della funzione sigmoidale, definita come segue:</p> \\[ y = \\frac{1}{1+e^{-z}} \\] <p>la cui formulazione grafica \u00e8 la seguente:</p> <p> </p> Figura 1 - Interprete Python <p>Nell'espressione precedente, notiamo che:</p> <ul> <li>\\(y\\) \u00e8 l'uscita della regressione logistica;</li> <li>\\(z\\) \u00e8 pari, per un generico modello lineare, a \\(b + w_1 x_1 + \\ldots + w_N z_N\\).</li> </ul>"},{"location":"material/03_ml/05_log_reg/lecture/#funzione-di-costo","title":"Funzione di costo","text":"<p>La funzione di costo per la funzione logistica \u00e8 chiamata log loss, ed \u00e8 espressa come:</p> \\[ LogLoss = \\sum_{(x, y) \\in D} -y log(y') - (1 - y) log (1 - y') \\] <p>dove:</p> <ul> <li>\\((x, y)\\) sono le coppie date da feature e label nel dataset \\(D\\);</li> <li>\\(y\\) \u00e8 la label vera per un dato insieme di feature;</li> <li>\\(y'\\) \u00e8 il valore predetto.</li> </ul>"},{"location":"material/03_ml/06_trees/01_decision_trees/","title":"6.1 - Gli alberi decisionali","text":"<p>Gli alberi decisionali sono una tra le famiglie di modelli maggiormente utilizzate per l'apprendimento supervisionato, e sono in grado di risolvere sia problemi di classificazione, sia di regressione. In particolare, gli alberi decisionali offrono alcuni benefici rispetto ad altri tipi di modello, tra cui:</p> <ul> <li>semplicit\u00e0 di configurazione, grazie alla presenza di un numero limitato di parametri, la cui modifica influenza in maniera abbastanza limitata il risultato finale;</li> <li>gestione di feature di diverso tipo, ovvero sia numeriche, sia categoriche, con l'ovvia conseguenza di richiedere un preprocessing limitato rispetto ad altri modelli;</li> <li>efficienza con dataset di piccole dimensioni.</li> </ul> <p>In pratica, gli alberi decisionali sono spesso in grado di fornire una buona accuratezza, sono semplici da configurare, robusti a rumore e feature mancanti, non richiedono preprocessing, ed i risultati ottenuti sono facilmente interpretabili. </p> <p>Gli alberi decisionali sono molto efficaci quando si usano dei dataset di tipo tabellare, normalmente contenuti in file CSV o tabelle di database, come ad esempio il dataset Titanic. Tuttavia, risultano inadeguati quando il tipo di dato utilizzato non \u00e8 strutturato: in pratica, non possiamo efficacemente utilizzarli su immagini o testo.</p> <p>Un altro punto di forza \u00e8 che un albero decisionale \u00e8 efficace anche su dataset di dimensioni ridotte, ovverosia quelli nei quali il rapporto tra feature e numero di campioni \u00e8 di poco superiore ad uno; si parla, in questo caso, di sample efficiency.</p> <p>Alberi e dati</p> <p>Anche se gli alberi decisionali sono sample efficient, il loro funzionamento risulta comunque migliore nel caso di disponibilit\u00e0 di grosse quantit\u00e0 di dati.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#funzionamento-degli-alberi-decisionali","title":"Funzionamento degli alberi decisionali","text":"<p>Un albero decisionale \u00e8 un modello creato a partire da una serie di condizioni, che potremmo interpretare come delle \"domande\", organizzate in maniera gerarchica a ricalcare, per l'appunto, un albero. Ognuna delle foglie dell'albero contiene il valore predetto, che pu\u00f2 essere sia una classe, sia un valore numerico; i restanti nodi, invece, descrivono una certa condizione. Un semplice esempio \u00e8 mostrato nel seguente schema.</p> <pre><code>flowchart TB\n  A[\"Zampe &gt; 2\"] --&gt;|S\u00ec| B[\"Occhi &gt; 2\"]\n  A --&gt;|No| C(Gallina)\n  B --&gt;|S\u00ec| D(Ragno)\n  B --&gt;|No| E(Cane)</code></pre> <p>L'abero decisionale determina il valore predetto seguendo il percorso che va dalla radice fino ad una delle foglie, a seconda dei valori assunti dalle diverse feature. Questo cammino \u00e8 detto percorso di inferenza. Nel nostro caso, alla radice dell'albero viene valutata la feature Zampe. In particolare, se questo valore \u00e8 maggiore di \\(2\\) andremo a valutare il valore della feature Occhi; in caso contrario, il percorso di inferenza ci porta direttamente a predire come Gallina l'animale caratterizzato.</p> <p>Per quello che riguarda il nostro esempio, immaginiamo di avere un campione con i seguenti valori per le feature:</p> <ul> <li>Zampe: 4</li> <li>Occhi: 2</li> </ul> <p>Dato che le zampe sono \\(4\\), alla prima domanda si risponder\u00e0 ovviamente con un No. Andando quindi a valutare la seconda condizione (il numero di occhi), avremo in questo caso un valore pari a \\(2\\), per cui il risultato della predizione sar\u00e0 un cane.</p> <pre><code>flowchart TB\n  A[\"Zampe &gt; 2\"] --&gt;|S\u00ec| B[\"Occhi &gt; 2\"]\n  A --&gt;|No| C(Gallina)\n  B --&gt;|S\u00ec| D(Ragno)\n  B --&gt;|No| E(Cane)\n  linkStyle 0,3 stroke-width:2px,fill:none,stroke:red;</code></pre> <p>Nell'esempio appena visto, il valore predetto \u00e8 categorico, e le feature numeriche. Facciamo un esempio per dimostrare la versatilit\u00e0 degli alberi decisionali, predicendo la tenerezza di un animale a partire dalle categorizzazioni delle feature Pelosit\u00e0 e Carineria.</p> <pre><code>flowchart TB\n  A[\"Pelosit\u00e0 &gt; medio\"] --&gt;|Si| B[\"Carineria &gt; medio\"]\n  A --&gt;|No| C(1)\n  B --&gt;|S\u00ec| D(3)\n  B --&gt;|No| E(2)</code></pre> <p>Questo problema \u00e8 caratterizzabile come un problema di regressione: infatti, a partire da feature di tipo categorico, il risultato predetto \u00e8 numerico.</p> <p>Risultati della regressione</p> <p>Dall'esempio precedente, \u00e8 evidente come cani, gatti e pulcini siano gli animali che ispirano pi\u00f9 tenerezza nell'essere umano. D'altro canto, aracnidi, insetti e serpenti appaiono spesso molto meno teneri ed affettuosi.</p> <p>Per andare avanti nella nostra discussione, dobbiamo adesso distinguere tra i diversi tipi di condizione descrivibili da un albero decisionale.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#condizioni-in-un-albero-decisionale","title":"Condizioni in un albero decisionale","text":"<p>Esistono due categorizzazioni possibili per le condizioni in un albero decisionale.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#axis-aligned-vs-oblique","title":"Axis-aligned vs. oblique","text":"<p>La prima categorizzazione possibile per le condizioni in un albero decisionale riguarda il fatto che queste interessino una o pi\u00f9 feature. In particolare, una condizione che interessa un'unica feature \u00e8 detta axis-aligned, mentre una condizione oblique riguarda diverse feature.</p> <p>Tornando all'esempio precedente, la condizione \\(Zampe &gt; 2\\) \u00e8 chiaramente axis-aligned, in quanto prevede la valutazione esclusiva del numero di zampe dell'animale. Se per qualche motivo la condizione fosse del tipo \\(Zampe &lt; Occhi\\), allora avremmo a che fare con una condizione oblique.</p> <p>Cosa accade nella pratica?</p> <p>Spesso gli alberi decisionali contengono soltanto condizioni axis-aligned, soprattutto a causa del fatto che pu\u00f2 essere saggio eliminare feature interdipendenti prima di effettuare l'addestramento. Le condizioni oblique restano comunque potenzialmente molto potenti, in quanto in grado di modellare relazioni complesse, anche se, nella pratica, l'uso (ed abuso) di queste condizioni non garantisce necessariamente migliori performance.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#binarie-vs-non-binarie","title":"Binarie vs. non binarie","text":"<p>La seconda distinzione che \u00e8 possibile fare tra diversi tipi di condizione riguarda quelle binarie, ovvero quelle che hanno soltanto due possibili esiti, e non binarie che, prevedibilmente, hanno pi\u00f9 di due possibili esiti. Prevedibilmente, un albero decisionale contenente esclusivamente delle condizioni binarie \u00e8 detto binario, mentre uno contenente anche condizioni non binarie \u00e8 detto non binario.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#addestramento-degli-alberi-decisionali","title":"Addestramento degli alberi decisionali","text":"<p>Come per tutti i modelli di apprendimento supervisionato, gli alberi decisionali sono addestrati a spiegare al meglio un insieme di esempi di training. Gli algoritmi utilizzati nell'addestramento usano spesso un approccio di tipo divide-et-impera. Infatti, l'algoritmo inizia creando un singolo nodo, ovvero la radice, e quindi va ad aumentare le dimensioni dell'albero in maniera ricorsiva usando un approccio greedy.</p> <p>Approccio greedy</p> <p>Per approccio greedy si intende il metodo secondo il quale l'algoritmo va a scegliere la migliore opzione possibile al momento, senza considerare quello che accadr\u00e0 negli istanti successivi.</p> <p>In particolare, l'addestramento valuta, per ogni nodo, tutte le possibili condizioni, scegliendo quella con il punteggio pi\u00f9 alto, in modo da massimizzare il valore della metrica.</p> <p>Ad esempio, nel nostro dataset, tutti i cani ed i ragni hanno un numero di zampe maggiore di quattro, mentre tutte le galline ne hanno due. Di conseguenza, la condizione \\(Zampe &gt; 2\\) ci permette di arrivare a determinare in maniera affidabile le galline, ma non riesce a discernere tra ragni e cani. Di conseguenza, al primo step, l'albero sar\u00e0 in questa forma:</p> <pre><code>flowchart TB\n  A[\"Zampe &gt; 2\"] --&gt;|S\u00ec| B[\"Ragno o Cane\"]\n  A --&gt;|No| C[Gallina]</code></pre> <p>Successivamente, l'albero andr\u00e0 ad esplorare i nodi Ragno e Cane, cercando una maniera per caratterizzarli sulla base delle feature disponibili. Se non viene individuata una condizione soddisfacente, il nodo diventa una foglia: in altre parole, senza il numero di occhi, l'albero non riuscirebbe a distinguere tra ragni e cani.</p> <p>Ragni, cani, e zampe</p> <p>Nella realt\u00e0, nel caso precedente, l'algoritmo andrebbe a specializzare ulteriormente il valore considerato per le zampe.</p> <p>Vediamo adesso pi\u00f9 nel dettaglio i passi necessari a creare il precedente albero decisionale.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#step-1-creazione-del-nodo-radice","title":"Step 1: Creazione del nodo radice","text":"<p>Al primo step l'algoritmo si occupa di creare un nodo radice. Nel nostro caso, il nodo radice si occuper\u00e0 di valutare il numero di zampe.</p> <pre><code>flowchart TD\n\nA[\"Zampe\"]</code></pre>"},{"location":"material/03_ml/06_trees/01_decision_trees/#step-2-accrescimento-del-nodo-radice","title":"Step 2: Accrescimento del nodo radice","text":"<p>Al secondo step, accresceremo il nodo radice. L'algoritmo verificher\u00e0, in base ai dati a sua disposizione, che tutti i campioni etichettati come \"Ragno\" o \"Cane\" hanno pi\u00f9 di due zampe, mentre quelli etichettati con \"Gallina\" ne hanno soltanto due. Di conseguenza, andremo a creare due nodi figli:</p> <pre><code>A[\"Zampe &gt; 2\"] --&gt; Yes --&gt; B[\"Ragno o Cane\"]\n  A --&gt;|No| C[Gallina]</code></pre>"},{"location":"material/03_ml/06_trees/01_decision_trees/#step-3-accrescimento-dei-nodi-figli","title":"Step 3: Accrescimento dei nodi figli","text":"<p>Proviamo in primis ad accrescere il nodo \"Gallina\". Ovviamente, dato che l'algoritmo non \u00e8 in grado di suddividere tra loro i dati etichettati in questo modo, non saranno effettuate ulteriori suddivisioni, per cui il nodo diverr\u00e0 una foglia.</p> <p>Step 3: accresdciamo il nodo 2. Non sono state trovate condizioni soddisfacenti. Per cui, il nodo diventa una foglia.</p> <pre><code>flowchart TD\n\nA[\"x1 &gt;= 1 nodo radice\"] --&gt; s\u00ec --&gt; B[\"? nodo 3\"]\nA --&gt; No --&gt; C[\"foglia nodo 2\"]</code></pre> <p>Step 4: accresciamo il nodo 3. La condizione \"x2 &gt;= 0.5\" \u00e8 stata individuata. Due nodi figli sono creati.</p> <pre><code>flowchart TD\n  A[\"x1 &gt;= 1 nodo radice\"] --&gt; s\u00ec --&gt; B[\"x2 &gt; 5 nodo 3\"]\n  A --&gt; No --&gt; C[\"foglia nodo 2\"]\n  B --&gt; Si --&gt; D[\"? nodo 5\"]\n  B --&gt; No --&gt; E[\"?nodo 4\"]</code></pre> <p>Esistono altri metodi per accrescere gli alberi decisionali. Un'alternativa popolare \u00e8 ottimizzare globalmente i nodi invece di usare una strategia divide-et-impera.</p> <p>A seconda del numero e del tipo di feature di input, il numoer di possibili condizioni per un dato nodo pu\u00f2 essere enorme, generalmente infiito. Ad esempio, data una condizione di soglia \\(feature_i \\geq t\\), la combinaizone di tutti i possibili valore di soglia \\(t \\in \\mathbb{R}\\) \u00e8 infiniat.</p> <p>La routine responsabiel per individualre la miglireo condizione \u00e8 chiamata splitter. Siccome deve testare un gran numero di possibili condizioni, gli splitter sono i colli di bottiglia quando si addestra un albero decisionale.</p> <p>Il punteggio massimizzzato dallo splitter dipende dal task. AD esempio:</p> <ul> <li>Information Ga\u00ecni e Gini sono normalmente usati per la classiciazione.</li> <li>l'0errore quadratico medio \u00e8 normalmente usato per la regressione</li> </ul> <p>Ci sono molti algoretimi di splitting, ognuno con vario spporto per:</p> <ul> <li>tipo di feature; ad esempio, numerica, categorica, testuale;</li> <li>task: p\u00e8er esempio, classificazione binaria, multiclasse, regtressione;</li> <li>tipo di condizione: per esempio, condizione di soglia, obliqua, etc.;</li> <li>criterio di regolarizzaizone: per esempio, splitter essatti o approssimati per le condizioni di soglia.</li> </ul> <p>Inoltre, ci sono deglle varianti equivalenti delgi splitter con diversi compromessi per l'uso di memoria, CPUI, e via dicendo.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#classificazione-binaria","title":"Classificazione binaria","text":"<p>Splitter per la classificazione binaria con feature numeriche</p> <p>Vediamo il pi\u00f9 semplice e comune algoritmo di splitting, che crea condizioni nella fomra \\(feature_i \\geq t\\) nel seguente setting:</p> <ul> <li>task di classificazione binaria</li> <li>senza valori mancanti negli esempi</li> <li>senza indici precalcolati sugli esempi</li> </ul> <p>Assumiamo un insieme di \\(n\\) campioni con una freatrure numerica ed una label bianrai \"arancio\" e \"blu\". Formalmente, il dataset pu\u00f2 essere descritto come:</p> \\[ D={(x_i, y_i)}_{i \\in[1, n]} \\] <p>dove:</p> <ul> <li>\\(x_i\\) \u00e8 il valore di una featrure numerica in \\(\\mathbb{R}\\) (l'insieme di numeri reali)</li> <li>\\(y_i\\) \u00e8 una valore per la label di classificazione binaria tra arancio e blu</li> </ul> <p>L'obiettivo \u00e8 trovare un valore di soglia \\(t\\) tale che dividendo i campioni \\(D\\) nei gruppi \\(T(rue)\\) ed \\(F(alse)\\) secondo \\(x_i \\geq t\\) migliroaiamo la separazione delle label. Ad esmepio, pi\u00f9 esempi arancioni saranno in \\(T\\), e pi\u00f9 esempi blu saranno in \\(F\\).</p> <p>L'entropia di Shanno \u00e8 una misura di disordine. Per una label binaria:</p> <ul> <li>l'etnropia di Shanno \u00e8 massima qunado le label negli esempi sono bilanciate (\\(50\\%\\) blu, \\(50\\%\\) arancioni)</li> <li>l'entropia di SHanno \u00e8 minima (valore zero) quando le label negli esempi sono pure (\\(100\\%\\) blu o \\(100\\%\\) arancioni)</li> </ul> <p>Formalmente, vogliamo trovare una condizione che diminuisce la somma pesata dell'entropia delle distribuzioni delle label in \\(T\\) ed \\(F\\). Il punteggio corrispondente \u00e8 detto information gain, che \u00e8 la differneza tra l'entropia di \\(D\\) e quella dell'insieme \\({T, F}\\).</p> <p>La seguente figura mostra una suddivisione errata, nella quale l'entropia rimane alta ed il guadagno informativo basso.</p> <p>In contrasto, la seguente figura mostra uno split miglire nel quale le'ntropia diventa bassa (ed il guadagno informativo  alto).</p> <p>Formalmente:</p> \\[ T = {(x_i, y_i)|(x_i, y_i) \\in D con x_i \\geq t} \\\\ F = {(x_i, y_i)|(x_i, y_i) \\in D con x_i &lt; t} \\\\ R(X) = \\frac{|{x|x \\in X, x=pos}|}{|X|} \\\\ H(X) = -p log p - (1-p) log(1-p) con p = R(X) \\\\ IG(D, T, F) = H(D) - \\frac{|T|}{|D|} H(T) - \\frac{|F|}{|D|}H(F) \\] <p>con:</p> <ul> <li>\\(IG(D,T,F)\\) guadagno infomrativo legato alla suddivisione di \\(D\\) in \\(T\\) ed \\(F\\).</li> <li>$H(X) \u00e8 l'entropia dell'insieme di campioni \\(X\\).</li> <li>\\(|X|\\) \u00e8 il numero di elementi nell'insieme \\(|X|\\).</li> <li>\\(t\\) \u00e8 il valore di sopglia.</li> <li>\\(pos\\) \u00e8 il valore della label positivo, ad esempio, blue nell'esempio prec edfentre. Scegelier una diversa label come positiva non cambia il valore dell'entropia o dell'information gain.</li> <li>\\(R(X)\\) \u00e8 il rapporto dei valori delle label positive nei campioni \\(X\\).</li> <li>\\(D\\) \u00e8 il dataset.</li> </ul> <p>Nel seguente esempio, consideriamo un datraset poer la classificazione binaria con una singola feature numerica \\(x\\). La seguente figura mostra per differenti valori della soglia \\(t\\) (sull'asse X):</p> <ol> <li>L'istogramma della feature \\(x\\).</li> <li>Il rapporto di campioni \"blu\" negli insiemni \\(D\\), \\(T\\) ed \\(F\\) secondo il valore di soglia.</li> <li>L'entropia in \\(D\\), \\(T\\), ed \\(F\\).</li> <li>Il guadagno informativo, ovvero il delta, in termini di entropia, tra \\(D\\) e \\({T, F}\\) p\u00e8ersato per il numero di campioni.</li> </ol> <p>Questi plot mostrano i seguenti:</p> <ul> <li>il plot di  frequenza mostra che le osserrvazioni sono relativamente ben diffuse con concentrazioni tra 18 e 60. Un valore dello spread ampio indica che ci sono molti split potenziali, il che \u00e8 un bene per l'addestramento del modello.</li> <li>il rapporto di label blue nel dataset \u00e8 di circa il 25%. Il plot relativo mostra questo per i valori di soglia tra 20 e 50:</li> <li>l'insieme T contiene un eccesso di campioni blu (fino al 35% per la soglia 35)</li> <li>l'insieme F contiene un deficit complementare di caompionio etichettati con blu (solo 8% per la soglia 35)   Sia il \"rapporto di label blu\" sia il plot di entropia indicano che le label possono essere relativamente ben sep\u00e8arate in questo range di soglie.</li> <li>Questa osservazione \u00e8 confermata nel plot \"information gain\". VEdiamo che il massimo guadagno informativo \u00e8 ottenuto con \\(t \\sim 28\\) per un valore di circa \\(0.074\\). Quindi, la condizione restituita dallo splitter sar\u00e0 \\(x \\geq 28\\).</li> <li>Il guadagno informativo \u00e8 sempre maggiore o uguale a zero. Converge a zero man mano che il valore di soglia va verso il suo valore massimo (minimo). In questi casi, o \\(F\\) o \\(T\\) diventano vuoti mentre l'altro contiene l'0iutenro dataset e mostra un'entropia uguale a quella in \\(D\\). Il guadagno informatiov pu\u00f2 anche essere zero quando \\(H(T)=H(F)=H(D)\\). Alla soglia 60, il rapporto di label blue per sia \\(T\\) sia \\(F\\) \u00e8 lo stesso di quello di \\(D\\), ed il guadagno informatiov \u00e8 nullo.</li> </ul> <p>I valori candidati per \\(t\\) nell'isnieme dei numeri reali (\\(\\mathbb{R}\\)) sono infiniti. TTuttavia,d ato un numeor finito di campioni, osltmnatop un numero difnito di divisioni di \\(D\\) in \\(T\\) ed \\(F\\) esiste. Quidni, solo un numero finito di valori di \\(t\\) possono essere testati in modod singificativo.</p> <p>Un approccio classico \u00e8 quello di ordinare i valori \\(x_j\\) in ordine crescente \\(x_{s(i)}\\) in modo che:</p> \\[ x_{s(i)} \\leq x_{s(i+1)} \\] <p>Quindi, sit esta \\(t\\) per ogni valore a met\u00e0 tra valori ordinati consecutivi di \\(x_i\\). Ad esempio, supponiamo di avere 1000 valori a virgola mobile per una certa feature. Dopo l'ordianmento, supponiamo che i primi due valori siano 8.5 e 8.7. In questo caso, il primo valore di soglia da testare dovrebbe essere 8.6.</p> <p>Formalmente, consideriamo i seguenti valori candidati per \\(t\\):</p> \\[ X = \\{\\frac{x_{s(i)}+x_{s(i+1)}}{2}|x_{s(i)} \\diff x_{s(i+1)}\\} \\] <p>La complessit\u00e0 nel tempo di questo algoritmo \u00e8 un \\(O(n log n)\\), con \\(n\\) il numero di campioni nel nodo (a causa dell'ordinamento dei valori delle feature). Quando applicato ad un albero decisionale, l'algoritmod i splitting viene applicato ad ogni nodo ed ogni feature. Notiamo che ogni nodo riceve circa la met\u00e0\u00f2 degli esempi del suo nodo genitore. Quindi, in accordo al teorema dell'esperto, la complessit\u00e0 nel tempo di addestare un albero decisioanle con questo splitter \u00e8 data da:</p> \\[ O(mn log^2 n) \\] <p>dove:</p> <ul> <li>m \u00e8 il numero di feature;</li> <li>\\(n\\) \u00e8 il numero di campioni di training.</li> </ul> <p>In questo algoritmo, il valore delle feature non importa; soltanto l'ordine \u00e8 importante. Per questra ragione, questo algoritmo lavora in modo indipendente dalla scala o dalla distribuzione dei valori delle feature. Questo \u00e8+ il motivo per cui non dobbiamo normalizzare o scalare le featrur numeriche quando addestriamo un albero decisionale.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#overfitting-e-pruning","title":"Overfitting e pruning","text":"<p>Usando l'algoritmo dfescritto in precedenza, possiamo addestrare un albero decisionale che classifichi perfettamente i campioni di training, a patto che questi siano separabili. Tuttavia, se il dataset contiene del rumore, questo albero andr\u00e0 in overfitting sui dati, e mostrer\u00e0 scarse abilit\u00e0 in fase di test.</p> <p>La seguente figura mostra un dataset rumoroso con una relazione tra una feature \\(x\\) e la label \\(y\\). La figura mostra anche un albero decisioanle addestrato su qeusto dataset senza alcun tipo di regolarizzzione. Questo modello predice correttamente tutti i campioni di training (in pratica, le predizioni dle modello sono in grado di combaciare con gli esempi di training). Tuttavia, su un dataset contenente lo stesso pattern lineare con un diverso tipo di rumore, il modello offrir\u00e0 performance subottimali.</p> <p>Per limitare l'overfitting di un albeor decisionale, applichiamo uno o entrambi i seguenti criteri di regolarizzaizone mentre addestriamo l'albero stesso:</p> <ul> <li>impostare una profondit\u00e0 massiam: facciamo in modo che l'albero decisionale non vada oltre una massima profondit\u00e0, come 10;</li> <li>impostiamo un numero minimo di campioni nelle foglie: una foglia con meno di un certo numero di campioni non sar\u00e0 considerata per la divisoine.</li> </ul> <p>La seguente figura illustra gli effetti di usare un numero minimo di campioni per foglia variabile. Il modello cattura un minor quantitativo di rumore.</p> <p>TODO</p> <p>Possiamo anche efefttuare la regolarizzaizone dopo l'addestramento rimuovendo in modo selettivo alcuni rami (pruning), ovvero, convertendo certi nodi non-foglia in foglia. UNa soluzione comune ad selezionare i rami da rimuovere \u00e8 quella di usare und ataset per la validazione. Ovvero, se rimuovere un ramo migliora la qualit\u00e0 del modello sul dataset di valdiazione, quindi il ramo viene rimosso.</p> <p>La seguente illustrazione mostra quesrta idea. Qui, testiamo se l'accuracy dik validazione dell'albero decsiionale \u00e8 migliroata se il nodo non-foglia in verede \u00e8 trasformato in foglia; ovvero, effettuando il pruning dei nodi arancvioini.</p> <p>DA FIGURA 14</p> <p>La segyunte figura illustra l'effetto di usare il 20% del dataset come validazione per effettaure il pruning dell'albero decisionale.</p> <p>Notiamo che l'uso di un dataset di validazioen riduce il numero di esempi disponibili per l'addestramento iniziale dell'albero decisionale.</p> <p>Molti modelli inoltre applicano pi\u00f9 criteri. Ad sempio, possiamo usare i seguenti:</p> <ul> <li>applicare un numero minimo di campioni per nodo foglia</li> <li>applicare una profondit\u00e0 massima per limitare la crescita dell'albero decisionale</li> <li>effettuare il pruning dell'albero decisionale</li> </ul> <p>Questi criteri introducono nuovi iperparametri che devono essere impostati (ad esempio, la massima profondit\u00e0 dell'albero), spesso con tuning degli iperparametri automatizzzato. Gli alberi decisionali sono in geenrale abbastanza veloci da addestrare usando l'ottimizzazione degli iperparametri in crss-validazione. Per esempio, su un dataset con \"n\" campioni:</p> <ul> <li>dividiamo i campioni di training in \\(p\\) gruppi non-sovrapposti, per esempio \\(p=10\\).</li> <li>per tutti i possibili valori degli iperprametri, valutiamo, su ogni gruppo, la qualit\u00e0 dell'albero decisionale addestrato sugli altri \\(p-1\\) gruppi; facciamo poi la media delle valutazioni sui diversi gruppi;</li> <li>selezioniamo i valori degli iperparametri con la migliore valutazione media;</li> <li>addestriamo un albero decisionale finale usando tutti gli \\(n\\) campioni con gli iperparametri selezionati.</li> </ul> <p>In questa sezione abbiamo discusso il modo in cui gli alberi decisionali limintano l'overfitting. Nononstante questi metodi, l'underfitting e l'overfitting sono delle debolezze degli alberi decisionali. Le foreste decisionali introducono nuovi metodi per limtiare l'overfitting, come vedremo dopo.</p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#interpretazione-diretta-dellalbero-decisionale","title":"interpretazione diretta dell'albero decisionale","text":"<p>Gli alberi decisionali sono facili da interpretare. Detto questo, cambiare anche pochi esempi pu\u00f2 modificare completamente la struttura (e quindi l'interpretazione) dell'albero decisionale.</p> <p>Nota</p> <p>Specialmente quando il dataset contiene molte feature in qualche modo simili, l'albero decisionale appreso \u00e8 solo uno di pi\u00f9 alberi decisionali pi\u00f9 o meno equivalnetni che fittano i dati.</p> <p>Visto il modo in cui gli alberi decisionali sono costruiti, effettuando il partizionalmento dei campiioni di trainging, si pu\u00f2 usare un albero decisioanle per interpretare il dataset (invece di modellarlo). Ogni foglia rappresnta un particolare angolo del dataset. </p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#importanza-delle-variabili","title":"Importanza delle variabili","text":"<p>Per importasnza delle variabili (detto anche feature importance) si intende un punteggio che indica quanto \"importante\" sia una feature per il modello. Ad esempio, se per un dato modello con due feature in input \\(f_1\\) ed \\(f_2\\) l'importanza delle variabili sono \\(f_1 = 5.8, f_2=2.5\\), allora la feature \\(f1\\) \u00e8 pi\u00f9 importante per il modello della feature \\(f2\\). Cos\u00ec come per altri modelli di machine learning, l'importanza delle variabili \u00e8 un modo semplice di comprendere come funziona un albero decisionale.</p> <p>Possiamo definire l'importanza delle feature in modo agnostico usando metodi come permutation impotrance.</p> <p>Gli alberi decisionali hanno anche delle specifiche importanze per le variabili, come:</p> <ul> <li>somma dei punteggi parziali associati ad unac erta feaature</li> <li>numero di nodi con una data feature</li> <li>profondit\u00e0 media della prima occorrenza di unaf eature in tutti  i percorsi dell'albero</li> </ul> <p>L'importanza delle variabili pu\u00f2 differire in base a qualit\u00e0 come semantica, scala o propriet\u00e0. Inoltre, l'importanza delle variabili foirnisce diversi tipi di informazione circa modello, dataset, e processo di addestramento.</p> <p>Ad esempio, il numero di condizioni contenenti una certa feature indca quanto un albero decisionale sta guardando a quella specifica feature, il che pu\u00f2 indicare l'importanza della variabile. Dopo tutto, l'algoritmo di apprendimento non avrebbe usato una feature in diverse condizioni se questa non avesse avuot importanza. Tuttavia, la stessa feature che appare in pi\u00f9 condizioni pu\u00f2 anche indicare che il modello sta provando a generalizzare il pattern per quella feature, fallendo. Ad esempio, questo pu\u00f2 accadere quando una feature \u00e8 specifica per ogni campione (il nome e cognome), senza alcuna infomrazione da generalizzare.</p> <p>D'altro canto, un alto valore di importanza per la variabile indica che rimuovere quella feature inficia il modello, il che \u00e8 un'indicazione dell'importanza della variabile. Tuttavia, se il modello \u00e8 robusto, rimuovere una qualsiasi delle feature non dovrebbe influenzare il modello.</p> <p>Dato che diverse variabili informano su diversi aspetti del modello, osservare contestualmente l'importanza di diverse varaibili \u00e8 informativo. Ad esempio, se una feature \u00e8 importante in accordo a tutte le altre, \u00e8 plausibile che sia molto importante. </p>"},{"location":"material/03_ml/06_trees/01_decision_trees/#esempio-con-tensorflow-decision","title":"Esempio con tensorflow-decision","text":"<p>Vediamo come usare la libreria TF-DF per addestrare, rifinire ed interpretare un albero decisionale.</p> <p>Possiamo farlo sia in locale, sia da un notebook Colab. Per farlo, dovremo installare la libreria TensorFlow Decision Forests.</p> <pre><code>pipenv install tensorflow_decision_forests\n</code></pre> <p>All'apice del nostro codice, importiamo le seguenti librerie:</p> <pre><code>import numpy as np\nimport pandas as pd\nimport tensorflow_decision_forests as tfdf\n</code></pre> <p>Useremo il dataset relativo ai Palmer Pengiuns, che contiene le misurazioni in termini di dimensione per tre specier di pinguini , ovvero il pigoscelide antartico (Chinstrap), il pinguino Gentoo, ed il pinguino di Adelia (Adelie).</p> <p>Per prima cosa, carichiamo il dataset in memoria utilizznado Pandas:</p> <pre><code>path = \"https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv\"\ndataset = pd.read_csv(path)\n</code></pre> <p>Visualizziamo la testa del dataset.</p> <pre><code>dataset.head()\n</code></pre> <p>TODO: IMMAGINE</p> <p>Notiamo come il dataset contenga diversi tipi di dato, sia numerici (ad esempio, billlengthmm), sia categorici (ad esempio, sex). Vi sono inoltre delle feature mancanti. A differenza delle reti nuerali, tuttavia, le foreste decisionali sono in grado di supportare tutti questi tipi di feature in maneira nativa, per cui non dobbiamo effettaure encoding, normalizzazioni o roba del genere.</p> <p>Per semplificare l'interpretabilit\u00e0, convertiamo manualmente le specie dei pinguini in label intere:</p> <pre><code>label = \"species\"\nclasses = list(pandas_dataset[label].unique())\nprint(f\"Label classes: {classes}\")\n# &gt;&gt; Label classes: ['Adelie', 'Gentoo', 'Chinstrap']\npandas_dataset[label] = pandas_dataset[label].map(classes.index)\n</code></pre> <p>https://developers.google.com/machine-learning/decision-forests/practice?hl=en</p>"},{"location":"material/03_ml/06_trees/02_decision_forests/","title":"6.2 - Foreste decisionali","text":"<p>Per foresta decisionale si intendono tutti quei modelli composti da un insieme di alberi decisionali (trattati nella lezione precedente). Il modo in cui i diversi alberi si aggregano dipende dall'algoritmo usato per l'addestramento: ad esempio, in una foresta decisionale che affronta un problema multiclasse, ogni albero potrebbe dare il suo \"voto\" ad una singola classe, e la predizione globale sarebbe quindi la classe pi\u00f9 votata. Un'altra implementazione potrebbe invece prevedere che ciascun albero mandi in output un valore decimale compreso tra zero ed uno, con il valore complessivo della predizione dato dalla somma normalizzata dei valori predetti da ciascun albero e successivamente sogliata (nel caso, ovviamente, di predizione binaria).</p> <p>Partiremo la nostra trattazione da quello che, probabilmente, \u00e8 l'esempio pi\u00f9 noto di foresta decisionale: il random forest.</p>"},{"location":"material/03_ml/06_trees/02_decision_forests/#random-forest","title":"Random Forest","text":"<p>Per introdurre il random forest \u00e8 opportuno partire da un aneddoto.</p> <p>Nel 1906 si svolse in Inghilterra una competizione che vedeva i partecipanti tentare di valutare il peso di un bue (ovviamente, senza usare una bilancia). Al termine della competizione, l'errore mediano delle predizioni era di circa \\(37\\) libbre, ovvero \\(17\\) kg. Tuttavia, la mediana delle predizioni era distante soltanto nove libbre (quattro kilogrammi) dal valore reale. Ci\u00f2 descrive perfettamente il cosiddetto principio della saggezza della folla: in altre parole, in determinate situazioni, il giudizio fornito dall'opinione collettiva risulta essere (inaspettatamente) molto preciso.</p> <p>Dal punto di vista statistico, questo principio ricalca il teorema centrale del limite, che dice che lo scarto quadratico medio tra il valore vero \\(x\\) e quello \\(\\hat{x}\\) derivante dalla media di \\(N\\) stime (rumorose) di \\(x\\) tende a zero con un fattore pari ad \\(\\frac{1}{n}\\).</p> <p>Note</p> <p>Nel machine learning, un ensemblke \u00e8 un insieme di modelli le cui predizioni sono mediate (o aggregate in qualche maniera). Se i modelli nell'ensemble sono abbastanza differenti senza essere pessimi se presi da soli, la qualit\u00e0 dell'ensemble \u00e8 generalmente pi\u00f9 alta che la qualit\u00e0 di ognuno dei modelli individuali. Un ensemble richiede maggior tempo di addestramento ed inferenza rispetto ad un singolo modello. Dopotutto, dobbiamo effettuare il trainign e l'inferenza di pi\u00f9 modelli invece di un singolo modello.</p> <p>Informalmente, affinch\u00e9 un ensemble lavori al meglio, i modelli dinivudali dovrebbero essere indipendenti. Per esempio, un esnseble composto di 10 modelli identici (ovvero, non indipendenti tra loro) non sar\u00e0 meglio del modello idnividuale. D'altro canto, forzare i modelli affinch\u00e9 siano indipendenti pu\u00f2 renderli peggiori. Un ensemblingf efficace richiede l'indivioduazione del bilancio tra l'ndiepenze del modello e la qualit\u00e0 dei suoi sotto-modelli.</p>"},{"location":"material/03_ml/06_trees/02_decision_forests/#randomn-forest","title":"Randomn forest","text":"<p>Un random forest \u00e8 un insieme di alberi decisionali nei quali ogni albero decisioanle \u00e8 addestrato con un certo rumore casuale. Le random forest sono la fforma pi\u00f9 popolare di ensemble di alberi decisionali. Vediamo alcuen tecniche per creare degli alebri decisionali indipendenti per migliorare le cahnce di creare una random forest efficace.</p>"},{"location":"material/03_ml/06_trees/02_decision_forests/#bagging","title":"Bagging","text":"<p>La tecnica del bagging (bootstrap aggregating) fa in modo che ogni albero decisionale sia addestrato su un sottoinsieme casuale dei campioni nell'insieme di training. In altre parole, ogni albero decisionale nelle random forest \u00e8 addestrato su un sottoinsieme differente di campioni.</p> <p>Il bagging \u00e8 peculiare. Ogni albero decisionale \u00e8 addestrato sullo stesso numero di campioni dell'insieme di addestramento originario. Per esempio, se l'insieme di training originario contiene 60 campioni, allora ogni albero decisionale \u00e8 addestrato su 60 campioni. Tuttavia, il bagging addestra soltanto ogni decision tre su un sottoinsieme (tipicamente, il 67%) di questi esempi. Per cui, alcuni di questi 40 campioni nel sottoinsieme saranno riutilizzati quando si addestra un dato albero decisionale. Questo riutilizzo \u00e8 chiamato addestramentp con rimpiazzo.</p> <p>Facciamo un esempio. Nella tabella successiva, vediamo come il bagging pu\u00f2 distribuire sei campioni su tre alberi decisionaloi. Notiamo che:</p> <ul> <li>ogni albero decisionale \u00e8 addestrato su un totale di sei campioni</li> <li>ogni albero cdecisioanle +\u00e8 addestrato su un insieme diverso di campioni</li> <li>ogni albero decisionale riutilizza certi campioni. Ad esempio, il campione 4 \u00e8 usato due volte nell'albero decisionale 1, quindi, i pesi appresi da parte del campion 4 \u00e8 effettivamente duplicato nel primo albero decisionale.</li> </ul> Campioni di training 1 2 3 4 5 6 dataset originario 1 1 1 1 1 1 albero decisionale 1 1 0 2 1 1 1 albero decisionale 2 3 2 0 1 0 1 albero decisionale 3 2 1 3 0 0 1 <p>Nel bagging, ogni albero decisionale \u00e8 quasi sempre addestarto sul numero ttoale di campioni nell'insieme di training originale. L'addestramento di ogni albero decisionale su un numero maggiore o inferiore di campioni pu\u00f2 degradare la qualit\u00e0 del randomn forest.</p> <p>Anche se non presente nel paper originale, il campionamento dei campioni alle volte \u00e8 svolto senza rimpiazzo; in altri termini, un campione di training non pu\u00f2 essere presente pi\u00f9 di una volta nell'insieme di addestramento di un albeor decisionale. Ad esempio, nella tabella precedente, tutti i valori sarebbero 0 o 1.</p>"},{"location":"material/03_ml/06_trees/02_decision_forests/#attribute-sampling","title":"Attribute sampling","text":"<p>L'attribute sampling indica che invece di guardare alla migliore condizione rispetto a tutte le feature disponibili, soltanto un sottoinsieme casuale di feature sono testate ad ogni nodo. L'insieme di feature testate \u00e8 campionato casualmente ad ogni nodo dell'albero decisionale.</p> <p>Il seguente albero decisionale illustra l'attribute sampling. Qui, un albero decisionale \u00e8 addestrato su 5 feature (f1-f5). I nodi in blu rappresentano le feature testate, mentre quelli in bianco non sono testati. La condizione \u00e8 costruita a parteire dalle feature meglio testate (rappresentate con un contorno rosso).</p> <p>TODO: FARE FIGURA</p> <p>Il rapporto dell'attribute sampling \u00e8 un importante iperparametro per la regolarizzazione. La figura precednete usa un rapporto di \u2157. Molte implemnentazioni di random forest testano, di default, \u2153 delkle feature in fase di regressione, e la radice quadrata del numero dif eature epr la classificazione.</p> <p>In TF-DF, i seugenti iperparametri controllano l'attribute sampling:</p> <ul> <li>numcandidateattributes</li> <li>numcandidateattributes_ratio</li> </ul> <p>Per esempio, se numcandidateattributes_ratio=0.5, met\u00e0 delle featrure saranno testate ad ogni nodo.</p>"},{"location":"material/03_ml/06_trees/02_decision_forests/#disabiliatre-la-regoalrizzazione-degli-alberi-decisionali","title":"Disabiliatre la regoalrizzazione degli alberi decisionali","text":"<p>Gli alberi decisionali in una foresta casuale sono addestrati senza il pruning. La mancanza di pruning aumenta singificativamente la varianbza, riducendo singificativamente il bias legato al singolo albero decisionale. In altre parole, l'albero individuale pu\u00f2 andare in overfitting, ma la random forest no.</p> <p>Ci aspettiamo che le accuracy di trainign e di test di una random forest siano differenti. L'accuracy di training di una random forest \u00e8, generalmente, molto alta (alle volte pari al 100%). Tuttavia, un'accuracy di training molto alta in una random forest \u00e8p normale, e non indica che la random forest sia in overfitting.</p> <p>Le due sorgenti di casualit\u00e0 (il baggin e l'attribute sampling) si assicurano che vi sia indipendenza relativa tra gli alberi decisionali. Questa indipendenza corregege l'overfitting dei singoli alberi decisionali. Di conseguenza, l'ensemble non \u00e8 in overfitting. Vedremo questo effetto (controintuitivo) nella seguente unit\u00e0.</p> <p>Le random forest pure sono addestrate senza una profondit\u00e0 massima o un numero minimo di osservazioni per foglia. Nella praica, limitare la profondit\u00e0 massima ed il minimo numero di osservazioni per foglia \u00e8 un beneficio. Di default, molte random forest usano i sengeunti valori di default.</p> <ul> <li>massima profondit\u00e0 di circa 16</li> <li>minimo numero di osservaizoni per foglia di circa 5</li> </ul>"},{"location":"material/03_ml/06_trees/02_decision_forests/#chiarezza-del-rumore","title":"Chiarezza del rumore","text":"<p>Perch\u00e9 il rumore casuale migliora la qualit\u00e0 del random forest? Per illustrare i benefici del\u00f2 rumore casuale, vediamo le rpedizioni di un albero decisionale classico e di una random forest addestrata su alcuni campioni di un semplice problema ellittico.</p> <p>I pattern ellittici sono notoriamente complessi per gli alberi decisionali e. notiamo come l'albero decisionale dopo il pruning non riesce ad ottenre la stessa qualit\u00e0 di predizione delle random forest.</p> <p>TODO: IMMAGINE CON RIFERIMENTO</p> <p>Vediamo anche le predizioni dei primi tre alberi decisionali senza pruning nel random forest; ovvero, gli alberi decisionali sono tutti addestrati con una combinazione di bagging, attribute sampling e senza pruning.</p> <p>Le rpedizioni individuali di questi tre alberi sono peggiori delle predizioni dell'albero decisionale con pruning nella precedente figura. TUttavia, dal momento che gli errori degli alberi decisionali individuali sono soltanto correlati debolmente, i tre alberi decisionali combinano in un ensemble per creare delle predizioni efficace.</p> <p>Dato che gli alberi decisionali di una random forest non sono prunati, il training di una random forest non richiede un dataset di validazione. Nella pratica, e specialmente su piccoli dataset, i modelli dovrebbero essere addestrati su tutti i dati disponibili.</p> <p>Quando si addestra una random forest, man mano che pi\u00f9 alberi decisionali sono aggiunti, l'errore quasi sempre diminuisce; ci\u00f2 singific ache la qualit\u00e0d el modello quasi sempre aumenbta. Aggiungere pi\u00f9 alberi decisionali quasi sempre riduce l'errore della random forest. In altre parole, aggiungere pi\u00f9 alberi decisionali non pu\u00f2 causare l'overfit della random forest. Ad un certo punto, il modello semplicemente smette diu migliorare.</p> <p>Ad esempio, il seguente plot mostra la valutazione di una random forest man mano che vengono aggiunti pi\u00f9 alberi decisionali. L'accuracy migliropa rapidamente fino a che non si ferma attorno al val\u00f2ore di TODO: ESPERIMENTO. Tuttavia, aggiungere pi\u00f9 alberi decisionali non fa diminuire l'accuracyt; in altre parole, il modello non va in overfittng. QUestro comportamento \u00e8 quasi sempre vero ed indipendente dagli iperparametri.</p>"},{"location":"material/03_ml/06_trees/02_decision_forests/#out-of-bag-evaluation","title":"Out-of-bag evaluation","text":"<p>Le random forest non richiedono un dataset di validazione. La maggior parte delle random forest usa una tecnica chaimata out-of-bag evaluation (OOB) per valutare la qualit\u00e0 del modello. La OOB evaluation tratta il set di training come se fosse il set di test di una cross-validazione.</p> <p>COme spiegato in precedenza, ogni albero decisionale in una random forest \u00e8 tipicamente addestrato su circa il 67%% degli esempi di training. Di conseguenza, ogni albero decisionale non vede circa il 33% degli esempi di training. L'idea alla base della OOB-evaluation \u00e8 la seguente:</p> <ul> <li>valutare la randomn forest sull'insieme di training</li> <li>per ogni campione, usiamo solo l'albero decisionale che non vede il campione durante il training</li> </ul> <p>La seugente tabella illustra la valutazione OOB di una random forest con 3 alberi decisionali addestrati su 6 campioni (COPIARE QUELLA DI PRIMA). La tabella mostra quale albero decisionale \u00e8 usato con quale esempio nella valutazione OOB.</p> Campioni di training Campioni per la valutazione OOB 1 2 3 4 5 6 dataset originario 1 1 1 1 1 1 albero decisionale 1 1 0 2 1 1 1 3 albero decisionale 2 3 2 0 1 0 1 2, 4 albero decisionale 3 2 1 3 0 0 1 1, 5, 6 <p>Nell'esempio mostrato nella precedente tabella, le predizioni OOB per l'esempio di training 1 saranno calcolate con l'albero decisionale 3 (dal momento che gli alberi decisionali 1 e 2 usano questo campione per il training). Nella pratica, su unb dataset con dimensioni ragionevoli con alcuni alberi decisionali, tutti gli esempi hanno una predizione OOB.</p> <p>La valutaizone OOB \u00e8 efficace anche per calcolare l'importanza delle variabili nei modelli random forest. Ricordiamo che questa importanza misura l'importanza di una variabile misurando la caduta dell a qualit\u00e0 del modello quando questa variabile viene \"mescolata\". In caso di OOB epr un random forest, l'importanza \u00e8 calcolata usando la valutazione OOB.</p>"},{"location":"material/03_ml/06_trees/02_decision_forests/#altri-topic","title":"Altri topic","text":""},{"location":"material/03_ml/06_trees/02_decision_forests/#interpretazione-dei-random-forest","title":"interpretazione dei random forest","text":"<p>I random forest sono pi\u00f9 comp\u00e8lessi da interpretare degfliu alberei decisionali. Le random forest contengono degli alberi decisionali addestrati con rumore casuale. Quindi, diviene difficile dare un giudizio suilla struttura dell'albero decisionale. Tuttavia, possiamo interpretare i modelli del random forest in due diversi modi.</p> <p>Un approccio \u00e8 quello di limitarsi ad addestrare ed interpretare un albero decisionale con l'algortimo CART. Siccome sia le random forest che il cCART sono addestrati con lo stessdo algoritmo alla base, \"condividono la stessa visione globale\" sul datasaet. Qeusta opzione funziona al meglio epr dataset semplici e per comprendere l'interpretazione compelssiva del modello.</p> <p>L'importanza delle variabili \u00e8 un altro approccio all'intepretabilit\u00e0.</p> <p>Un altro tipo di metodo per la spiegazione \u00e8 quello di suare algoritmi agnostici, come lo SHAP (SHapley Additive exPlanations). </p> <p>Vantaggi:</p> <ul> <li>come gli alberi defcisionali, i random forest supportano natgivamente feature categoriche e numeriche e non richiedono il preprocessing delle stesse</li> <li>dato che gli alberi decisionali sono indipendenti, i random forest possono essere addestrati in parallelo, e quindi pi\u00f9 velocemente</li> <li>le random forest hannod ei aprametri di default che danno ottimi risutlati. il tuning di questi parametri ha spesso poche conseguenze sul modello</li> </ul> <p>Svantaggi:</p> <ul> <li>siccome gli alberi decisionali non sono soggetti a pruning, possono essere grandi, con modelli con anche un milione di nodi. La dimensione delle random forest pu\u00f2 quindi essere un problema</li> <li>le random forest non possono apprendere e riutilizzare delle rappresentazioni interne. Ogni albero decisionale (ed ogni ramo di ogni albero decisionale) deve apprendere nuovamente il pattern del datset. Ina lcuni dataset (specie quelli non tabellari) questo fa s\u00ec che le random forst abbiano risutlati peggiori daltrri metodi.</li> </ul>"},{"location":"material/03_ml/06_trees/03_gradient_boost/","title":"Gradient Boosted Decision Trees","text":"<p>Come per il bagging ed il boosting, il gradient boosting \u00e8 una metodologia applicata su altri algoritmi di mcahine learning.</p> <p>Informalmente, il gradient boosting coinvolge due tipi di modelli:</p> <ul> <li>un modello debole, che \u00e8 tipicamente un albero decisionale</li> <li>un modello forte, che \u00e8 tipicamente fatto da pi\u00f9 modelli deboli</li> </ul> <p>Nel gradient boosting, ad ogni stewp, un nuovo modello debole \u00e8 addestrato a predire l'errore dell'attuale modello forte (chiamato pseudo risposta). Definiremo succesviamente il concetto di errore. PEr ora, assumiamo che l'errore sia la differenza tra la predizione ed un valore di regressione. Il modello debole (ovvero l'errore) \u00e8 quindi aggiunto al modello forte con segno negativo per ridurre l'errore del modello forte.</p> <p>Il gradient boosting \u00e8 iterativo. Ogni iterazione invoca la seguente formula:</p> \\[ F_{i+1} = F_i - f_i \\] <p>dove:</p> <ul> <li>\\(F_i\\) \u00e8 il modello forte allo step \\(i\\)</li> <li>\\(f_i\\) \u00e8 il modello debole allo step \\(i\\)</li> </ul> <p>Questa operazione \u00e8 ripetuta fino a che non si trova un criterio di arresto, come il numero massimo di iterazione o se il modello forte inizia ad essere in overfitting su un dataset di validazione separato.</p> <p>Facciamo il gradient boosting su un semplice dataset di regressione. L'obiettivo \u00e8 quello di predire \\(y\\) a partire da \\(x\\); il modello forte viene inizializzato ad una costante pari a zero: \\(F_0(x) = 0\\).</p> <p>Vediamo dello pseudocodice per capire il gradient boosting.</p> <pre><code># Simplified example of regressive gradient boosting.\n\ny = ... # the labels\nx = ... # the features\n\nstrong_model = []\nstrong_predictions = np.zeros_like(y) # Initially, the strong model is empty.\n\nfor i in range(num_iters):\n\n    # Error of the strong model\n    error = strong_predictions - y\n\n    # The weak model is a decision tree (see CART chapter)\n    # without pruning and a maximum depth of 3.\n    weak_model = tfdf.keras.CartModel(\n        task=tfdf.keras.Task.REGRESSION,\n        validation_ratio=0.0,\n        max_depth=3)\n    weak_model.fit(x=x, y=error)\n\n    strong_model.append(weak_model)\n\n    weak_predictions = weak_model.predict(x)[:,0]\n\n    strong_predictions -= weak_predictions\n</code></pre> <p>Applichiamo questo codice al seguente dataset:</p> <p>FARE ESEMPIO</p> <p>Vediamo cosa acade dopo la prima iterazione dell'algoritmo di gradient boosting:</p> <p>FARE ESEMPIO</p> <p>Notiamo che:</p> <ul> <li>il primo plot (a sinsitra) mostra le predizioni del modellop forte, che sono sempre zero</li> <li>il secondo plot mostra l'errore, che \u00e8 il label del modello debole</li> <li>il terzo plot mostra il modello debole</li> </ul> <p>Il primo modello debole sta apprendendo una rappresentazione grossolana della label e si focalizza sulla parte sinistra dello spazio delle feature (la parte con la maggiore variazione, e quindi l'errore maggiore per il modello costantemente errato).</p> <p>A seguire gli stessi plot per un'altra iterazione dell'algoritmo:</p> <p>ALTRA FIGURA</p> <p>A questo punto:</p> <ul> <li>il modello forte contiene le predizioni del modello debolerispetto alla precdente iterazione</li> <li>il nuoivo errore del modello forte \u00e8 ifneriroe</li> <li>la nuova predizione del modello debole \u00e8 focalizzata sulla parte destra dello spazio della feature</li> </ul> <p>Se eseguiamo ulteriormente il modello:</p> <p>FARE FIGURA</p> <p>Noptiamo che, dopo alcune iterazioni, la predizione del modello forte inizia a ricordare il plot del dataset  originario.</p> <p>Qeuste figure illustriano l'algoritmo di gradient boosting che usa gli alberi decisionali come mdoelli deboli. Questa combinazione \u00e8 chiamata gradient boosting decision trees.</p> <p>Le operazioni, tuttavia, mancano di due operazioni che sono svolte nel modno relae, ovvero shrinkage ed ottimizzazione.</p>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#shrinkage","title":"Shrinkage","text":"<p>Il modello debole \\(f_i\\) \u00e8 moltiplicato per un valore piccolo \\(\\epsilon\\) priam di esere aggiunto al modello forte \\(F_i\\). Questo piccolo valroe \u00e8 chiamatop shrinkage (FARE TRADUZIONE). In altre parole,. invece di usare ad ogni iterazione la formula:</p> \\[ F_{i+1} = F_i - f_i \\] <p>usiamo:</p> \\[ F_{i+1} = F_i - \\ni f_i \\] <p>Lo shirnkage nel gradient boosting \u00e8 analogo al learning rate nelle reti neurali. Lo shringkage controlla quanto veloce il modello forte sta apprendendo, il che aiuta a limitare l'overfitting. In altre parole, un valore di shrinkage vicino allo 0' riduce l'overfitting di pi\u00f9 rispetto ad un valore vicino ad 1.</p> <p>shrinkage = 0.1   # 0.1 is a common shrinkage value. strongpredictions -= shrinkage * weakpredictions</p>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#l0algoritmo-di-gradient-boosting","title":"L'0algoritmo di Gradient boosting","text":"<p>Nei problemi di regressione, ha senso definire l'errore con segno come la differenza tra la predizione ed il label. Tuttavia, in altri tipi di problemi, questa strategia spesso conduce a risultati scadenti.  Una miogliore strategia usata nel gradient boosting \u00e8 quella di:</p> <ul> <li>definire una funzoine di costo simile a quella usata nelle reti neurali (ad esempio, l'entropia per un problema di classificazione)</li> <li>addestrare il modello debole a predire il gradiente del costo in accordo all'output del modello forte</li> </ul> <p>Formalmente, data una funzione di costo \\(L(y, p)\\), dove \\(y\\) \u00e8 una albel e \\(p\\) una predizione, la pseudo-risposta \\(z_i\\) uisata per addestrare il modello debole allo step \\(i\\) \u00e8:</p> \\[ z_i = \\frac{\\delta L(y, F_i)}{\\delta F_i} \\] <p>dove:</p> <ul> <li>\\(F_i\\) \u00e8 la predizione del modello forte</li> </ul> <p>L'esempio precedente era un problema di regressione: l'obiettivo \u00e8 predire un valore numerico. Nel caso della regressione, l'errore quadratico \u00e8 una normale funcione di costo:</p> \\[ L(y,p)=(y-p)^2 \\] <p>In questo caso, il gradiente \u00e8:</p> \\[ z =  \\frac{\\delta L(y, F_i)}{\\delta F_i} = \\frac{\\delta (y-p)^2}{\\delta p} = 2(y-p) = 2 * e_p \\] <p>dove \\(e_p\\) \u00e8 l'errore di predizione MSE (Mean Signed Error) NOTA: NON E' MEDIO. In pratica, il gradiente \u00e8 il doppio dell'errore di predizione. Notiamo chei fattori costanti non contano a causa dello shrinkage. Questa equivalenza \u00e8 inoltre vera soltanto per prpobnlemi di regressione con costo correlato all'errore quadratico. Per altri tipi di problema di apprendimento supervisionato (ad esempio, classificaizone, ranking, regressione con altre funzioni di costo) non vi \u00e8 equivalenza tra il gradiente e l'errore di predizione.</p>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#foglieed-ottimizzazione-della-struttura-con-il-metodo-di-newton","title":"Foglieed ottimizzazione della struttura con il metodo di Newton","text":"<p>Il metodo di Neuwton \u00e8 un metodo di ottimizzazione come quello a discesa di gradiente. Tuttavia, a differenza della discesa di gradiente che usa soltanto il gradiente della funzione da ottimizzazre, il metodo di Newton usa sia il gradiente (derivata prima) che la derivata seconda della funzione.</p> <p>Uno step dell'algoritmo a discesa di gradiente \u00e8 dato dalla seguente:</p> \\[ x_{i+1} = x_i - \\frac{\\delta f}{\\delta x}(x_i) = x_i - f^'(x_i) \\] <p>mentre per il metodo di Newton abbiamo:</p> \\[ x_{i+1} = x_i - \\frac{\\frac{\\delta f}{\\delta x}(x_i)}{\\frac{\\delta^2 f}{\\delta^2 x}(x_i)} = x_i - \\frac{f^'(x_i)}{f^{''}(x_i)} \\] <p>Opzionalmente, il metodo di Newton pu\u00f2 essere integrato nell'addestramento dei GBT in due modi:</p> <ol> <li>una volta che un albero viene addestrato, un passo del meotod di Newton \u00e8 applciato su ogni foglia, andando a sovrscrivere il suo valore. La struttura ad albero \u00e8 lasciata intatta; soltanto i valori foglia cambiano.</li> <li>durante l'accrescimento dell'albero, sono scelte delle condizioni secondo un punteggio che include una componente della formula di Newton. La struttura dell'albero \u00e8 alterata.</li> </ol>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#overfitting-regolarizzazione-ed-early-stopping","title":"Overfitting, regolarizzazione ed early stopping","text":"<p>A differenza delle random forest, i GBT possono andare in overfitting. Quindi, come per la rete neurale, si pu\u00f2 applicare la regolarizzazione e l'early stopping usando un dataset di validazione.</p> <p>Dei tipici parametri di regolarizzazione per i GBT includono:</p> <ul> <li>massima profondit\u00e0 ell'albero</li> <li>tasso di shrinkage</li> <li>rapporto degli attributi testati ad ogni nodo</li> <li>coefficienti L1 ed L2 sulla loss</li> </ul> <p>Notiamo che gli alberi decisionali generalmente sono molto meno profondi dei modelli random forest. Di defautl, i GBT in TF-DF cresdcono fino alla profondit\u00e0 di 6. Siccome gli alberi sono poco profondi, il numero minimo di campioni epr foglia ha un piccolo impatto, e di solito non viene TUNED.</p> <p>La necessit\u00e0 di un dataset di validazione \u00e8 un problema quando il numero di campioni di esempio \u00e8 piccolo. Quindi, \u00e8 comune addestrae i GBT all'interno di un loop di cross-validazione, o disabilitare l'early stopping quando il modello si \u00e8 sicuri non vada in overfitting.</p>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#esempi-di-utilizzo","title":"Esempi di utilizzo","text":"<p>model = tfdf.keras.GradientBoostedTreesModel()</p>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#part-of-the-training-dataset-will-be-used-as-validation-and-removed","title":"Part of the training dataset will be used as validation (and removed","text":""},{"location":"material/03_ml/06_trees/03_gradient_boost/#from-training","title":"from training).","text":"<p>model.fit(tftraindataset)</p>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#the-user-provides-the-validation-dataset","title":"The user provides the validation dataset.","text":"<p>model.fit(tftraindataset, validationdata=tfvalid_dataset)</p>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#disable-early-stopping-and-the-validation-dataset-all-the-examples-are","title":"Disable early stopping and the validation dataset. All the examples are","text":""},{"location":"material/03_ml/06_trees/03_gradient_boost/#used-for-training","title":"used for training.","text":"<p>model.fit(    tftraindataset,    validationratio=0.0,    earlystopping=\"NONE\")</p>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#note-when-validation_ratio0-early-stopping-is-automatically-disabled","title":"Note: When \"validation_ratio=0\", early stopping is automatically disabled,","text":""},{"location":"material/03_ml/06_trees/03_gradient_boost/#so-early_stoppingnone-is-redundant-here","title":"so early_stopping=\"NONE\" is redundant here.","text":""},{"location":"material/03_ml/06_trees/03_gradient_boost/#vantaggi","title":"Vantaggi","text":"<p>I GBT hanno i seguenti vantaggi.</p> <ul> <li>come gli alberi decisionali, supportano nativamente lef eature numeriche e categoriche e spesso non hanno bisogno del preprocessing delle feature</li> <li>i GBT hanno degli iperparametri di default che spesso danno ottimi risultati. Tuttavia, il tunign di questi iperparametri pu\u00f2 singificativamente miglikorare il modello</li> <li>i GBT sono di solito piccoli (come numero di nodi ed in memoria) e veloci da eseguire (di solito solo uno o pochi microsecondi per campione)</li> </ul>"},{"location":"material/03_ml/06_trees/03_gradient_boost/#svantaggi","title":"Svantaggi","text":"<ul> <li>gli alberi decisionalid evono essere addestrati in maniera sequenziale, che pu\u00f2 rallentare consierevolmente il training. Tuttavia, il rallentamento nell'0addestramento \u00e8 in qualche modo compensato dalle piccole dimensioni dell'albero</li> <li>cos\u00ec come le random forest, i GBT non possono apprendere e riutilzizare rappresentazioni interne. Ogni albero decisionale (ed ogni ramo di ogni albero decisionale) deve apprendere nuovamente il pattern del dataset. In alcuni dataset, specie quelli con dati non strutturati (ad esempio, immagini e testo) possono fare in modo che i GBT abbaino risultati peggiori rispetto ad altri metodi.</li> </ul> <p>ULTIMA: https://developers.google.com/machine-learning/decision-forests/overfitting-gbdt?hl=en</p>"},{"location":"material/03_ml/07_metrics/lecture/","title":"7 - Metriche","text":"<p>Abbiamo visto come la regressione logistca restituisca una probabilit\u00e0, che grazie alla classe <code>LogisticRegression()</code> viene automaticamente convertita in un valore relativo ad una classe.</p> <p>Torniamo al nostro spam detector. Un modello di regressione logistica che restituisca una probabilit\u00e0 \\(p = 0.999\\) ci sta dicendo che, molto probabilmente, questo \u00e8 di spam; di converso, se il modello restituisce \\(p = 0.003\\) allora \u00e8 molto probabile che il messaggio non sia spam. Cosa accade per\u00f2 nel caso in cui \\(p = 0.505\\)?</p>"},{"location":"material/03_ml/07_metrics/lecture/#soglia-di-decisione","title":"Soglia di decisione","text":"<p>L'esempio precedente ci fa comprendere come per passare da una probabilit\u00e0 ad una classe sia necessario definire una soglia di decisione: un valore oltre questa soglia indicher\u00e0, ad esempio, che la mail ricevuta \u00e8 di spam, mentre uno al di sotto della soglia ci suggerir\u00e0 che non lo \u00e8.</p> <p>Ovviamente, la tentazione potrebbe essere quella di presupporre che la soglia di decisione sia sempre pari a \\(0.5\\): questo, ovviamente, non \u00e8 vero, in quanto la soglia dipende dal problema, ed \u00e8 un valore che bisogna stabilire in base al problema affrontato. Introduciamo alcune metriche che possono essere usate in tal senso.</p>"},{"location":"material/03_ml/07_metrics/lecture/#metriche-per-i-classificatori","title":"Metriche per i classificatori","text":"<p>Continuiamo a concentrarci sul caso della classificazione dello spam, ed introduciamo il concetto di classe positiva e classe negativa.</p> <p>In particolare, la classe positiva sar\u00e0 rappresentata da tutte le mail di spam, mentre la classe negativa sar\u00e0 rappresentata dalle mail non spam. In tal senso, le predizioni del modello potranno essere di quattro tipi:</p> <ul> <li>nel primo caso, il modello classificher\u00e0 correttamente una mail di spam. In questo caso, si parla di vero positivo, o true positive (TP);</li> <li>nel secondo caso, il modello classificher\u00e0 correttamente una mail legittima. In questo caso, si parla di vero negativo, o true negative (TN);</li> <li>nel terzo caso, il modello classificher\u00e0 una mail di spam come legittima. In questo caso, si parla di falso negativo, o false negative (FN);</li> <li>nel quarto caso, il modello classificher\u00e0 una mail legittima come di spam. In questo caso, si parla di falso positivo, o false positive (FP).</li> </ul> <p>In pratica, un TP (TN) si ha quando il modello predice correttamente la classe positiva (negativa), mentre un FP (FN) si ha quando il modello predice in maniera non corretta la classe positiva (negativa).</p>"},{"location":"material/03_ml/07_metrics/lecture/#accuratezza","title":"Accuratezza","text":"<p>L'accuratezza \u00e8 la prima metrica che vedremo per la valutazione dei modelli di classificazione. Informalmente, possiamo definirla come la percentuale di predizioni corrette effettuate dal nostro modello, e definirla come:</p> \\[ AC = \\frac{C}{T} \\] <p>dove \\(C\\) \u00e8 il numero totale di predizioni corrette, mentre \\(T\\) \u00e8 il numero totale di predizioni. Nel caso della classificazione binaria, possiamo calcolare l'accuratezza come segue:</p> \\[ AC = \\frac{TP + TN}{TP + TN + FP + FN} \\] <p>Immaginiamo ad esempio di aver ricevuto \\(100\\) email, tra cui \\(10\\) di spam. Il nostro spam detector ha individuato correttamente \\(5\\) messaggi di spam, e classificato per sbaglio come spam \\(5\\) messaggi legittimi. Allora:</p> \\[ AC = \\frac{TP+TN}{TP+TN+FP+FN}=\\frac{5+85}{5+85+5+5} \\] <p>In questo caso, l'accuratezza del modello \u00e8 pari a \\(0.90\\), o del \\(90\\%\\), il che significa che il nostro modello \u00e8 in grado di fare \\(90\\) predizioni su \\(100\\). Buon risultato, giusto?</p> <p>In realt\u00e0, non necessariamente. Infatti, delle mail che abbiamo ricevuto, \\(90\\) sono legittime, e \\(10\\) di spam. Questo significa che il modello \u00e8 stato in grado di individuare soltanto il \\(50\\%\\) dello spam ricevuto, ed ha inoltre classificato un buon \\(7\\%\\) delle email legittime come spam. Tra cui, prevedibilmente, quella che ci comunicava notizie di vitale importanza. In sostanza, il nostro modello ha un'efficacia \"vera e propria\" al pi\u00f9 in un caso su due.</p> <p>Di conseguenza, l'accuratezza non ci racconta \"tutta la storia\" quando lavoriamo su un dataset sbilanciato come questo, dove vi \u00e8 una disparit\u00e0 significativa tra la classe positiva e quella negativa.</p>"},{"location":"material/03_ml/07_metrics/lecture/#la-precisione","title":"La precisione","text":"<p>La precisione \u00e8 una metrica che prova a risolvere alcuni dei problemi dell'accuratezza valutando quale sia la proporzione di valori per la classe positiva identificati correttamente.</p> <p>La definizione analitica della precisione \u00e8 la seguente:</p> \\[ PR = \\frac{TP}{TP+FP} \\] <p>In pratica, riferendoci al nostro solito esempio, la precisione \u00e8 data dal rapporto tra le mail di spam riconosciute come tali e la somma tra queste e le mail legittime riconosciute come spam. Provando a calcolarla:</p> \\[ PR = \\frac{5}{5+5} = 0.5 \\] <p>Il modello ha quindi una precisione del \\(50\\%\\) nel riconoscere una mail di spam.</p>"},{"location":"material/03_ml/07_metrics/lecture/#il-recall","title":"Il recall","text":"<p>Il recall, traducibile in italiano come richiamo, verifica la porzione di veri positivi correttamente identificata dall'algoritmo, ed \u00e8 espresso come:</p> \\[ R = \\frac{TP}{TP+FN} \\] <p>Nel nostro caso, il recall sar\u00e0 quindi dato dal rapporto tra le mail correttamente indicate come spam e la somma tra le stesse e quelle erroneamente indicate come legittime. Va da s\u00e8 che anche in questo caso possiamo calcolarlo:</p> \\[ R = \\frac{5}{5+5} \\] <p>Cos\u00ec come la precisione, il recall \u00e8 pari a \\(0.5\\), ovvero \u00e8 del \\(50\\%\\).</p>"},{"location":"material/03_ml/07_metrics/lecture/#tuning-della-soglia-di-decisione","title":"Tuning della soglia di decisione","text":"<p>Per valutare l'effiacia del modello dobbiamo esaminare congiuntamente la precisione ed il recall. Sfortunatamente, questi due valori sono spesso in contrapposizione: spesso, infatti, migliorare la precisione riduce il recall, e viceversa. Per comprendere empiricamente questo concetto, facciamo un esempio con il nostro spam detector, immaginando di aver impostato la soglia di decisione a \\(0.6\\). I risultati sono mostrati nella figura successiva.</p> <p></p> <p>Calcoliamo la precisione e il recall in questo caso:</p> \\[ P = \\frac{TP}{TP+FP}=\\frac{4}{4+1} = 0.8 \\\\ R = \\frac{TP}{TP+FN}=\\frac{4}{4+2} = 0.66 \\] <p>Proviamo ad aumentare la soglia di decisione, portandola al \\(75\\%\\).</p> <p></p> \\[ P = \\frac{TP}{TP+FP}=\\frac{3}{3} = 1 \\\\ R = \\frac{TP}{TP+FN}=\\frac{3}{3+3} = 0.5 \\] <p>Proviamo infine a diminuire la soglia di decisione, portandola al \\(50%\\).</p> <p></p> \\[ P = \\frac{TP}{TP+FP}=\\frac{4}{4+3} \\approx 0.57 \\\\ R = \\frac{TP}{TP+FN}=\\frac{4}{4+2} = 0.66 \\] <p>Come possiamo vedere, la soglia di detection agisce su precisione e recall; non \u00e8 per\u00f2 possibile aumentarli contemporaneamente, per cui occorre scegliere un valore tale per cui, ad esempio, si massimizzi la media. La realt\u00e0 \u00e8 che, per\u00f2, dipende sempre dall'applicazione: se non abbiamo paura di perdere mail legittime, allora possiamo abbassare la soglia di decisione, aumentando il recall; viceversa, se siamo disposti ad eliminare manualmente un po' di spam, potremo alzare la soglia di decisione, aumentando la precisione.</p>"},{"location":"material/03_ml/07_metrics/lecture/#metriche-per-i-regressori","title":"Metriche per i regressori","text":"<p>Definiamo brevemente alcune delle metriche che \u00e8 possibile utilizzare per la valutazione delle performance di un modello di regressione.</p>"},{"location":"material/03_ml/07_metrics/lecture/#mean-squared-error-mse","title":"Mean Squared Error (MSE)","text":"<p>Abbiamo gi\u00e0 visto questa metrica quando abbiamo parlato della regressione. L'errore quadratico medio \u00e8 definito come:</p> \\[ MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i-\\hat{y}_i)^2 \\] <p>Questo errore, implementato in Scikit Learn dalla funzione <code>mean_squared_error()</code>, permette di tenere conto di eventuali errori negativi e positivi, ma viene influenzato dalla grandezza assoluta delle variabili. In altre parole, un errore dell'\\(1\\%\\) su un valore \\(y=100\\) sar\u00e0 pi\u00f9 influente di un errore del \\(50\\%\\) su un valore \\(y=1\\).</p> <p>Ovviamente, tanto \u00e8 minore l'MSE, tanto \u00e8 migliore il modello considerato.</p>"},{"location":"material/03_ml/07_metrics/lecture/#mean-absolute-percentage-error-mape","title":"Mean Absolute Percentage Error (MAPE)","text":"<p>Il mean absolute percentage error viene calcolato mediante il rapporto tra il valore assoluto della differenza tra i valori veri e quelli predetti dal regressore e i valori veri stessi. Tale rapporto viene quindi mediato sull'insieme dei campioni, e ne viene dedotta la percentuale. La formula \u00e8 la seguente:</p> \\[ MAPE = \\frac{1}{n} \\sum_{i=1}^n \\frac{|y_i - \\hat{y}_i|}{max (\\epsilon, y_i)} \\% \\] <p>Il MAPE \u00e8 implementato in Scikit Learn mediante la funzione <code>mean_average_percentage_error()</code>.</p> <p>Il vantaggio principale derivante dall'uso del MAPE sta nel fatto che l'uso del valore assoluto elimina eventuali annullamenti derivanti da contributi di segno opposto. Inoltre, la presenza del valore vero a denominatore fa in modo che la metrica sia sensibile agli errori relativi.</p> <p>Anche in questo caso, un valore di MAPE basso indica un'ottima approssimazione.</p>"},{"location":"material/03_ml/07_metrics/lecture/#r2-e-varianza-spiegata","title":"\\(R^2\\) e varianza spiegata","text":"<p>Il valore \\(R^2\\) determina la proporzione della varianza del valore vero che viene spiegata dal modello. In pratica, ci permette di definire quanta della variabilit\u00e0 del fenomeno (ovvero, del modo in cui il fenomeno combina le \\(n\\) variabili indipendenti per ottenere le \\(m\\) variabili dipendenti) viene correttamente caratterizzata attraverso il modello considerato.</p> <p>Il valore di \\(R^2\\) pu\u00f2 oscillare tra \\(1\\) e \\(- \\infty\\), ovvero tra la modellazione completa dell'intera variabilit\u00e0 del fenomeno ed un modello totalmente incorrelato allo stesso.</p> <p>Il valore di \\(R^2\\) \u00e8 definito come:</p> \\[ R^2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y_i})^2}{\\sum_{i=1}^n (y_i-avg(y_i))} \\] <p>con:</p> \\[ avg(y_i) = \\frac{1}{n} \\sum_{i=1}^n y_i \\] <p>Il valore \\(R^2\\) \u00e8 modellato in Scikit Learn mediante la funzione <code>r2_score()</code>, ed in alcuni casi \u00e8 anche presente come metodo all'interno degli stimatori stessi.</p>"},{"location":"material/03_ml/08_clustering/01_intro/","title":"8.1 - Il clustering","text":"<p>Il clustering \u00e8 l'operazione di categorizzare dei campioni in un dataset senza che questi abbiano necessariamente un'etichetta determinata a priori.</p> <p>Per fare un esempio, potremmo suddividere i nostri album musicali sulla base delle sonorit\u00e0 ispirate dal loro ascolto: in questo caso, non ci staremmo affidando ad una certa \"etichetta\", come ad esempio l'anno di produzione o l'artista, ma ad un concetto molto pi\u00f9 \"empirico\", ovvero la vicinanza o meno dell'album ai nostri gusti musicali.</p> <p>Ovviamente, dato che nel clustering i campioni non considerano una label, stiamo parlando di apprendimento non supervisionato. Se i campioni fossero etichettati, avremmo una normale procedura di classificazione.</p> <p>Il clustering pu\u00f2 avere numerose applicazioni: ad esempio, potrebbe essere usato per segmentare il mercato mediante dei profili di clientela simili, oppure per suddividere le immagini in zone simili, o ancora per individuare delle anomalie all'interno di un insieme di dati.</p> <p>Una volta che il clustering \u00e8 completo, ad ogni cluster viene assegnato un certo identificativo, che ci permette in qualche modo di \"condensare\" e \"riassumere\" le informazioni dell'intero cluster. Quest'assegnazione pu\u00f2 anche essere usata come ingresso ad altri sistemi di machine learning, ad esempio di classificazione, che possono usare l'identificativo assegnato come una vera e propria label.</p>"},{"location":"material/03_ml/08_clustering/01_intro/#tipologie-di-clustering","title":"Tipologie di clustering","text":"<p>La scelta di un algoritmo di clustering deve essere condotta sulla base della scalabilit\u00e0 dello stesso. Infatti, laddove alcuni algoritmi di clustering confrontano tra loro ogni possibile coppia di dati, con una complessit\u00e0 \\(O(n^2)\\) per \\(n\\) campioni, altri, come il k-means, effettuano un numero molto pi\u00f9 limitato di operazioni, ottenendo una complessit\u00e0 nell'ordine di \\(O(n)\\), il che cambia radicalmente la situazione nel caso di dataset con milioni di campioni. Tuttavia, ogni algoritmo ha anche diversi vantaggi e svantaggi che devono essere valutati sulla base dell'applicazione scelta.</p> <p>In generale, abbiamo quattro diverse categorie di clustering:</p> <ul> <li>nel centroid-based clustering, i dati sono organizzati secondo la loro distanza da dei centroidi, ovvero dei campioni considerati come \"base\" per ciascun cluster. Questo tipo di algoritmi risulta essere mediamente efficace, ma \u00e8 sensibile alle condizioni iniziali ed alla presenza di eventuali outliers;</li> <li>nel density-based clustering, i dati sono organizzati in aree ad alta densit\u00e0. Ci\u00f2 permette la connessione di cluster di forma arbitraria, e facilita inoltre l'individuazione di outlier, che per definizione sono nelle zone a minore densit\u00e0 di campioni. Possono per\u00f2 essere sensibili a dataset con densit\u00e0 variabile ed alta dimensionalit\u00e0;</li> <li>nel distribution-based clustering, si suppone che i dati abbiano distribuzione gaussiana, e siano quindi suddivisibili come tali. Questo tipo di algoritmi non \u00e8 efficiente se non si conosce a priori il tipo di distribuzione dei dati;</li> <li>nello hierarchical clustering viene creato un albero a partire dai dati. Questo tipo di clustering \u00e8 particolarmente efficace nel caso si trattino certi tipi di dati, come ad esempio le tassonomie, e prevede che possa essere selezionato un numero ridotto di cluster tagliando l'albero al giusto livello.</li> </ul>"},{"location":"material/03_ml/08_clustering/01_intro/#workflow-del-clustering","title":"Workflow del clustering","text":"<p>L'esecuzione di un algoritmo di clustering prevede tre step:</p> <ol> <li>nel primo, dobbiamo preparare i dati, effettuando le operazioni che abbiamo visto in precedenza per la classificazione e la regressione;</li> <li>nel secondo, dovremo definire una metrica di similarit\u00e0;</li> <li>nel terzo, eseguiremo l'algoritmo vero e proprio.</li> </ol> <p>Concentriamoci per un attimo sul secondo step. Definire una metrica di similarit\u00e0 significa nella pratica stabilire quando due campioni risultano essere simili tra loro. In tal senso, \u00e8 possibile operare in due modi:</p> <ul> <li>la metrica pu\u00f2 essere scelta manualmente, ovvero scegliendo le feature da considerare nella valutazione della distanza tra i campioni;</li> <li>oppure, la metrica pu\u00f2 essere scelta in maniera automatica a partire da un embedding, ovvero da una rappresentazione a dimensionalit\u00e0 ridotta del dato iniziale.</li> </ul> <p>Nel primo caso questo avviene in modo abbastanza intuitivo: se, ad esempio, volessimo suddividere un insieme di scarpe in base a taglia e prezzo, potremmo considerare la distanza euclidea come rappresentativa dello \"spazio\" che intercorre tra due campioni. Questo approccio, tuttavia, \u00e8 efficace soltanto nel caso di campioni a bassa dimensionalit\u00e0.</p> <p>Il secondo caso \u00e8 invece preferibile nel momento in cui si vanno a considerare dei dati ad alta dimensionalit\u00e0: infatti, in queste situazioni si rischia di incorrere nel fenomeno della curse of dimensionality, che rende difficile distinguere tra due campioni differenti, per cui si tende ad estrarre delle rappresentazioni \"ridotte\" dei dati a partire dalle quali applicare il concetto di distanza.</p>"},{"location":"material/03_ml/08_clustering/01_intro/#applicazione-di-un-algoritmo-di-clustering-il-k-means","title":"Applicazione di un algoritmo di clustering: il K-Means","text":"<p>Vediamo adesso come usare il pi\u00f9 conosciuto ed utilizzato algoritmo di clustering, ovvero il k-means, algoritmo centroid-based che raggruppa i campioni in \\(k\\) diversi cluster assegnando ogni dato in base alla distanza dal centroide del cluster stesso. Il k-means ha diverse ipotesi alla base, tra cui la pi\u00f9 restrittiva \u00e8 una, ovvero quella legata alla conoscenza del numero iniziale di cluster \\(k\\).</p> <p>Una volta fissato questo valore, l'algoritmo lavora in tre step successivi:</p> <ol> <li>al primo step, l'algoritmo sceglie casualmente \\(k\\) centroidi tra i diversi dati a disposizione;</li> <li>al secondo step, l'algoritmo assegna ogni punto al centroide pi\u00f9 vicino, definendo i \\(k\\) cluster iniziali;</li> <li>al terzo step, l'algoritmo ricalcola il centroide considerando il valore medio di tutti i punti del cluster, e ritorna allo step 2.</li> </ol> <p>Il k-means proseguir\u00e0 fino a che i cluster calcolati al punto 2 non saranno stabili o, nei casi pi\u00f9 complessi, fino a che non sar\u00e0 raggiunto il numero massimo di iterazioni impostato in fase di inizializzazione. In figura possiamo osservare una spiegazione visiva del funzionamento dell'algoritmo.</p> <p> </p> Figura 20.1 - Step dell'algoritmo K-Means"},{"location":"material/03_ml/08_clustering/01_intro/#clustering-in-scikit-learn","title":"Clustering in Scikit Learn","text":"<p>Per implementare un algoritmo di clustering in Scikit Learn dovremo fare affidamento sulla classe <code>KMeans()</code>, utilizzabile come segue:</p> <pre><code>from sklearn.cluster import KMeans\nimport numpy as np\nX = np.array([[1, 2], [2, 1], [5, 2], [3, 3]])\ncl = KMeans()\ncl.fit(X)\n</code></pre>"},{"location":"material/03_ml/08_clustering/01_intro/#scelta-del-valore-ottimale-di-cluster","title":"Scelta del valore ottimale di cluster","text":"<p>La scelta del valore ottimale di \\(k\\) \u00e8 un procedimento emnpirico, in quanto non abbiamo a disposizione delle vere e proprie label per la verifica dell'uscita dell'algoritmo. In tal senso, abbiamo a disposizione sia delle metriche, che vedremo in seguito, sia degli approcci pi\u00f9 qualitativi, che dipendono dai concetti di cardinalit\u00e0 e magnitudine del clustering.</p> <p>In particolare, per cardinalit\u00e0 si intende il numero di campioni per ogni cluster, mentre per magnitudine la somma delle distanze di tutti i campioni in un cluster dal centroide. Immaginiamo di essere in un caso come quello descritto nella seguente figura.</p> <p> </p> Figura 20.2 - Rapporto tra cardinalit\u00e0 e magnitudine dei cluster <p>Prevedibilmente, il rapporto tra cardinalit\u00e0 e magnitudine dovrebbe essere all'incirca lineare. Quindi, come si pu\u00f2 vedere dalla figura precedente, ci potrebbe essere qualcosa che non va con il cluster \\(4\\).</p> <p>A questo punto, avendo valutato empiricamente la possibile presenza di un problema qualitativo con il clustering, possiamo provare ad eseguire l'algoritmo per un valore crescente di \\(k\\). Proviamo a plottare questo valore in rapporto alla somma delle magnitudini del risultato, che diminuir\u00e0 all'aumentare di \\(k\\); un valore ottimale per \\(k\\) \u00e8 quello che si ottiene quando questo grafico tende a stabilizzarsi, ad esempio considerando il valore per cui la derivata diventa maggiore di -1 (e quindi l'angolo della funzione dei \\(k\\) \u00e8 maggiore di \\(135\u00b0\\)).</p> <p> </p> Figura 20.3 - Rapporto tra il numero dei cluster e la magnitudine"},{"location":"material/03_ml/08_clustering/01_intro/#un-altro-algoritmo-il-dbscan","title":"Un altro algoritmo: il DBSCAN","text":"<p>Il DBSCAN \u00e8 un algoritmo di clustering di tipo agglomerativo density-based che opera considerando due parametri principali:</p> <ul> <li>la distanza massima \\(\\epsilon\\) per considerare due punti come appartenenti allo stesso cluster;</li> <li>il numero minimo di campioni \\(m\\) per il quale \u00e8 possibile definire un cluster.</li> </ul> <p>Nella pratica, il DBSCAN seleziona un campione casuale tra quelli non visitati, e valuta se ci sono \\(m\\) campioni all'interno della distanza \\(\\epsilon\\), nel qual caso si ha un core point. In alternativa, se il numero di campioni presenti in \\(\\epsilon\\) \u00e8 minore di \\(m\\), ma comunque maggiore di 0, i campioni si dicono \\(density reachable\\) e, se connessi ad un core point, appartengono allo stesso cluster. Infine, se non vi sono campioni presenti in \\(\\epsilon\\), allora il punto \u00e8 isolato, ed \u00e8 interpretato come un outlier. Un'interpretazione visiva \u00e8 quella proposta in figura; in particolare, i punti in rosso definiscono diversi core points, i punti in giallo sono density reachable, e quindi fanno parte dello stesso cluster dei core points, mentre \\(N\\) \u00e8 un outlier.</p> <p> </p> Figura 20.4 - Algoritmo DBSCAN.  Di Chire - Opera propria, CC BY-SA 3.0, Wikipedia"},{"location":"material/03_ml/08_clustering/02_k_means/","title":"Approfondimento sul k-Means","text":""},{"location":"material/03_ml/08_clustering/02_k_means/#vantaggi-del-k-means","title":"Vantaggi del k-Means","text":"<ul> <li>relativamente semplice da implemenare</li> <li>in grado di scalare a grossi dataset</li> <li>garantisce la convergenza</li> <li>\u00e8 possibile scegliere una posizione iniziale adeguata per i centroidi</li> <li>si adatta facilmente a nuovi campioni</li> <li>generalizza a cluster di diverse forme e dimensioni, come cluster ellittici</li> </ul>"},{"location":"material/03_ml/08_clustering/02_k_means/#generalizzazione-del-k-means","title":"Generalizzazione del k-means","text":"<p>Cosa accade quando i cluster sono di diverse densit\u00e0 e dimensioni? Vediamo nella seguente figura. Compariamo i cluster che intuitivamente possiamo individuare a sinistra con i cluster che vengono individuati dal k-means a destra. La comparazione mostra come il k-means possa avere dei problemi su certi dataset.</p> <p>TODO: FIGURA</p> <p>Per effettuare il clsutering di cluster non bilanciati come quelli mostrati nella figura precedente, possiamo adattare (o, meglio, generalizzare) il k-means. Nella figura 2, le linee mostrano i confini dei cluster dopo la generalizzazione del k-means come:</p> <ul> <li>a sinistra: mancanza di generalizzazione, il che risulta in un confine tra cluster antiintuitivo</li> <li>al centro: permette diverse dimensioni dei clsuter, il che risulta in cluster pi\u00f9 intuitoivi di diverese dimensioni</li> </ul>"},{"location":"material/03_ml/08_clustering/02_k_means/#svantaggi","title":"Svantaggi","text":"<ul> <li>scelta del \\(k\\) manualmente</li> <li>dipendenza dai valori iniziali: per un basso valore di \\(K\\), possiamo mitrigare questa dipendenza eseguendo il k-means diverse volte con diversi valori iniziali e scegliere i migliori risultati. Man mano che \\(k\\) aumenta, abbiamo bisogno di versioni avanzate del k-means per individuare miglioriv alori dei centroidi iniziali (ovvero il seeding del k-means).</li> <li>clustering di dati di varie dimensioni e densit\u00e0: il k-means ha problemi nel clustering dei dati quando i cluster sono di varie dimensioni e densit\u00e0. Per effettuare il clustering di questi dati, dobbiamo generalizzare il k-menas. Per generalizzarlo: http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/clustering.pdf</li> <li>clustering di outliner: i centroidi possono essere \"trascinati\" dagli outlier, o gli outlier potrebbero avere il loro cluster invece di essere ignorati. Dovremo considerare la rimozione degli outlier prima del clustering.</li> <li>scaling con il numero di dimensione: man mano che il numero di dimensioni aumenta, una misura di similarit\u00e0 basata sulla distanza converge ad un valroe costante per ogni possibile esempio. E' quindi necessario ridurre la dimensionalit\u00e0 oi usando la PCA sui dati delle feature o suando delle tecniche di clsutering spettrale.</li> </ul> <p>In particolare, lo spectral clustering evita il problema della curse of dimensionality aggiungendo uno step prima dell'algoritmo:</p> <ol> <li>ridurre la dimensionalit\u00e0 dei dati delle feature usando la PCA</li> <li>proiettare tutti i data point in un sottospazio a minore dimensionalit\u00e0\u00e0</li> <li>effettuare il clsutering dei dati in questo sottospazio usando l'algoritmo di nostra scelta</li> </ol> <p>Quindi, lo spectral clustering non \u00e8 un algoritmo di clustering separato, ma uno step predcdente al clustering che possiamo usare con un qualsioasi algoritmo di clsutering. https://github.com/petermartigny/Advanced-Machine-Learning/blob/master/DataLab2/Luxburg07_tutorial_4488%5B0%5D.pdf</p>"},{"location":"material/03_ml/08_clustering/02_k_means/#implementazione-del-k-means","title":"Implementazione del k-Means","text":"<p>Possiamo implementare ilm k_means usando le API k-Means di TensorFlow. L'APIO di TensorfLow ci permette di scalare il k-means fornendo le seguenti funzionalit\u00e0:</p> <ul> <li>clusteering usnado mini-batches invece dell'intero dataset</li> <li>scelta </li> </ul> <p>ESEMPI</p> <p>https://colab.research.google.com/gist/anhelus/2d436e290996d8fdb1b52cdf68417479/colab-manual-similarity-with-chocolates.ipynb</p> <p>https://colab.research.google.com/github/google/eng-edu/blob/main/ml/clustering/clustering-supervised-similarity.ipynb?utm_source=ss-clustering&amp;utm_campaign=colab-external&amp;utm_medium=referral&amp;utm_content=clustering-supervised-similarity</p> <p>Reference del k-means seeding: https://arxiv.org/abs/1209.1960</p>"},{"location":"material/03_ml/08_clustering/03_dbscan/","title":"03 dbscan","text":""},{"location":"material/03_ml/08_clustering/03_dbscan/#206-un-altro-algoritmo-il-dbscan","title":"20.6 - Un altro algoritmo: il DBSCAN","text":"<p>Il DBSCAN \u00e8 un algoritmo di clustering di tipo agglomerativo density-based che opera considerando due parametri principali:</p> <ul> <li>la distanza massima \\(\\epsilon\\) per considerare due punti come appartenenti allo stesso cluster;</li> <li>il numero minimo di campioni \\(m\\) per il quale \u00e8 possibile definire un cluster.</li> </ul> <p>Nella pratica, il DBSCAN seleziona un campione casuale tra quelli non visitati, e valuta se ci sono \\(m\\) campioni all'interno della distanza \\(\\epsilon\\), nel qual caso si ha un core point. In alternativa, se il numero di campioni presenti in \\(\\epsilon\\) \u00e8 minore di \\(m\\), ma comunque maggiore di 0, i campioni si dicono \\(density reachable\\) e, se connessi ad un core point, appartengono allo stesso cluster. Infine, se non vi sono campioni presenti in \\(\\epsilon\\), allora il punto \u00e8 isolato, ed \u00e8 interpretato come un outlier. Un'interpretazione visiva \u00e8 quella proposta in figura; in particolare, i punti in rosso definiscono diversi core points, i punti in giallo sono density reachable, e quindi fanno parte dello stesso cluster dei core points, mentre \\(N\\) \u00e8 un outlier.</p> <p> </p> Figura 20.4 - Algoritmo DBSCAN.  Di Chire - Opera propria, CC BY-SA 3.0, Wikipedia"},{"location":"material/03_ml/08_clustering/04_metrics/","title":"21 - Metriche di clustering","text":"<p>Cos\u00ec come per la regressione e la classificazione, esistono delle metriche appositamente progettate per valutare la qualit\u00e0 dei risultati ottenuti da un algoritmo di clustering. Nello specifico, valuteremo l'adjusted rand index ed il silhouette score.</p>"},{"location":"material/03_ml/08_clustering/04_metrics/#211-adjusted-rand-index","title":"21.1 - Adjusted Rand Index","text":"<p>Sia \\(C\\) l'insieme dei cluster \"veri\" assegnati ad un certo dataset, e \\(K\\) l'insieme dei cluster assegnati a valle dell'applicazione di un algoritmo di clustering. Allora definiamo l'indice di Rand come:</p> \\[ RI = \\frac{a + b}{C_2^n} \\] <p>dove:</p> <ul> <li>\\(a\\) \u00e8 il numero di coppie di campioni che appartengono allo stesso cluster sia in \\(C\\) sia a valle dell'assegnazione \\(K\\);</li> <li>\\(b\\) \u00e8 il numero di coppie di campioni che non appartengono allo stesso cluster sia in \\(C\\) sia a valle dell'assegnazione \\(K\\);</li> <li>\\(C_2^n\\) \u00e8 il numero totale di coppie di campioni presenti nel dataset.</li> </ul> <p>In pratica, se:</p> \\[ s = [s_1, s_2, s_3, s_4, s_5] \\\\ C = [s_1, s_2], [s_3, s_4, s_5] \\\\ K = [s_1, s_2, s_3], [s_4, s_5] \\\\ \\] <p>allora:</p> \\[ a = |(s_1, s_2), (s_4, s_5)| = 2 \\\\ b = |(s_1, s_4), (s_1, s_5), (s_4, s_2), (s_5, s_2)| = 4 \\\\ C_2^n = \\frac{|s|*|s-1|}{2} = 5 * 2 = 10 \\] <p>Di conseguenza, \\(RI=\\frac{6}{10}=0.6\\).</p> <p>Si pu\u00f2 dimostrare non \u00e8 garantito che l'indice di Rand assuma valore vicino allo zero a seguito di un'assegnazione completamente casuale dei cluster da parte dell'algoritmo.</p> <p>Possiamo quindi tenere conto dell'aspettazione \\(E[RI]\\) di ottenere un'assegnazione casuale mediante l'indice di Rand modificato:</p> \\[ ARI = \\frac{RI - E[RI]}{max(RI) - E[RI]} \\] <p>In Scikit Learn, l'indice di Rand modificato \u00e8 ottenuto usando la funzione <code>adjusted_rand_score()</code> del package <code>metrics</code>.</p> <p>Il valore ottimale dell'ARI \u00e8 pari proprio ad 1, caso in cui il clustering \u00e8 riuscito a predire correttamente tutte le classi dei singoli campioni. Valori prossimi allo zero o negativi (fino a -1) contraddistinguono invece labeling non corretti.</p> <p>Una metrica di questo tipo ha l'ovvio vantaggio di essere facilmente interpretabile, oltre che di non essere collegata ad uno specifico algoritmo di clustering. Tuttavia, vi \u00e8 una criticit\u00e0 indotta dalla necessit\u00e0 di conoscere a priori il labeling esatto dei campioni (il che, quindi, potrebbe farci propendere per l'uso di un algoritmo di classificazione).</p>"},{"location":"material/03_ml/08_clustering/04_metrics/#212-silhouette-score","title":"21.2 - Silhouette Score","text":"<p>A differenza dell'ARI, il silhouette score non richiede la conoscenza aprioristica delle label vere; per valutare la qualit\u00e0 del clustering, invece, questa metrica si affida a valutazioni sulla separazione dei cluster, ottenendo un valore tanto pi\u00f9 alto quanto questi sono tra di loro ben separati e definiti.</p> <p>In particolare, il silhouete score per un singolo campione \u00e8 definito come:</p> \\[ s = \\frac{b-a}{max(a, b)} \\] <p>dove:</p> <ul> <li>\\(a\\) \u00e8 la distanza media tra un campione e tutti gli altri campioni appartenenti allo stesso cluster;</li> <li>\\(b\\) \u00e8 la distanza media tra un campione e tutti gli altri campioni appartenenti al cluster pi\u00f9 vicino.</li> </ul> <p>Questa metrica, implementata grazie alla funzione <code>silhouette_score()</code> del package <code>metrics</code>, \u00e8 anch'essa di facile interpretazione, in quanto pu\u00f2 assumere valori compresi nell'intervallo \\([-1, 1]\\), con:</p> <ul> <li>valori prossimi a \\(-1\\) che indicano un clustering non corretto;</li> <li>valori prossimi allo \\(0\\) che indicano cluster sovrapposti;</li> <li>valori prossimi a \\(+1\\) che indicano cluster densi e ben suddivisi.</li> </ul> <p>Uno svantaggio del silhouette score \u00e8 che, in generale, pu\u00f2 variare in base all'algoritmo utilizzato.</p>"},{"location":"material/04_sklearn/01_intro/","title":"1 - Una breve introduzione a Scikit Learn","text":"<p>Notebook di accompagnamento</p> <p>Per questa lezione esiste un notebook di accompagnamento, reperibile a questo indirizzo.</p> <p>Scikit Learn \u00e8 una delle librerie per il machine learning tra le pi\u00f9 utilizzate in Python. Questo avviene principalmente a causa di tre fattori:</p> <ul> <li>un esteso supporto ad una grande variet\u00e0 di algoritmi di machine learning;</li> <li>la semplicit\u00e0 di utilizzo della libreria;</li> <li>la perfetta integrazione con NumPy e Pandas.</li> </ul> <p>Per iniziare, quindi, diamo una panoramica ad ampio spettro sulle potenzialit\u00e0 della libreria.</p> <p>Installazione di Scikit Learn</p> <p>Ovviamente, prima di inizizare, installiamo la libraria:</p> <pre><code>pip install scikit-learn\n</code></pre>"},{"location":"material/04_sklearn/01_intro/#stimatori-e-transformer","title":"Stimatori e transformer","text":"<p>Scikit Learn si basa su due concetti fondamentali, ovvero quelli di stimatore (estimator) e transformer.</p> <p>In particolare, uno stimatore \u00e8 un oggetto che implementa uno specifico algoritmo di machine learning, mentre un trasformer permette di effettuare delle trasformazioni sui dati. Per esempio, un'istanza della classe <code>RandomForestClassifier</code> \u00e8 uno stimatore, mentre un'istanza della classe <code>StandardScaler</code> \u00e8 un transformer.</p> <p>Gli stimatori ed i transformer offrono un'interfaccia comune, la quale offre (nella maggior parte dei casi) i metodi <code>fit</code> e <code>transform</code> per, rispettivamente, addestrare l'algoritmo (<code>fit</code>) ed effettuare le predizioni (<code>transform</code>). Tuttavia, \u00e8 importante notare come ogni stimatore e transformer abbiano parametri specifici e dipendenti dalla natura dell'algoritmo utilizzato; ogni algoritmo, inoltre, andr\u00e0 verificato secondo delle opportune metriche, che permettono di definire, in termini percentuali o assoluti, l'accuratezza dell'algoritmo utilizzato.</p> <p>OOP in NumPy</p> <p>Gli stimatori derivano tutti da una classe base comune, chiamata <code>BaseEstimator</code>. Questa scelta garantisce l'interfaccia comune accennata in precedenza e, conseguentemente, il rispetto dei principi di incapsulamento e polimorfismo. Anche i transformer offrono un'interfaccia comune, basata tuttavia sull'uso del <code>TransformerMixin</code>, ovvero di un particolare tipo di classe (detta, per l'appunto, mixin) che permette di implementare meccanismi di ereditariet\u00e0 multipla. </p>"},{"location":"material/04_sklearn/01_intro/#preprocessing","title":"Preprocessing","text":"<p>Quando abbiamo introdotto i concetti alla base del machine learning, abbiamo visto come sia spesso necessario effettuare una serie di operazioni di preprocessing sui dati. Scikit-Learn offre un gran numero di strumenti per farlo; tra questi, vale la pena ricordarne tre in particolare, ovvero:</p> <ul> <li>la funzione <code>train_test_split</code>, utile a suddividere il dataset in un insieme di training ed uno di test;</li> <li>gli imputer come <code>SimpleImputer()</code> transformer che ci permettono di assegnare eventuali valori mancanti all'interno del dataset;</li> <li>i transformer, come il gi\u00e0 citato <code>StandardScaler()</code>, che permettono di categorizzare e normalizzare i dati.</li> </ul>"},{"location":"material/04_sklearn/01_intro/#convenzioni","title":"Convenzioni","text":"<p>Gli stimatori in Scikit Learn seguono alcune regole; elenchiamone alcune tra le pi\u00f9 rilevanti.</p>"},{"location":"material/04_sklearn/01_intro/#type-casting","title":"Type casting","text":"<p>Quando possibile, Scikit Learn fa in modo che i dati di ingresso mantengano il loro tipo; in caso contrario, saranno convertiti in <code>float64</code>. Ad esempio:</p> <pre><code>import numpy as np\nfrom sklearn import kernel_approximation\nrng = np.random.RandomState(0)\nX = rng.rand(0, 100)\nX = np.array(X, dtype='float32')\ntransformer = kernel_approximation.RBFSampler()\nX_new = transformer.fit_transform(X)\nX_new.dtype\nprint(X.dtype)              # Il risultato sar\u00e0 dtype('float32')\nprint(X_new.dtype)          # Anche qui, il risultato sar\u00e0 dtype('float32')\n</code></pre> <p>In questo esempio, il formato di <code>X</code> \u00e8 <code>float32</code>, e possiamo verificare come non cambi dopo la chiamata a <code>fit_transform(X)</code>.</p> <p>Tipo di dati e prestazioni</p> <p>L'uso di dati <code>float32</code> \u00e8 spesso pi\u00f9 efficiente rispetto all'uso del formato <code>float64</code>, in quanto permette di ridurre i requisiti sia spaziali, sia temporali. Tuttavia, ci potrebbero essere degli errori di troncamento che causando problemi di stabilit\u00e0 numerica.</p> <p>Nota</p> <p>Esistono anche degli stimatori (soprattutto regressori) che lavorano esclusivamente con dati in formato <code>float64</code>.</p>"},{"location":"material/04_sklearn/01_intro/#refitting-ed-aggiornamento-dei-parametri","title":"Refitting ed aggiornamento dei parametri","text":"<p>I parametri di uno stimatore vengono fissati passando gli opportuni argomenti al costruttore. Tuttavia, questi possono essere successivamente modificati utilizzando il metodo <code>set_params()</code>. Tuttavia, per vedere gli effetti dei nuovi valori dei parametri, dovremo provvedere a ri-addestrare il modello. Ad esempio:</p> <pre><code>X, y = load_iris(return_X_y=True)\nclf = SVC()\nclf.set_params(kernel='linear').fit(X, y)\nclf.predict(X[:10])\nclf.set_params(kernel='rbf').fit(X, y)\nclf.predict(X[:10])\n</code></pre> <p>Nel codice precedente:</p> <ul> <li>alla riga 1, carichiamo il dataset Iris;</li> <li>alla riga 2, creiamo uno stimatore di classe <code>SVC</code>;</li> <li>alla riga 3, impostiamo il parametro <code>kernel</code> del nostro stimatore a <code>linear</code>, e lo addestriamo sui dati a nostra disposizione;</li> <li>alla riga 4, effettuiamo la predizione sui primi dieci campioni con i parametri impostati in precedenza;</li> <li>alla riga 5, modifichiamo il parametro <code>kernel</code>, riaddestrando il modello con il nuovo valore impostato;</li> <li>alla riga 6, infine, effettuiamo un'altra predizione, usando il modello appena riaddestrato.</li> </ul>"},{"location":"material/04_sklearn/01_intro/#problemi-multiclasse-vs-problemi-multilabel","title":"Problemi multiclasse vs. problemi multilabel","text":"<p>Un problema si definisce multiclasse quando ad ogni campione \u00e8 possibile associare una ed una sola classe tra molte disponibili. Un problema \u00e8 invece definito come multilabel quando ad ogni campione \u00e8 possibile associare pi\u00f9 di una tra le classi disponibili.</p> <p>Ad esempio, classificare un film in base al numero di stelle ricevute pu\u00f2 essere interpretato come un problema multiclasse:</p> Film Numero di stelle Jumanji 5 Il Grinch 2 La fabbrica di cioccolato 4 <p>Se invece considerassimo il genere a cui ciascun film appartiene, potremmo trovarci di fronte ad una situazione di questo tipo:</p> Film Avventura Commedia Fantasy Crime Per bambini Jumanji Vero Falso Vero Falso Vero Il Grinch Falso Vero Vero Falso Vero La fabbrica di cioccolato Vero Falso Vero Falso Vero <p>In questo caso, avremmo diverse etichette \"vere\" per ciascun campione, per cui il problema pu\u00f2 essere impostato come un multilabel.</p> <p>Nel caso si voglia affrontare un problema multiclasse, l'apprendimento e la predizione dipendono dal formato dei dati di output:</p> <p>Quando usiamo un classificatore multiclasse, il task di learning e predizione che viene effettuato \u00e8 dipendente dal formato dei dati target. Proviamo con un array monodimensionale:</p> <pre><code>X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\ny = [0, 0, 1, 1, 2]\nclf = OneVsRestClassifier(estimator=SVC(random_state=0))\nclf.fit(X, y).predict(X)\n</code></pre> <p>Il risultato sar\u00e0:</p> <pre><code>array([0, 0, 1, 1, 2])\n</code></pre> <p>Notiamo quindi come il metodo <code>predict()</code> fornisca un array a singola dimensione, nel quale l'\\(i\\)-mo elemento \u00e8 associato alla classe predetta per l'\\(i\\)-mo campione. Se invece volessimo effettuare il fitting su un array bidimensionale, dovremmo trasformare <code>y</code>, ad esempio mediante un'operazione di one-hot encoding:</p> <pre><code>y = LabelBinarizer().fit_transform(y)\nclf.fit(X, y).predict(X)\n</code></pre> <p>In questo caso, il risultato sar\u00e0:</p> <pre><code>array([[1, 0, 0],\n[1, 0, 0],\n[0, 1, 0],\n[0, 0, 0],\n[0, 0, 0]])\n</code></pre> <p>Notiamo quindi come <code>predict()</code> restituisca un array bidimensionale, nel quale ad ogni riga \u00e8 associato un campione, con il valore <code>1</code> assegnato alla classe predetta, e <code>0</code> altrimenti. In altre parole, per il primo campione, il predittore associer\u00e0 la classe \\(0\\), per il secondo sempre la classe \\(0\\), per il terzo la classe \\(1\\), e via dicendo.</p> <p>In caso di problema multilabel dovremo usare un <code>MultiLabelBinarizer</code>:</p> <p>Notiamo che la quarta e quinta istanza restituiscono tutti zero, il che indica che non combaciano con nessuna delle tre label su cui sono state addestrate. Con gli output multilable, \u00e8 simile per un'istanza ad avere label multiple:</p> <pre><code>y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\ny = MultiLabelBinarizer().fit_transform(y)\nclf.fit(X, y).predict(X)\n</code></pre> <p>Il risultato sar\u00e0:</p> <pre><code>array([[1, 1, 0, 0, 0],\n[1, 0, 1, 0, 0],\n[0, 1, 0, 1, 0],\n[1, 0, 1, 0, 0],\n[1, 0, 1, 0, 0]])\n</code></pre> <p>Come \u00e8 possibile vedere, l'array bidimensionale restituito ha diverse label per ogni singola istanza.</p>"},{"location":"material/04_sklearn/neural_network/","title":"Rete neurale","text":"<p>L'area delle reti nuerali \u00e8 stata originariamente ispirata dall'obiettivo di modellare i sistemi neurali biologici, ma c'\u00e8 stata successivamentre divergenza, ed \u00e8 diventata una questione di ingegnerizzazione e di ottenere buoi risultati nei task di machine learning. Nonostante questo, iniziamo la discussione con una descrizione breve ed ad alto livello dei sistemi biologici che hanno ispirato buona parte di quest'area.</p>"},{"location":"material/04_sklearn/neural_network/#motivazioni-biologiche-e-connessioni","title":"MOtivazioni biologiche e connessioni","text":"<p>L'unit\u00e0 di calcolo base del cervello \u00e8 chiamata neurone. Il sistema nervoso umano ha circa 86 miliardi di neuroni connessi tra loro mediante approssimativamente \\(10^14 - 10^15\\) sinapsi. In figura 1, possiamo vedre un neurone biologico (a siunistra) ed un modello matematico di neurone (a destra).</p> <p>TODO FIGURA 1</p> <p>Ogni neurone riceve i segnali di ingresso dai suoi dendriti, e produce segnali di uscita lungo il suo singolo assione. L'assione si ramifica e si connette, mediante delle sinapsi, ai dendriti di altri neuroni. Nel modello computazionale di un neurone, i segnali che viaggiano lungo gli assoni (ad esempio, \\(x_0\\)) interagiscono in maniera moltiplicativa (ovvero, \\(w_0 x_0\\)) con le dendriti di altri neuroni sulla base della forza sinaptica a quella sinapsi (ad esempio, \\(w_0\\)). L'idea \u00e8 che la forza sinaptica (i pesi \\(w\\)) siano in grado di essere apprese e controllino la forza di influenza (e la sua direzione: eccitatoria, con pesi positivi, o inibitoria, con pesi negativi) di un neurone rispetto all'altro. Nel modello base, i dendritri portano il segnale al corpo della cellula, dove sono sommati tra loro. Se la somma finale \u00e8 oltre una certa soglia, il neurone pu\u00f2 attivarsi, mandando un segnale lungo il suo assone. Nel dmodello cmputazionale, assumiamo che la temporizzazione dell'attivazione non conti, e che solo la frequenza delle attivazioni comunichi delle informaizoni. In base a questa interpetazioni, modelliamo il tasso di attivazione di un neurone con una funzione di attivazione \\(f\\), che rappresenta la frequena dei picchi lungo l'assione.</p> <p>Storicamente, una scelta comune per la ufnzione di attivazoine \u00e8 la funzione sigmoidale \\(\\sigma\\), dal momento che prende un input a valori reali (la forza del segnale dopo la somma) e la comprime nel range tra \\(0\\) ed \\(1\\). In altre parole, ogni neurone effettua un prodotto tra gli input ed i suoi pesi, aggiunge i bias, ed applica la non linearit\u00e0, nel caso di sigmoidale \\(\\sigma(x) = \\frac{1}{1+e^{-x}}\\).</p> <p>Modello grossolano</p> <p>Sottolineamo come questo modello di neurone biologico \u00e8 molto grossolano. Nella realt\u00e0, esistono infatti motli tipi di neuroni, ognuno con diverse propriet\u00e0. I denditri effettuano dei calcoli non lineari molto complessi. Le sinapsi non sono solo un singolo peso, ma sono sistemi dinamici non  lineari complessi. Inoltre, la temporizzazione dell'attivazione \u00e8 imporatnte, il che suggerisce che la nostra approssimazione non abbia valenza. </p>"},{"location":"material/04_sklearn/neural_network/#il-singolo-neurone-come-classificatore-lineare","title":"Il singolo neurone come classificatore lineare","text":"<p>La formulazione matematica della forward computation di un neurone \u00e8 abbastanza semplice. Un neurone ha infatti la capacit\u00e0 di piacere (attivazione vicino ad uno) o meno (attivazione vicino a zero) certe regioni del suo spazio di ingresso. Quindi, con un'appropriata funzione di costo sull'output del neurone, possiamo modificare un singolo neurone in un classificatore lineare.</p> <p>Ad esempio, possiamo interpretare il valore \\(\\sigma (\\sum_i w_i x_i + b)\\) come la probabilit\u00e0 di una delle due classi di un problema binario \\(P (y_i = 1 | x_i; w)\\). La probabilit\u00e0 dell'altra classe sar\u00e0 \\(P(y_i = 0 | x_i; w) = 1 - P(y_i = 1 | x_i; w)\\), dal momento che devono essere a sommma unitaria. Con questa interpretazione, possiamo formulare la cross-entropy loss, ed ottimizzarla ci porta ad un classificatore softmax binario (conosciuto anche come regressore logistico). Dal momento che la funzione sigmoidale \u00e8 ristretta tra \\(0\\) ed \\(1\\), le predizioni di questo classificaote sono basate sul fatto che l'output del neurone sia maggiore o minore di \\(0.5\\). Per quello che rioguarda la regolarizzazione, queste possono essere interpretate come gradual forgetting, dal momento che avrebbe l'effetto di portare tutti i pesi sinaptici \\(w\\) verso zero dopo ogni aggiornamento del parametro.</p> <p>https://cs231n.github.io/neural-networks-1/</p>"},{"location":"material/04_sklearn/optimization/","title":"Reti neurali","text":""},{"location":"material/04_sklearn/optimization/#ottimizzazione","title":"Ottimizzazione","text":"<p>Abbiamo visto che ci sono due componenti chiave nel contesto dei task collegati alla classificazione.</p> <ol> <li>Una funzione di scoring parametrizzata, che mappa l'input ad un punteggio.</li> <li>Una funzione di costo che misura la qualit\u00e0 di un certo insieme di parametri sulla base di quanto bene i punteggi assegnati concordano con i label di ground truth nei dati di training. Abbiamo visto che ci sono molti modi e versioni di questo.</li> </ol> <p>Concretamente, ricordiamo che le funzioni lineari hanno la forma del tipo:</p> \\[ f(x_i, W) = W x_i \\] <p>In generale, un insieme di parametri \\(W\\) che produce le predizioni \\(\\hat{y}_i\\) per dei campioni \\(x_i\\) consistenti con le label di ground truth \\(y_i\\) ha un valore per la funzione di costo \\(L\\) molto basso. Vediamo qual \u00e8 l'ultimo componente di tutto ci\u00f2, ovvero l'ottimizzazione. Questo \u00e8 il processo di individuare l'insieme di parametri \\(W\\) che minimizza la funzione di costo.</p>"},{"location":"material/04_sklearn/optimization/#visualizzare-la-funzione-di-costo","title":"Visualizzare la funzione di costo","text":"<p>La funzione di costo sono normalmente definite in spazi ad elevata dimensionalit\u00e0, il che le rende difficili da visualizzare. Tuttavia, possiamo trovare delle intuizioni andando a vedere ci\u00f2 che accade in spazi di tipo monodimensionali o bidimensionali.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/","title":"6.2 - Foreste decisionali","text":"<p>Per foresta decisionale si intendono tutti quei modelli composti da un insieme di alberi decisionali (trattati nella lezione precedente). Il modo in cui i diversi alberi si aggregano dipende dall'algoritmo usato per l'addestramento: ad esempio, in una foresta decisionale che affronta un problema multiclasse, ogni albero potrebbe dare il suo \"voto\" ad una singola classe, e la predizione globale sarebbe quindi la classe pi\u00f9 votata. Un'altra implementazione potrebbe invece prevedere che ciascun albero mandi in output un valore decimale compreso tra zero ed uno, con il valore complessivo della predizione dato dalla somma normalizzata dei valori predetti da ciascun albero e successivamente sogliata (nel caso, ovviamente, di predizione binaria).</p> <p>Partiremo la nostra trattazione da quello che, probabilmente, \u00e8 l'esempio pi\u00f9 noto di foresta decisionale: il random forest.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#random-forest","title":"Random Forest","text":"<p>Per introdurre il random forest \u00e8 opportuno partire da un aneddoto.</p> <p>Nel 1906 si svolse in Inghilterra una competizione che vedeva i partecipanti tentare di valutare il peso di un bue (ovviamente, senza usare una bilancia). Al termine della competizione, l'errore mediano delle predizioni era di circa \\(37\\) libbre, ovvero \\(17\\) kg. Tuttavia, la mediana delle predizioni era distante soltanto nove libbre (quattro kilogrammi) dal valore reale. Ci\u00f2 descrive perfettamente il cosiddetto principio della saggezza della folla: in altre parole, in determinate situazioni, il giudizio fornito dall'opinione collettiva risulta essere (inaspettatamente) molto preciso.</p> <p>Dal punto di vista statistico, questo principio ricalca il teorema centrale del limite, che dice che lo scarto quadratico medio tra il valore vero \\(x\\) e quello \\(\\hat{x}\\) derivante dalla media di \\(N\\) stime (rumorose) di \\(x\\) tende a zero con un fattore pari ad \\(\\frac{1}{n}\\).</p> <p>Note</p> <p>Nel machine learning, un ensemblke \u00e8 un insieme di modelli le cui predizioni sono mediate (o aggregate in qualche maniera). Se i modelli nell'ensemble sono abbastanza differenti senza essere pessimi se presi da soli, la qualit\u00e0 dell'ensemble \u00e8 generalmente pi\u00f9 alta che la qualit\u00e0 di ognuno dei modelli individuali. Un ensemble richiede maggior tempo di addestramento ed inferenza rispetto ad un singolo modello. Dopotutto, dobbiamo effettuare il trainign e l'inferenza di pi\u00f9 modelli invece di un singolo modello.</p> <p>Informalmente, affinch\u00e9 un ensemble lavori al meglio, i modelli dinivudali dovrebbero essere indipendenti. Per esempio, un esnseble composto di 10 modelli identici (ovvero, non indipendenti tra loro) non sar\u00e0 meglio del modello idnividuale. D'altro canto, forzare i modelli affinch\u00e9 siano indipendenti pu\u00f2 renderli peggiori. Un ensemblingf efficace richiede l'indivioduazione del bilancio tra l'ndiepenze del modello e la qualit\u00e0 dei suoi sotto-modelli.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#randomn-forest","title":"Randomn forest","text":"<p>Un random forest \u00e8 un insieme di alberi decisionali nei quali ogni albero decisioanle \u00e8 addestrato con un certo rumore casuale. Le random forest sono la fforma pi\u00f9 popolare di ensemble di alberi decisionali. Vediamo alcuen tecniche per creare degli alebri decisionali indipendenti per migliorare le cahnce di creare una random forest efficace.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#bagging","title":"Bagging","text":"<p>La tecnica del bagging (bootstrap aggregating) fa in modo che ogni albero decisionale sia addestrato su un sottoinsieme casuale dei campioni nell'insieme di training. In altre parole, ogni albero decisionale nelle random forest \u00e8 addestrato su un sottoinsieme differente di campioni.</p> <p>Il bagging \u00e8 peculiare. Ogni albero decisionale \u00e8 addestrato sullo stesso numero di campioni dell'insieme di addestramento originario. Per esempio, se l'insieme di training originario contiene 60 campioni, allora ogni albero decisionale \u00e8 addestrato su 60 campioni. Tuttavia, il bagging addestra soltanto ogni decision tre su un sottoinsieme (tipicamente, il 67%) di questi esempi. Per cui, alcuni di questi 40 campioni nel sottoinsieme saranno riutilizzati quando si addestra un dato albero decisionale. Questo riutilizzo \u00e8 chiamato addestramentp con rimpiazzo.</p> <p>Facciamo un esempio. Nella tabella successiva, vediamo come il bagging pu\u00f2 distribuire sei campioni su tre alberi decisionaloi. Notiamo che:</p> <ul> <li>ogni albero decisionale \u00e8 addestrato su un totale di sei campioni</li> <li>ogni albero cdecisioanle +\u00e8 addestrato su un insieme diverso di campioni</li> <li>ogni albero decisionale riutilizza certi campioni. Ad esempio, il campione 4 \u00e8 usato due volte nell'albero decisionale 1, quindi, i pesi appresi da parte del campion 4 \u00e8 effettivamente duplicato nel primo albero decisionale.</li> </ul> Campioni di training 1 2 3 4 5 6 dataset originario 1 1 1 1 1 1 albero decisionale 1 1 0 2 1 1 1 albero decisionale 2 3 2 0 1 0 1 albero decisionale 3 2 1 3 0 0 1 <p>Nel bagging, ogni albero decisionale \u00e8 quasi sempre addestarto sul numero ttoale di campioni nell'insieme di training originale. L'addestramento di ogni albero decisionale su un numero maggiore o inferiore di campioni pu\u00f2 degradare la qualit\u00e0 del randomn forest.</p> <p>Anche se non presente nel paper originale, il campionamento dei campioni alle volte \u00e8 svolto senza rimpiazzo; in altri termini, un campione di training non pu\u00f2 essere presente pi\u00f9 di una volta nell'insieme di addestramento di un albeor decisionale. Ad esempio, nella tabella precedente, tutti i valori sarebbero 0 o 1.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#attribute-sampling","title":"Attribute sampling","text":"<p>L'attribute sampling indica che invece di guardare alla migliore condizione rispetto a tutte le feature disponibili, soltanto un sottoinsieme casuale di feature sono testate ad ogni nodo. L'insieme di feature testate \u00e8 campionato casualmente ad ogni nodo dell'albero decisionale.</p> <p>Il seguente albero decisionale illustra l'attribute sampling. Qui, un albero decisionale \u00e8 addestrato su 5 feature (f1-f5). I nodi in blu rappresentano le feature testate, mentre quelli in bianco non sono testati. La condizione \u00e8 costruita a parteire dalle feature meglio testate (rappresentate con un contorno rosso).</p> <p>TODO: FARE FIGURA</p> <p>Il rapporto dell'attribute sampling \u00e8 un importante iperparametro per la regolarizzazione. La figura precednete usa un rapporto di \u2157. Molte implemnentazioni di random forest testano, di default, \u2153 delkle feature in fase di regressione, e la radice quadrata del numero dif eature epr la classificazione.</p> <p>In TF-DF, i seugenti iperparametri controllano l'attribute sampling:</p> <ul> <li>numcandidateattributes</li> <li>numcandidateattributes_ratio</li> </ul> <p>Per esempio, se numcandidateattributes_ratio=0.5, met\u00e0 delle featrure saranno testate ad ogni nodo.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#disabiliatre-la-regoalrizzazione-degli-alberi-decisionali","title":"Disabiliatre la regoalrizzazione degli alberi decisionali","text":"<p>Gli alberi decisionali in una foresta casuale sono addestrati senza il pruning. La mancanza di pruning aumenta singificativamente la varianbza, riducendo singificativamente il bias legato al singolo albero decisionale. In altre parole, l'albero individuale pu\u00f2 andare in overfitting, ma la random forest no.</p> <p>Ci aspettiamo che le accuracy di trainign e di test di una random forest siano differenti. L'accuracy di training di una random forest \u00e8, generalmente, molto alta (alle volte pari al 100%). Tuttavia, un'accuracy di training molto alta in una random forest \u00e8p normale, e non indica che la random forest sia in overfitting.</p> <p>Le due sorgenti di casualit\u00e0 (il baggin e l'attribute sampling) si assicurano che vi sia indipendenza relativa tra gli alberi decisionali. Questa indipendenza corregege l'overfitting dei singoli alberi decisionali. Di conseguenza, l'ensemble non \u00e8 in overfitting. Vedremo questo effetto (controintuitivo) nella seguente unit\u00e0.</p> <p>Le random forest pure sono addestrate senza una profondit\u00e0 massima o un numero minimo di osservazioni per foglia. Nella praica, limitare la profondit\u00e0 massima ed il minimo numero di osservazioni per foglia \u00e8 un beneficio. Di default, molte random forest usano i sengeunti valori di default.</p> <ul> <li>massima profondit\u00e0 di circa 16</li> <li>minimo numero di osservaizoni per foglia di circa 5</li> </ul>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#chiarezza-del-rumore","title":"Chiarezza del rumore","text":"<p>Perch\u00e9 il rumore casuale migliora la qualit\u00e0 del random forest? Per illustrare i benefici del\u00f2 rumore casuale, vediamo le rpedizioni di un albero decisionale classico e di una random forest addestrata su alcuni campioni di un semplice problema ellittico.</p> <p>I pattern ellittici sono notoriamente complessi per gli alberi decisionali e. notiamo come l'albero decisionale dopo il pruning non riesce ad ottenre la stessa qualit\u00e0 di predizione delle random forest.</p> <p>TODO: IMMAGINE CON RIFERIMENTO</p> <p>Vediamo anche le predizioni dei primi tre alberi decisionali senza pruning nel random forest; ovvero, gli alberi decisionali sono tutti addestrati con una combinazione di bagging, attribute sampling e senza pruning.</p> <p>Le rpedizioni individuali di questi tre alberi sono peggiori delle predizioni dell'albero decisionale con pruning nella precedente figura. TUttavia, dal momento che gli errori degli alberi decisionali individuali sono soltanto correlati debolmente, i tre alberi decisionali combinano in un ensemble per creare delle predizioni efficace.</p> <p>Dato che gli alberi decisionali di una random forest non sono prunati, il training di una random forest non richiede un dataset di validazione. Nella pratica, e specialmente su piccoli dataset, i modelli dovrebbero essere addestrati su tutti i dati disponibili.</p> <p>Quando si addestra una random forest, man mano che pi\u00f9 alberi decisionali sono aggiunti, l'errore quasi sempre diminuisce; ci\u00f2 singific ache la qualit\u00e0d el modello quasi sempre aumenbta. Aggiungere pi\u00f9 alberi decisionali quasi sempre riduce l'errore della random forest. In altre parole, aggiungere pi\u00f9 alberi decisionali non pu\u00f2 causare l'overfit della random forest. Ad un certo punto, il modello semplicemente smette diu migliorare.</p> <p>Ad esempio, il seguente plot mostra la valutazione di una random forest man mano che vengono aggiunti pi\u00f9 alberi decisionali. L'accuracy migliropa rapidamente fino a che non si ferma attorno al val\u00f2ore di TODO: ESPERIMENTO. Tuttavia, aggiungere pi\u00f9 alberi decisionali non fa diminuire l'accuracyt; in altre parole, il modello non va in overfittng. QUestro comportamento \u00e8 quasi sempre vero ed indipendente dagli iperparametri.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#out-of-bag-evaluation","title":"Out-of-bag evaluation","text":"<p>Le random forest non richiedono un dataset di validazione. La maggior parte delle random forest usa una tecnica chaimata out-of-bag evaluation (OOB) per valutare la qualit\u00e0 del modello. La OOB evaluation tratta il set di training come se fosse il set di test di una cross-validazione.</p> <p>COme spiegato in precedenza, ogni albero decisionale in una random forest \u00e8 tipicamente addestrato su circa il 67%% degli esempi di training. Di conseguenza, ogni albero decisionale non vede circa il 33% degli esempi di training. L'idea alla base della OOB-evaluation \u00e8 la seguente:</p> <ul> <li>valutare la randomn forest sull'insieme di training</li> <li>per ogni campione, usiamo solo l'albero decisionale che non vede il campione durante il training</li> </ul> <p>La seugente tabella illustra la valutazione OOB di una random forest con 3 alberi decisionali addestrati su 6 campioni (COPIARE QUELLA DI PRIMA). La tabella mostra quale albero decisionale \u00e8 usato con quale esempio nella valutazione OOB.</p> Campioni di training Campioni per la valutazione OOB 1 2 3 4 5 6 dataset originario 1 1 1 1 1 1 albero decisionale 1 1 0 2 1 1 1 3 albero decisionale 2 3 2 0 1 0 1 2, 4 albero decisionale 3 2 1 3 0 0 1 1, 5, 6 <p>Nell'esempio mostrato nella precedente tabella, le predizioni OOB per l'esempio di training 1 saranno calcolate con l'albero decisionale 3 (dal momento che gli alberi decisionali 1 e 2 usano questo campione per il training). Nella pratica, su unb dataset con dimensioni ragionevoli con alcuni alberi decisionali, tutti gli esempi hanno una predizione OOB.</p> <p>La valutaizone OOB \u00e8 efficace anche per calcolare l'importanza delle variabili nei modelli random forest. Ricordiamo che questa importanza misura l'importanza di una variabile misurando la caduta dell a qualit\u00e0 del modello quando questa variabile viene \"mescolata\". In caso di OOB epr un random forest, l'importanza \u00e8 calcolata usando la valutazione OOB.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#altri-topic","title":"Altri topic","text":""},{"location":"material/04_sklearn/04_decision_trees/decision_forests/#interpretazione-dei-random-forest","title":"interpretazione dei random forest","text":"<p>I random forest sono pi\u00f9 comp\u00e8lessi da interpretare degfliu alberei decisionali. Le random forest contengono degli alberi decisionali addestrati con rumore casuale. Quindi, diviene difficile dare un giudizio suilla struttura dell'albero decisionale. Tuttavia, possiamo interpretare i modelli del random forest in due diversi modi.</p> <p>Un approccio \u00e8 quello di limitarsi ad addestrare ed interpretare un albero decisionale con l'algortimo CART. Siccome sia le random forest che il cCART sono addestrati con lo stessdo algoritmo alla base, \"condividono la stessa visione globale\" sul datasaet. Qeusta opzione funziona al meglio epr dataset semplici e per comprendere l'interpretazione compelssiva del modello.</p> <p>L'importanza delle variabili \u00e8 un altro approccio all'intepretabilit\u00e0.</p> <p>Un altro tipo di metodo per la spiegazione \u00e8 quello di suare algoritmi agnostici, come lo SHAP (SHapley Additive exPlanations). </p> <p>Vantaggi:</p> <ul> <li>come gli alberi defcisionali, i random forest supportano natgivamente feature categoriche e numeriche e non richiedono il preprocessing delle stesse</li> <li>dato che gli alberi decisionali sono indipendenti, i random forest possono essere addestrati in parallelo, e quindi pi\u00f9 velocemente</li> <li>le random forest hannod ei aprametri di default che danno ottimi risutlati. il tuning di questi parametri ha spesso poche conseguenze sul modello</li> </ul> <p>Svantaggi:</p> <ul> <li>siccome gli alberi decisionali non sono soggetti a pruning, possono essere grandi, con modelli con anche un milione di nodi. La dimensione delle random forest pu\u00f2 quindi essere un problema</li> <li>le random forest non possono apprendere e riutilizzare delle rappresentazioni interne. Ogni albero decisionale (ed ogni ramo di ogni albero decisionale) deve apprendere nuovamente il pattern del datset. Ina lcuni dataset (specie quelli non tabellari) questo fa s\u00ec che le random forst abbiano risutlati peggiori daltrri metodi.</li> </ul>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/","title":"X.X - Gli alberi decisionali","text":"<p>Gli alberi decisionali sono una tra le famiglie di modelli maggiormente utilizzate per l'apprendimento supervisionato, sia in fase di classificazione, sia in fase di regressione. Offrono alcuni benefici rispetto agli altri modelli, tra cui:</p> <ul> <li>una maggiore semplicit\u00e0 di configurazione rispetto alle reti neurali, legata alla presenza di meno iperparametri, il cui tuning, tra l'altro, risulta essere meno influente per le prestazioni finali (in pratica, \u00e8 possibile utilizzare tranquillamente i valori di default);</li> <li>la capacit\u00e0 di gestire feature di diverso tipo (ad esempio, numeriche, categoriche, o anche mancanti), il che comporta la possibilit\u00e0 di effettuare meno preprocessing rispetto ad altri modelli;</li> <li>la possibilit\u00e0 di essere usati su dataset di piccole dimensioni con una maggiore efficienza rispetto a modelli pi\u00f9 complessi come le rete neurali.</li> </ul> <p>Da non sottovalutare, inoltre, il fatto che gli alberi decisionali forniscono spesso buoni risultati, sono robusti al rumore, ed hanno dei risultati che sono facilmente interpretabile.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#xx-dataset-per-gli-alberi-decisionali","title":"X.X. - Dataset per gli alberi decisionali","text":"<p>Gli alberi decisionali risultano essere molto efficaci quando si ha a che fare con dataset di tipo tabulare, come file CSV o tabelle di un database. Un esempio \u00e8, ovviamente, il dataset Titanic. Inoltre, non abbiamo la necessit\u00e0 di effettuare operazioni di preprocessing, come normalizzazioni, one-hot encoding, o data imputation.</p> <p>Tuttavia, gli alberi decisionali non sono assolutamente adatti ad essere utilizzati su dati non tabulari (anche detti non strutturati), come ad esempio immagini o testo. </p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#performance","title":"Performance","text":"<p>Gli alberi decisionali possono essere addestrati con efficacia su piccoli dataset, o su dataset sui quali comunque il rapporto tra feature e numero di campioni non \u00e8 di molto superiore ad 1.</p> <p>Efficacia degli alberi</p> <p>Anche se gli alberi decisionali sono efficaci in caso di rapporto quasi unitario tra feature e numero di campioni (sample efficiency), il funzionamento migliora quando sono disponibili molti dati, cos\u00ec come tutti gli algoritmi di machine learning.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#funzionamento-degli-alberi-decisionali","title":"Funzionamento degli alberi decisionali","text":"<p>Vediamo un esempio di funzionamento degli alberi decisionali.</p> <p>Un albero decisionale non \u00e8 altro se non un modello composto da un insieme di domande, o per meglio dire condizioni, organizzate in maniera gerarchica sotto forma di albero. Ognuno dei nodi non foglia dell'albero descrive una condizione, mentre ogni nodo foglia contiene una predizione. Nella seguente figura vediamo un esempio di albero decisionale:</p> <pre><code>flowchart TB\n  A[Gambe&gt;2] --&gt;|No| B[Occhi&gt;2]\n  A --&gt;|S\u00ec| C(Cane)\n  B --&gt;|S\u00ec| D(Ragno)\n  B --&gt;|No| E(Gallina)</code></pre> <p>L'inferenza dell'albero decisionale viene quindi calcolata eseguendo il routing di un campione dalla radice fino ad una delle foglie, a seconda dei valori assunti dalle feature; il valore della foglia raggiunta rappresenta la predizione raggiunta dall'albero, mentre l'insieme dei nodi visitati \u00e8 detto percorso di inferenza. </p> <p>Cerchiamo di capire cosa sta succedendo nel nostro esempio. Nel nodo radice, viene descritta la condizione relativa al fatto che il nostro campione abbia pi\u00f9 o meno di due gambe. Nel nodo B, che non \u00e8 un nodo foglia, viene valutata la presenza di un numero di occhi maggiore o minore di due. Nei tre nodi foglia, ovvero C, D ed E, abbiamo la decisione presa dall'albero (rispettivamente, cane, ragno o gallina). Ad esempio, consideriamo un campione avente due gambe e due occhi. Allora, partendo dalla radice ed arrivando alla foglia, avremo il seguente percorso di inferenza:</p> <pre><code>flowchart TB\n  A[Gambe&gt;2] --&gt;|No| B[Occhi&gt;2]\n  A --&gt;|S\u00ec| C(Cane)\n  B --&gt;|S\u00ec| D(Ragno)\n  B --&gt;|No| E(Gallina)\n  linkStyle 1,3 stroke-width:2px,fill:none,stroke:red;</code></pre> <p>In modo simile, \u00e8 possibile fare in modo che un albero decisionale effettui una predizione di regressione su dei valori numerici. Ad esempio, possiamo predire l'indice di tenerezza di un animale:</p> <pre><code>flowchart TB\n  A[Pelosit\u00e0&gt;medio] --&gt;|Si| B[Carineria&gt;medio]\n  A --&gt;|No| C(1)\n  B --&gt;|S\u00ec| D(3)\n  B --&gt;|No| E(2)</code></pre> <p>Risultati della regressione</p> <p>Dall'esempio precedente, \u00e8 evidente come cani, gatti e pulcini siano gli animali che ispirano pi\u00f9 tenerezza nell'essere umano, laddove aracnidi, insetti e serpenti risultino essere molto meno teneri.</p> <p>Vediamo adesso come distinguere i diversi tipi di condizione descritti in un albero decisionale.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#tipi-di-condizione-in-un-albero-decisionale","title":"Tipi di condizione in un albero decisionale","text":""},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#axis-aligned-vs-oblique","title":"Axis-aligned vs. oblique","text":"<p>La prima distinzione che \u00e8 possibile fare tra diverse condizioni riguarda il fatto che queste interessino una o pi\u00f9 feature. In particolare, le condizioni axis-aligned interessano un'unica feature, mentre quelle oblique riguardano pi\u00f9 feature. Tornando all'esempio precedente, la condizione \\(Gambe \\geq 2\\) \u00e8 chiaramente axis-aligned, in quanto coinvolge solamente il numero di gambe dell'animale. Se, ad esempio, ci fosse stata una condizione del tipo \\(Gambe \\geq Occhi\\), avremmo avuto a che fare con una condizione oblique.</p> <p>Spesso, gli alberi decisionali vengono addestrati esclusivamente con condizioni axis-aligned. D'altro canto, l'uso di condizioni oblique \u00e8 potenzialmente molto potente, in quanto queste sono in grado di esprimere relazioni molto complesse tra dati; tuttavia, nella pratica, molto spesso (ab)usare delle condizioni oblique comporta performance inferiori al netto di maggiori costi in termini di tempo di addestramento.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#binarie-vs-non-binarie","title":"Binarie vs. non binarie","text":"<p>La seconda distinzione che esiste tra diverse condizioni riguarda quelle binarie, che hanno soltanto due possibili esiti, e non binarie, che hanno pi\u00f9 di due possibili esiti. Prevedibilmente, gli alberi decisionali contenenti soltanto condizioni binarie sono detti alberi binari, mentre gli alberi contenenti anche condizioni non binarie sono detti non binari.</p> <p>In questo caso, il compromesso \u00e8 tra la generalizzazione </p> <p>TODO ESEMPIO</p> <p>Le condizioni con troppa specificit\u00e0, comunque, tendono a causare overfitting. Per questa ragione, gli alberi decisionali usano generalmente delle condizioni binarie.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#come-addestrare-gli-alberi-decisionali","title":"Come addestrare gli alberi decisionali?","text":"<p>Come tutti i modelli di apprendimento supervisionato, gli alberi decisionali sono addestrati per spiegare al meglio un insisem di esempi di training. Il training ottimale di un albero decisionale \u00e8 un problema NP-hard. Quindi, il training \u00e8 generalmente fatto mediante delle euristiche - un algoritmi di apprendimento semplice da creare che restituisce un ablero decisionale subottimo, ma vicino all'ottimo.</p> <p>La maggior parte degli algoritmi usati per addestrare gli alberi decisionali usa un approccio divide-et-impera. L'algoritmo inizia creando un singolo nodo (la radice) ed aumenta l'albero in maniera ricorsiva usando un approccio greedy.</p> <p>Ad ogni nodo, tutte le possibili condizioni sono valutate. L'algoritmo seleziona la migliore condizione, ovvero, la condizione con il punteggio pi\u00f9 alto. Per adesso, ci limitiamo a sapere che il punteggio \u00e8 una metrica che \u00e8 correlata al task, e le condizioni sono selezionati per massimizzare questa metrica.</p> <p>Per esempio, nel dataset Palmer Pengiuns, la maggio parte dei pinguini Adelie e Chinstrap hanno la lunghezza del becco maggiore a 16mm, mentre la maggior parte dei pinguinig Gentoo ha dei becchi pi\u00f9 piccoli. Quindi, la condizione lunghezzabeccomm &gt; 16 permette di predire in maniera affidabile i pinguini Gentoo, ma non riesce a discerneere tra gli Adelie ed i Chinstrap. L'algoritmo considerer\u00e0 quindi questa condizione.</p> <pre><code>flowchart TD\nA[\"lunghezza_becco_mm &gt; 16\"] --&gt; B[Adelie o Chinstrap]\nA --&gt; C[Gentoo]</code></pre> <p>L'algoritmo quindi ripete in maniera ricorsiva ed indipendente o entrambi i nodi figli. Quando non si trova una condizione soddisfacente, il nodo diventa una foglia. La predizione della foglia \u00e8 determianta come l'etichetta pi\u00f9 rappresentativa negli esempi.</p> <p>L'algoritmo \u00e8 il seguente:</p> <pre><code>def train_decision_tree(training_examples):\nroot = create_root() # Create a decision tree with a single empty root.\ngrow_tree(root, training_examples) # Grow the root node.\nreturn root\ndef grow_tree(node, examples):\ncondition = find_best_condition(examples) # Find the best condition.\nif condition is None:\n# No satisfying conditions were found, therefore the grow of the branch stops.\nset_leaf_prediction(node, examples)\nreturn\n# Create two childrens for the node.\npositive_child, negative_child = split_node(node, condition)\n# List the training examples used by each children.\nnegative_examples = [example for example in examples if not condition(example)]\npositive_examples = [example for example in examples if condition(example)]\n# Continue the growth of the children.\ngrow_tree(negative_child, negative_examples)\ngrow_tree(positive_child, positive_examples)\n</code></pre> <p>Vediamo i passi necessari ad addestrare un certo albero decisionale in dettaglio.</p> <ul> <li>Step 1: creiamo un nodo radice</li> </ul> <pre><code>flowchart TD\n\nA[\"nodo radice\"]</code></pre> <p>Step 2: accresciamo il nodo 1. La condizione x1 &gt;= 1 viene trovata. Sono creati due nodi figli:</p> <pre><code>A[\"x1 &gt;= 1 nodo radice\"] --&gt; Yes --&gt; B[\"? nodo 3\"]\nA --&gt; No --&gt; C[\"? nodo 2\"]</code></pre> <p>Step 3: accresdciamo il nodo 2. Non sono state trovate condizioni soddisfacenti. Per cui, il nodo diventa una foglia.</p> <pre><code>flowchart TD\n\nA[\"x1 &gt;= 1 nodo radice\"] --&gt; s\u00ec --&gt; B[\"? nodo 3\"]\nA --&gt; No --&gt; C[\"foglia nodo 2\"]</code></pre> <p>Step 4: accresciamo il nodo 3. La condizione \"x2 &gt;= 0.5\" \u00e8 stata individuata. Due nodi figli sono creati.</p> <pre><code>flowchart TD\n  A[\"x1 &gt;= 1 nodo radice\"] --&gt; s\u00ec --&gt; B[\"x2 &gt; 5 nodo 3\"]\n  A --&gt; No --&gt; C[\"foglia nodo 2\"]\n  B --&gt; Si --&gt; D[\"? nodo 5\"]\n  B --&gt; No --&gt; E[\"?nodo 4\"]</code></pre> <p>Esistono altri metodi per accrescere gli alberi decisionali. Un'alternativa popolare \u00e8 ottimizzare globalmente i nodi invece di usare una strategia divide-et-impera.</p> <p>A seconda del numero e del tipo di feature di input, il numoer di possibili condizioni per un dato nodo pu\u00f2 essere enorme, generalmente infiito. Ad esempio, data una condizione di soglia \\(feature_i \\geq t\\), la combinaizone di tutti i possibili valore di soglia \\(t \\in \\mathbb{R}\\) \u00e8 infiniat.</p> <p>La routine responsabiel per individualre la miglireo condizione \u00e8 chiamata splitter. Siccome deve testare un gran numero di possibili condizioni, gli splitter sono i colli di bottiglia quando si addestra un albero decisionale.</p> <p>Il punteggio massimizzzato dallo splitter dipende dal task. AD esempio:</p> <ul> <li>Information Ga\u00ecni e Gini sono normalmente usati per la classiciazione.</li> <li>l'0errore quadratico medio \u00e8 normalmente usato per la regressione</li> </ul> <p>Ci sono molti algoretimi di splitting, ognuno con vario spporto per:</p> <ul> <li>tipo di feature; ad esempio, numerica, categorica, testuale;</li> <li>task: p\u00e8er esempio, classificazione binaria, multiclasse, regtressione;</li> <li>tipo di condizione: per esempio, condizione di soglia, obliqua, etc.;</li> <li>criterio di regolarizzaizone: per esempio, splitter essatti o approssimati per le condizioni di soglia.</li> </ul> <p>Inoltre, ci sono deglle varianti equivalenti delgi splitter con diversi compromessi per l'uso di memoria, CPUI, e via dicendo.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#classificazione-binaria","title":"Classificazione binaria","text":"<p>Splitter per la classificazione binaria con feature numeriche</p> <p>Vediamo il pi\u00f9 semplice e comune algoritmo di splitting, che crea condizioni nella fomra \\(feature_i \\geq t\\) nel seguente setting:</p> <ul> <li>task di classificazione binaria</li> <li>senza valori mancanti negli esempi</li> <li>senza indici precalcolati sugli esempi</li> </ul> <p>Assumiamo un insieme di \\(n\\) campioni con una freatrure numerica ed una label bianrai \"arancio\" e \"blu\". Formalmente, il dataset pu\u00f2 essere descritto come:</p> \\[ D={(x_i, y_i)}_{i \\in[1, n]} \\] <p>dove:</p> <ul> <li>\\(x_i\\) \u00e8 il valore di una featrure numerica in \\(\\mathbb{R}\\) (l'insieme di numeri reali)</li> <li>\\(y_i\\) \u00e8 una valore per la label di classificazione binaria tra arancio e blu</li> </ul> <p>L'obiettivo \u00e8 trovare un valore di soglia \\(t\\) tale che dividendo i campioni \\(D\\) nei gruppi \\(T(rue)\\) ed \\(F(alse)\\) secondo \\(x_i \\geq t\\) migliroaiamo la separazione delle label. Ad esmepio, pi\u00f9 esempi arancioni saranno in \\(T\\), e pi\u00f9 esempi blu saranno in \\(F\\).</p> <p>L'entropia di Shanno \u00e8 una misura di disordine. Per una label binaria:</p> <ul> <li>l'etnropia di Shanno \u00e8 massima qunado le label negli esempi sono bilanciate (\\(50\\%\\) blu, \\(50\\%\\) arancioni)</li> <li>l'entropia di SHanno \u00e8 minima (valore zero) quando le label negli esempi sono pure (\\(100\\%\\) blu o \\(100\\%\\) arancioni)</li> </ul> <p>Formalmente, vogliamo trovare una condizione che diminuisce la somma pesata dell'entropia delle distribuzioni delle label in \\(T\\) ed \\(F\\). Il punteggio corrispondente \u00e8 detto information gain, che \u00e8 la differneza tra l'entropia di \\(D\\) e quella dell'insieme \\({T, F}\\).</p> <p>La seguente figura mostra una suddivisione errata, nella quale l'entropia rimane alta ed il guadagno informativo basso.</p> <p>In contrasto, la seguente figura mostra uno split miglire nel quale le'ntropia diventa bassa (ed il guadagno informativo  alto).</p> <p>Formalmente:</p> \\[ T = {(x_i, y_i)|(x_i, y_i) \\in D con x_i \\geq t} \\\\ F = {(x_i, y_i)|(x_i, y_i) \\in D con x_i &lt; t} \\\\ R(X) = \\frac{|{x|x \\in X, x=pos}|}{|X|} \\\\ H(X) = -p log p - (1-p) log(1-p) con p = R(X) \\\\ IG(D, T, F) = H(D) - \\frac{|T|}{|D|} H(T) - \\frac{|F|}{|D|}H(F) \\] <p>con:</p> <ul> <li>\\(IG(D,T,F)\\) guadagno infomrativo legato alla suddivisione di \\(D\\) in \\(T\\) ed \\(F\\).</li> <li>$H(X) \u00e8 l'entropia dell'insieme di campioni \\(X\\).</li> <li>\\(|X|\\) \u00e8 il numero di elementi nell'insieme \\(|X|\\).</li> <li>\\(t\\) \u00e8 il valore di sopglia.</li> <li>\\(pos\\) \u00e8 il valore della label positivo, ad esempio, blue nell'esempio prec edfentre. Scegelier una diversa label come positiva non cambia il valore dell'entropia o dell'information gain.</li> <li>\\(R(X)\\) \u00e8 il rapporto dei valori delle label positive nei campioni \\(X\\).</li> <li>\\(D\\) \u00e8 il dataset.</li> </ul> <p>Nel seguente esempio, consideriamo un datraset poer la classificazione binaria con una singola feature numerica \\(x\\). La seguente figura mostra per differenti valori della soglia \\(t\\) (sull'asse X):</p> <ol> <li>L'istogramma della feature \\(x\\).</li> <li>Il rapporto di campioni \"blu\" negli insiemni \\(D\\), \\(T\\) ed \\(F\\) secondo il valore di soglia.</li> <li>L'entropia in \\(D\\), \\(T\\), ed \\(F\\).</li> <li>Il guadagno informativo, ovvero il delta, in termini di entropia, tra \\(D\\) e \\({T, F}\\) p\u00e8ersato per il numero di campioni.</li> </ol> <p>Questi plot mostrano i seguenti:</p> <ul> <li>il plot di  frequenza mostra che le osserrvazioni sono relativamente ben diffuse con concentrazioni tra 18 e 60. Un valore dello spread ampio indica che ci sono molti split potenziali, il che \u00e8 un bene per l'addestramento del modello.</li> <li>il rapporto di label blue nel dataset \u00e8 di circa il 25%. Il plot relativo mostra questo per i valori di soglia tra 20 e 50:</li> <li>l'insieme T contiene un eccesso di campioni blu (fino al 35% per la soglia 35)</li> <li>l'insieme F contiene un deficit complementare di caompionio etichettati con blu (solo 8% per la soglia 35)   Sia il \"rapporto di label blu\" sia il plot di entropia indicano che le label possono essere relativamente ben sep\u00e8arate in questo range di soglie.</li> <li>Questa osservazione \u00e8 confermata nel plot \"information gain\". VEdiamo che il massimo guadagno informativo \u00e8 ottenuto con \\(t \\sim 28\\) per un valore di circa \\(0.074\\). Quindi, la condizione restituita dallo splitter sar\u00e0 \\(x \\geq 28\\).</li> <li>Il guadagno informativo \u00e8 sempre maggiore o uguale a zero. Converge a zero man mano che il valore di soglia va verso il suo valore massimo (minimo). In questi casi, o \\(F\\) o \\(T\\) diventano vuoti mentre l'altro contiene l'0iutenro dataset e mostra un'entropia uguale a quella in \\(D\\). Il guadagno informatiov pu\u00f2 anche essere zero quando \\(H(T)=H(F)=H(D)\\). Alla soglia 60, il rapporto di label blue per sia \\(T\\) sia \\(F\\) \u00e8 lo stesso di quello di \\(D\\), ed il guadagno informatiov \u00e8 nullo.</li> </ul> <p>I valori candidati per \\(t\\) nell'isnieme dei numeri reali (\\(\\mathbb{R}\\)) sono infiniti. TTuttavia,d ato un numeor finito di campioni, osltmnatop un numero difnito di divisioni di \\(D\\) in \\(T\\) ed \\(F\\) esiste. Quidni, solo un numero finito di valori di \\(t\\) possono essere testati in modod singificativo.</p> <p>Un approccio classico \u00e8 quello di ordinare i valori \\(x_j\\) in ordine crescente \\(x_{s(i)}\\) in modo che:</p> \\[ x_{s(i)} \\leq x_{s(i+1)} \\] <p>Quindi, sit esta \\(t\\) per ogni valore a met\u00e0 tra valori ordinati consecutivi di \\(x_i\\). Ad esempio, supponiamo di avere 1000 valori a virgola mobile per una certa feature. Dopo l'ordianmento, supponiamo che i primi due valori siano 8.5 e 8.7. In questo caso, il primo valore di soglia da testare dovrebbe essere 8.6.</p> <p>Formalmente, consideriamo i seguenti valori candidati per \\(t\\):</p> \\[ X = \\{\\frac{x_{s(i)}+x_{s(i+1)}}{2}|x_{s(i)} \\diff x_{s(i+1)}\\} \\] <p>La complessit\u00e0 nel tempo di questo algoritmo \u00e8 un \\(O(n log n)\\), con \\(n\\) il numero di campioni nel nodo (a causa dell'ordinamento dei valori delle feature). Quando applicato ad un albero decisionale, l'algoritmod i splitting viene applicato ad ogni nodo ed ogni feature. Notiamo che ogni nodo riceve circa la met\u00e0\u00f2 degli esempi del suo nodo genitore. Quindi, in accordo al teorema dell'esperto, la complessit\u00e0 nel tempo di addestare un albero decisioanle con questo splitter \u00e8 data da:</p> \\[ O(mn log^2 n) \\] <p>dove:</p> <ul> <li>m \u00e8 il numero di feature;</li> <li>\\(n\\) \u00e8 il numero di campioni di training.</li> </ul> <p>In questo algoritmo, il valore delle feature non importa; soltanto l'ordine \u00e8 importante. Per questra ragione, questo algoritmo lavora in modo indipendente dalla scala o dalla distribuzione dei valori delle feature. Questo \u00e8+ il motivo per cui non dobbiamo normalizzare o scalare le featrur numeriche quando addestriamo un albero decisionale.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#overfitting-e-pruning","title":"Overfitting e pruning","text":"<p>Usando l'algoritmo dfescritto in precedenza, possiamo addestrare un albero decisionale che classifichi perfettamente i campioni di training, a patto che questi siano separabili. Tuttavia, se il dataset contiene del rumore, questo albero andr\u00e0 in overfitting sui dati, e mostrer\u00e0 scarse abilit\u00e0 in fase di test.</p> <p>La seguente figura mostra un dataset rumoroso con una relazione tra una feature \\(x\\) e la label \\(y\\). La figura mostra anche un albero decisioanle addestrato su qeusto dataset senza alcun tipo di regolarizzzione. Questo modello predice correttamente tutti i campioni di training (in pratica, le predizioni dle modello sono in grado di combaciare con gli esempi di training). Tuttavia, su un dataset contenente lo stesso pattern lineare con un diverso tipo di rumore, il modello offrir\u00e0 performance subottimali.</p> <p>Per limitare l'overfitting di un albeor decisionale, applichiamo uno o entrambi i seguenti criteri di regolarizzaizone mentre addestriamo l'albero stesso:</p> <ul> <li>impostare una profondit\u00e0 massiam: facciamo in modo che l'albero decisionale non vada oltre una massima profondit\u00e0, come 10;</li> <li>impostiamo un numero minimo di campioni nelle foglie: una foglia con meno di un certo numero di campioni non sar\u00e0 considerata per la divisoine.</li> </ul> <p>La seguente figura illustra gli effetti di usare un numero minimo di campioni per foglia variabile. Il modello cattura un minor quantitativo di rumore.</p> <p>TODO</p> <p>Possiamo anche efefttuare la regolarizzaizone dopo l'addestramento rimuovendo in modo selettivo alcuni rami (pruning), ovvero, convertendo certi nodi non-foglia in foglia. UNa soluzione comune ad selezionare i rami da rimuovere \u00e8 quella di usare und ataset per la validazione. Ovvero, se rimuovere un ramo migliora la qualit\u00e0 del modello sul dataset di valdiazione, quindi il ramo viene rimosso.</p> <p>La seguente illustrazione mostra quesrta idea. Qui, testiamo se l'accuracy dik validazione dell'albero decsiionale \u00e8 migliroata se il nodo non-foglia in verede \u00e8 trasformato in foglia; ovvero, effettuando il pruning dei nodi arancvioini.</p> <p>DA FIGURA 14</p> <p>La segyunte figura illustra l'effetto di usare il 20% del dataset come validazione per effettaure il pruning dell'albero decisionale.</p> <p>Notiamo che l'uso di un dataset di validazioen riduce il numero di esempi disponibili per l'addestramento iniziale dell'albero decisionale.</p> <p>Molti modelli inoltre applicano pi\u00f9 criteri. Ad sempio, possiamo usare i seguenti:</p> <ul> <li>applicare un numero minimo di campioni per nodo foglia</li> <li>applicare una profondit\u00e0 massima per limitare la crescita dell'albero decisionale</li> <li>effettuare il pruning dell'albero decisionale</li> </ul> <p>Questi criteri introducono nuovi iperparametri che devono essere impostati (ad esempio, la massima profondit\u00e0 dell'albero), spesso con tuning degli iperparametri automatizzzato. Gli alberi decisionali sono in geenrale abbastanza veloci da addestrare usando l'ottimizzazione degli iperparametri in crss-validazione. Per esempio, su un dataset con \"n\" campioni:</p> <ul> <li>dividiamo i campioni di training in \\(p\\) gruppi non-sovrapposti, per esempio \\(p=10\\).</li> <li>per tutti i possibili valori degli iperprametri, valutiamo, su ogni gruppo, la qualit\u00e0 dell'albero decisionale addestrato sugli altri \\(p-1\\) gruppi; facciamo poi la media delle valutazioni sui diversi gruppi;</li> <li>selezioniamo i valori degli iperparametri con la migliore valutazione media;</li> <li>addestriamo un albero decisionale finale usando tutti gli \\(n\\) campioni con gli iperparametri selezionati.</li> </ul> <p>In questa sezione abbiamo discusso il modo in cui gli alberi decisionali limintano l'overfitting. Nononstante questi metodi, l'underfitting e l'overfitting sono delle debolezze degli alberi decisionali. Le foreste decisionali introducono nuovi metodi per limtiare l'overfitting, come vedremo dopo.</p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#interpretazione-diretta-dellalbero-decisionale","title":"interpretazione diretta dell'albero decisionale","text":"<p>Gli alberi decisionali sono facili da interpretare. Detto questo, cambiare anche pochi esempi pu\u00f2 modificare completamente la struttura (e quindi l'interpretazione) dell'albero decisionale.</p> <p>Nota</p> <p>Specialmente quando il dataset contiene molte feature in qualche modo simili, l'albero decisionale appreso \u00e8 solo uno di pi\u00f9 alberi decisionali pi\u00f9 o meno equivalnetni che fittano i dati.</p> <p>Visto il modo in cui gli alberi decisionali sono costruiti, effettuando il partizionalmento dei campiioni di trainging, si pu\u00f2 usare un albero decisioanle per interpretare il dataset (invece di modellarlo). Ogni foglia rappresnta un particolare angolo del dataset. </p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#importanza-delle-variabili","title":"Importanza delle variabili","text":"<p>Per importasnza delle variabili (detto anche feature importance) si intende un punteggio che indica quanto \"importante\" sia una feature per il modello. Ad esempio, se per un dato modello con due feature in input \\(f_1\\) ed \\(f_2\\) l'importanza delle variabili sono \\(f_1 = 5.8, f_2=2.5\\), allora la feature \\(f1\\) \u00e8 pi\u00f9 importante per il modello della feature \\(f2\\). Cos\u00ec come per altri modelli di machine learning, l'importanza delle variabili \u00e8 un modo semplice di comprendere come funziona un albero decisionale.</p> <p>Possiamo definire l'importanza delle feature in modo agnostico usando metodi come permutation impotrance.</p> <p>Gli alberi decisionali hanno anche delle specifiche importanze per le variabili, come:</p> <ul> <li>somma dei punteggi parziali associati ad unac erta feaature</li> <li>numero di nodi con una data feature</li> <li>profondit\u00e0 media della prima occorrenza di unaf eature in tutti  i percorsi dell'albero</li> </ul> <p>L'importanza delle variabili pu\u00f2 differire in base a qualit\u00e0 come semantica, scala o propriet\u00e0. Inoltre, l'importanza delle variabili foirnisce diversi tipi di informazione circa modello, dataset, e processo di addestramento.</p> <p>Ad esempio, il numero di condizioni contenenti una certa feature indca quanto un albero decisionale sta guardando a quella specifica feature, il che pu\u00f2 indicare l'importanza della variabile. Dopo tutto, l'algoritmo di apprendimento non avrebbe usato una feature in diverse condizioni se questa non avesse avuot importanza. Tuttavia, la stessa feature che appare in pi\u00f9 condizioni pu\u00f2 anche indicare che il modello sta provando a generalizzare il pattern per quella feature, fallendo. Ad esempio, questo pu\u00f2 accadere quando una feature \u00e8 specifica per ogni campione (il nome e cognome), senza alcuna infomrazione da generalizzare.</p> <p>D'altro canto, un alto valore di importanza per la variabile indica che rimuovere quella feature inficia il modello, il che \u00e8 un'indicazione dell'importanza della variabile. Tuttavia, se il modello \u00e8 robusto, rimuovere una qualsiasi delle feature non dovrebbe influenzare il modello.</p> <p>Dato che diverse variabili informano su diversi aspetti del modello, osservare contestualmente l'importanza di diverse varaibili \u00e8 informativo. Ad esempio, se una feature \u00e8 importante in accordo a tutte le altre, \u00e8 plausibile che sia molto importante. </p>"},{"location":"material/04_sklearn/04_decision_trees/decision_trees/#esempio-con-tensorflow-decision","title":"Esempio con tensorflow-decision","text":"<p>Vediamo come usare la libreria TF-DF per addestrare, rifinire ed interpretare un albero decisionale.</p> <p>Possiamo farlo sia in locale, sia da un notebook Colab. Per farlo, dovremo installare la libreria TensorFlow Decision Forests.</p> <pre><code>pipenv install tensorflow_decision_forests\n</code></pre> <p>All'apice del nostro codice, importiamo le seguenti librerie:</p> <pre><code>import numpy as np\nimport pandas as pd\nimport tensorflow_decision_forests as tfdf\n</code></pre> <p>Useremo il dataset relativo ai Palmer Pengiuns, che contiene le misurazioni in termini di dimensione per tre specier di pinguini , ovvero il pigoscelide antartico (Chinstrap), il pinguino Gentoo, ed il pinguino di Adelia (Adelie).</p> <p>Per prima cosa, carichiamo il dataset in memoria utilizznado Pandas:</p> <pre><code>path = \"https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv\"\ndataset = pd.read_csv(path)\n</code></pre> <p>Visualizziamo la testa del dataset.</p> <pre><code>dataset.head()\n</code></pre> <p>TODO: IMMAGINE</p> <p>Notiamo come il dataset contenga diversi tipi di dato, sia numerici (ad esempio, billlengthmm), sia categorici (ad esempio, sex). Vi sono inoltre delle feature mancanti. A differenza delle reti nuerali, tuttavia, le foreste decisionali sono in grado di supportare tutti questi tipi di feature in maneira nativa, per cui non dobbiamo effettaure encoding, normalizzazioni o roba del genere.</p> <p>Per semplificare l'interpretabilit\u00e0, convertiamo manualmente le specie dei pinguini in label intere:</p> <pre><code>label = \"species\"\nclasses = list(pandas_dataset[label].unique())\nprint(f\"Label classes: {classes}\")\n# &gt;&gt; Label classes: ['Adelie', 'Gentoo', 'Chinstrap']\npandas_dataset[label] = pandas_dataset[label].map(classes.index)\n</code></pre> <p>https://developers.google.com/machine-learning/decision-forests/practice?hl=en</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/","title":"Gradient Boosted Decision Trees","text":"<p>Come per il bagging ed il boosting, il gradient boosting \u00e8 una metodologia applicata su altri algoritmi di mcahine learning.</p> <p>Informalmente, il gradient boosting coinvolge due tipi di modelli:</p> <ul> <li>un modello debole, che \u00e8 tipicamente un albero decisionale</li> <li>un modello forte, che \u00e8 tipicamente fatto da pi\u00f9 modelli deboli</li> </ul> <p>Nel gradient boosting, ad ogni stewp, un nuovo modello debole \u00e8 addestrato a predire l'errore dell'attuale modello forte (chiamato pseudo risposta). Definiremo succesviamente il concetto di errore. PEr ora, assumiamo che l'errore sia la differenza tra la predizione ed un valore di regressione. Il modello debole (ovvero l'errore) \u00e8 quindi aggiunto al modello forte con segno negativo per ridurre l'errore del modello forte.</p> <p>Il gradient boosting \u00e8 iterativo. Ogni iterazione invoca la seguente formula:</p> \\[ F_{i+1} = F_i - f_i \\] <p>dove:</p> <ul> <li>\\(F_i\\) \u00e8 il modello forte allo step \\(i\\)</li> <li>\\(f_i\\) \u00e8 il modello debole allo step \\(i\\)</li> </ul> <p>Questa operazione \u00e8 ripetuta fino a che non si trova un criterio di arresto, come il numero massimo di iterazione o se il modello forte inizia ad essere in overfitting su un dataset di validazione separato.</p> <p>Facciamo il gradient boosting su un semplice dataset di regressione. L'obiettivo \u00e8 quello di predire \\(y\\) a partire da \\(x\\); il modello forte viene inizializzato ad una costante pari a zero: \\(F_0(x) = 0\\).</p> <p>Vediamo dello pseudocodice per capire il gradient boosting.</p> <pre><code># Simplified example of regressive gradient boosting.\n\ny = ... # the labels\nx = ... # the features\n\nstrong_model = []\nstrong_predictions = np.zeros_like(y) # Initially, the strong model is empty.\n\nfor i in range(num_iters):\n\n    # Error of the strong model\n    error = strong_predictions - y\n\n    # The weak model is a decision tree (see CART chapter)\n    # without pruning and a maximum depth of 3.\n    weak_model = tfdf.keras.CartModel(\n        task=tfdf.keras.Task.REGRESSION,\n        validation_ratio=0.0,\n        max_depth=3)\n    weak_model.fit(x=x, y=error)\n\n    strong_model.append(weak_model)\n\n    weak_predictions = weak_model.predict(x)[:,0]\n\n    strong_predictions -= weak_predictions\n</code></pre> <p>Applichiamo questo codice al seguente dataset:</p> <p>FARE ESEMPIO</p> <p>Vediamo cosa acade dopo la prima iterazione dell'algoritmo di gradient boosting:</p> <p>FARE ESEMPIO</p> <p>Notiamo che:</p> <ul> <li>il primo plot (a sinsitra) mostra le predizioni del modellop forte, che sono sempre zero</li> <li>il secondo plot mostra l'errore, che \u00e8 il label del modello debole</li> <li>il terzo plot mostra il modello debole</li> </ul> <p>Il primo modello debole sta apprendendo una rappresentazione grossolana della label e si focalizza sulla parte sinistra dello spazio delle feature (la parte con la maggiore variazione, e quindi l'errore maggiore per il modello costantemente errato).</p> <p>A seguire gli stessi plot per un'altra iterazione dell'algoritmo:</p> <p>ALTRA FIGURA</p> <p>A questo punto:</p> <ul> <li>il modello forte contiene le predizioni del modello debolerispetto alla precdente iterazione</li> <li>il nuoivo errore del modello forte \u00e8 ifneriroe</li> <li>la nuova predizione del modello debole \u00e8 focalizzata sulla parte destra dello spazio della feature</li> </ul> <p>Se eseguiamo ulteriormente il modello:</p> <p>FARE FIGURA</p> <p>Noptiamo che, dopo alcune iterazioni, la predizione del modello forte inizia a ricordare il plot del dataset  originario.</p> <p>Qeuste figure illustriano l'algoritmo di gradient boosting che usa gli alberi decisionali come mdoelli deboli. Questa combinazione \u00e8 chiamata gradient boosting decision trees.</p> <p>Le operazioni, tuttavia, mancano di due operazioni che sono svolte nel modno relae, ovvero shrinkage ed ottimizzazione.</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#shrinkage","title":"Shrinkage","text":"<p>Il modello debole \\(f_i\\) \u00e8 moltiplicato per un valore piccolo \\(\\epsilon\\) priam di esere aggiunto al modello forte \\(F_i\\). Questo piccolo valroe \u00e8 chiamatop shrinkage (FARE TRADUZIONE). In altre parole,. invece di usare ad ogni iterazione la formula:</p> \\[ F_{i+1} = F_i - f_i \\] <p>usiamo:</p> \\[ F_{i+1} = F_i - \\ni f_i \\] <p>Lo shirnkage nel gradient boosting \u00e8 analogo al learning rate nelle reti neurali. Lo shringkage controlla quanto veloce il modello forte sta apprendendo, il che aiuta a limitare l'overfitting. In altre parole, un valore di shrinkage vicino allo 0' riduce l'overfitting di pi\u00f9 rispetto ad un valore vicino ad 1.</p> <p>shrinkage = 0.1   # 0.1 is a common shrinkage value. strongpredictions -= shrinkage * weakpredictions</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#l0algoritmo-di-gradient-boosting","title":"L'0algoritmo di Gradient boosting","text":"<p>Nei problemi di regressione, ha senso definire l'errore con segno come la differenza tra la predizione ed il label. Tuttavia, in altri tipi di problemi, questa strategia spesso conduce a risultati scadenti.  Una miogliore strategia usata nel gradient boosting \u00e8 quella di:</p> <ul> <li>definire una funzoine di costo simile a quella usata nelle reti neurali (ad esempio, l'entropia per un problema di classificazione)</li> <li>addestrare il modello debole a predire il gradiente del costo in accordo all'output del modello forte</li> </ul> <p>Formalmente, data una funzione di costo \\(L(y, p)\\), dove \\(y\\) \u00e8 una albel e \\(p\\) una predizione, la pseudo-risposta \\(z_i\\) uisata per addestrare il modello debole allo step \\(i\\) \u00e8:</p> \\[ z_i = \\frac{\\delta L(y, F_i)}{\\delta F_i} \\] <p>dove:</p> <ul> <li>\\(F_i\\) \u00e8 la predizione del modello forte</li> </ul> <p>L'esempio precedente era un problema di regressione: l'obiettivo \u00e8 predire un valore numerico. Nel caso della regressione, l'errore quadratico \u00e8 una normale funcione di costo:</p> \\[ L(y,p)=(y-p)^2 \\] <p>In questo caso, il gradiente \u00e8:</p> \\[ z =  \\frac{\\delta L(y, F_i)}{\\delta F_i} = \\frac{\\delta (y-p)^2}{\\delta p} = 2(y-p) = 2 * e_p \\] <p>dove \\(e_p\\) \u00e8 l'errore di predizione MSE (Mean Signed Error) NOTA: NON E' MEDIO. In pratica, il gradiente \u00e8 il doppio dell'errore di predizione. Notiamo chei fattori costanti non contano a causa dello shrinkage. Questa equivalenza \u00e8 inoltre vera soltanto per prpobnlemi di regressione con costo correlato all'errore quadratico. Per altri tipi di problema di apprendimento supervisionato (ad esempio, classificaizone, ranking, regressione con altre funzioni di costo) non vi \u00e8 equivalenza tra il gradiente e l'errore di predizione.</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#foglieed-ottimizzazione-della-struttura-con-il-metodo-di-newton","title":"Foglieed ottimizzazione della struttura con il metodo di Newton","text":"<p>Il metodo di Neuwton \u00e8 un metodo di ottimizzazione come quello a discesa di gradiente. Tuttavia, a differenza della discesa di gradiente che usa soltanto il gradiente della funzione da ottimizzazre, il metodo di Newton usa sia il gradiente (derivata prima) che la derivata seconda della funzione.</p> <p>Uno step dell'algoritmo a discesa di gradiente \u00e8 dato dalla seguente:</p> \\[ x_{i+1} = x_i - \\frac{\\delta f}{\\delta x}(x_i) = x_i - f^'(x_i) \\] <p>mentre per il metodo di Newton abbiamo:</p> \\[ x_{i+1} = x_i - \\frac{\\frac{\\delta f}{\\delta x}(x_i)}{\\frac{\\delta^2 f}{\\delta^2 x}(x_i)} = x_i - \\frac{f^'(x_i)}{f^{''}(x_i)} \\] <p>Opzionalmente, il metodo di Newton pu\u00f2 essere integrato nell'addestramento dei GBT in due modi:</p> <ol> <li>una volta che un albero viene addestrato, un passo del meotod di Newton \u00e8 applciato su ogni foglia, andando a sovrscrivere il suo valore. La struttura ad albero \u00e8 lasciata intatta; soltanto i valori foglia cambiano.</li> <li>durante l'accrescimento dell'albero, sono scelte delle condizioni secondo un punteggio che include una componente della formula di Newton. La struttura dell'albero \u00e8 alterata.</li> </ol>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#overfitting-regolarizzazione-ed-early-stopping","title":"Overfitting, regolarizzazione ed early stopping","text":"<p>A differenza delle random forest, i GBT possono andare in overfitting. Quindi, come per la rete neurale, si pu\u00f2 applicare la regolarizzazione e l'early stopping usando un dataset di validazione.</p> <p>Dei tipici parametri di regolarizzazione per i GBT includono:</p> <ul> <li>massima profondit\u00e0 ell'albero</li> <li>tasso di shrinkage</li> <li>rapporto degli attributi testati ad ogni nodo</li> <li>coefficienti L1 ed L2 sulla loss</li> </ul> <p>Notiamo che gli alberi decisionali generalmente sono molto meno profondi dei modelli random forest. Di defautl, i GBT in TF-DF cresdcono fino alla profondit\u00e0 di 6. Siccome gli alberi sono poco profondi, il numero minimo di campioni epr foglia ha un piccolo impatto, e di solito non viene TUNED.</p> <p>La necessit\u00e0 di un dataset di validazione \u00e8 un problema quando il numero di campioni di esempio \u00e8 piccolo. Quindi, \u00e8 comune addestrae i GBT all'interno di un loop di cross-validazione, o disabilitare l'early stopping quando il modello si \u00e8 sicuri non vada in overfitting.</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#esempi-di-utilizzo","title":"Esempi di utilizzo","text":"<p>model = tfdf.keras.GradientBoostedTreesModel()</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#part-of-the-training-dataset-will-be-used-as-validation-and-removed","title":"Part of the training dataset will be used as validation (and removed","text":""},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#from-training","title":"from training).","text":"<p>model.fit(tftraindataset)</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#the-user-provides-the-validation-dataset","title":"The user provides the validation dataset.","text":"<p>model.fit(tftraindataset, validationdata=tfvalid_dataset)</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#disable-early-stopping-and-the-validation-dataset-all-the-examples-are","title":"Disable early stopping and the validation dataset. All the examples are","text":""},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#used-for-training","title":"used for training.","text":"<p>model.fit(    tftraindataset,    validationratio=0.0,    earlystopping=\"NONE\")</p>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#note-when-validation_ratio0-early-stopping-is-automatically-disabled","title":"Note: When \"validation_ratio=0\", early stopping is automatically disabled,","text":""},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#so-early_stoppingnone-is-redundant-here","title":"so early_stopping=\"NONE\" is redundant here.","text":""},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#vantaggi","title":"Vantaggi","text":"<p>I GBT hanno i seguenti vantaggi.</p> <ul> <li>come gli alberi decisionali, supportano nativamente lef eature numeriche e categoriche e spesso non hanno bisogno del preprocessing delle feature</li> <li>i GBT hanno degli iperparametri di default che spesso danno ottimi risultati. Tuttavia, il tunign di questi iperparametri pu\u00f2 singificativamente miglikorare il modello</li> <li>i GBT sono di solito piccoli (come numero di nodi ed in memoria) e veloci da eseguire (di solito solo uno o pochi microsecondi per campione)</li> </ul>"},{"location":"material/04_sklearn/04_decision_trees/gradient_boost/#svantaggi","title":"Svantaggi","text":"<ul> <li>gli alberi decisionalid evono essere addestrati in maniera sequenziale, che pu\u00f2 rallentare consierevolmente il training. Tuttavia, il rallentamento nell'0addestramento \u00e8 in qualche modo compensato dalle piccole dimensioni dell'albero</li> <li>cos\u00ec come le random forest, i GBT non possono apprendere e riutilzizare rappresentazioni interne. Ogni albero decisionale (ed ogni ramo di ogni albero decisionale) deve apprendere nuovamente il pattern del dataset. In alcuni dataset, specie quelli con dati non strutturati (ad esempio, immagini e testo) possono fare in modo che i GBT abbaino risultati peggiori rispetto ad altri metodi.</li> </ul> <p>ULTIMA: https://developers.google.com/machine-learning/decision-forests/overfitting-gbdt?hl=en</p>"},{"location":"material/04_sklearn/16_lin_reg/exercises/","title":"E16 - Apprendimento supervisionato e regressione lineare","text":""},{"location":"material/04_sklearn/16_lin_reg/exercises/#esercizio-e161","title":"Esercizio E16.1","text":"<p>Proviamo ad operare sul dataset Tips di Seaborn, effettuando una regressione lineare che riguardi le mance ed il conto totale. Per farlo, usiamo un oggetto di classe <code>LinearRegression()</code> messo a disposizione dal package <code>linear_model</code> di Scikit Learn.</p> <p>Valutiamo lo score \\(R^2\\) ottenuto, e mostriamo a schermo i risultati dell'interpolazione, assieme al coefficiente angolare ed all'intercetta ottenuti.</p>"},{"location":"material/04_sklearn/16_lin_reg/exercises/#esercizio-e162","title":"Esercizio E16.2","text":"<p>L'algoritmo RANSAC (RANdom SAmple Consensus) permette di effettuare una regressione in quattro step.</p> <ol> <li>Per prima cosa, viene scelto un sottoinsieme dei dati iniziali.</li> <li>Viene stimato un modello a partire dal sottoinsieme considerato nel punto 1.</li> <li>Tutti i dati sono classificati come inlier o outlier sulla base di un valore di soglia.</li> <li>Se il modello ha un numero di outlier inferiore a quello estrapolato dal modello all'iterazione precedente, viene aggiornato il \"modello migliore\", e si passa all'iterazione successiva.</li> </ol> <p>Proviamo ad effettuare poi un'interpolazione mediante un oggetto di classe <code>RANSACRegression()</code>, e confrontiamo i risultati ottenuti in precedenza in tre modi:</p> <ul> <li>tramite un plot;</li> <li>valutando lo score;</li> <li>valutando i valori di coefficiente ed intercetta del modello usato.</li> </ul> <p>Proviamo infine ad eseguire due volte il RANSAC, e verifichiamo che i risultati ottenuti siano differenti.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/04_sklearn/16_lin_reg/lecture/","title":"16 - Apprendimento supervisionato: la regressione lineare","text":"<p>Quelli di apprendimento supervisionato sono probabilmente tra i sistemi di machine learning pi\u00f9 diffusi, soprattutto a causa dei numerosi casi d'uso disponibili. Abbiamo detto che esistono fondamentalmente due tipi di tecniche di apprendimento supervisionato, ovvero regressione e classificazione. Vediamole maggiormente nel dettaglio.</p>"},{"location":"material/04_sklearn/16_lin_reg/lecture/#161-un-esempio-di-regressione","title":"16.1 - Un esempio di regressione","text":"<p>A tutti noi \u00e8 intuitivamente noto che i millimetri di pioggia che cadono sono in qualche modo correlati alle temperature medie che abbiamo durante la giornata. Immaginiamo quindi di avere un dataset che contenga al suo interno i dati medi sui millimetri di pioggia degli ultimi dieci anni per undici valori differenti di temperatura. Se provassimo a visualizzare i dati mediante un <code>relplot()</code>, otterremmo la seguente figura.</p> <p></p> <p>Proviamo ad usare la funzione <code>lmplot()</code> che, ricordiamo, effettua una regressione tra i dati.</p> <p></p>"},{"location":"material/04_sklearn/16_lin_reg/lecture/#162-rappresentazione-analitica-del-modello","title":"16.2 - Rappresentazione analitica del modello","text":"<p>Notiamo subito che, come prevedibile, i millimetri di pioggia attesi diminuiscono all'aumentare della temperatura, andando a definire una sorta di relazione lineare tra i dati sull'asse delle ascisse (ovvero i gradi) e quelli sull'asse delle ordinate (ovvero la pioggia).</p> <p>Ovviamente, la retta di regressione non tocca direttamente tutti i punti, ma li approssima. Possiamo quindi dire che la relazione tra gradi e mm di pioggia \u00e8 riconducibile ad una forma del tipo:</p> \\[ y = mx + b \\] <p>dove:</p> <ul> <li>\\(y\\) sono i millimetri di pioggia medi caduti nell'arco di tutte le giornate con un dato valore medio di temperatura;</li> <li>\\(x\\) \u00e8 il valore medio di temperatura;</li> <li>\\(m\\) \u00e8 il coefficiente angolare della retta di regressione;</li> <li>\\(b\\) \u00e8 l'incercetta della retta di regressione.</li> </ul> <p>Questa notazione analitica si traduce in un modello usando la seguente notazione:</p> \\[ y' = b + w_1 x_1 \\] <p>dove:</p> <ul> <li>\\(y'\\) \u00e8 l'output predetto dal modello;</li> <li>\\(b\\) \u00e8 il bias, equivalente al concetto analitico di intercetta;</li> <li>\\(w_1\\) \u00e8 il peso della prima feature, equivalente al concetto analitico di coefficiente angolare;</li> <li>\\(x_1\\) \u00e8 il valore di ingresso assunto dalla prima feature.</li> </ul> <p>Per inferire un nuovo valore di \\(y'\\) ci baster\u00e0 quindi cambiare il valore assunto da \\(x1\\). In pratica, potremo prevedere che per una temperatura di 8 gradi, avremo un valore di precipitazioni pari a 25 mm, mentre per una temperatura di 32 gradi il valore di precipitazioni sar\u00e0 pari a 0.</p> <p>Nota</p> <p>In questo caso, abbiamo presupposto che vi sia un'unica variabile indipendente, o feature, a determinare il valore dell'output. Esistono ovviamente casi pi\u00f9 complessi, nei quali il valore di \\(y'\\) \u00e8 determinato a partire da pi\u00f9 feature come \\(y' = b + w_1 x_1 + \\ldots + w_n x_n\\).</p>"},{"location":"material/04_sklearn/16_lin_reg/lecture/#163-addestramento-e-funzione-di-costo","title":"16.3 - Addestramento e funzione di costo","text":"<p>Addestrare un modello significa fare in modo che determini dei valori ottimali per tutti i pesi ed i bias a partire dagli esempi dotati di label. Per determinare tali valori, i modelli ad apprendimento supervisionato provano ad esaminare iterativamente tutti i campioni presenti nel set di addestramento alla ricerca di un modo per minimizzare un costo, il quale rappresenta una certa penalit\u00e0 assegnata al modello in caso di predizione errata.</p> <p>In pratica, il costo (o, in inglese, loss) \u00e8 un numero che determina se la predizione effettuata dal modello su un singolo \u00e8 stata pi\u00f9 o meno conforme alla label assegnata. In caso di predizione perfetta, la loss \u00e8 pari a \\(0\\); tuttavia, nel caso la predizione sia sbagliata, la loss sar\u00e0 tanto pi\u00f9 grande quanto pi\u00f9 il valore predetto sar\u00e0 divergente dal valore atteso. Proviamo ad interpretare graficamente questo concetto, riferendoci ai modelli di regressione:</p> <p></p> <p>In particolare, nella figura precedente, le frecce rappresentano la loss, mentre il segmento blu rappresenta la predizione. Appare evidente come il secondo esempio abbia una loss complessiva inferiore rispetto al primo.</p> <p>Per calcolare la loss complessiva del modello su un insieme di campioni \u00e8 possibile utilizzare una funzione di costo, o loss function. Esistono molteplici esempi di funzioni di costo; tuttavia, uno dei pi\u00f9 semplici da comprendere \u00e8 l'errore quadratico medio, calcolato a partire dalla seguente formula:</p> \\[ MSE = \\frac{1}{N} \\sum_{(x, y) \\in D} (y - y')^2 \\] <p>Nella formula precedente:</p> <ul> <li>\\((x, y)\\) \u00e8 una coppia di feature e label;</li> <li>\\(y'\\) \u00e8 il valore predetto della label a partire dall'applicazione del modello;</li> <li>\\(D\\) \u00e8 il nostro dataset etichettato;</li> <li>\\(N\\) \u00e8 il numero di campioni prensenti in \\(D\\).</li> </ul> <p>In pratica, l'MSE \u00e8 tanto pi\u00f9 alto quanto maggiore \u00e8 la distanza quadratica complessiva tra ogni label \"vera\" ed il rispettivo valore predetto dall'algoritmo di machine learning. Nel caso precedente, \u00e8 chiaro come l'MSE sia maggiore per la prima approssimazione rispetto alla seconda.</p>"},{"location":"material/04_sklearn/16_lin_reg/lecture/#165-addestramento-iterativo","title":"16.5 - Addestramento iterativo","text":"<p>Gli algoritmi di machine learning tendono ad essere addestrati seguendo un approccio iterativo, che prevede che al termine di ciascuna iterazione i valori dei pesi siano aggiornati in maniera da ridurre ulteriormente il valore della funzione di costo. Questo \u00e8 riassumibile nel seguente schema:</p> <pre><code>flowchart TB\n    A[Dataset] --&gt; B[Feature] &amp; C[Label];\n    B &amp; C --&gt; D[Prediction];\n    D --&gt; E[Loss evaluation];\n    E --&gt; F[Parameters update];\n    F --&gt; D;</code></pre> <p>In pratica, durante l'addestramento, ad ogni iterazione il modello effettua una predizione sulle feature. Questa predizione viene comparata con la label, e la loss viene calcolata. I pesi sono quindi aggiornati in base ad una determinata regola di ottimizzazione, ed il ciclo si ripete.</p> <p>Nota</p> <p>Le iterazioni non sono infinite: normalmente, si imposta un numero preciso di epoche di training, oppure si aspetta che l'algoritmo arrivi ad una sorta di \"convergenza\", nella quale il valore della loss non decresce ulteriormente.</p>"},{"location":"material/04_sklearn/16_lin_reg/lecture/#1651-ottimizzazione-della-loss","title":"16.5.1 - Ottimizzazione della loss","text":"<p>Abbiamo in precedenza accennato al fatto che l'aggiornamento dei pesi segue una certa regola di ottimizzazione volta a minimizzare la loss. Ne esistono diverse versioni, ma in generale si rifanno al concetto di discesa di gradiente, illustrato nella seguente immagine.</p> <p></p> <p>Spieghiamo brevemente cosa accade guardando da sinistra verso destra.</p> <p>Possiamo immaginare la funzione che modella la nostra loss come una sorta di paraboloide, dotato di un valore minimo prossimo allo zero che viene raggiunto in corrispondenza di una determinata combinazione dei valori dei pesi.</p> <p>Ipotizzando di trovarci all'inizio dell'addestramento nella situazione raffigurata nella figura a sinistra, ovvero con dei pesi nel ramo sinistro del paraboloide, il nostro obiettivo sar\u00e0 quello di muoverci verso \"destra\", ovvero verso il minimo globale della funzione. Per farlo, intuitivamente, dovremo valutare la derivata o, nel caso di funzioni ad \\(n\\) dimensioni, con \\(n\\) numero di feature, il gradiente della nostra funzione di costo, ed aggiornare i pesi in maniera tale che questo assuma, alla successiva iterazione, un valore inferiore.</p> <p>Questo aggiornamento ci porta alla figura centrale, in cui vediamo che il gradiente si \u00e8 spostato dal punto rosso al punto blu. In questa iterazione dovremo ancora aumentare il valore dei pesi affinch\u00e8 il valore della funzione di costo diminuisca, portandoci quindi nella situazione raffigurata nella figura a destra.</p> <p>In quest'ultima situazione vedremo che il segno del gradiente sar\u00e0 diventato positivo, in quanto ci troveremo su una parte ascendente del paraboloide; di conseguenza, dovremo diminuire i pesi per far convergere l'algoritmo.</p> <p>Learning rate</p> <p>Il \"quantitativo\" di cui sono aggiornati i pesi \u00e8 spesso denotato come learning rate. Un learning rate troppo basso porta ad una convergenza molto lenta dell'algoritmo, che potrebbe \"esaurire\" le iterazioni prima di arrivare al minimo della funzione di costo. Un learning rate eccessivamente altro potrebbe invece fare in modo che l'algoritmo \"salti\" da una parte all'altra del minimo, non arrivando neanche in questo caso a convergenza.</p> <p>Minimi locali</p> <p>Il nostro banale esempio presuppone che la funzione di costo non abbia alcun minimo locale. Ci\u00f2 non \u00e8 ovviamente vero, e delle scelte sbagliate in termini di punto di partenza o learning rate potrebbero farci finire all'interno di un minimo locale, impedendoci di arrivare a convergenza.</p>"},{"location":"material/04_sklearn/16_lin_reg/lecture/#1652-overfitting-e-regolarizzazione","title":"16.5.2 - Overfitting e regolarizzazione","text":"<p>Alle volte, accade che il nostro modello sia in grado di arrivare ad una loss estremamente bassa sui dati di training, ma che tuttavia inizia ad aumentare sui dati di validazione, un po' come nella figura successiva:</p> <p></p> <p>Ci\u00f2 pu\u00f2 accadere per diversi motivi, come errori nei parametri di addestramento o dati non ben bilanciati. Ad ogni modo, questo fenomeno prende il nome di overfitting, e comporta che il modello, che si comporta benissimo sui dati di training, non riesca a generalizzare, comportandosi in maniera meno egregia sui dati di validazione. L'overfitting si manifesta all'aumentare delle epoche di training, quando il nostro modello diventa sempre pi\u00f9 \"complesso\", ed apprende sempre meglio a caratterizzare relazioni di complessit\u00e0 crescente intercorrenti tra feature e label.</p> <p>Per arginare il fenomeno dell'overfitting, oltre ad agire sui dati e sui parametri del modello, si inserisce spesso un termine di regolarizzazione, che tende a penalizzare un modello in grado di caratterizzare relazioni eccessivamente complesse. Il termine di regolarizzazione interviene direttamente sul valore trattato dall'ottimizzatore, che non avr\u00e0 pi\u00f9 come unico obiettivo quello di minimizzare la loss, ma quello di minimizzare congiuntamente la loss e la complessit\u00e0 del modello ottenuto.</p> <p>Una funzione di regolarizzazione molto usata \u00e8 la regolarizzazione \\(L_2\\), definita come la somma dei quadrati dei pesi associati alle feature:</p> \\[ L_2 = ||w||_2^2 = w_1^2 + w_2^2 + \\ldots + w_n^2 \\] <p>Minimizzare questo termine significa dare meno \"importanza\" ad alcuni pesi che inficiano la complessit\u00e0 totale del modello. Se, ad esempio, avessimo i seguenti pesi:</p> \\[ {w_1 = 0.1, w_2 = 0.025, w_3 = 0.4, w_4 = 10} \\] <p>il termine di regolarizzazione \\(L_2\\) diverrebbe pari a:</p> \\[ L_2 = 0.01 + 0,000625 + 0.16 + 100 \\sim 100.17 \\] <p>E' evidente come la maggior parte del contributo sia data dal quarto peso, per cui risulta essere necessario diminuirne l'influenza nel modello allo scopo di bilanciare l'overfitting.</p>"},{"location":"material/04_sklearn/16_lin_reg/lecture/#166-la-regressione-lineare-in-scikit-learn","title":"16.6 La regressione lineare in Scikit Learn","text":"<p>La regressione lineare in Scikit Learn \u00e8 implementata mediante gli oggetti di classe <code>LinearRegression()</code> contenuti all'interno del package <code>linear_model</code> delal libreria.</p> <p>Oggetti di questo tipo sono degli estimator, e funzionano in questo modo:</p> <pre><code>import numpy as np\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\ndata = np.array([[0, 0], [1, 1], [2, 2]])\nreg.fit(data)\n</code></pre> <p>Nel codice precedente stiamo creando un oggetto di classe <code>LinearRegression()</code> ed un array NumPy chiamato genericamente <code>data</code>. Per effettuare l'addestramento del nostro modello, dovremo chiamare il metodo <code>fit</code> di <code>reg</code> passandogli <code>data</code>; fatto questo, l'istanza <code>reg</code> sar\u00e0 stata regolarmente addestrata, e sar\u00e0 pronta per effettuare le predizioni.</p> <p>In tal senso, dovremo usare il metodo <code>predict()</code>:</p> <pre><code>reg.predict([[4, 4]])\n</code></pre> <p>Per accedere ai parametri dello stimatore (ovvero al coefficiente angolare ed all'intercetta) dovremo usare gli attributi <code>coef_</code> ed <code>intercept_</code>:</p> <pre><code>reg.coef_\n</code></pre> <p>La classe <code>LinearRegression()</code> ci mette a disposizione anche il metodo <code>score()</code>, che ci permette di ottenere il coefficiente \\(R^2\\) ottenuto dal modello di regressione. Questo \u00e8 pari a:</p> \\[ R^2 = (1 - \\frac{u}{v}) \\] <p>dove:</p> <ul> <li>\\(u\\) \u00e8 pari alla sommatoria dei quadrati dei residui, ovvero \\(\\sum (y - y')^2\\);</li> <li>\\(v\\) \u00e8 pari alla sommatoria della differenza tra i valori veri ed il valor medio, ovvero \\(\\sum (y - \\mu(y))^2\\).</li> </ul> <p>Conoscere il valore di \\(R^2\\) \u00e8 importante per avere un'idea della bont\u00e0 del modello. Nel caso ideale, infatti, questo valore \u00e8 \\(1\\), mentre valori inferiori (o addirittura negativi) rappresentano delle possibili criticit\u00e0 del modello.</p> <p>Intervalli di confidenza</p> <p>Scikit Learn non fornisce un intervallo di confidenza per le predizioni ottenute; pi\u00f9 informazioni su questa scelta di design qui. Tuttavia, \u00e8 possibile implementare questa funzionalit\u00e0 usando NumPy, come descritto qui, o in alternativa usare il package Statsmodels.</p>"},{"location":"material/04_sklearn/17_logistic/exercises/","title":"E17 - Regressione logistica","text":""},{"location":"material/04_sklearn/17_logistic/exercises/#esercizio-e171","title":"Esercizio E17.1","text":"<p>Continuiamo ad operare sul dataset Tips di Seaborn. In particolare, scegliamo come label il giorno, e come feature sulle quali operare il conto totale, la mancia e la dimensione del tavolo. Addestriamo un classificatore a determinare qual \u00e8 il giorno pi\u00f9 probabile sulla base delle feature selezionate.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/04_sklearn/17_logistic/lecture/","title":"17 - Modelli supervisionati: regressione logistica","text":"<p>Esistono diversi problemi, tra cui quelli di classificazione multiclasse, che richiedono che l'uscita del sistema sia una stima di probabilit\u00e0; per far questo, la regressione logistica \u00e8 lo strumento \"principe\" da utilizzare.</p> <p>Per comprenderne il funzionamento, supponiamo di creare un modello di regressione logistica che predica la probabilit\u00e0 che una mail ricevuta da un indirizzo sconosciuto sia di spam. Chiameremo questa probabilit\u00e0 come:</p> \\[ p(mail|unknown) \\] <p>Se il modello afferma che la probabilit\u00e0 \\(p(mail|unknown) = 0.05\\), allora, su \\(100\\) mail ricevute da indirizzi sconosciuti, \\(5\\) saranno di spam:</p> \\[ spam = p(mail|unknown) \\cdot mail_rec = 0.05 * 100 = 5 \\] <p>Questo \u00e8 un esempio di utilizzo della probabilit\u00e0 as is. In molti casi, tuttavia, mapperemo l'output della soluzione su un problema di classificazione binario, nel quale l'obiettivo \u00e8 predire correttamente uno di due possibili label (in questo caso, spam o non spam).</p>"},{"location":"material/04_sklearn/17_logistic/lecture/#171-la-funzione-sigmoidale","title":"17.1 - La funzione sigmoidale","text":"<p>Ci si potrebbe chiedere come un modello per la regressione logistica sia in grado di asicurarsi che l'uscita ricada sempre nell'intervallo tra \\(0\\) ed \\(1\\). In tal senso, questo \u00e8 assicurato dall'uso della funzione sigmoidale, definita come segue:</p> \\[ y = \\frac{1}{1+e^{-z}} \\] <p>la cui formulazione grafica \u00e8 la seguente:</p> <p></p> <p>Nell'espressione precedente, notiamo che:</p> <ul> <li>\\(y\\) \u00e8 l'uscita della regressione logistica;</li> <li>\\(z\\) \u00e8 pari, per un generico modello lineare, a \\(b + w_1 x_1 + \\ldots + w_N z_N\\).</li> </ul>"},{"location":"material/04_sklearn/17_logistic/lecture/#172-funzione-di-costo","title":"17.2 - Funzione di costo","text":"<p>La funzione di costo per la funzione logistica \u00e8 chiamata log loss, ed \u00e8 espressa come:</p> \\[ LogLoss = \\sum_{(x, y) \\in D} -y log(y') - (1 - y) log (1 - y') \\] <p>dove:</p> <ul> <li>\\((x, y)\\) sono le coppie date da feature e label nel dataset \\(D\\);</li> <li>\\(y\\) \u00e8 la label vera per un dato insieme di feature;</li> <li>\\(y'\\) \u00e8 il valore predetto.</li> </ul>"},{"location":"material/04_sklearn/17_logistic/lecture/#173-regressione-logistica-in-scikit-learn","title":"17.3 - Regressione logistica in Scikit Learn","text":"<p>In Scikit Learn la regressione logistica \u00e8 implementata mediante la classe <code>LogisticRegression()</code>. </p> <p>E' importante sottolineare come la regressione logistica, nonostante il nome, si comporti a tutti gli effetti come un classificatore: di conseguenza, l'output del modello sar\u00e0 una classe, e non un valore di regressione.</p>"},{"location":"material/04_sklearn/18_metrics/exercises/","title":"E18 - Metriche","text":""},{"location":"material/04_sklearn/18_metrics/exercises/#esercizio-e181","title":"Esercizio E18.1","text":"<p>Consideriamo il regressore logistico usato nell'esercizio 17.1. Valutiamo per prima cosa i risultati ottenuti in termini di accuratezza, precisione e recall usando le apposite funzioni di Scikit Learn. Utilizziamo anche la funzione <code>classification_report()</code> per ottenere un report completo dell'esito del classificatore.</p>"},{"location":"material/04_sklearn/18_metrics/exercises/#esercizio-e182","title":"Esercizio E18.2","text":"<p>Proviamo adesso a verificare come variano i valori di accuratezza, precisione e recall per diversi valori della soglia di decisione. In tal senso:</p> <ul> <li>semplifichiamo il problema riducendolo ad una classificazione binaria, e quindi considerando come label la colonna <code>time</code>;</li> <li>utilizziamo il metodo <code>predict_proba(X)</code> del <code>LogisticRegressor()</code>.</li> </ul>"},{"location":"material/04_sklearn/18_metrics/exercises/#esercizio-e183","title":"Esercizio E18.3","text":"<p>Consideriamo il regressore lineare usato nell'esercizio 16.1. Valutiamo i risultati ottenuti in termini di MSE, MAPE ed \\(R^2\\).</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/04_sklearn/18_metrics/lecture/","title":"18 - Metriche","text":"<p>Abbiamo visto come la regressione logistca restituisca una probabilit\u00e0, che grazie alla classe <code>LogisticRegression()</code> viene automaticamente convertita in un valore relativo ad una classe.</p> <p>Torniamo al nostro spam detector. Un modello di regressione logistica che restituisca una probabilit\u00e0 \\(p = 0.999\\) ci sta dicendo che, molto probabilmente, questo \u00e8 di spam; di converso, se il modello restituisce \\(p = 0.003\\) allora \u00e8 molto probabile che il messaggio non sia spam. Cosa accade per\u00f2 nel caso in cui \\(p = 0.505\\)?</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#181-soglia-di-decisione","title":"18.1 - Soglia di decisione","text":"<p>L'esempio precedente ci fa comprendere come per passare da una probabilit\u00e0 ad una classe sia necessario definire una soglia di decisione: un valore oltre questa soglia indicher\u00e0, ad esempio, che la mail ricevuta \u00e8 di spam, mentre uno al di sotto della soglia ci suggerir\u00e0 che non lo \u00e8.</p> <p>Ovviamente, la tentazione potrebbe essere quella di presupporre che la soglia di decisione sia sempre pari a \\(0.5\\): questo, ovviamente, non \u00e8 vero, in quanto la soglia dipende dal problema, ed \u00e8 un valore che bisogna stabilire in base al problema affrontato. Introduciamo alcune metriche che possono essere usate in tal senso.</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#182-metriche-per-i-classificatori","title":"18.2 - Metriche per i classificatori","text":"<p>Continuiamo a concentrarci sul caso della classificazione dello spam, ed introduciamo il concetto di classe positiva e classe negativa.</p> <p>In particolare, la classe positiva sar\u00e0 rappresentata da tutte le mail di spam, mentre la classe negativa sar\u00e0 rappresentata dalle mail non spam. In tal senso, le predizioni del modello potranno essere di quattro tipi:</p> <ul> <li>nel primo caso, il modello classificher\u00e0 correttamente una mail di spam. In questo caso, si parla di vero positivo, o true positive (TP);</li> <li>nel secondo caso, il modello classificher\u00e0 correttamente una mail legittima. In questo caso, si parla di vero negativo, o true negative (TN);</li> <li>nel terzo caso, il modello classificher\u00e0 una mail di spam come legittima. In questo caso, si parla di falso negativo, o false negative (FN);</li> <li>nel quarto caso, il modello classificher\u00e0 una mail legittima come di spam. In questo caso, si parla di falso positivo, o false positive (FP).</li> </ul> <p>In pratica, un TP (TN) si ha quando il modello predice correttamente la classe positiva (negativa), mentre un FP (FN) si ha quando il modello predice in maniera non corretta la classe positiva (negativa).</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#1821-accuratezza","title":"18.2.1 - Accuratezza","text":"<p>L'accuratezza \u00e8 la prima metrica che vedremo per la valutazione dei modelli di classificazione. Informalmente, possiamo definirla come la percentuale di predizioni corrette effettuate dal nostro modello, e definirla come:</p> \\[ AC = \\frac{C}{T} \\] <p>dove \\(C\\) \u00e8 il numero totale di predizioni corrette, mentre \\(T\\) \u00e8 il numero totale di predizioni. Nel caso della classificazione binaria, possiamo calcolare l'accuratezza come segue:</p> \\[ AC = \\frac{TP + TN}{TP + TN + FP + FN} \\] <p>Immaginiamo ad esempio di aver ricevuto \\(100\\) email, tra cui \\(10\\) di spam. Il nostro spam detector ha individuato correttamente \\(5\\) messaggi di spam, e classificato per sbaglio come spam \\(5\\) messaggi legittimi. Allora:</p> \\[ AC = \\frac{TP+TN}{TP+TN+FP+FN}=\\frac{5+85}{5+85+5+5} \\] <p>In questo caso, l'accuratezza del modello \u00e8 pari a \\(0.90\\), o del \\(90\\%\\), il che significa che il nostro modello \u00e8 in grado di fare \\(90\\) predizioni su \\(100\\). Buon risultato, giusto?</p> <p>In realt\u00e0, non necessariamente. Infatti, delle mail che abbiamo ricevuto, \\(90\\) sono legittime, e \\(10\\) di spam. Questo significa che il modello \u00e8 stato in grado di individuare soltanto il \\(50\\%\\) dello spam ricevuto, ed ha inoltre classificato un buon \\(7\\%\\) delle email legittime come spam. Tra cui, prevedibilmente, quella che ci comunicava notizie di vitale importanza. In sostanza, il nostro modello ha un'efficacia \"vera e propria\" al pi\u00f9 in un caso su due.</p> <p>Di conseguenza, l'accuratezza non ci racconta \"tutta la storia\" quando lavoriamo su un dataset sbilanciato come questo, dove vi \u00e8 una disparit\u00e0 significativa tra la classe positiva e quella negativa.</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#18211-accuratezza-in-scikit-learn","title":"18.2.1.1 - Accuratezza in Scikit Learn","text":"<p>L'accuratezza delle predizioni effettuate da un classificatore \u00e8 ottenuta in Scikit Learn utilizzando il metodo <code>accuracy_score()</code>.</p> <p>Ad esempio:</p> <pre><code>from sklearn.metrics import accuracy_score\nclf = LogisticRegression(max_iter=1000)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\naccuracy_score(y_test, y_pred)\n</code></pre>"},{"location":"material/04_sklearn/18_metrics/lecture/#1822-la-precisione","title":"18.2.2 - La precisione","text":"<p>La precisione \u00e8 una metrica che prova a risolvere alcuni dei problemi dell'accuratezza valutando quale sia la proporzione di valori per la classe positiva identificati correttamente.</p> <p>La definizione analitica della precisione \u00e8 la seguente:</p> \\[ PR = \\frac{TP}{TP+FP} \\] <p>In pratica, riferendoci al nostro solito esempio, la precisione \u00e8 data dal rapporto tra le mail di spam riconosciute come tali e la somma tra queste e le mail legittime riconosciute come spam. Provando a calcolarla:</p> \\[ PR = \\frac{5}{5+5} = 0.5 \\] <p>Il modello ha quindi una precisione del \\(50\\%\\) nel riconoscere una mail di spam.</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#18221-precisione-in-scikit-learn","title":"18.2.2.1 - Precisione in Scikit Learn","text":"<p>La precisione delle predizioni effettuate da un classificatore \u00e8 ottenuta in Scikit Learn utilizzando il metodo <code>precision_score()</code>.</p> <p>Ad esempio:</p> <pre><code>from sklearn.metrics import precision_score\nprecision_score(y_test, y_pred)\n</code></pre>"},{"location":"material/04_sklearn/18_metrics/lecture/#1823-il-recall","title":"18.2.3 - Il recall","text":"<p>Il recall, traducibile in italiano come richiamo, verifica la porzione di veri positivi correttamente identificata dall'algoritmo, ed \u00e8 espresso come:</p> \\[ R = \\frac{TP}{TP+FN} \\] <p>Nel nostro caso, il recall sar\u00e0 quindi dato dal rapporto tra le mail correttamente indicate come spam e la somma tra le stesse e quelle erroneamente indicate come legittime. Va da s\u00e8 che anche in questo caso possiamo calcolarlo:</p> \\[ R = \\frac{5}{5+5} \\] <p>Cos\u00ec come la precisione, il recall \u00e8 pari a \\(0.5\\), ovvero \u00e8 del \\(50\\%\\).</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#18231-recall-in-scikit-learn","title":"18.2.3.1 - Recall in Scikit Learn","text":"<p>Ovviamente, anche il recall ha una rappresentazione in Scikit Learn mediante la funzione <code>recall_score()</code>:</p> <pre><code>from sklearn.metrics import recall_score\nrecall_score(y_test, y_pred)\n</code></pre>"},{"location":"material/04_sklearn/18_metrics/lecture/#183-tuning-della-soglia-di-decisione","title":"18.3 - Tuning della soglia di decisione","text":"<p>Per valutare l'effiacia del modello dobbiamo esaminare congiuntamente la precisione ed il recall. Sfortunatamente, questi due valori sono spesso in contrapposizione: spesso, infatti, migliorare la precisione riduce il recall, e viceversa. Per comprendere empiricamente questo concetto, facciamo un esempio con il nostro spam detector, immaginando di aver impostato la soglia di decisione a \\(0.6\\). I risultati sono mostrati nella figura successiva.</p> <p></p> <p>Calcoliamo la precisione e il recall in questo caso:</p> \\[ P = \\frac{TP}{TP+FP}=\\frac{4}{4+1} = 0.8 \\\\ R = \\frac{TP}{TP+FN}=\\frac{4}{4+2} = 0.66 \\] <p>Proviamo ad aumentare la soglia di decisione, portandola al \\(75\\%\\).</p> <p></p> \\[ P = \\frac{TP}{TP+FP}=\\frac{3}{3} = 1 \\\\ R = \\frac{TP}{TP+FN}=\\frac{3}{3+3} = 0.5 \\] <p>Proviamo infine a diminuire la soglia di decisione, portandola al \\(50%\\).</p> <p></p> \\[ P = \\frac{TP}{TP+FP}=\\frac{4}{4+3} \\approx 0.57 \\\\ R = \\frac{TP}{TP+FN}=\\frac{4}{4+2} = 0.66 \\] <p>Come possiamo vedere, la soglia di detection agisce su precisione e recall; non \u00e8 per\u00f2 possibile aumentarli contemporaneamente, per cui occorre scegliere un valore tale per cui, ad esempio, si massimizzi la media. La realt\u00e0 \u00e8 che, per\u00f2, dipende sempre dall'applicazione: se non abbiamo paura di perdere mail legittime, allora possiamo abbassare la soglia di decisione, aumentando il recall; viceversa, se siamo disposti ad eliminare manualmente un po' di spam, potremo alzare la soglia di decisione, aumentando la precisione.</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#184-metriche-per-i-regressori","title":"18.4 - Metriche per i regressori","text":"<p>Definiamo brevemente alcune delle metriche che \u00e8 possibile utilizzare per la valutazione delle performance di un modello di regressione.</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#1841-mean-squared-error-mse","title":"18.4.1 - Mean Squared Error (MSE)","text":"<p>Abbiamo gi\u00e0 visto questa metrica quando abbiamo parlato della regressione. L'errore quadratico medio \u00e8 definito come:</p> \\[ MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i-\\hat{y}_i)^2 \\] <p>Questo errore, implementato in Scikit Learn dalla funzione <code>mean_squared_error()</code>, permette di tenere conto di eventuali errori negativi e positivi, ma viene influenzato dalla grandezza assoluta delle variabili. In altre parole, un errore dell'\\(1\\%\\) su un valore \\(y=100\\) sar\u00e0 pi\u00f9 influente di un errore del \\(50\\%\\) su un valore \\(y=1\\).</p> <p>Ovviamente, tanto \u00e8 minore l'MSE, tanto \u00e8 migliore il modello considerato.</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#1842-mean-absolute-percentage-error-mape","title":"18.4.2 - Mean Absolute Percentage Error (MAPE)","text":"<p>Il mean absolute percentage error viene calcolato mediante il rapporto tra il valore assoluto della differenza tra i valori veri e quelli predetti dal regressore e i valori veri stessi. Tale rapporto viene quindi mediato sull'insieme dei campioni, e ne viene dedotta la percentuale. La formula \u00e8 la seguente:</p> \\[ MAPE = \\frac{1}{n} \\sum_{i=1}^n \\frac{|y_i - \\hat{y}_i|}{max (\\epsilon, y_i)} \\% \\] <p>Il MAPE \u00e8 implementato in Scikit Learn mediante la funzione <code>mean_average_percentage_error()</code>.</p> <p>Il vantaggio principale derivante dall'uso del MAPE sta nel fatto che l'uso del valore assoluto elimina eventuali annullamenti derivanti da contributi di segno opposto. Inoltre, la presenza del valore vero a denominatore fa in modo che la metrica sia sensibile agli errori relativi.</p> <p>Anche in questo caso, un valore di MAPE basso indica un'ottima approssimazione.</p>"},{"location":"material/04_sklearn/18_metrics/lecture/#1843-r2-e-varianza-spiegata","title":"18.4.3 - \\(R^2\\) e varianza spiegata","text":"<p>Il valore \\(R^2\\) determina la proporzione della varianza del valore vero che viene spiegata dal modello. In pratica, ci permette di definire quanta della variabilit\u00e0 del fenomeno (ovvero, del modo in cui il fenomeno combina le \\(n\\) variabili indipendenti per ottenere le \\(m\\) variabili dipendenti) viene correttamente caratterizzata attraverso il modello considerato.</p> <p>Il valore di \\(R^2\\) pu\u00f2 oscillare tra \\(1\\) e \\(- \\infty\\), ovvero tra la modellazione completa dell'intera variabilit\u00e0 del fenomeno ed un modello totalmente incorrelato allo stesso.</p> <p>Il valore di \\(R^2\\) \u00e8 definito come:</p> \\[ R^2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y_i})^2}{\\sum_{i=1}^n (y_i-avg(y_i))} \\] <p>con:</p> \\[ avg(y_i) = \\frac{1}{n} \\sum_{i=1}^n y_i \\] <p>Il valore \\(R^2\\) \u00e8 modellato in Scikit Learn mediante la funzione <code>r2_score()</code>, ed in alcuni casi \u00e8 anche presente come metodo all'interno degli stimatori stessi.</p>"},{"location":"material/04_sklearn/19_classifiers_regressors/exercises/","title":"E19 - Classificatori e regressori","text":""},{"location":"material/04_sklearn/19_classifiers_regressors/exercises/#esercizio-e191","title":"Esercizio E19.1","text":"<p>Operiamo sul problema visto nell'esercizio 17.1 usando un albero decisionale, un random forest ed un multilayer perceptron. Compariamo i risultati in termini di precisione, recall ed accuracy.</p>"},{"location":"material/04_sklearn/19_classifiers_regressors/exercises/#esercizio-e192","title":"Esercizio E19.2","text":"<p>Operiamo sul problema visto nell'esercizio 16.1 usando un albero decisionale, un random forest ed un multilayer perceptron. Compariamo i risultati in termini di errore quadratico medio usando la funzione <code>mean_squared_error</code> del package <code>sklearn.metrics</code>.</p>"},{"location":"material/04_sklearn/19_classifiers_regressors/exercises/#esercizio-e193","title":"Esercizio E19.3","text":"<p>Esploriamo i risultati ottenuti dall'albero decisionale nell'esercizio E19.1. Per farlo, usiamo il metodo <code>plot_tree</code> del package <code>sklearn.tree</code>.</p>"},{"location":"material/04_sklearn/19_classifiers_regressors/exercises/#esercizio-e194","title":"Esercizio E19.4","text":"<p>Proviamo a variare leggermente alcuni parametri per i classificatori ed i regressori usati negli esercizi precedenti. Confrontiamo i risultati ottenuti nei termini delle metriche viste in precedenza.</p> <p>Soluzione</p> <p>Le soluzioni a questi esercizi sono contenute in questo notebook.</p>"},{"location":"material/04_sklearn/19_classifiers_regressors/lecture/","title":"19 - Classificatori e regressori","text":""},{"location":"material/04_sklearn/19_classifiers_regressors/lecture/#191-alberi-decisionali","title":"19.1 - Alberi decisionali","text":"<p>Gli alberi decisionali creano un modello che predice una classe o un valore in output a partire da regole di tipo binario inferite dalle feature dei dati. Per far questo, utilizzano una tecnica chiamata recursive partitioning: in pratica, l'insieme di test viene suddiviso imponendo delle soglie sulle diverse variabili, le quali saranno modificate fino a che tutti i dati appartenenti ad una certa classe (o con valori simili di regressione) ricadono all'interno di uno stesso sottoinsieme.</p> <p>Gli alberi decisionali sono facili da interpretare, in quanto rappresentano una serie di regole binarie: un esempio \u00e8 mostrato nella seguente figura.</p> <p></p> <p>Inoltre, non richiedono particolari accortezze in fase di preparazione dei dati, ed hanno una complessit\u00e0 computazionale di tipo logaritmico (e quindi abbastanza bassa).</p> <p>Dall'altro lato, per\u00f2, sono spesso soggetti ad overfitting, ed inoltre non assicurano una predizione continua, ma piuttosto un'approssimazione lineare a tratti.</p> <p>Scikit Learn implementa due versioni degli alberi decisionali: la prima \u00e8 dedicata alla classificazione, ed \u00e8 chiamata <code>DecisionTreeClassifier()</code>, mentre la seconda \u00e8 orientata alla regressione ed \u00e8 chiamata <code>DecisionTreeRegressor()</code>.</p>"},{"location":"material/04_sklearn/19_classifiers_regressors/lecture/#192-random-forest","title":"19.2 - Random forest","text":"<p>I random forest sono dei metodi ensemble basati su alberi decisionali. Un metodo ensemble (letteralmente \"insieme\") permette di combinare i risultati provenienti da diversi algoritmi, ottenendo in generale risultati migliori.</p> <p>In particolare, il random forest sfrutta un insieme di alberi decisionali, ognuno dei quali modellato su un sottoinsieme di dati e feature presenti nel set di training; i risultati provenienti da ciascuno degli alberi saranno poi mediati e combinati. La presenza di queste due componenti di casualit\u00e0 permette di raggiungere un obiettivo ben preciso, ovvero diminuire l'overfitting proprio di un singolo albero decisionale, ottenendo un modello generalmente migliore.</p> <p>Anche per il random forest esistono due versioni, ovvero quella dedicata alla regressione (RandomForestRegressor()) e quella dedicata alla classificazione (RandomForestClassifier()).</p>"},{"location":"material/04_sklearn/19_classifiers_regressors/lecture/#193-multilayer-perceptron","title":"19.3 - Multilayer perceptron","text":"<p>Un multilayer perceptron \u00e8 il pi\u00f9 semplice modello di rete neurale che \u00e8 possibile concepire. Nella pratica, \u00e8 un algoritmo che considera una relazione del tipo:</p> \\[ f:\\mathbb{R}^m \\rightarrow \\mathbb{R}^o \\] <p>dove \\(m\\) \u00e8 il numero di input ed \\(o\\) \u00e8 il numero di dimensioni per l'output. Ad esempio, se avessimo un insieme di feature \\(X=x_1, x_2, \\ldots, x_m\\) ed un'output \\(y\\), sia esso una classe o un valore di regressione, il multilayer perceptron apprender\u00e0 una funzione \\(f: \\mathbb{R}^m \\rightarrow \\mathbb{R}^1\\).</p> <p>Una rappresentazione del multilayer perceptron \u00e8 mostrata nella seguente figura.</p> <p></p> <p>Nella pratica, il layer di input (a sinistra) consiste di un insieme di neuroni, uno per ogni feature. Ogni neurone nello strato nascosto trasforma i valori del layer precedente con una sommatoria pesata \\(w_1 x_1 + \\ldots + w_m x_m\\) seguita da una funzione di attivazione non lineare del tipo \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\).</p> <p>La funzione di attivazione</p> <p>Le funzioni di attivazioni pi\u00f9 usate sono state per lungo tempo le sigmoidali e le loro varianti. Vedremo in seguito come negli ultimi anni quelle maggiormente gettonate siano diventate le ReLU.</p> <p>Nell'ultimo layer, infine, i valori ricevuti dal layer nascosto sono sommati e combinati nell'output.</p> <p>Ovviamente, Scikit Learn offre due varianti dell'algoritmo, quella per la classificazione (<code>MLPClassifier()</code>) e quella per la regressione (<code>MLPRegressor()</code>)</p>"},{"location":"material/04_sklearn/20_clustering/dbscan/","title":"Dbscan","text":""},{"location":"material/04_sklearn/20_clustering/dbscan/#206-un-altro-algoritmo-il-dbscan","title":"20.6 - Un altro algoritmo: il DBSCAN","text":"<p>Il DBSCAN \u00e8 un algoritmo di clustering di tipo agglomerativo density-based che opera considerando due parametri principali:</p> <ul> <li>la distanza massima \\(\\epsilon\\) per considerare due punti come appartenenti allo stesso cluster;</li> <li>il numero minimo di campioni \\(m\\) per il quale \u00e8 possibile definire un cluster.</li> </ul> <p>Nella pratica, il DBSCAN seleziona un campione casuale tra quelli non visitati, e valuta se ci sono \\(m\\) campioni all'interno della distanza \\(\\epsilon\\), nel qual caso si ha un core point. In alternativa, se il numero di campioni presenti in \\(\\epsilon\\) \u00e8 minore di \\(m\\), ma comunque maggiore di 0, i campioni si dicono \\(density reachable\\) e, se connessi ad un core point, appartengono allo stesso cluster. Infine, se non vi sono campioni presenti in \\(\\epsilon\\), allora il punto \u00e8 isolato, ed \u00e8 interpretato come un outlier. Un'interpretazione visiva \u00e8 quella proposta in figura; in particolare, i punti in rosso definiscono diversi core points, i punti in giallo sono density reachable, e quindi fanno parte dello stesso cluster dei core points, mentre \\(N\\) \u00e8 un outlier.</p> <p> </p> Figura 20.4 - Algoritmo DBSCAN.  Di Chire - Opera propria, CC BY-SA 3.0, Wikipedia"},{"location":"material/04_sklearn/20_clustering/exercises/","title":"E20 - Il clustering","text":""},{"location":"material/04_sklearn/20_clustering/exercises/#esercizio-e201","title":"Esercizio E20.1","text":"<p>Il dataset Iris contiene i dati riguardanti lunghezza ed ampiezza di steli e petali per tre classi di fiori, ed \u00e8 uno dei dataset \"standard\" per l'analisi dei dati nel machine learning. In tal senso, usiamo il metodo <code>load_iris</code> del package <code>datasets</code> di Scikit Learn per caricarlo. Una volta caricato in memoria, proviamo ad effettuare un primo clustering usando l'algoritmo k-means con 3 cluster.</p>"},{"location":"material/04_sklearn/20_clustering/exercises/#esercizio-e202","title":"Esercizio E20.2","text":"<p>Verificare il valore di magnitudine e cardinalit\u00e0 per i cluster identificati nell'esercizio precedente.</p>"},{"location":"material/04_sklearn/20_clustering/exercises/#esercizio-e203","title":"Esercizio E20.3","text":"<p>Valutiamo il valore migliore per il numero di cluster da utilizzare per il K-means utilizzando il dataset Iris e l'approccio empirico discusso a lezione. Usiamo valori per il clustering compresi tra 2 e 4.</p>"},{"location":"material/04_sklearn/20_clustering/exercises/#esercizio-e204","title":"Esercizio E20.4","text":"<p>Il K-Means parte da alcune ipotesi sulla natura dei diversi cluster in cui sono organizzati i dati, ovvero che questi siano:</p> <ol> <li>isotropi, e quindi che abbiano una forma \"identica\" in tutte le direzioni;</li> <li>ad eguale varianza, e quindi che non vi siano dei cluster di varianza sensibilmente superiore o inferiore alla varianza media dell'insieme degli stessi;</li> <li>ad eguale cardinalit\u00e0, e quindi che il numero di campioni per i diversi cluster sia all'incirca costante.</li> </ol> <p>Verifichiamo questi assunti su dati generati dal metodo <code>make_blobs()</code>.</p> <p>Note</p> <ol> <li>Per ottenere l'anisotropia, potete applicare una rotazione all'insieme dei dati. Questa pu\u00f2 essere definita in questo modo: <pre><code>t = np.tan(np.radians(60))\nrot = np.array([[1, t], [0, 1]])\nX_an = X.dot(rot)\n</code></pre> </li> <li>Per ottenere dei cluster a diversa cardinalit\u00e0, proviamo a selezionare diversi sottoinsiemi dei dati originari in base al loro valore di <code>y</code>.</li> </ol>"},{"location":"material/04_sklearn/20_clustering/exercises/#esercizio-e205","title":"Esercizio E20.5","text":"<p>Proviamo ad utilizzare l'algoritmo DBSCAN, implementato mediante la classe <code>DBSCAN()</code> del package <code>cluster</code>, nelle tre diverse situazioni ispirate dall'esercizio precedente.</p> <p>Soluzione</p> <p>Le soluzioni a questi esercizi sono contenute in questo notebook.</p>"},{"location":"material/04_sklearn/20_clustering/k_means/","title":"Approfondimento sul k-Means","text":""},{"location":"material/04_sklearn/20_clustering/k_means/#vantaggi-del-k-means","title":"Vantaggi del k-Means","text":"<ul> <li>relativamente semplice da implemenare</li> <li>in grado di scalare a grossi dataset</li> <li>garantisce la convergenza</li> <li>\u00e8 possibile scegliere una posizione iniziale adeguata per i centroidi</li> <li>si adatta facilmente a nuovi campioni</li> <li>generalizza a cluster di diverse forme e dimensioni, come cluster ellittici</li> </ul>"},{"location":"material/04_sklearn/20_clustering/k_means/#generalizzazione-del-k-means","title":"Generalizzazione del k-means","text":"<p>Cosa accade quando i cluster sono di diverse densit\u00e0 e dimensioni? Vediamo nella seguente figura. Compariamo i cluster che intuitivamente possiamo individuare a sinistra con i cluster che vengono individuati dal k-means a destra. La comparazione mostra come il k-means possa avere dei problemi su certi dataset.</p> <p>TODO: FIGURA</p> <p>Per effettuare il clsutering di cluster non bilanciati come quelli mostrati nella figura precedente, possiamo adattare (o, meglio, generalizzare) il k-means. Nella figura 2, le linee mostrano i confini dei cluster dopo la generalizzazione del k-means come:</p> <ul> <li>a sinistra: mancanza di generalizzazione, il che risulta in un confine tra cluster antiintuitivo</li> <li>al centro: permette diverse dimensioni dei clsuter, il che risulta in cluster pi\u00f9 intuitoivi di diverese dimensioni</li> </ul>"},{"location":"material/04_sklearn/20_clustering/k_means/#svantaggi","title":"Svantaggi","text":"<ul> <li>scelta del \\(k\\) manualmente</li> <li>dipendenza dai valori iniziali: per un basso valore di \\(K\\), possiamo mitrigare questa dipendenza eseguendo il k-means diverse volte con diversi valori iniziali e scegliere i migliori risultati. Man mano che \\(k\\) aumenta, abbiamo bisogno di versioni avanzate del k-means per individuare miglioriv alori dei centroidi iniziali (ovvero il seeding del k-means).</li> <li>clustering di dati di varie dimensioni e densit\u00e0: il k-means ha problemi nel clustering dei dati quando i cluster sono di varie dimensioni e densit\u00e0. Per effettuare il clustering di questi dati, dobbiamo generalizzare il k-menas. Per generalizzarlo: http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/clustering.pdf</li> <li>clustering di outliner: i centroidi possono essere \"trascinati\" dagli outlier, o gli outlier potrebbero avere il loro cluster invece di essere ignorati. Dovremo considerare la rimozione degli outlier prima del clustering.</li> <li>scaling con il numero di dimensione: man mano che il numero di dimensioni aumenta, una misura di similarit\u00e0 basata sulla distanza converge ad un valroe costante per ogni possibile esempio. E' quindi necessario ridurre la dimensionalit\u00e0 oi usando la PCA sui dati delle feature o suando delle tecniche di clsutering spettrale.</li> </ul> <p>In particolare, lo spectral clustering evita il problema della curse of dimensionality aggiungendo uno step prima dell'algoritmo:</p> <ol> <li>ridurre la dimensionalit\u00e0 dei dati delle feature usando la PCA</li> <li>proiettare tutti i data point in un sottospazio a minore dimensionalit\u00e0\u00e0</li> <li>effettuare il clsutering dei dati in questo sottospazio usando l'algoritmo di nostra scelta</li> </ol> <p>Quindi, lo spectral clustering non \u00e8 un algoritmo di clustering separato, ma uno step predcdente al clustering che possiamo usare con un qualsioasi algoritmo di clsutering. https://github.com/petermartigny/Advanced-Machine-Learning/blob/master/DataLab2/Luxburg07_tutorial_4488%5B0%5D.pdf</p>"},{"location":"material/04_sklearn/20_clustering/k_means/#implementazione-del-k-means","title":"Implementazione del k-Means","text":"<p>Possiamo implementare ilm k_means usando le API k-Means di TensorFlow. L'APIO di TensorfLow ci permette di scalare il k-means fornendo le seguenti funzionalit\u00e0:</p> <ul> <li>clusteering usnado mini-batches invece dell'intero dataset</li> <li>scelta </li> </ul> <p>ESEMPI</p> <p>https://colab.research.google.com/gist/anhelus/2d436e290996d8fdb1b52cdf68417479/colab-manual-similarity-with-chocolates.ipynb</p> <p>https://colab.research.google.com/github/google/eng-edu/blob/main/ml/clustering/clustering-supervised-similarity.ipynb?utm_source=ss-clustering&amp;utm_campaign=colab-external&amp;utm_medium=referral&amp;utm_content=clustering-supervised-similarity</p> <p>Reference del k-means seeding: https://arxiv.org/abs/1209.1960</p>"},{"location":"material/04_sklearn/20_clustering/lecture/","title":"20 - Il clustering","text":"<p>Il clustering \u00e8 l'operazione di categorizzare dei campioni in un dataset senza che questi abbiano necessariamente un'etichetta determinata a priori.</p> <p>Per fare un esempio, potremmo suddividere i nostri album musicali sulla base delle sonorit\u00e0 ispirate dal loro ascolto: in questo caso, non ci staremmo affidando ad una certa \"etichetta\", come ad esempio l'anno di produzione o l'artista, ma ad un concetto molto pi\u00f9 \"empirico\", ovvero la vicinanza o meno dell'album ai nostri gusti musicali.</p> <p>Ovviamente, dato che nel clustering i campioni non considerano una label, stiamo parlando di apprendimento non supervisionato. Se i campioni fossero etichettati, avremmo una normale procedura di classificazione.</p> <p>Il clustering pu\u00f2 avere numerose applicazioni: ad esempio, potrebbe essere usato per segmentare il mercato mediante dei profili di clientela simili, oppure per suddividere le immagini in zone simili, o ancora per individuare delle anomalie all'interno di un insieme di dati.</p> <p>Una volta che il clustering \u00e8 completo, ad ogni cluster viene assegnato un certo identificativo, che ci permette in qualche modo di \"condensare\" e \"riassumere\" le informazioni dell'intero cluster. Quest'assegnazione pu\u00f2 anche essere usata come ingresso ad altri sistemi di machine learning, ad esempio di classificazione, che possono usare l'identificativo assegnato come una vera e propria label.</p>"},{"location":"material/04_sklearn/20_clustering/lecture/#201-tipi-di-clustering","title":"20.1 - Tipi di clustering","text":"<p>La scelta di un algoritmo di clustering deve essere condotta sulla base della scalabilit\u00e0 dello stesso. Infatti, laddove alcuni algoritmi di clustering confrontano tra loro ogni possibile coppia di dati, con una complessit\u00e0 \\(O(n^2)\\) per \\(n\\) campioni, altri, come il k-means, effettuano un numero molto pi\u00f9 limitato di operazioni, ottenendo una complessit\u00e0 nell'ordine di \\(O(n)\\), il che cambia radicalmente la situazione nel caso di dataset con milioni di campioni. Tuttavia, ogni algoritmo ha anche diversi vantaggi e svantaggi che devono essere valutati sulla base dell'applicazione scelta.</p> <p>In generale, abbiamo quattro diverse categorie di clustering:</p> <ul> <li>nel centroid-based clustering, i dati sono organizzati secondo la loro distanza da dei centroidi, ovvero dei campioni considerati come \"base\" per ciascun cluster. Questo tipo di algoritmi risulta essere mediamente efficace, ma \u00e8 sensibile alle condizioni iniziali ed alla presenza di eventuali outliers;</li> <li>nel density-based clustering, i dati sono organizzati in aree ad alta densit\u00e0. Ci\u00f2 permette la connessione di cluster di forma arbitraria, e facilita inoltre l'individuazione di outlier, che per definizione sono nelle zone a minore densit\u00e0 di campioni. Possono per\u00f2 essere sensibili a dataset con densit\u00e0 variabile ed alta dimensionalit\u00e0;</li> <li>nel distribution-based clustering, si suppone che i dati abbiano distribuzione gaussiana, e siano quindi suddivisibili come tali. Questo tipo di algoritmi non \u00e8 efficiente se non si conosce a priori il tipo di distribuzione dei dati;</li> <li>nello hierarchical clustering viene creato un albero a partire dai dati. Questo tipo di clustering \u00e8 particolarmente efficace nel caso si trattino certi tipi di dati, come ad esempio le tassonomie, e prevede che possa essere selezionato un numero ridotto di cluster tagliando l'albero al giusto livello.</li> </ul>"},{"location":"material/04_sklearn/20_clustering/lecture/#202-workflow-del-clustering","title":"20.2 - Workflow del clustering","text":"<p>L'esecuzione di un algoritmo di clustering prevede tre step:</p> <ol> <li>nel primo, dobbiamo preparare i dati, effettuando le operazioni che abbiamo visto in precedenza per la classificazione e la regressione;</li> <li>nel secondo, dovremo definire una metrica di similarit\u00e0;</li> <li>nel terzo, eseguiremo l'algoritmo vero e proprio.</li> </ol> <p>Concentriamoci per un attimo sul secondo step. Definire una metrica di similarit\u00e0 significa nella pratica stabilire quando due campioni risultano essere simili tra loro. In tal senso, \u00e8 possibile operare in due modi:</p> <ul> <li>la metrica pu\u00f2 essere scelta manualmente, ovvero scegliendo le feature da considerare nella valutazione della distanza tra i campioni;</li> <li>oppure, la metrica pu\u00f2 essere scelta in maniera automatica a partire da un embedding, ovvero da una rappresentazione a dimensionalit\u00e0 ridotta del dato iniziale.</li> </ul> <p>Nel primo caso questo avviene in modo abbastanza intuitivo: se, ad esempio, volessimo suddividere un insieme di scarpe in base a taglia e prezzo, potremmo considerare la distanza euclidea come rappresentativa dello \"spazio\" che intercorre tra due campioni. Questo approccio, tuttavia, \u00e8 efficace soltanto nel caso di campioni a bassa dimensionalit\u00e0.</p> <p>Il secondo caso \u00e8 invece preferibile nel momento in cui si vanno a considerare dei dati ad alta dimensionalit\u00e0: infatti, in queste situazioni si rischia di incorrere nel fenomeno della curse of dimensionality, che rende difficile distinguere tra due campioni differenti, per cui si tende ad estrarre delle rappresentazioni \"ridotte\" dei dati a partire dalle quali applicare il concetto di distanza.</p>"},{"location":"material/04_sklearn/20_clustering/lecture/#203-applicazione-di-un-algoritmo-di-clustering-il-k-means","title":"20.3 - Applicazione di un algoritmo di clustering: il K-Means","text":"<p>Vediamo adesso come usare il pi\u00f9 conosciuto ed utilizzato algoritmo di clustering, ovvero il k-means, algoritmo centroid-based che raggruppa i campioni in \\(k\\) diversi cluster assegnando ogni dato in base alla distanza dal centroide del cluster stesso. Il k-means ha diverse ipotesi alla base, tra cui la pi\u00f9 restrittiva \u00e8 una, ovvero quella legata alla conoscenza del numero iniziale di cluster \\(k\\).</p> <p>Una volta fissato questo valore, l'algoritmo lavora in tre step successivi:</p> <ol> <li>al primo step, l'algoritmo sceglie casualmente \\(k\\) centroidi tra i diversi dati a disposizione;</li> <li>al secondo step, l'algoritmo assegna ogni punto al centroide pi\u00f9 vicino, definendo i \\(k\\) cluster iniziali;</li> <li>al terzo step, l'algoritmo ricalcola il centroide considerando il valore medio di tutti i punti del cluster, e ritorna allo step 2.</li> </ol> <p>Il k-means proseguir\u00e0 fino a che i cluster calcolati al punto 2 non saranno stabili o, nei casi pi\u00f9 complessi, fino a che non sar\u00e0 raggiunto il numero massimo di iterazioni impostato in fase di inizializzazione. In figura possiamo osservare una spiegazione visiva del funzionamento dell'algoritmo.</p> <p> </p> Figura 20.1 - Step dell'algoritmo K-Means"},{"location":"material/04_sklearn/20_clustering/lecture/#204-clustering-in-scikit-learn","title":"20.4 - Clustering in Scikit Learn","text":"<p>Per implementare un algoritmo di clustering in Scikit Learn dovremo fare affidamento sulla classe <code>KMeans()</code>, utilizzabile come segue:</p> <pre><code>from sklearn.cluster import KMeans\nimport numpy as np\nX = np.array([[1, 2], [2, 1], [5, 2], [3, 3]])\ncl = KMeans()\ncl.fit(X)\n</code></pre>"},{"location":"material/04_sklearn/20_clustering/lecture/#205-scelta-del-valore-ottimale-di-cluster","title":"20.5 - Scelta del valore ottimale di cluster","text":"<p>La scelta del valore ottimale di \\(k\\) \u00e8 un procedimento emnpirico, in quanto non abbiamo a disposizione delle vere e proprie label per la verifica dell'uscita dell'algoritmo. In tal senso, abbiamo a disposizione sia delle metriche, che vedremo in seguito, sia degli approcci pi\u00f9 qualitativi, che dipendono dai concetti di cardinalit\u00e0 e magnitudine del clustering.</p> <p>In particolare, per cardinalit\u00e0 si intende il numero di campioni per ogni cluster, mentre per magnitudine la somma delle distanze di tutti i campioni in un cluster dal centroide. Immaginiamo di essere in un caso come quello descritto nella seguente figura.</p> <p> </p> Figura 20.2 - Rapporto tra cardinalit\u00e0 e magnitudine dei cluster <p>Prevedibilmente, il rapporto tra cardinalit\u00e0 e magnitudine dovrebbe essere all'incirca lineare. Quindi, come si pu\u00f2 vedere dalla figura precedente, ci potrebbe essere qualcosa che non va con il cluster \\(4\\).</p> <p>A questo punto, avendo valutato empiricamente la possibile presenza di un problema qualitativo con il clustering, possiamo provare ad eseguire l'algoritmo per un valore crescente di \\(k\\). Proviamo a plottare questo valore in rapporto alla somma delle magnitudini del risultato, che diminuir\u00e0 all'aumentare di \\(k\\); un valore ottimale per \\(k\\) \u00e8 quello che si ottiene quando questo grafico tende a stabilizzarsi, ad esempio considerando il valore per cui la derivata diventa maggiore di -1 (e quindi l'angolo della funzione dei \\(k\\) \u00e8 maggiore di \\(135\u00b0\\)).</p> <p> </p> Figura 20.3 - Rapporto tra il numero dei cluster e la magnitudine"},{"location":"material/04_sklearn/20_clustering/lecture/#206-un-altro-algoritmo-il-dbscan","title":"20.6 - Un altro algoritmo: il DBSCAN","text":"<p>Il DBSCAN \u00e8 un algoritmo di clustering di tipo agglomerativo density-based che opera considerando due parametri principali:</p> <ul> <li>la distanza massima \\(\\epsilon\\) per considerare due punti come appartenenti allo stesso cluster;</li> <li>il numero minimo di campioni \\(m\\) per il quale \u00e8 possibile definire un cluster.</li> </ul> <p>Nella pratica, il DBSCAN seleziona un campione casuale tra quelli non visitati, e valuta se ci sono \\(m\\) campioni all'interno della distanza \\(\\epsilon\\), nel qual caso si ha un core point. In alternativa, se il numero di campioni presenti in \\(\\epsilon\\) \u00e8 minore di \\(m\\), ma comunque maggiore di 0, i campioni si dicono \\(density reachable\\) e, se connessi ad un core point, appartengono allo stesso cluster. Infine, se non vi sono campioni presenti in \\(\\epsilon\\), allora il punto \u00e8 isolato, ed \u00e8 interpretato come un outlier. Un'interpretazione visiva \u00e8 quella proposta in figura; in particolare, i punti in rosso definiscono diversi core points, i punti in giallo sono density reachable, e quindi fanno parte dello stesso cluster dei core points, mentre \\(N\\) \u00e8 un outlier.</p> <p> </p> Figura 20.4 - Algoritmo DBSCAN.  Di Chire - Opera propria, CC BY-SA 3.0, Wikipedia"},{"location":"material/04_sklearn/21_cls_metrics/exercises/","title":"E21 - Metriche di clustering","text":""},{"location":"material/04_sklearn/21_cls_metrics/exercises/#esercizio-e211","title":"Esercizio E21.1","text":"<p>Ricreiamo le condizioni sperimentali degli esercizi E20.4 ed E20.5. Stavolta, per\u00f2, valutiamo le performance di ogni algoritmo utilizzando l'ARI ed il silhouette score.</p> <p>Inoltre, proviamo a vedere cosa accade per i seguenti parametri:</p> <ul> <li>per il K-Means, facciamo variare il numero di cluster tra <code>2</code> e <code>5</code>;</li> <li>per il DBSCAN, assegnamo ad \\(\\epsilon\\) i valori <code>0.5</code> o <code>1.0</code>, ed a <code>min_samples</code> i valori <code>5</code> e <code>10</code>.</li> </ul> <p>Per ognuno dei due algoritmi, infine, riportiamo a schermo solo i valori dei parametri per i quali le metriche assumono valore massimo.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/04_sklearn/21_cls_metrics/lecture/","title":"21 - Metriche di clustering","text":"<p>Cos\u00ec come per la regressione e la classificazione, esistono delle metriche appositamente progettate per valutare la qualit\u00e0 dei risultati ottenuti da un algoritmo di clustering. Nello specifico, valuteremo l'adjusted rand index ed il silhouette score.</p>"},{"location":"material/04_sklearn/21_cls_metrics/lecture/#211-adjusted-rand-index","title":"21.1 - Adjusted Rand Index","text":"<p>Sia \\(C\\) l'insieme dei cluster \"veri\" assegnati ad un certo dataset, e \\(K\\) l'insieme dei cluster assegnati a valle dell'applicazione di un algoritmo di clustering. Allora definiamo l'indice di Rand come:</p> \\[ RI = \\frac{a + b}{C_2^n} \\] <p>dove:</p> <ul> <li>\\(a\\) \u00e8 il numero di coppie di campioni che appartengono allo stesso cluster sia in \\(C\\) sia a valle dell'assegnazione \\(K\\);</li> <li>\\(b\\) \u00e8 il numero di coppie di campioni che non appartengono allo stesso cluster sia in \\(C\\) sia a valle dell'assegnazione \\(K\\);</li> <li>\\(C_2^n\\) \u00e8 il numero totale di coppie di campioni presenti nel dataset.</li> </ul> <p>In pratica, se:</p> \\[ s = [s_1, s_2, s_3, s_4, s_5] \\\\ C = [s_1, s_2], [s_3, s_4, s_5] \\\\ K = [s_1, s_2, s_3], [s_4, s_5] \\\\ \\] <p>allora:</p> \\[ a = |(s_1, s_2), (s_4, s_5)| = 2 \\\\ b = |(s_1, s_4), (s_1, s_5), (s_4, s_2), (s_5, s_2)| = 4 \\\\ C_2^n = \\frac{|s|*|s-1|}{2} = 5 * 2 = 10 \\] <p>Di conseguenza, \\(RI=\\frac{6}{10}=0.6\\).</p> <p>Si pu\u00f2 dimostrare non \u00e8 garantito che l'indice di Rand assuma valore vicino allo zero a seguito di un'assegnazione completamente casuale dei cluster da parte dell'algoritmo.</p> <p>Possiamo quindi tenere conto dell'aspettazione \\(E[RI]\\) di ottenere un'assegnazione casuale mediante l'indice di Rand modificato:</p> \\[ ARI = \\frac{RI - E[RI]}{max(RI) - E[RI]} \\] <p>In Scikit Learn, l'indice di Rand modificato \u00e8 ottenuto usando la funzione <code>adjusted_rand_score()</code> del package <code>metrics</code>.</p> <p>Il valore ottimale dell'ARI \u00e8 pari proprio ad 1, caso in cui il clustering \u00e8 riuscito a predire correttamente tutte le classi dei singoli campioni. Valori prossimi allo zero o negativi (fino a -1) contraddistinguono invece labeling non corretti.</p> <p>Una metrica di questo tipo ha l'ovvio vantaggio di essere facilmente interpretabile, oltre che di non essere collegata ad uno specifico algoritmo di clustering. Tuttavia, vi \u00e8 una criticit\u00e0 indotta dalla necessit\u00e0 di conoscere a priori il labeling esatto dei campioni (il che, quindi, potrebbe farci propendere per l'uso di un algoritmo di classificazione).</p>"},{"location":"material/04_sklearn/21_cls_metrics/lecture/#212-silhouette-score","title":"21.2 - Silhouette Score","text":"<p>A differenza dell'ARI, il silhouette score non richiede la conoscenza aprioristica delle label vere; per valutare la qualit\u00e0 del clustering, invece, questa metrica si affida a valutazioni sulla separazione dei cluster, ottenendo un valore tanto pi\u00f9 alto quanto questi sono tra di loro ben separati e definiti.</p> <p>In particolare, il silhouete score per un singolo campione \u00e8 definito come:</p> \\[ s = \\frac{b-a}{max(a, b)} \\] <p>dove:</p> <ul> <li>\\(a\\) \u00e8 la distanza media tra un campione e tutti gli altri campioni appartenenti allo stesso cluster;</li> <li>\\(b\\) \u00e8 la distanza media tra un campione e tutti gli altri campioni appartenenti al cluster pi\u00f9 vicino.</li> </ul> <p>Questa metrica, implementata grazie alla funzione <code>silhouette_score()</code> del package <code>metrics</code>, \u00e8 anch'essa di facile interpretazione, in quanto pu\u00f2 assumere valori compresi nell'intervallo \\([-1, 1]\\), con:</p> <ul> <li>valori prossimi a \\(-1\\) che indicano un clustering non corretto;</li> <li>valori prossimi allo \\(0\\) che indicano cluster sovrapposti;</li> <li>valori prossimi a \\(+1\\) che indicano cluster densi e ben suddivisi.</li> </ul> <p>Uno svantaggio del silhouette score \u00e8 che, in generale, pu\u00f2 variare in base all'algoritmo utilizzato.</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/exercises/","title":"E22 - Scikit Learn: Tips &amp; Tricks","text":""},{"location":"material/04_sklearn/22_sklearn_tricks/exercises/#esercizio-e221","title":"Esercizio E22.1","text":"<p>Creiamo una pipeline di processing che, dati i dati relativi a conto e mance del dataset <code>tips</code>, e come label il giorno dello stesso, calcoli l'ARI a valle dell'applicazione di un'operazione di scaling prima dell'algoritmo di clustering. Successivamente, provare a modificare il numero di cluster, ricalcolando l'ARI.</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/exercises/#esercizio-e222","title":"Esercizio E22.2","text":"<p>Usiamo un column transformer per filtrare e pre-elaborare i dati contenuti nel dataset Titanic. In particolare, selezioniamo i dati relativi all'et\u00e0 ed alla tariffa dei passeggeri, riempiendo eventuali dati mancanti e scalandoli nel range <code>[0, 1]</code>, e codifichiamo i dati relativi alla sopravvivenza, classe, genere e porta di imbarcazione del passeggero mediante un <code>OrdinalEncoder()</code> seguito da un imputer. Una volta completato il transformer, usiamolo in una pipeline di clustering.</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/exercises/#esercizio-e223","title":"Esercizio E22.3","text":"<p>Utilizziamo la tecnica della grid search per automatizzare la prova fatta nell'esercizio E22.1. In particolare, andiamo a variare il numero di cluster (<code>n_clusters</code>) tra 3 ed 8 e l'algoritmo usato dal kmeans (<code>algorithm</code>) tra <code>lloyd</code> ed <code>elkan</code>.</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/exercises/#esercizio-e224","title":"Esercizio E22.4","text":"<p>Utilizziamo la tecnica di feature selection pi\u00f9 semplice offerta da Scikit Learn, ovvero <code>VarianceThreshold()</code> per effettuare una procedura di feature selection sul dataset Titanic. In tal senso, integriamo tale procedura nel transformer per i dati di tipo numerico usati nell'esercizio E22.2, e proviamo ad effettuare una grid search impostando due threshold (0 e 0.05) e facendo variare il numero di cluster tra 3 ed 8.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/lecture/","title":"22 - Scikit Learn: Tips &amp; Tricks","text":"<p>In questa lezione vedremo alcuni concetti e costrutti che ci permettono di semplificarci la vita nell'utilizzo di Scikit Learn.</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/lecture/#221-pipeline","title":"22.1 - Pipeline","text":"<p>Finora abbiamo visto gli algoritmi come dei singoli blocchi a s\u00e8 stanti. Tuttavia, spesso questo non corrisponde a ci\u00f2 che accade nella realt\u00e0: infatti, si parla di processing pipeline, intesa come sequenza di pi\u00f9 algoritmi e metodi da applicare per trasformare dei dati e portarli all'elaborazione.</p> <p>In tal senso, potremmo decidere di applicare \"a cascata\" diversi transformer e stimatori oppure, in maniera pi\u00f9 compatta, sfruttare le potenzialit\u00e0 offerte dalla classe <code>Pipeline()</code> di Scikit Learn.</p> <p>Per capire come questa funziona, facciamo un esempio. Immaginiamo di fare in modo che ad un algoritmo di clustering segua uno step di normalizzazione usando uno standard scaler. Abbiamo in tal senso due possibilit\u00e0.</p> <p>La prima \u00e8 quella di usare il transformer e lo stimatore in cascata:</p> <pre><code>from sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nX, y = make_blobs()\nscaler = StandardScaler()\nX_new = scaler.fit_transform(X)\nkmeans = KMeans()\nkmeans.fit_predict(X_new)\n</code></pre> <p>L'altra \u00e8 quella di utilizzare un oggetto di tipo <code>Pipeline()</code>, che ci permette di indicare i singoli step da seguire nella nostra linea di elaborazione dati:</p> <pre><code>from sklearn.pipeline import Pipeline\npipe = Pipeline(steps=[\n('scaler', StandardScaler()),\n('kmeans', KMeans())\n])\npipe.fit_predict(X)\n</code></pre> <p>Nota</p> <p>Notiamo come l'oggetto di classe <code>Pipeline()</code> implementi nativamente i metodi <code>fit</code>, <code>predict</code> e <code>transform</code> (pi\u00f9 altri) per permettere l'uso di pipeline in cui lo step finale \u00e8 un transformer o uno stimatore.</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/lecture/#2211-accesso-e-modifica-dei-parametri-degli-stimatori","title":"22.1.1 - Accesso e modifica dei parametri degli stimatori","text":"<p>Possiamo accedere ed impostare manualmente i parametri dei singoli stimatori e transformer dall'interno della pipeline.</p> <p>Questo pu\u00f2 essere fatto al momento dell'inizializzazione:</p> <pre><code>pipe = Pipeline(steps=[\n('scaler', MinMaxScaler(range=(0, 2))),\n('kmeans', KMeans(n_clusters=3))\n])\n</code></pre> <p>oppure successivamente mediante il comando <code>set_params</code> e la notazione <code>stimatore__parametro</code>:</p> <pre><code>pipe.set_params(kmeans__n_clusters=4)\n</code></pre> <p>Possiamo anche accedere al singolo stimatore come se la pipeline fosse un dizionario:</p> <pre><code>pipe['kmeans']\n</code></pre>"},{"location":"material/04_sklearn/22_sklearn_tricks/lecture/#222-columntransformer","title":"22.2 - ColumnTransformer","text":"<p>Abbiamo visto come i dataset che utilizziamo non abbiano sempre dati di tipo uniforme (ad esempio, tutti numerici o categorici), e che alle volte sia necessario applicare differenti trasformazioni a feature differenti.</p> <p>Cos\u00ec come la pipeline di processing, anche questa operazione pu\u00f2 essere svolta una feature alla volta o, in maniera estremamente pi\u00f9 semplice, creando un oggetto di classe <code>ColumnTransformer()</code>.</p> <p>Immaginiamo ad esempio di dover trasformare tutte le colonne del dataset tips, normalizzando quelle numeriche ed usando un <code>OrdinalEncoder()</code> per le categoriche. Per farlo, possiamo usare un <code>ColumnTransformer()</code> in questo modo:</p> <pre><code>import seaborn as sns\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\ntips = sns.load_dataset('tips')\nct = ColumnTransformer(\n[('scaler', StandardScaler(), ['total_bill', 'tip']),\n('encoder', OrdinalEncoder(), ['sex', 'smoker', 'day', 'time'])],\nremainder='passthrough'\n)\nct.fit(tips)\nct.transform(tips)\n</code></pre> <p>Nota</p> <p>Il <code>ColumnTransformer()</code> lavora sui dataframe.</p> <p>Possiamo anche combinare il concetto di <code>ColumnTransformer()</code> con quello di <code>Pipeline()</code>, usando al posto di un singolo transformer una pipeline di transformer. Ad esempio, se volessimo assegnare i dati mancanti usando un <code>SimpleImputer()</code> prima dello scaling, potremmo usare una pipeline da passare al transformer:</p> <pre><code>from sklearn.impute import Imputer\nnumerical_transformer = Pipeline(\n[('imputer', SimpleImputer()),\n('scaler', StandardScaler())]\n)\nct = ColumnTransformer(\n[('scaler', numerical_transformer, ['total_bill', 'tip']),\n('encoder', OrdinalEncoder(), ['sex', 'smoker', 'day', 'time'])],\nremainder='passthrough'\n)\n</code></pre> <p>Nota</p> <p>Ovviamente, anche un <code>ColumnTransformer()</code> pu\u00f2 essere usato in una pipeline!</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/lecture/#223-crossvalidazione","title":"22.3 - Crossvalidazione","text":"<p>Quando abbiamo parlato di preparazione dei dati abbiamo visto come sia necessario suddividere gli stessi in due insiemi, ovvero quello di training e quello di validazione, allo scopo di assicurarsi che il modello sia in grado di generalizzare.</p> <p>Tuttavia, questa procedura spesso non \u00e8 sufficiente, perch\u00e9 all'interno dei dati di training o testing, anche se scelti con meccanismi casuali, \u00e8 possibile che siano presenti dei particolari meccanismi di generazione propri di quel sottinsieme. In altre parole, c'\u00e8 il rischio che l'algoritmo vada comunque in overfitting sui dati di training!</p> <p>Per ovviare a questa evenienza, molto spesso non ci si limita ad un'unica iterazione di addestramento, ma si effettua la procedura chiamata \\(k\\)-fold cross validation. La cross validation consiste di \\(k\\) iterazioni, e prevede che l'intero set di dati sia suddiviso in \\(k\\) porzioni, ognuna delle quali sar\u00e0 usata ad ogni iterazione come test set, mentre la restante parte del dataset sar\u00e0 utilizzata per il training. Dopo \\(k\\) iterazioni, i risultati saranno quindi mediati tra loro, ed il modello risulter\u00e0 essere pi\u00f9 robusto all'overfitting. Questa procedura \u00e8 descritta graficamente nella seguente immagine (presa direttamente dalla documentazione di Scikit Learn).</p> <p></p> <p>Ovviamente, in Scikit Learn \u00e8 possibile effettuare la procedura di cross validazione utilizzando la funzione <code>cross_validate()</code>, che permette di effettuare \\(k\\) round di cross-validazione di un algoritmo su un dataset.</p> <pre><code>from sklearn.model_selection import cross_validate\nkmeans = KMeans()\ncross_validate(kmeans, X, y, scoring=['adjusted_rand_score', 'adjusted_mutual_info_score'])\n</code></pre> <p>Se ci si vuole concentrare su un'unica metrica, si pu\u00f2 usare la funzione <code>cross_val_score()</code>:</p> <pre><code>from sklearn.model_selection import cross_val_score\ncross_val_score(kmeans, X, y, scoring='adjusted_rand_score')\n</code></pre> <p>Infine, possiamo usare la funzione <code>cross_val_predict()</code> per ottenere i valori predetti a valle della cross-validazione:</p> <pre><code>from sklearn.model_selection import cross_val_predict\ncross_val_predict(kmeans, X, y)\n</code></pre>"},{"location":"material/04_sklearn/22_sklearn_tricks/lecture/#224-ottimizzazione-degli-iperparametri","title":"22.4 - Ottimizzazione degli iperparametri","text":"<p>Le funzioni che abbiamo visto finora hanno due problemi.</p> <p>Il primo \u00e8 che le funzioni di cross-validazione non restituiscono uno stimatore fittato, mentre il secondo \u00e8 che la valutazione di diversi iperparametri \u00e8 delegata manualmente all'utente. Per ovviare a questi problemi, esistono delle tecniche di ottimizzazione degli iperparametri, che permettono di esplorare una serie di valori per ogni parametro dell'algoritmo selezionato, valutando la combinazione degli stessi che produce i risultati migliori.</p>"},{"location":"material/04_sklearn/22_sklearn_tricks/lecture/#2241-tecniche-di-ottimizzazione-degli-iperparametri-la-grid-search","title":"22.4.1 - Tecniche di ottimizzazione degli iperparametri: la grid search","text":"<p>Esistono numerose tecniche di ottimizzazione degli iperparametri; in questo frangente, valuteremo la pi\u00f9 semplice di tutte, ovvero la grid search (traducibile in italiano con \"ricerca a griglia\").</p> <p></p> <p>La tecnica della grid search \u00e8 schematizzata nella precedente immagine. Immaginiamo per semplicit\u00e0 che il nostro algoritmo abbia soltanto due possibili parametri, e che tutti i possibili valori che vogliamo esplorare possano essere disposti lungo una griglia. All'interno di questa, i valori di una metrica a nostra scelta (ad esempio, l'accuratezza) si andranno a disporre secondo picchi e valli; il nostro obiettivo, in questo specifico caso, \u00e8 ovviamente trovare il massimo picco della funzione che correla i valori dei parametri con l'accuratezza. Per farlo, la grid search prova ad eseguire l'algoritmo sui dati di training per ogni combinazione di parametri, fino a trovare la migliore possibile.</p> <p>Scikit Learn implementa oggetti di classe <code>GridSearchCV()</code>, che prendono uno stimatore (o una pipeline), effettuano la crossvalidazione sui dati, e restituiscono quello con i parametri migliori dopo l'addestramento. Ad esempio:</p> <pre><code>from sklearn.model_selection import GridSearchCV\nparameters = {\n'n_clusters': [3, 4, 5]\n}\nkmeans = KMeans()\nest = GridSearchCV(kmeans, parameters)\nest.fit(X)\n</code></pre> <p>E' anche possibile usare la grid search in combinazione con con una pipeline.</p> <pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.decomposition import PCA\npipe = Pipeline([\n('pca', PCA()),\n('kmeans', KMeans())\n])\nparam_grid = {\n'pca__n_components': [2, 3],\n'kmeans__n_clusters': [3, 4, 5]\n}\nest = GridSearchCV(pipe, param_grid)\nest.fit(X)\n</code></pre>"},{"location":"material/04_sklearn/22_sklearn_tricks/lecture/#225-feature-selection","title":"22.5 - Feature selection","text":"<p>Concludiamo con un breve cenno alle tecniche di feature selection, che ci permettono di isolare le feature maggiormente significative all'interno del nostro dataset, scartando le altre. In tal senso, Scikit Learn ci offre un intero package, ovvero il <code>feature_selection</code>, operante in tal senso.</p>"},{"location":"material/04_sklearn/23_sklearn_ex/exercises/","title":"Esercitazione 23","text":""},{"location":"material/04_sklearn/23_sklearn_ex/exercises/#e231","title":"E23.1","text":"<p>Caricare i dataset Diabetes (a scopo di regressione) ed Iris (a scopo di classificazione). Visualizzarne rapidamente la struttura.</p>"},{"location":"material/04_sklearn/23_sklearn_ex/exercises/#e232","title":"E23.2","text":"<p>Studiare le feature e la distribuzione delle stesse del dataset Diabetes.</p>"},{"location":"material/04_sklearn/23_sklearn_ex/exercises/#e233","title":"E23.3","text":"<p>Effettuare un'analisi delle cross-correlazioni presenti tra le feature del dataset Diabetes. Utilizzare il \\(\\tau\\) di Kendall.</p>"},{"location":"material/04_sklearn/23_sklearn_ex/exercises/#e234","title":"E23.4","text":"<p>Isolare le \\(k\\) feature pi\u00f9 importanti del dataset Diabetes. Per farlo, utilizzare un oggetto di classe <code>SelectKBest()</code> scegliendo la metrica pi\u00f9 appropriata tra <code>mutual_info_regression</code> e <code>mutual_info_classif</code>.</p>"},{"location":"material/04_sklearn/23_sklearn_ex/exercises/#e235","title":"E23.5","text":"<p>Comparare i risultati di regressione ottenuti da un regressore lineare e da un albero decisionale in termini di MAPE.</p>"},{"location":"material/04_sklearn/23_sklearn_ex/exercises/#e236","title":"E23.6","text":"<p>Provare ad eseguire una <code>GridSearchCV</code> sull'albero decisionale, e valutare se i risultati in termini di MAPE migliorano.</p>"},{"location":"material/04_sklearn/23_sklearn_ex/exercises/#e237","title":"E23.7","text":"<p>Ripetere gli stessi step degli esercizi precedenti per il dataset Iris.</p>"},{"location":"material/04_sklearn/23_sklearn_ex/exercises/#e238","title":"E23.8","text":"<p>Comparare, per mezzo di due pipeline, i risultati ottenuti effettuando il clustering mediante algoritmo KMeans sui dati di Iris con e senza feature selection.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/04_sklearn/exercises/exercises/","title":"Esercitazione 4 - Scikit Learn","text":""},{"location":"material/04_sklearn/exercises/exercises/#esercizio-1","title":"Esercizio 1","text":"<p>Usiamo Scikit Learn per una prima analisi del dataset Tips. In particolare, proviamo a:</p> <ul> <li>classificare i clienti in base al fatto che siano fumatori o meno;</li> <li>prevedere il conto di un tavolo in base alle sue caratteristiche.</li> </ul>"},{"location":"material/04_sklearn/exercises/solutions/","title":"Esercitazione 4 - Scikit Learn","text":""},{"location":"material/04_sklearn/exercises/solutions/#esercizio-1","title":"Esercizio 1","text":"<p>Usando Scikit Learn, analizziamo i dati del dataset Titanic. Proviamo a:</p> <ul> <li>rimuovere le feature rumorose o non necessarie;</li> <li>normalizzare le feature numeriche nell'intervallo \\([0, 1]\\);</li> <li>convertire le feature categoriche in valori numerici.</li> </ul> <p>Facciamolo utilizzando Scikit Learn.</p>"},{"location":"material/05_dl/anchor/","title":"Anchor","text":"<p>Anchor Boxes for Object Detection Object detection using deep learning neural networks can provide a fast and accurate means to predict the location and size of an object in an image. Ideally, the network returns valid objects in a timely manner, regardless of the scale of the objects. The use of anchor boxes improves the speed and efficiency for the detection portion of a deep learning neural network framework.</p> <p>What Is an Anchor Box? Anchor boxes are a set of predefined bounding boxes of a certain height and width. These boxes are defined to capture the scale and aspect ratio of specific object classes you want to detect and are typically chosen based on object sizes in your training datasets. During detection, the predefined anchor boxes are tiled across the image. The network predicts the probability and other attributes, such as background, intersection over union (IoU) and offsets for every tiled anchor box. The predictions are used to refine each individual anchor box. You can define several anchor boxes, each for a different object size. Anchor boxes are fixed initial boundary box guesses.</p> <p>The network does not directly predict bounding boxes, but rather predicts the probabilities and refinements that correspond to the tiled anchor boxes. The network returns a unique set of predictions for every anchor box defined. The final feature map represents object detections for each class. The use of anchor boxes enables a network to detect multiple objects, objects of different scales, and overlapping objects.</p>"},{"location":"material/05_dl/attention/","title":"CBAM","text":"<p>I meccanismi di attensione sono ispirati dalle capacit\u00e0 umane di focalizzarsi su uno o pi\u00f9 oggetti.</p> <p>Se pensiamo all'occhio umano, la luce viene riflessa dall'oggetto di interesse e va alla macula, che \u00e8 la regione funzionale primaria della retina all'interno dell'occhio. Cosa accade quando abbiamo pi\u00f9 oggetti nel campo visivo?</p> <p>Quando dobbiamo focalizzarci su un singolo oggetto qunado vi \u00e8 un array di diversi oggetti nel nostro campo visivo, il meccanismo di attenzione all'interno del sistema di percezione visivo usa un sofisticato gruppo di filtri per creare un effetto di focatura e fare in modo che l'oggetto di interesse sia focalizzato, mentre quelli circostanti siano sfocati.</p> <p>Adesso, l'idea dei meccanismi di attenzione \u00e8 stat aintodotta per prima cosa nel 2017 nell'ambito del Natural Language Processing, nel paper Attention is all you need.</p> <p>Nel paper, il meccanismo di attenzione \u00e8 stato calcolato suando tre componenti principali: QUery, Key, e Value.</p> <p>https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/</p>"},{"location":"material/05_dl/yolo/","title":"X.X - You Only Look Once (YOLO)","text":""},{"location":"material/05_dl/yolo/#architettura","title":"Architettura","text":"<p>L'archiettura di YOLO consta di 24 layer convoluzionali, quattro layer di max pooling, e due layer completamente connessi.</p> <p>Il funzionamento \u00e8 come segue:</p> <ul> <li>le immagini sono ridimensionate in \\(448 \\times 448\\) prima di attraversare la rete convoluzionale;</li> <li>una convoluzione \\(1 \\times 1\\) viene per prima cosa applicata per ridurre il numero di canali, seguita quindi da una convoluzione \\(3 \\times 3\\);</li> <li>la funzione di attivazione \u00e8 la ReLU, ad eccezione del layer finale, che usa una funzione di attivazione lineare; *tecniche di regolarizzazione come batch normalization e dropout sono utilizzate per far ein modo che il modello non vada in overfitting.</li> </ul> <p>L'algoritmo lavora sulla base di quattro step.</p>"},{"location":"material/05_dl/yolo/#step-1-residual-blocks","title":"Step 1: residual blocks","text":"<p>Il primo step divide l'immagine originaria in \\(N \\times N\\) griglie di forma uguale. Ogni cella nella griglia \u00e8 responsabile per la localizzazione e la predizione della classe di oggetti che copre, assieme ad un punteggio di confidenza.</p> <p>TODO IMMAGINE</p>"},{"location":"material/05_dl/yolo/#step-2-bounding-box-regression","title":"Step 2: bounding box regression","text":"<p>Il passo successivo consiste nel determinare le bounding box, ovvero i rettangoli che contengono al loro interno tutti gli oggetti presenti nell'immagine. Possiamo avere tanti bounding box quanti sono gli oggetti all'interno di una certa immagine.</p> <p>YOLO determina gli attributi di questi bounding box usando un singolo modulo di regressione nel seguente formato, dove \\(Y\\) \u00e8 il vettore che rappresenta ciascun bounding box:</p> \\[ Y = [p_c, b_x, b_y, b_h, b_w, c_1, c_2] \\] <p>Questo \u00e8 importante specialmente durante la fase di addestramento del modello.</p> <ul> <li>p_c corrisponde al punteggio di probabilit\u00e0 associato al fatto che la griglia contenga un oggetto. Ad esempio, tutte le griglie mostrate in rosso in FIGURA 2 hanno un punteggio pi\u00f9 alto di zero, mentre quelle in giallo hanno un punteggio pari a zero.</li> <li>bx e by sono le coordinate \\((x, y)\\) del centro della bounding box rispetto alla cella che racchiude l'oggetto;</li> <li>\\(b_h, b_w\\) sono invece l'altezza e l'ampiezza della bounding box che contiene l'oggetto di interesse;</li> <li>\\(c_1, c_2\\) corrispondono alle due classi (giocatore e palla). Ovviamente, possiamo avere tante classi quante richieste dal caso d'uso specifico.</li> </ul> <p>FIGURA</p>"},{"location":"material/05_dl/yolo/#step-3-intersection-over-unions-iou","title":"Step 3: Intersection Over Unions (IoU)","text":"<p>La maggior parte delle volte, un singolo oggetto in un'immagine pu\u00f2 avere pi\u00f9 candidati per la stessa griglia, anche se non tutti sono rilevanti. L'obiettivo della IoU, valore compreso tra \\(0\\) ed \\(1\\), \u00e8 quello di scartare le bounding box non rilevanti, mantendo solo quelle rilevanti. In pratica:</p> <ul> <li>l'utente definisce la soglia per la IoU (di solito, \\(0.5\\));</li> <li>YOLO quindi calcola la IoU di ogni cella, ovvero il rapporto tra l'area delle intersezioni e quella dell'unione;</li> <li>infine, sono ignorate le predizioni che hanno una IoU minore o uguale alla soglia, e considerano quelle con una IoU maggiore o uguale alla soglia.</li> </ul> <p>TODO FIGURA 4</p>"},{"location":"material/05_dl/yolo/#step-4-non-max-suppression-nms","title":"Step 4: Non-Max Suppression (NMS)","text":"<p>Impostare una soglia per la IoU non sempre basta, perch\u00e9 un oggetto pu\u00f2 avere pi\u00f9 bounding box con una IoU al di sopra della soglia, e lasciare tutte queste soglie pu\u00f2 causare del rumore. Qui, possiamo usare il NMS per mantenere solo le box con lo score di detection pi\u00f9 alto.</p>"},{"location":"material/05_dl/yolo/#oltre-yolo","title":"Oltre YOLO","text":"<p>La prima versione di YOLO ha comportato numerose innovazioni in ambito di object detection grazie alla sua capacit\u00e0 di riconoscere oggetti in maniera rapida ed efficiente.</p> <p>Tuttavia, cos\u00ec come per molte altre soluzioni, la prima versione di YOLO aveva le sue limitazioni:</p> <ul> <li>non era in grado di indiivudare immagini di piccole dimensioni all'intertno di un gruppo di immagini, come un gruppo di persone in uno stadio. Questo \u00e8 legato al fatto che ogni griglia nell'archiettura YOLO \u00e8 progettata per individuare singoli oggetti;</li> <li>quindi, YOLO non \u00e8 in grado di individuare forme nuove o non usuali;</li> <li>infine, la funzione di costo usata per approssimare le performance di detectiontratta gli errori allo stesso modo per le bounding box di piccole e grandi dimensioni, il che crea delle localizzazioni non corrette.</li> </ul>"},{"location":"material/06_tflow/01_intro_autoencoders/","title":"Introduzione agli autoencoder","text":"<p>In questa lezione, vedremo tre esempi di utilizzo degli autoencoder.</p> <p>Un autoencoder \u00e8 uno speciale tipo di rete neurale che viene addestrata a copiare il suo input sul suo output. Ad esempio, data un'immagine di una cifra scritta a mano, un autoencoder per prima cosa codifica l'immagine in una rappresentazione a bassa dimensionalit\u00e0, quindi decodifica questa rappresentazione restituendo l'immagine originaria. Per far questo, l'autoencoder apprende a comprimere i dati minimizzando contestualmente l'errore di ricostruzione.</p>"},{"location":"material/06_tflow/01_intro_autoencoders/#definizione","title":"Definizione","text":"<p>FOrmalmente, un autoencoder ha un layer nascosto \\(h\\) che descrive un codice usato per rappresentare l'input.</p> <p>Un autoencoder pu\u00f2 essere visto come composto di due parti: una funzione di codifica \\(h = f(x)\\) (chiamata, per l'appunto, encoder), ed una funzione di ricostruzione chiamata \\(r = g(h)\\), chiamata decoder.</p> <p>TODO FIGURA AUTOENCODER</p> <p>Se un autoencoder \u00e8 in grado semplicemente di impostare \\(g(f(x)) = h\\), allora non sarebbe utile. Invece, gli autoencoder sono progettati nin modo tale da non essere in grado di apprendere a copiare perfettamente il dato. Normalmente sono ristretti in modi che permettono di copiare i dati soltanto in maniera approssimativa, e copiare soltanto gli input che assomigliano ai dati di addestramento. Dato che il modello viene forzato a prioritizzare quali aspetti dell'ingresso dovrebbero essere copiati, spesso \u00e8 in grado di apprendere delle propriet\u00e0 utili sui dati.</p> <p>Gli autoencoder moderni hanno genralizzato l'idea della coppia encoder/decoder oltre alle funzioni deterministiche, producendo dei mapping stocastici di tipo \\(p_{encoder}(h | x)\\) e \\(p_{decoder}(x | h)\\).</p> <p>L'idea di autoencoder \u00e8 stata parte del paesaggio delle reti neurali per decadi. Tradizionalmente, gli autoencoder erano suati per la riduzione della dimensionalit\u00e0, o l'estrazione di feature. Di recente, nuove connessioni teoriche tra gli autencoder ed i modelli a variabili latenti hanno portato gli autoencoder nel mondo dei modelli generativi. Gli autoencoder possono essere pensati come un caso speciale di reti feedforward, e possono essere adestrati con le stesse tecniche, tipicamente il gradient deshent che segue i gradienti calcolati mediante back-propagataion. A differenza delle reti feedforward generiche, gli autoencoder possono anche essere addestrati usando tecniche come la recirculation (HINTON MCCLELLAND 1988), un algoritmod i apprendimento basato sulla comparazione delle attivazioni della rete sull'input originario con le attivazioni sull'input ricostruito. La recirculation \u00e8 consdierata maggiormente plausibile dal punto di vista biologico rispetto alla back-propagation, ma viene raramente usata per applicazioni di machine learning.</p>"},{"location":"material/06_tflow/01_intro_autoencoders/#autoencoder-sottocompleti","title":"Autoencoder sottocompleti","text":"<p>Copiare l'input all'output potrebbe suonare inutili, ma tipicamente non siamo interessati nell'output del decoder. Invece, speriamo che addestrare l'autoencoder ad effettuare il task di copia dell'input risulter\u00e0 nel fatto che \\(h\\) assuma delle propriet\u00e0 utili.</p> <p>Un modo per ottenere feature utili dall'autoencoder \u00e8 vincolare \\(h\\) ad avere una dimensione inferiore ad \\(x\\). Un autoencoder la cui dimensione del codice \u00e8 inferiore alla dimensione dell'ingresso \u00e8 chiamato sottocompleto. Apprendere una rappresentazione sottocompleta forza l'autoencoder a catturare le feature maggiormente significative dei dati di training.</p> <p>Per questo tipo di autoencoder, il processo di apprendimento pu\u00f2 essere definito come la minimizzazione di una funzione di costro:</p> \\[ L(x,g(f(x))) \\] <p>dove \\(L\\) \u00e8 la funzione i costo che penalizza \\(g(f(x))\\) dall'essere dissimile da \\(x\\), come l'MSE.</p> <p>Quando il decoder \u00e8 lineare ed \\(L\\) \u00e8 l'errore quadratico medio, un autoencoder sottocompleto apprende lo stesso sottospazio della PCA. In questo caso, un autoencoder addestrato ad effettuare il task di copying ha appreso il sottospazio principale dei dati di addestramento come effetto collaterale.</p> <p>Gli autoencoder con le funzioni non lineari di encoding \\(f\\) e decoding \\(g\\) possono quindi apprendere una generalizzazione non lineare pi\u00f9 potente della PCA. Sfortunatamente, se l'encoder ed il decoder hanno eccessiva capacit\u00e0, l'autoencoder pu\u00f2 apprendere a d effettuare il task di copia senza estrarre informazioni utili sulla distribuzione dei dati. Teoricamente, si pu\u00f2 immaginare che un autoencoder con un codice monodimensionale ma con un encoder non lineare molto potente pu\u00f2 apprendere a rappresentare ogni campione di training \\(x^(i)\\) con il codice \\(i\\). Il decoder pu\u00f2 apprendere a mappare questi indici interi ai valori degli specifici campioni di training. Questo specifico scenario non avviene nella pratica, ma illustra chiaramente che un autoencoder addestrato ad effettuare il task di copying pu\u00f2 fallire ad apprendere qualcosa di utile nel dataset se la capacit\u00e0d dell'autoencoder pu\u00f2 diventare eccessivamente grande.</p>"},{"location":"material/06_tflow/01_intro_autoencoders/#esempio","title":"Esempio","text":"<p>Per prima cosa, importiamo le librerie necessarie.</p> <p>import matplotlib.pyplot as plt import numpy as np import pandas as pd import tensorflow as tf</p> <p>from sklearn.metrics import accuracyscore, precisionscore, recallscore from sklearn.modelselection import traintestsplit from tensorflow.keras import layers, losses from tensorflow.keras.datasets import fashion_mnist from tensorflow.keras.models import Model</p> <p>A questo punto, carichiamo il dataset usando MNIST.</p> <p>(xtrain, _), (xtest, ) = fashionmnist.load_data()</p> <p>xtrain = xtrain.astype('float32') / 255. xtest = xtest.astype('float32') / 255.</p> <p>print (xtrain.shape) print (xtest.shape)</p>"},{"location":"material/06_tflow/01_intro_autoencoders/#primo-esempio-autoencoder-base","title":"Primo esempio: autoencoder base","text":"<p>Per il primo esempio, definiremo un autoencoder con due layer densi: un encoder, che comprime l'immagine in un vettore a 64 dimensioni, ed un decoder, ceh ricostruisce l'immagine originale dallo spazio latente. Per definire il modello, useremo l'API Model di Keras:</p> <p>latent_dim = 64 </p> <p>class Autoencoder(Model):   def init(self, latentdim):     super(Autoencoder, self).init()     self.latentdim = latentdim      self.encoder = tf.keras.Sequential([       layers.Flatten(),       layers.Dense(latentdim, activation='relu'),     ])     self.decoder = tf.keras.Sequential([       layers.Dense(784, activation='sigmoid'),       layers.Reshape((28, 28))     ])</p> <p>def call(self, x):     encoded = self.encoder(x)     decoded = self.decoder(encoded)     return decoded</p> <p>autoencoder = Autoencoder(latent_dim)</p> <p>autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())</p> <p>Addestriamo adesso il modello usando <code>x_train</code> sia come input, sia come target. L'encoder apprender\u00e0 a comprimere il dataset da 784 dimensioni (28x28) allo spazio latente, mentre il decoder apprender\u00e0 a ricostruire le immagini originarie.</p> <p>autoencoder.fit(xtrain, xtrain,                 epochs=10,                 shuffle=True,                 validationdata=(xtest, x_test))</p> <p>Una volta addestrato il modello, testiamolo codificando e decodificando delle immagini dal set di test.</p> <p>encodedimgs = autoencoder.encoder(xtest).numpy() decodedimgs = autoencoder.decoder(encodedimgs).numpy()</p> <p>n = 10 plt.figure(figsize=(20, 4)) for i in range(n):   # display original   ax = plt.subplot(2, n, i + 1)   plt.imshow(xtest[i])   plt.title(\"original\")   plt.gray()   ax.getxaxis().setvisible(False)   ax.getyaxis().set_visible(False)</p> <p># display reconstruction   ax = plt.subplot(2, n, i + 1 + n)   plt.imshow(decodedimgs[i])   plt.title(\"reconstructed\")   plt.gray()   ax.getxaxis().setvisible(False)   ax.getyaxis().set_visible(False) plt.show()</p>"},{"location":"material/06_tflow/01_intro_autoencoders/#regolarized-autoencoders","title":"Regolarized autoencoders","text":"<p>Gli autoencoder sottocompleti, con le dimensioni del codice inferiori alle dimensioni di input, possono apprendere le feature maggiormente importanti della distribuzione dei dati. Abbiamo visto che questi autoencoder falliscono ad apprendere delle informazioni utili se all'encoder ed al decoder \u00e8 data una capacit\u00e0 eccessiva.</p> <p>Un problema simile avviene se il codice pu\u00f2 avere una dimensione uguale all'ingresso, e nel caso sovracompleto, nel quale il codice ha dimensioni superiori a quelle dell'input. IN questi casi, anche un encoder lineare ed un decoder lineare pu\u00f2 apprendere a copiare l'input all'output senza dover apprendere delle informazioni sulla distribuzione dei dati.</p> <p>Idealmente, si pu\u00f2 addestrare una qualsiasi archietttura di autoencoder con successo, scegliendo la dimensione del codice e la capacit\u00e0 di encoder e decoder sulla base della complessit\u00e0 della distribuzione da modellare. Gli autoencoder regolarizzati forniscono la capacit\u00e0 di far questo. Pitutosto che limitare la capacit\u00e0 del moello mantenendo l'encoder ed il decoder poco profondi con ridotta dimensione del codice, gli autoencoder regolarizzati usano una funzione di costo che incoraggia il modello ad avere altre propriet\u00e0 oltre alla capacit\u00e0 di copiare i suoi input ai suoi output. Queste altre prorpiet\u00e0 includono la sparsezza della rappresentazione, al riduzione elle derivate della rappresentazione, e la robustezza al rumore o agli input mancanti. Un autoencoder regolarizzato pu\u00f2 essere non lineare ed overcompleto, ed apprendere comunque qualcosa di utile sulla distribuzione dei dati, anches e la capacit\u00e0 del modello \u00e8 abbastanza grande per apprendere una banale funzione di identit\u00e0. Oltre ai metodi descritti qui, che sono interpretati come autoencoder regolarizzati, praticamente ogni modello generativo con variabili latenti ed equipaggiato con una procedura di inferenza per calcolare delle rappresentazioni latenti dato un certo input pu\u00f2 essere visto come una forma particolare di autoencoder. </p> <p>Un primo esempio di autoencoder regolarizzato \u00e8 lo sparse autoencoder. Questo \u00e8 semplicemente un autoencoder i cui criteri di addestramento coinvolgono la presenza di una penalit\u00e0 di sparsit\u00e0 \\(\\Omega(h)\\) sul code layer \\(h\\), otlre all'errore di ricostruzione. La funzione diventa quindi:</p> \\[ L(x, g(f(x))) + \\Omega(h) \\] <p>dove \\(g(h)\\) \u00e8 l'output del decoder, e tipicamente abbiamo \\(h=f(x)\\), l'outpu dell'encoder. Gli sparse autoencoder sono tipicamente usati per apprendere feature per altri task, come quelli di classificazione. Un autoencoder che \u00e8 stato regolarizzato per essere sparso deve rispondere a feature statistiche univoche per il dataset su cui \u00e8 stato addestrato, piuttosto che agire semplicemente come funzione identit\u00e0. In questo modo, addestrare ad effettuare il task di copia con una penalit\u00e0 di sparsit\u00e0 pu\u00f2 potrare ad un modello che ha appreso delle feature utili.</p> <p>Possiamo pensare alla penalit\u00e0 \\(\\Omega(h)\\) come al termine di regolaizzazione aggiunto ad una rete feedforward il cui task primario \u00e8 quello di copiare l'input all'output (obiettivo di apprendimento non supervisionato) ed effettuare possibilmente anche dei task </p> <p>https://www.deeplearningbook.org/contents/autoencoders.html -&gt; Denoising autoencoder</p>"},{"location":"material/06_tflow/01_intro_autoencoders/#image-denoising","title":"Image denoising","text":"<p>Un autoencoder pu\u00f2 anche essere addestrato a rimuovere del rumore dalle immagini. In questo esempio, creeremo una versione rumorosa del dataset MNIST andando ad applicare del rumore casuale ad ogni immagine. Addestreremo quindi un autoencoder usando l'immagine rumorosa come input, e l'immagine originaria come target.</p> <p>Aggiungiamo rumore casuale alle immagini</p> <p>noisefactor = 0.2 xtrainnoisy = xtrain + noisefactor * tf.random.normal(shape=xtrain.shape)  xtestnoisy = xtest + noisefactor * tf.random.normal(shape=x_test.shape) </p> <p>xtrainnoisy = tf.clipbyvalue(xtrainnoisy, clipvaluemin=0., clipvaluemax=1.) xtestnoisy = tf.clipbyvalue(xtestnoisy, clipvaluemin=0., clipvaluemax=1.)</p> <p>Plottiamo le immagini rumorose.</p> <p>n = 10 plt.figure(figsize=(20, 2)) for i in range(n):     ax = plt.subplot(1, n, i + 1)     plt.title(\"original + noise\")     plt.imshow(tf.squeeze(xtestnoisy[i]))     plt.gray() plt.show()</p>"},{"location":"material/06_tflow/01_intro_autoencoders/#definiamo-un-convolutional-autoencoder","title":"definiamo un convolutional autoencoder","text":""},{"location":"material/06_tflow/cnn/","title":"Convolutional Neural Networks","text":"<p>Le Convolutional Neural Networks sono molto simili alle reti neurali tradizionali. Sono fatte di neuroni che hanno appreso dei valori di pesi e bias. Ogni neurone riceve un certo input, lo pesa per il peso e, opzionalmente, ha una non linearit\u00e0 in uscita. L'intera rete espriem sempre una singola funzione di costo differenziabile: dai pixel grezzi dell'immagine al punteggio di classe. E questi nuroni hanno comunque una funzione di costo (spesso una softmax) sull'ultimo layer completamente connesso, e vale tutto ci\u00f2 fatto per le reti neurali.</p>"},{"location":"material/06_tflow/dense/","title":"Multi-layer perceptron","text":"<p>I multi-layer perceptron sono i modelli di deep learning fondamentali. L'obiettivo di un MLP \u00e8 quello di approssimare una funzione \\(f^*\\). Ad esempio, per un classificatore \\(y=f^*(x)\\) mappa un input \\(x\\) ad una classe \\(y\\). Un MLP definisce quindi un mapping \\(y = f(x; \\theta)\\) ed apprende il valore dei parametri \\(\\theta\\) che restituiscono la migliore approssimazione della funzione.</p> <p>Questi modelli sono chiamati anche feedforward network, dato chel'informazione fluisce attraverso la funzione valutata da \\(x\\), attraverso dei blocchi di calcolo intermedi ustai per definire \\(f\\), ed infine verso l'output \\(y\\). In pratica, non vi sono dei feedback che l'output del modello d\u00e0 a se stesso. Quando questo tipo di rete \u00e8 esteso per includere delle connessioni di fedback, siamo di fronte a delle recurrent neural network.</p> <p>Gli MLP sono di estrema importanza nelle applicazioni di machine learning, e formano la base di molte applicazioni commerciali di interesse. Ad esempio, le reti convoluzionali usate per il riconoscimento degli oggetti non sono altro se non un tipo specializzato di rete feedforward.</p> <p>Il termine rete si riferisce al fatto che sono tipicamente rappresentate componendo insieme diverse funzioni. Il modello ottenuto \u00e8 associato ad un grafo aciclico diretto che descrive come queste funzioni sono composte tra lroo. Ad esempio, possiamo avere tre funzioni \\(f^{(1)}\\), \\(f^{(2)}\\) ed \\(f^{(3)}\\) connesse a formare una $f(x)=f{(3)}(f(f^{(1)}(x))). Queste strutture a catena sono quelle pi\u00f9 comuni tra le reti neurali. In questo caso, \\(f^{(1)}\\) sar\u00e0 il primo layer della rete, \\(f^{(2)}\\) il secondo layer, e cos\u00ec via. La lunghezza complessiva ci d\u00e0 il numero di layer della rete e, conseguentemente, la profondit\u00e0 del modello. Il nome deep learning deriva proprio da questa terminologia. L'ultimo strato di un MLP \u00e8 chiamato strato di output. </p> <p>Durante l'addestramento di una rete neurale, modifichiamo \\(f(x)\\) per fare in modo che rispecchi quanto pi\u00f9 possibile \\(f^{*}(x)\\). I dati di training ci forniscono esempi rumorosi ed approssimati di \\(f^{*}(x)\\) in diversi punti di addestramento. Ogni campione \\(x\\) \u00e8 accompagnato da una label \\(y \\sim f*(x)\\). I campioni di training specificanod irettamente quello che deve fare il layer di output in ogni punto \\(x\\): deve produrre quindi un valore che sia quanto pi\u00f9 vicino possibile ad \\(y\\). Il comprotamento degli altri layer non \u00e8 direttamente specificato dai dati di training. L'algoritmo di apprendimento deve qeuindi decidere come usare questi layer per produrre l'output deisderato, ma i dati di training non dicono quello che dve fare goni singolo layer. Invece, l'algoritmo di apprendimento deve decieder come usare questi layer per implementare al meglio un'approssimazione di \\(f^{*}\\). Dato che i dati di training non mostrano l'output deisderato per ciascuno di questi layer, questi sono chiamati hidden layer.</p> <p>Infine, queste reti sono chiamate neurali perch\u00e9 sono ispirate dalla neuroscienza. Ogni strato nascosto della rete \u00e8 tipicamente valutato come un vettore. La dimensionalit\u00e0 di questi strati nascosti determina l'ampiezza del modello. Ogni elemento del vettore gioca un ruolo analogo a quello di un neurone. Pituttosto che pensare al layer come rappresentativo di una singola funzioen vettore-vettore, possiamo pensare al layer come composto da diverse unit\u00e0 che agiscono in parallelo, ognuna rappresentativa di una funzione che prende in ingresso un vettore dando in uscita uno scalare. Ogni unit\u00e0 ricorda un neurone nel senso che riceve l'input da moltre altre unit\u00e0 e calcola il suo valore di attivazione. L'idea di usare molti layer di rappresentazioni vettoriali \u00e8 estratta dalla neuroscienza. La sclet a delle funzioni \\(f^{(i)}(x)\\) usate per caloclare queste rappresentazioni \u00e8 anche guidata dalle osservazioni neuroscientifiche sul funzionamento del neurone bioogoico. La ricerca moderna nel campo delle reti neurali, tuttavia, \u00e8 guidata da molte discipline matematiche ed ingengeristiche, e l'obiettivo delle reti neurali non \u00e8 quello di modellare perfettamente il cervello umano. E' meglio pensare alle MLP come funzioni approssimate che sono progettate per ottnere una generalizzazione statisitca, occasionalmente estraendo delle nozioni da quello che sappiamo sul cervello, piuttosto che come modelli del funzionamento del cervello.</p> <p>Un modo per comprendere le reti feedforward \u00e8 quello di partire dai modelli lineari, e comprendere come superano i loro limiti. I modelli lineari, come la regressione lineare o logistica, sono invitanti perch\u00e9 possono effettuare un'approssimazione efficiente ed affidabile, sia in forma chiusa che mediante ottimizzazione convessa. I modelli lineari hanno anche il difetto ovvio che la loro capacit\u00e0 di modellazione \u00e8 limitata alle funzioni lineari, per cui il modello non pu\u00f2 modellare l'interazione tra una qualsiasi coppia di variabili.</p> <p>Per estendere un modello lineare e rappreesntare una funzione non ilneare di \\(x\\), possiamo applicarlo non ad \\(x\\) stessa, ma ad un output trasformato \\(\\phi(x)\\) dove \\(\\phi\\) \u00e8 una trasformazione non lineare. In pratica, \\(\\phi\\) \u00e8 un insieme di feature che descrive \\(x\\), o una nuova rappresentazione di \\(x\\). La domanda, quindi, diventa come scegliere il mapping \\(\\phi\\). Le opzioni sono le seguenti:</p> <ol> <li>La prima opzione \u00e8 quella di usare uno \\(\\phi\\) estremamente generico, come quello a dimensionalit\u00e0 infita usato dalle macchine kernel basate su kernel RBF. Se \\(\\phi(x)\\) \u00e8 di dimensionalit\u00e0 molto alta, possiamo pensare di avere sempre capacit\u00e0 per rappresentare il training set; tuttavia, la generalizzazione sul test set spesso d\u00e0 risultati deludenti. Dei feature mapping molto generici sono di solito infatti basati solo sul principio dell'approssimazione locale, e non hanno al loro interno abbastanza informazioni per risolvere problemi avanzati.</li> <li>Un'altra opzione \u00e8 quella di ingegnerizzare \\(\\phi\\) manualmente. Fino all'avvento del deep learning, questo era l'approccio predominante. Richiede per\u00f2 decadi di sforzi per ogni singolo task, con esperit di dominio per ciascun dominio, e poca replicabilit\u00e0 tra domini anche leggermente differenti.</li> <li>La strategia usata dal deep learning \u00e8 quella di apprendere \\(\\phi\\). In questo approccio, abbiamo un modello \\(y=f(x; \\theta, v)=\\phi(x; \\theta)^Tw\\). Abbiamo adessod ei parametri \\(\\theta\\) che usiamo per apprendere \\(\\phi\\) da un'ampia classe di funzioni, e dei parametri \\(w\\) che mappano da \\(\\phi(x)\\) all'output desiderato. Questo \u00e8 un esempio di MLP, con \\(\\phi\\) che definisce uno strato nascosto. Questo approccio \u00e8 l'unico dei tre che non considera un problema di addestramento non convesso, ma i benefici superano i problemi. In questo approccio, parametrizziamo la rappresentazione come \\(\\phi(x; \\theta)\\) ed usiamo l'algoritmo di ottimizzazione per trovare la \\(\\theta\\) che corrisponde ad una buona rappresentazione. Volendo, questo approccio pu\u00f2 catturare i benefici del primo approccio, in quanto \u00e8 altamente generico (possiamo farlo scegliendo una famglia molto ampia di \\(\\phi(x; \\theta)\\)). Il deep learning pu\u00f2 anceh catturare il beneficio del secondo approccio. Gli esperit di domniono possono codificare la loro conoscenza per aiturare la generalizzazione progettando famiglie \\(\\phi(x; \\theta)\\) che si aspettano che vadano bene. Il vantaggio \u00e8 che il progettista umano deve solo indivudare la gisuta famiglia di funzioni generichepituttosto che idnividuare la funzione cofrretta in maniera precisa.</li> </ol> <p>Questo principio generale di migliorare i modelli apprendendo delle feature si estende oltre le reti feedfowrard. E' un tema ricorrente nel deep learning che si applica a tutti i tipi di modelli.</p>"},{"location":"material/06_tflow/rnn/","title":"Rnn","text":"<p>LE recurrent neural netrwork, o RNN, sono una famioglia di reti neurali usate per elaborare dati sequenziali. Proprio come una rete convoluzionale \u00e8 una rete neurale specializzata nell'elaborazione di una griglia di valori \\(X\\) come un'immagine, una RNN \u00e8 una rete neruale specializzata nell'elaboraziozne di una sequenza di valori \\(x^{(1)}, \\ldots, x^{(\\pi)}\\). Proprio come le CNN possono prontamente scalare in immagini con grande ampiezza ed altezza, ed alcune CNN possono elaborare immagini di dimensione variabile, le RNN possono scalare a sequenze molto pi\u00f9 lunghe di quelle gestibili da reti non specializzate. La maggior parte delle RNN pul\u00f2 anche elabroare sequenze di lunghezza variabile.</p> <p>Per Passare dalle reti multistrato alle RNN, dobbiamo sfruttare una delle prime idee nel machine learning e nei modelli statistici degli anni '80, ovvero quella di condividere i parametri tra diverse parti di un modello. Il parameter sharing rende possibile estendere ed applicare il modello ad esempi di diversa forma (lunghezza) e generalizzare. SE abbiiamo parametri separati per ogni valore dell'indice di tempo, non possiamo generalizzare a sequenzea di lunghezza non vista durante l'addestramento, n\u00e9 condividere punti statistici rilevanti lungo diverse lunghezza di sequenza e doiverse posizioni nel tempo. QUesta condivisione \u00e8 particolarmente imporntae quando una specifica parte di informazione pu\u00f2 avvenire a diverse posizioni nella sequenza. Ad esempio, consideriamo le due frasi:</p> <ul> <li>Sono andato in Nepal nel 2009* e *Nel 2009, sono andato in Nepal\"</li> </ul> <p>Se chiediamo ad un modello di machine learning di leggere ogni frase ed estrarre l'anno nel quale il narratore \u00e8 andato in Nepal, vorremmo che l'anno 2009 venisse riconosciuto come la parte di informazione rilevante, sia che appaia nella sesta parola sia che appaia nella seconda parola della frase. Supponiamo di aver addestrato una rete feedforward che elabori frasi di lunghezza fissa. Una rete tradizionale compeltamente connessa avrebbe parametri separati per ogni feature di unput, per cui dovrebbe apprendere tutte le regole del liunguagguio separatamente in ogni posizione della frase. Per comparazione, una RNN condivide gli stessi pesi lugno vari step temporali.</p> <p>Un'idea correlata \u00e8 l'uso delle convoluzioni nelle sequenze temporali monodimensionali. QUesto approccio convoluzionale \u00e8 alla base per le time-delay neural networks. L'operazione di convoluzione permette ad una rete di condividere i pamraetri nel tempo, ma \u00e8 superficiale. L'usicta di una convoluzoien \u00e8 ujna sequenza dove ogni membro dell'output \u00e8 funzione di un piccolo numero di membri vicini dell'input. L'idea della convidivisione dei parametri si manifesta enll'applciazione dello stesso kernel convoluzionale ad ogni step temporale. Le RNN condividono i parametri in modod diferfrente. Ogni membro dell'output \u00e8 una funzione dei precedneti membri dell'output. Ogni membro dell'output \u00e8 prodotto suando la stessa regola di aggiornamento applicata agli output precedenti. Quewsta formulazione ricorrente risulta nella concidivisione di parma,metri attraverso un grafo computazionale estremamente profondo.</p> <p>Per semplicit\u00e0, ci riferiamop alle RNN come operanti su una sequenza che contiene vettori \\(x^{(t)}\\) con l'indice dello step temporale \\(t\\) che spazia da \\(1\\) a \\(\\tau\\). In pratica, le RNN normalmente operano su minibatch di queste sequenze, con una diversa lunghezza di sequenza \\(\\tau\\) per ogni membro del minibatch. AAbbiamo omesso gli indici del minibatch per semplificare la notzione. Inoltre, l'indice dellos tep temporale non deve necessariamentre riferirsi al passaggio di tempo nel mondo reale. ALle volte si riferisce soltanto alla posziione nella sequenza. Le RNN possono essere anche applicate in due dimensioni su dati spaziali come le immagini, ed anche quando applicate ai dati che coinvolgono il tempo, la rete pu\u00f2 avere connessioni che vanno indietro nel tempo, posto che l'intera sequenza sia osservata prima che sia stata fornita alla rete.</p> <p>In questo capitolo, estendiamo l'idea di grafo computazionale per includere dei cicli. Questi rappresentano l'influenza del valore attuale di una varioabile sul suo valore in un futuro isntante temporale. Questi grafi computazionali ci permettono di definire le RNN. Descriviamo quindi diversi modi per costruire,a ddestra,re ed utilizzare le RNN.</p>"},{"location":"material/06_tflow/rnn/#esploriamo-i-grafi-computazionali","title":"Esploriamo i grafi computazionali","text":"<p>Un grafo computazionale \u00e8 un modo per formalizzare la struttura di un insieme di calcoli, come quelli coinvoltti nella mappatura degli input e dei parametri verso output e costi. In questa sezione, esploriamo l'idea di svolgere un calcolo ricorsivo o ricorrente in un grafo computazionale che aabbia una struttura ripetitiva, tipicamente coirrispondente all'insieme di evneti sotto analisi. Svolgere questo grafico permette di condividere i parametri in una struttura di deep network.</p> <p>Ad esempioo, consideriamo la classifca forma di un sistema dinamico:</p> \\[ s^{(t)}=f(s^{(t-1)}, \\theta) \\] <p>dove \\(s^{(t)}\\) \u00e8 chiamato stato del sistema.</p> <p>La precedente equazione \u00e8 definita come ricorrente perch\u00e8 la definizione di \\(s\\) al tempo \\(t\\) torna indietro alla stessa definizione al tempo \\(t-1\\).</p> <p>Per un numero finito di istanti temporali \\(\\tau\\), il grafo pu\u00f2 essere dispiegato applicando la definziione \\(\\tau - 1\\) volte. Ad eesempio, per \\(\\tau=3\\) optteniamo:</p> \\[ s^{(3)}=f(s^{(2)}, \\theta) = f(f(s^{(1)}, \\theta), \\theta) \\] <p>Dispiegare l'equazione applicando ripetutatmente la definizione ci ha portato un'espressione che non prevede la ricorrenza. UN'espressione di questo tipo pu\u00f2 essere adesso rappresentata da un grafo tradizionale aciclico. Nella figura successiva vediamo un esempio.</p> <p>TODO: FIGURA DISPIEGAMENTO GRAFO</p> <p>Le RNN possono esesre costruite in diversi modi. Cos\u00ec come quasi ognfi funzione pu\u00f2 essere considerata una rete feedformard, opgni funzione che coinvolge la ricorrenza pu\u00f2 essere considerata una RNN.</p> <p>Molte RNN usano la sequenge equazione per definrie i valori delle loro unit\u00e0 nascoste.</p> \\[ h^{(t)}=f(h^{(t-1)}, x^{(t)}, \\theta) \\] <p>dove \\(h\\) rappresenta lo stato della rete.</p> <p>Quadno le RRNN sono addestrate ad effettuare un task che richiede la predizione del futuro dal passato, la rete tipicamente aprpender ad usare \\(h^{(t)}\\) come un tipo di LOSSY SYMMARY degli aspetti rielvnati per il task della sequenza passata di input fino a \\(t\\). Questo sommario \u00e8 in genrarle necessariamente lossy, dal momento che mappa una lunghezza di sequenza arboitraria $(x^{(t)}, x^{(t-1)}, x^{(t-2)}, \\ldots, x^{(2)}, x^{(1)}) in un vettore di lunghezza fissata \\(h^{(t)}\\). A seconda del criterio di addestramento, questo sommario pu\u00f2 mantenere selettivamente alcuni aspetti della sequenza passata con pi\u00f9 precisione di altri aspetti. Ad esempio, se la RNN \u00e8 usata nello statistical language mdoeling, tipicamente per predire la parola successiva data delle parole precedenti, mermoizzare tutte le informazioni nella sequenza di uinput fino all'istante \\(t\\) potrebbe non essere necessario; memorizzare soltnato infomrazioni sufficienti a predire il resto della frase \u00e8 sufficiente. La situazione pi\u00f9 sfidante \u00e8 quando chiediamo ad \\(h^{(t)}\\) di essere ricco a sufficienza per permettere di recuperare in maneira approssimativa la sequenza di input, come negli autoencoder. </p>"},{"location":"material/06_tflow/rnn_ok/","title":"X - Recurrent Neural Network","text":"<p>Le Recurrent Neural Network sono un tipo di rete neurale specificamente sviluppata per elaborare dati di tipo sequenziale.</p> <p>Le RNN sono un tipo di rete neurale artificiale (ANN) che \u00e8 stata sviluppata per elaborare dati sequenziali, come il testo o l'audio, che hanno una struttura temporale. A differenza delle reti neurali feedforward (FFNN), che elaborano i dati in modo sequenziale e non mantengono alcuna informazione sulle osservazioni precedenti, le RNN sono progettate per elaborare dati sequenziali tenendo conto della loro dipendenza temporale.</p> <p>La caratteristica distintiva delle RNN rispetto alle FFNN \u00e8 l'uso di uno o pi\u00f9 strati ricorrenti, in cui ogni neurone ha un'uscita che \u00e8 dipendente dalla sua uscita precedente e dall'input corrente. Ci\u00f2 consente alle RNN di mantenere una \"memoria\" delle informazioni che sono state passate attraverso la rete. Inoltre, le RNN sono in grado di elaborare sequenze di lunghezza variabile.</p> <p>Ci sono diversi tipi di architetture di RNN, ma il pi\u00f9 comune \u00e8 il cosiddetto strato di memoria a corto termine (LSTM). Le LSTM sono state introdotte per risolvere il problema dell'esplosione del gradiente, un problema che si verifica quando si addestra una rete neurale profonda con algoritmi di backpropagation, in cui il gradiente diventa troppo grande e rende l'aggiornamento dei pesi instabile.</p> <p>L'architettura LSTM \u00e8 composta da quattro elementi principali: un gate di input, un gate di output, un gate di dimenticanza e una cella di memoria. Il gate di input controlla quanto delle informazioni dell'input corrente viene aggiunto alla cella di memoria, il gate di dimenticanza controlla quanto della cella di memoria viene dimenticata, mentre il gate di output controlla quanto della cella di memoria viene trasmessa all'uscita. La cella di memoria \u00e8 dove viene memorizzata la \"memoria\" della RNN.</p> <p>Le RNN possono essere utilizzate per una vasta gamma di applicazioni, tra cui la generazione di testo, la traduzione automatica, l'analisi del sentimento, la riconoscimento del parlato, la modellizzazione del linguaggio naturale e molte altre.</p> <p>Per addestrare una RNN, si utilizza un algoritmo di backpropagation che propaga l'errore attraverso la rete e aggiorna i pesi dei neuroni in base all'errore commesso. Ci sono diversi algoritmi di backpropagation che possono essere utilizzati, come il backpropagation through time (BPTT) e il backpropagation con il truncation della backpropagation through time (TBPTT).</p> <p>In sintesi, le RNN sono un tipo di rete neurale artificiale progettata per elaborare dati sequenziali, come il testo o l'audio, che hanno una struttura temporale. Le RNN mantengono una \"memoria\" delle informazioni che sono state passate attraverso la rete utilizzando uno o pi\u00f9 strati ricorrenti, e possono essere addestrate utilizzando algoritmi di backpropagation come il BPTT e il TBPTT.</p>"},{"location":"material/06_tflow/rnn_ok/#lstm","title":"LSTM","text":"<p>L'architettura LSTM (Long Short-Term Memory) \u00e8 stata introdotta nel 1997 da Hochreiter e Schmidhuber come una soluzione per risolvere i problemi delle RNN tradizionali, ovvero il problema del vanishing gradient e dell'instabilit\u00e0 dell'apprendimento a lungo termine. Questi problemi si presentano quando si utilizzano RNN con strati ricorrenti per elaborare sequenze di dati molto lunghe o complesse.</p> <p>L'architettura LSTM \u00e8 composta da quattro elementi principali: un gate di input, un gate di output, un gate di dimenticanza e una cella di memoria. Ognuno di questi elementi svolge un ruolo importante nell'elaborazione dei dati in ingresso e nel mantenimento della memoria a lungo termine della rete.</p> <p>Il gate di input controlla quanto delle informazioni dell'input corrente viene aggiunto alla cella di memoria, il gate di dimenticanza controlla quanto della cella di memoria viene dimenticata, mentre il gate di output controlla quanto della cella di memoria viene trasmessa all'uscita. La cella di memoria \u00e8 dove viene memorizzata la \"memoria\" della RNN.</p> <p>In particolare, il gate di input controlla quale informazione \u00e8 utile per la rete, utilizzando una funzione sigmoidea per determinare il valore di ciascuna delle dimensioni dell'input. Successivamente, viene utilizzata una funzione tanh per ottenere i valori degli stati candidati, ovvero gli stati potenziali della cella di memoria.</p> <p>Il gate di dimenticanza controlla invece quale informazione \u00e8 inutile per la rete, utilizzando anch'esso una funzione sigmoidea per determinare il valore di ciascuna delle dimensioni dell'input. Successivamente, il risultato viene utilizzato per produrre un prodotto tra l'output del gate di dimenticanza e lo stato corrente della cella di memoria, in modo da dimenticare le informazioni non necessarie.</p> <p>Infine, il gate di output controlla quale informazione deve essere trasmessa all'uscita, utilizzando una funzione sigmoidea per determinare il valore di ciascuna delle dimensioni dell'input e una funzione tanh per determinare l'output. Il risultato del gate di output viene quindi utilizzato per produrre l'output finale della rete.</p> <p>In sintesi, l'architettura LSTM \u00e8 una variante delle RNN che utilizza un insieme di porte di controllo per mantenere una memoria a lungo termine della sequenza di input. L'utilizzo di questi meccanismi di controllo rende le LSTM particolarmente adatte per l'elaborazione di sequenze lunghe e complesse.</p>"},{"location":"material/06_tflow/rnn_ok/#vanishing-gradient","title":"Vanishing gradient","text":"<p>Certo, il problema del vanishing gradient si verifica quando si utilizzano reti neurali profonde, ovvero reti neurali con molteplici strati nascosti, e l'errore di retropropagazione del gradiente si riduce a valori molto piccoli man mano che ci si avvicina ai primi strati della rete.</p> <p>Durante l'addestramento di una rete neurale, si utilizza l'algoritmo di retropropagazione per aggiornare i pesi delle connessioni in modo da minimizzare l'errore di predizione. Il gradiente viene calcolato in base all'errore della rete rispetto all'output atteso e viene propagato all'indietro attraverso tutti gli strati della rete.</p> <p>Il problema del vanishing gradient si verifica quando il gradiente diventa sempre pi\u00f9 piccolo man mano che si va indietro nella rete, fino a diventare quasi nullo. Questo rende difficile l'aggiornamento dei pesi nei primi strati della rete, che quindi non ricevono informazioni utili per l'addestramento.</p> <p>Questo problema si verifica perch\u00e9 durante la retropropagazione del gradiente, si moltiplica il gradiente per i pesi delle connessioni in ogni strato. Se i pesi delle connessioni sono tutti vicini a uno, il prodotto delle derivate diventa molto piccolo, e di conseguenza anche il gradiente.</p> <p>Il problema del vanishing gradient pu\u00f2 essere particolarmente grave quando si utilizzano funzioni di attivazione come la sigmoide, che hanno una derivata massima di 0.25, che si avvicina a 0 quando i valori in input sono molto grandi o molto piccoli. In questo caso, il prodotto delle derivate pu\u00f2 diventare estremamente piccolo.</p> <p>Per superare questo problema, sono state proposte diverse tecniche, come l'utilizzo di funzioni di attivazione con derivate pi\u00f9 grandi (come la ReLU), l'utilizzo di tecniche di normalizzazione dei dati in input, l'utilizzo di tecniche di regolarizzazione per evitare l'overfitting e l'utilizzo di reti neurali ricorrenti come le LSTM che hanno meccanismi interni di controllo per mantenere la memoria a lungo termine e ridurre il problema del vanishing gradient.</p>"},{"location":"material/06_tflow/yolo/","title":"Yolo","text":"<p>YOLO (You Only Look Once) \u00e8 un algoritmo di object detection che utilizza una singola rete neurale convoluzionale per identificare gli oggetti in un'immagine e fornire le loro coordinate di bounding box e le relative etichette di classe.</p> <p>Il funzionamento di YOLO pu\u00f2 essere diviso in quattro fasi principali:</p> <p>Preprocessing dell'immagine: l'immagine in input viene ridimensionata alla dimensione di input della rete e normalizzata per avere valori di pixel tra 0 e 1.</p> <p>Feedforward nella rete neurale convoluzionale: l'immagine normalizzata viene passata attraverso una serie di strati convoluzionali e di pooling per estrarre le feature dell'immagine.</p> <p>Rilevazione degli oggetti: la feature map ottenuta dal passo precedente viene divisa in una griglia di celle, ciascuna delle quali \u00e8 responsabile di rilevare gli oggetti che si trovano all'interno della sua area. Per ogni cella, la rete produce un set di bounding box candidati, insieme alla probabilit\u00e0 di ogni candidato che contiene un oggetto. Successivamente, viene scelto il bounding box migliore per ogni oggetto, in base alla probabilit\u00e0 di contenere un oggetto e alla precisione del bounding box.</p> <p>Post-processing: dopo che la rete neurale ha prodotto i bounding box candidati e le relative probabilit\u00e0, viene applicato un filtro non massimo alla lista dei bounding box candidati per rimuovere i duplicati e mantenere solo i bounding box con la probabilit\u00e0 pi\u00f9 alta per ciascuna classe di oggetti rilevata.</p> <p>Infine, i bounding box selezionati vengono restituiti come output dell'algoritmo insieme alle rispettive etichette di classe e alle probabilit\u00e0 associate ad ogni bounding box.</p> <p>In sintesi, YOLO funziona esaminando l'immagine una sola volta e producendo in output i bounding box e le etichette di classe dei diversi oggetti presenti nell'immagine, il tutto in modo rapido ed efficiente grazie alla sua architettura di rete neurale convoluzionale.</p>"},{"location":"material/06_tflow/yolo/#yolov2","title":"YOLOv2","text":"<p>YOLOv2 \u00e8 un'evoluzione dell'algoritmo di object detection YOLO (You Only Look Once) che presenta numerose migliorie rispetto alla versione precedente, in termini di accuratezza e velocit\u00e0 di esecuzione.</p> <p>Il funzionamento di YOLOv2 pu\u00f2 essere diviso in quattro fasi principali, simili a quelle di YOLO originale:</p> <p>Preprocessing dell'immagine: l'immagine in input viene ridimensionata alla dimensione di input della rete e normalizzata per avere valori di pixel tra 0 e 1.</p> <p>Feedforward nella rete neurale convoluzionale: l'immagine normalizzata viene passata attraverso una serie di strati convoluzionali e di pooling per estrarre le feature dell'immagine. Tuttavia, rispetto a YOLO originale, YOLOv2 utilizza una rete pi\u00f9 profonda con pi\u00f9 strati convoluzionali e pooling, che permettono di estrarre feature pi\u00f9 complesse e dettagliate.</p> <p>Rilevazione degli oggetti: come in YOLO originale, la feature map ottenuta dal passo precedente viene divisa in una griglia di celle, ciascuna delle quali \u00e8 responsabile di rilevare gli oggetti che si trovano all'interno della sua area. Tuttavia, YOLOv2 utilizza diverse tecniche per migliorare la precisione dei bounding box candidati e ridurre gli errori di localizzazione degli oggetti. In particolare, utilizza:</p> <p>Dimensione dei bounding box: invece di prevedere la larghezza e l'altezza dei bounding box, YOLOv2 prevede direttamente la radice quadrata della loro area. Ci\u00f2 consente alla rete di concentrarsi maggiormente sui bounding box di piccole dimensioni, che possono essere pi\u00f9 difficili da individuare. Ancoraggi multipli: la rete prevede diversi bounding box candidati per ogni cella della griglia, utilizzando diversi valori predefiniti di larghezza e altezza. Questo consente alla rete di adattarsi meglio alla forma degli oggetti e di prevedere bounding box pi\u00f9 precisi. Mappe di caratteristiche a diverse scale: YOLOv2 utilizza mappe di caratteristiche a diverse scale per individuare oggetti di diverse dimensioni. In particolare, utilizza tre diverse mappe di caratteristiche, ciascuna delle quali \u00e8 responsabile di rilevare gli oggetti in una diversa fascia di dimensioni. Post-processing: dopo che la rete neurale ha prodotto i bounding box candidati e le relative probabilit\u00e0, viene applicato un filtro non massimo alla lista dei bounding box candidati per rimuovere i duplicati e mantenere solo i bounding box con la probabilit\u00e0 pi\u00f9 alta per ciascuna classe di oggetti rilevata. In sintesi, YOLOv2 utilizza una rete neurale pi\u00f9 profonda e utilizza diverse tecniche per migliorare la precisione e la velocit\u00e0 di esecuzione dell'algoritmo di object detection. Queste migliorie consentono a YOLOv2 di ottenere risultati migliori rispetto alla versione precedente in termini di accuratezza e velocit\u00e0 di esecuzione.</p>"},{"location":"material/06_tflow/yolo/#yolov3","title":"yolov3","text":"<p>YOLOv3 \u00e8 un'altra evoluzione dell'algoritmo di object detection YOLO che presenta ulteriori miglioramenti rispetto a YOLOv2. Le principali novit\u00e0 di YOLOv3 includono:</p> <p>Backbone della rete: YOLOv3 utilizza una versione pi\u00f9 avanzata della rete di feature extraction, chiamata Darknet-53, che ha 53 strati convoluzionali, rispetto ai 19 di Darknet-19 utilizzato in YOLOv2. Questo consente di estrarre feature pi\u00f9 dettagliate e complesse dalle immagini.</p> <p>Ancoraggi dinamici: invece di utilizzare gli ancoraggi fissi come in YOLOv2, YOLOv3 utilizza ancoraggi dinamici, che vengono calcolati in base alle dimensioni degli oggetti presenti nel dataset di addestramento. Ci\u00f2 consente alla rete di adattarsi meglio alle diverse dimensioni degli oggetti e di individuare bounding box pi\u00f9 precisi.</p> <p>Predictions multiple: YOLOv3 prevede tre bounding box candidati per ciascuna cella della griglia, invece di uno solo come in YOLOv2. Inoltre, prevede le probabilit\u00e0 per le classi degli oggetti in modo indipendente per ciascun bounding box. Ci\u00f2 consente alla rete di individuare oggetti sovrapposti o parzialmente coperti da altri oggetti.</p> <p>Feature Pyramid Network (FPN): YOLOv3 utilizza una FPN per combinare le mappe di feature a diverse scale e ottenere una rappresentazione pi\u00f9 completa dell'immagine. Ci\u00f2 consente alla rete di individuare oggetti di diverse dimensioni e forme.</p> <p>Non-maximum suppression (NMS) con umbralizzazione: YOLOv3 utilizza una NMS con umbralizzazione per rimuovere i bounding box candidati con bassa probabilit\u00e0 e ridurre i falsi positivi. Ci\u00f2 consente di ottenere una maggiore precisione e ridurre il numero di falsi allarmi.</p> <p>In sintesi, YOLOv3 utilizza una rete neurale pi\u00f9 avanzata e sfrutta diverse tecniche per migliorare la precisione e la velocit\u00e0 di esecuzione dell'algoritmo di object detection. Queste migliorie permettono a YOLOv3 di superare YOLOv2 e di ottenere risultati ancora migliori in termini di accuratezza e velocit\u00e0 di esecuzione.</p>"},{"location":"material/06_tflow/yolo/#yolov4","title":"yolov4","text":"<p>Certo! YOLOv4 \u00e8 l'ultima evoluzione dell'algoritmo di object detection YOLO ed \u00e8 stata pubblicata nel 2020. Ecco alcune delle sue caratteristiche principali:</p> <p>Backbone della rete: YOLOv4 utilizza una versione pi\u00f9 avanzata della rete di feature extraction chiamata CSPDarknet-53, che si basa sul concetto di \"Cross Stage Partial Network\". Questo consente di estrarre feature pi\u00f9 dettagliate e di aumentare la capacit\u00e0 di apprendimento della rete.</p> <p>Scaled-YOLOv4: YOLOv4 offre diverse versioni della rete, in base alla complessit\u00e0 del problema di object detection che si sta affrontando. Ad esempio, Scaled-YOLOv4 \u00e8 una versione leggera della rete che offre prestazioni elevate anche su dispositivi con risorse limitate.</p> <p>Data augmentation: YOLOv4 utilizza una vasta gamma di tecniche di data augmentation per migliorare la generalizzazione della rete e ridurre l'overfitting. Ad esempio, utilizza l'aumento casuale delle dimensioni, il taglio casuale dell'immagine, la rotazione, lo zoom e l'aggiunta di rumore.</p> <p>Data pre-processing: YOLOv4 utilizza un nuovo metodo di pre-processing delle immagini che include l'applicazione di filtri di aumento del contrasto e della nitidezza, la normalizzazione dell'istogramma dell'immagine e la riduzione del rumore.</p> <p>Focal Loss: YOLOv4 utilizza una nuova funzione di loss chiamata Focal Loss, che penalizza di pi\u00f9 gli errori fatti sui bounding box di oggetti rari o difficili da rilevare, migliorando la precisione complessiva della rete.</p> <p>Class activation maps (CAM): YOLOv4 genera anche mappe di attivazione delle classi, che mostrano quali parti dell'immagine sono state utilizzate dalla rete per riconoscere un determinato oggetto. Questo consente di avere una maggiore comprensione di come la rete sta effettivamente riconoscendo gli oggetti e pu\u00f2 essere utile per il debugging e l'ottimizzazione.</p> <p>Bag of Freebies (BOF) e Bag of Specials (BOS): YOLOv4 utilizza anche una combinazione di tecniche BOF e BOS, che comprendono rispettivamente tecniche di miglioramento delle prestazioni e tecniche di riduzione della complessit\u00e0, per ottenere una rete efficiente e precisa.</p> <p>In sintesi, YOLOv4 \u00e8 un algoritmo di object detection all'avanguardia che utilizza diverse tecniche avanzate per ottenere prestazioni ancora migliori rispetto alle versioni precedenti di YOLO. La combinazione di un backbone di rete potente, tecniche avanzate di data augmentation e pre-processing, una nuova funzione di loss e la generazione di mappe di attivazione delle classi, permette a YOLOv4 di ottenere una maggiore precisione e di essere ancora pi\u00f9 adatto a una vasta gamma di applicazioni.</p>"},{"location":"material/06_tflow/yolo/#yolo5","title":"yolo5","text":"<p>YoloV5 \u00e8 un algoritmo di rilevamento oggetti in tempo reale basato su deep learning, sviluppato da Ultralytics. \u00c8 stato introdotto nel 2020 come un'evoluzione delle precedenti versioni di YOLO (You Only Look Once), con l'obiettivo di migliorare la precisione e la velocit\u00e0 di rilevamento degli oggetti.</p> <p>Il cuore di YoloV5 \u00e8 un modello di rete neurale convoluzionale (CNN) ad architettura a una sola passata, che utilizza una serie di blocchi di convoluzione, pooling e normalizzazione per estrarre le caratteristiche dell'immagine di input. La rete utilizza una variante dell'algoritmo di backpropagation chiamata Gradient Centralization per migliorare la stabilit\u00e0 dell'addestramento e la convergenza del modello.</p> <p>Il modello \u00e8 stato addestrato su un vasto set di dati di immagini annotate, utilizzando una combinazione di tecniche di data augmentation (come la traslazione, la rotazione e la distorsione dell'immagine) e di regolarizzazione (come la Dropout e la L2-regularization) per ridurre l'overfitting. Inoltre, il modello \u00e8 stato ottimizzato per l'inferenza su hardware accelerato come le GPU.</p> <p>Il processo di rilevamento oggetti di YoloV5 \u00e8 diviso in tre fasi principali: la prima fase \u00e8 il pre-processing dell'immagine di input, che viene scalata e normalizzata per il modello. Nella seconda fase, il modello di YoloV5 esegue una sola passata attraverso l'immagine e produce una serie di bounding box che rappresentano la posizione e la dimensione degli oggetti rilevati. Infine, la terza fase applica una serie di tecniche di post-processing (come l'eliminazione dei bounding box sovrapposti e la selezione dei box pi\u00f9 affidabili) per produrre l'output finale del rilevamento oggetti.</p> <p>YoloV5 \u00e8 stato valutato su diversi benchmark di rilevamento oggetti, ottenendo risultati di precisione e velocit\u00e0 di rilevamento molto elevati. Inoltre, il modello \u00e8 stato reso open source e pu\u00f2 essere facilmente adattato per l'uso su una vasta gamma di applicazioni di rilevamento oggetti, come la sorveglianza video, la guida autonoma e il monitoraggio del traffico.</p>"},{"location":"material/06_tflow/yolo/#yolo6","title":"yolo6","text":"<p>Ciao! YOLOv6 \u00e8 un algoritmo di deep learning per l'object detection, che utilizza una rete neurale convoluzionale (CNN) per identificare e localizzare gli oggetti all'interno di un'immagine.</p> <p>La versione 6 di YOLO (You Only Look Once) \u00e8 stata sviluppata dal team di sviluppo open-source Ultralytics, ed \u00e8 una versione migliorata della versione precedente, YOLOv5. Le principali novit\u00e0 introdotte in YOLOv6 includono un'architettura di rete pi\u00f9 efficiente, un metodo di pre-processing delle immagini migliorato e una maggiore precisione nel rilevamento degli oggetti.</p> <p>YOLOv6 utilizza una rete neurale convoluzionale basata su Darknet-53, una architettura di rete pre-addestrata su un dataset di immagini. La rete di YOLOv6 \u00e8 costituita da una serie di strati convoluzionali, intercalati da strati di pooling e di normalizzazione, che permettono di estrarre caratteristiche dall'immagine di input. La rete convoluzionale \u00e8 seguita da un insieme di strati completamente connessi, che producono le predizioni finali.</p> <p>Per migliorare l'efficienza dell'algoritmo, YOLOv6 utilizza un metodo di pre-processing delle immagini chiamato \"Mosaic Data Augmentation\", che combina pi\u00f9 immagini in una singola immagine di input. Questo permette di aumentare il dataset di addestramento senza dover raccogliere nuove immagini, migliorando la capacit\u00e0 dell'algoritmo di riconoscere oggetti in condizioni di luce e posizioni diverse.</p> <p>Per rilevare gli oggetti, YOLOv6 divide l'immagine di input in una griglia di celle, e per ogni cella predice la presenza di un oggetto, la classe dell'oggetto e le coordinate del bounding box che lo circonda. Queste predizioni vengono poi combinate e filtrate per eliminare i falsi positivi e produrre le predizioni finali.</p> <p>In sintesi, YOLOv6 \u00e8 un algoritmo di object detection che utilizza una rete neurale convoluzionale per identificare e localizzare gli oggetti all'interno di un'immagine, utilizzando un metodo di pre-processing delle immagini efficiente e una serie di tecniche avanzate per migliorare la precisione delle predizioni.</p>"},{"location":"material/06_tflow/24_nn/lecture/","title":"25 - Anatomia di una rete neurale","text":"<p>Le reti neurali sono ormai sulla bocca di tutti: chiunque le usa per risolvere con successo ogni tipo di problema. Tuttavia, il passo giusto prima di usarle \u00e8 quello di comprendere effettivamente a cosa servono: in tal senso, introduciamo il concetto di problema non lineare.</p>"},{"location":"material/06_tflow/24_nn/lecture/#251-problemi-non-lineari","title":"25.1 - Problemi non lineari","text":"<p>Diamo un'occhiata al dataset rappresentato nella figura 25.1.</p> <p> </p> Figura 25.1 - Dataset non lineare <p>Questo dataset \u00e8 evidentemente non lineare: in pratica, questo significa che non esiste un algoritmo in grado di separare in maniera lineare le due classi tra loro o, in termini matematici, non esiste un modello in forma:</p> \\[ y = ax_1 + bx_2 + c \\] <p>che permetta di determinare \\(y\\) a partire dalle feature \\(x_1\\) ed \\(x_2\\).</p> <p>Numero di feature</p> <p>Ovviamente, se il numero di feature fosse pi\u00f9 elevato, il sommatore lineare dovrebbe considerare un maggior numero di variabili indipendenti.</p> <p>I lettori pi\u00f9 audaci potrebbero provare ad usare delle approssimazioni lineari a tratti. Costoro dovrebbero considerare la figura 25.2.</p> <p> </p> Figura 25.2 - Dataset *estremamente* non lineare"},{"location":"material/06_tflow/24_nn/lecture/#252-reti-neurali-e-problemi-non-lineari","title":"25.2 - Reti neurali e problemi non lineari","text":"<p>Per capire come le reti neurali ci aiutano a modellare un problema non lineare, visualizziamo un semplice sommatore pesato.</p> <p> </p> Figura 25.3 - Un sommatore lineare <p>In questo semplice caso abbiamo tre input ed un output. Proviamo ad aggiungere un ulteriore strato.</p> <p> </p> Figura 25.4 - Un sommatore lineare a pi\u00f9 strati <p>Lo strato che abbiamo aggiunto \u00e8 detto nascosto, e rappresenta una serie di valori intermedi considerati dal sommatore nel calcolo dell'uscita. Quest'ultima non sar\u00e0 pi\u00f9 una somma pesata degli input, ma una somma pesata dei valori in uscita dallo strato nascosto, che a loro volta sono dipendenti dall'input.</p> <p>Tuttavia, il modello rimane lineare: potremo aggiungere un numero arbitrario di strati nascosti, ma questo sar\u00e0 sempre vero, a meno che non si usi una particolare funzione, detta di attivazione.</p>"},{"location":"material/06_tflow/24_nn/lecture/#2521-funzioni-di-attivazione","title":"25.2.1 - Funzioni di attivazione","text":"<p>La modellazione di un problema non lineare prevede l'introduzione di (appunto) non linearit\u00e0 all'interno del modello. Nella pratica, potremo inserire delle opportune funzioni non lineari tra i diversi strati della rete. Queste funzioni sono dette di attivazione.</p> <p> </p> Figura 25.5 - Semplice rete neurale con funzioni di attivazione <p>Ovviamente, con un maggior numero di strati nascosti, l'impatto delle non linearit\u00e0 diventa maggiore: in questo modo, saremo in grado di inferire delle relazioni anche molto complesse tra gli input e gli output (predetti).</p> <p>Le funzioni di attivazione pi\u00f9 utilizzate in passato erano di tipo sigmoidale (simili, per intenderci, alla funzione che abbiamo visto in uscita alla regressione logistica). Attualmente, le funzioni pi\u00f9 usate sono le rectified linear unit, o ReLU, che hanno risultati comparabili in termini di accuratezza del modello alla sigmoidale, ma risultano essere significativamente meno complesse dal punto di vista computazionale.</p> <p>Le ReLU sono espresse dalla seguente funzione:</p> \\[ y = max(0, x) \\] <p>che graficamente si traduce in una forma espressa come:</p> <p> </p> Figura 25. - ReLU <p>ReLU nella pratica</p> <p>In pratica, una ReLU \"fa passare\" soltanto i valori positivi, portando a zero tutti quelli negativi.</p> <p>Riassumendo:</p> <ul> <li>una rete neurale \u00e8 data da un insieme di nodi, o neuroni, organizzati in uno o pi\u00f9 strati;</li> <li>ogni neurone \u00e8 connesso a quelli dello strato successivo mediante dei pesi, che rappresentano la \"forza\" della connessione;</li> <li>esiste una funzione di attivazione che trasforma l'uscita di ogni neurone verso lo strato successivo inserendo delle non linearit\u00e0.</li> </ul>"},{"location":"material/06_tflow/25_intro_tflow/lecture/","title":"25 - Introduzione a TensorFlow (e Keras)","text":"<p>Attenzione</p> <p>Dispensa in fase di stesura.</p>"},{"location":"material/06_tflow/26_dropout_reg/exercises/","title":"E26 - Overfitting e regolarizzazione","text":""},{"location":"material/06_tflow/26_dropout_reg/exercises/#esercizio-e261","title":"Esercizio E26.1","text":"<p>Proviamo ad utilizzare il dataset IMDB movie da Keras per addestrare una rete neurale con la seguente struttura:</p> <pre><code>_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\ninput (Dense)               (None, 8)                 8008      dense_1 (Dense)             (None, 8)                 72        classification (Dense)      (None, 1)                 9         _________________________________________________________________\n</code></pre> <p>Proviamo ad aggiungere una regolarizzazione ed un dropout sul secondo layer, e compariamo i risultati ottenuti.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/06_tflow/26_dropout_reg/lecture/","title":"26 - Overfitting e regolarizzazione","text":"<p>Nella lezione precedente abbiamo limitato il training delle reti neurali a 10 epoche, usando come metrica di test esclusivamente l'accuratezza sui dati di training.</p> <p>Tuttavia, se proseguissimo nel training e valutassimo anche l'accuratezza sui dati di validazione, noteremmo che ad una certa epoca questa raggiunger\u00e0 un picco, per poi iniziare a stagnare o, in alcuni casi, diminuire: in altre parole, il nostro modello andr\u00e0 incontro ad overfitting. Gestire correttamente questa situazione \u00e8 molto importante: infatti, ottenere un'elevata accuratezza sui dati di training non \u00e8 importante quanto sviluppare un modello in grado di generalizzare su dati che non ha visto durante l'addestramento.</p> <p>L'opposto dell'overfitting \u00e8, abbastanza prevedibilmente, l'underfitting, situazione che si verifica quando vi \u00e8 ancora la possibilit\u00e0 di migliorare il modello. Di solito, l'underfitting si verifica nel momento in cui un modello non \u00e8 abbastanza descrittivo, oppure quando non \u00e8 stato addestrato per un numero di epoche sufficienti, non permettendo alla rete di caratterizzare i pattern di rilievo presenti nei dati.</p> <p>Ovviamente, trovare i parametri ottimali di addestramento significa trovare un equilibrio tra overfitting ed underfitting. In primis, infatti, \u00e8 necessario scegliere accuratamente il numero di epoche di addestramento, per evitare una scarsa (o al contrario eccessiva) adesione del modello ai dati. Inoltre, \u00e8 necessario verificare che i dati di training utilizzati siano adeguati, seguendo magari le indicazioni date in precedenza; infine, qualora questi passi siano gi\u00e0 stati compiuti, pu\u00f2 essere necessario utilizzare delle tecniche di regolarizzazione.</p>"},{"location":"material/06_tflow/26_dropout_reg/lecture/#261-strategie-di-regolarizzazione","title":"26.1 - Strategie di regolarizzazione","text":"<p>Abbiamo gi\u00e0 discusso delle strategie di regolarizzazione quando abbiamo visto la regressione logistica.</p> <p>In pratica, per comprendere il motivo per cui si usa la regolarizzazione possiamo usare il concetto di rasoio di Occam, ovvero, date due possibili spiegazioni per lo stesso fenomeno, quella che con tutta probabilit\u00e0 lo descrive in maniera migliore \u00e8 anche la pi\u00f9 semplice o, in altre parole, quella che assume il minor numero di ipotesi.</p> <p>Questo concetto si applica anche ad un modello di rete neurale: data un'architettura, esistono diverse combinazioni di valori di pesi che possono spiegare i dati, ed in generale le combinazioni pi\u00f9 semplici corrono meno il rischio di andare in overfitting se comparati a quelli pi\u00f9 complessi.</p> <p>Dalla precedente affermazione discende che un modo comune di mitigare l'overfitting del modello ai dati \u00e8 inserire degli opportuni vincoli sulla complessit\u00e0 della rete, \"forzando\" i pesi ad assumere valori ridotti, e rendendo implicitamente la distribuzione di detti valori maggiormente uniforme. Questo procedimento, chiamato weight regularization, \u00e8 ottenuto aggiungendo alla funzione di costo della rete un termine direttamente proporzionale al valore del peso. Di solito, si utilizzano due tecniche di regolarizzazione:</p> <ul> <li>nella regolarizzazione L1 il costo aggiunto \u00e8 proporzionale al valore assoluto dei coefficienti dei pesi, ovvero alla norma \\(L^1\\);</li> <li>nella regolarizzazione L2 il costo aggiunto \u00e8 proporzionale al quadrato del valore dei coefficienti dei pesi, ovvero alla norma \\(L^2\\). </li> </ul> <p>Nota</p> <p>In generale, la regolarizzazione L1 favorisce la \"sparsit\u00e0\" dei dati, forzando il valore di alcuni pesi a \\(0\\). Ci\u00f2 non avviene con la regolarizzazione L2.</p> <p>In Keras, possiamo aggiungere un parametro di regolarizzazione usando il package <code>regularizers</code> ed il parametro <code>kernel_regularizers</code> del layer da regolarizzare:</p> <pre><code>from keras import regularizers\nlayers.Dense(\n64,\nactivation='relu',\nkernel_regularizers=regularizers.l2(0.001))\n</code></pre> <p>In questo caso, stiamo usando un valore di regolarizzazione pari a \\(0.001\\), il che significa che ogni peso del layer regolarizzato aggiunger\u00e0 un valore pari a \\(0.001 \\cdot w_i^2\\) al costo totale della rete, con \\(w_i\\) valore del peso dell'\\(i\\)-mo coefficiente.</p>"},{"location":"material/06_tflow/26_dropout_reg/lecture/#262-dropout","title":"26.2 - Dropout","text":"<p>Un altro metodo di regolarizzazione molto diffuso \u00e8 dato dall'uso di uno strato di dropout.</p> <p>L'idea alla base del dropout sta nel fatto che ogni nodo della rete deve restituire in output delle feature utili a prescindere da quelle restituite dagli altri nodi. Per ottenere questo risultato, si fa in modo che un certo numero di neuroni (scelti in maniera casuale ad ogni iterazione) dello strato precedente venga ignorato dal layer che implementa il dropout.</p> <p>In questo modo, il layer modifica ad ogni iterazione la sua connettivit\u00e0, ottenendo in un certo senso un diverso \"punto di vista\" sui dati stessi: in tal senso, il dropout aggiunge in maniera artificiosa del rumore sul processo di apprendimento, forzando una maggiore o minore importanza delle connessioni a seconda dei nodi scartati, ed evitando quindi delle situazioni dove i layer di rete tendono ad adattarsi vicendevolmente per \"correggere\" gli errori di predizione. Di conseguenza, il modello acquisisce maggiore capacit\u00e0 di generalizzazione, visto e considerato che ogni neurone isoler\u00e0 delle feature in maniera indipendente dagli altri.</p> <p>Per quello che riguarda gli iperparametri usati dal layer di dropout, il pi\u00f9 importante \u00e8 quello che specifica la probabilit\u00e0 con la quale gli output dello strato precedente vengono scartati. Un valore comune in tal senso \u00e8 \\(0.5\\) per gli strati nascosti, e \\(0.8\\) per lo strato di input.</p>"},{"location":"material/06_tflow/27_tflow_images/exercises/","title":"E27 - Convolutional Neural Networks in TensorFlow e Keras","text":""},{"location":"material/06_tflow/27_tflow_images/exercises/#esercizio-e271","title":"Esercizio E27.1","text":"<p>Creare un modello di rete neurale composto in questo modo:</p> <pre><code>_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\nconv_1 (Conv2D)             (None, 30, 30, 32)        896       pooling_1 (MaxPooling2D)    (None, 15, 15, 32)        0         conv_2 (Conv2D)             (None, 13, 13, 32)        9248      dropout (Dropout)           (None, 13, 13, 32)        0         flatten (Flatten)           (None, 5408)              0         classification (Dense)      (None, 10)                54090     _________________________________________________________________\n</code></pre> <p>Questo modello deve essere in grado di classificare le immagini presenti nel dataset CIFAR10.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/06_tflow/27_tflow_images/lecture/","title":"27 - Convolutional Neural Networks in TensorFlow e Keras","text":"<p>Una delle applicazioni pi\u00f9 diffuse del deep learning riguarda il riconoscimento degli oggetti presenti all'interno di un'immagine. In tal senso, \u00e8 necessario introdurre due ulteriori layer, che rappresentano la base per le cosiddette convolutional neural network.</p> <p>Queste reti (che chiameremo per brevit\u00e0 CNN) sono specializzate nel lavorare su immagini, ma possono anche essere usate per segnali monodimensionali (come la voce) o tridimensionali (come le nuvole di punti).</p> <p>Le CNN assumono una rilevanza fondamentale nel moderno deep learning: \u00e8 grazie a loro se il campo del deep learning \u00e8 diventato mainstream nel mondo della ricerca, il che ha portato ad un interesse e, conseguentemente, ad avanzamenti impensabili in un ridottissimo lasso di tempo di soli dieci anni. Oggigiorno, le CNN vengono utilizzate in ogni ambito che preveda l'elaborazione di dati bidimensionali, dal riconoscimento facciale all'individuazione e caratterizzazione delle targhe degli autoveicoli in transito; conoscerle, quindi, \u00e8 imprescindibile.</p>"},{"location":"material/06_tflow/27_tflow_images/lecture/#271-layer-convoluzionale","title":"27.1 - Layer convoluzionale","text":"<p>I layer convoluzionali sono alla base del funzionamento delle CNN.</p> <p>Il concetto alla base di questo tipo di layer \u00e8 la convoluzione che, nel contesto del deep learning, \u00e8 un'operazione lineare che prevede la moltiplicazione di un insieme di pesi, chiamato filtro, con una piccola porzione (o finestra) dell'immagine considerata, seguita ovviamente da una funzione di attivazione. Questo processo \u00e8 analogo a quello che avviene in una tradizionale rete neurale.</p> <p>Il filtro ha dimensioni volutamente inferiori rispetto a quelle dell'immagine da convolvere, tipicamente nell'ordine di \\(3 \\times 3\\) o \\(5 \\times 5\\) pixel; la convoluzione del filtro per ogni finestra dell'immagine \u00e8 inoltre assimilabile ad un prodotto scalare, per cui viene restituito sempre un unico valore per ogni finestra convoluta. In tal senso, il filtro viene \"fatto scorrere\" dall'alto in basso, da sinistra verso destra, anche su finestre sovrapposte, che scorrono quindi a passo di un pixel.</p> <p>Nota</p> <p>Tecnicamente, quindi, l'operazione definita come \"convoluzione\" \u00e8 in realt\u00e0 una cross-correlazione.</p> <p>Applicare sistematicamente lo stesso filtro su tutte le finestre possibili dell'immagine, anche sovrapposte, \u00e8 un'idea alquanto potente: infatti, un filtro viene opportunamente tarato per riconoscere uno specifico tipo di feature, come un bordo o una forma, che potr\u00e0 essere trovata ovunque nell'immagine grazie allo scorrimento, ottenendo la cosiddetta invarianza alla traslazione.</p> <p>Abbiamo accennato al fatto che l'output dell'applicazione di un filtro su di una finestra dell'immagine \u00e8 un prodotto scalare. Di conseguenza, man mano cheil filtro scorre, viene creato un array bidimensionale di valori, che viene indicato come mappa delle feature, o feature map. Sar\u00e0 proprio questa, e non l'immagine iniziale, ad essere passata al layer successivo.</p>"},{"location":"material/06_tflow/27_tflow_images/lecture/#272-layer-di-pooling","title":"27.2 - Layer di pooling","text":"<p>Abbiamo visto come i layer convoluzionali creino delle feature map che \"sintetizzano\" la presenza di determinate feature all'interno di un input. Un limite di queste mappature sta per\u00f2 nel fatto che registrano la posizione precisa della feature individuata all'interno dell'input: ci\u00f2 significa quindi che anche piccole variazioni nella posizione di una feature risulter\u00e0 in una feature map completamente differente, il che comporta un'estrema sensibilit\u00e0 della rete neurale a piccole trasformazioni dell'immagine di input.</p> <p>Per risolvere questo problema, si utilizza un approccio chiamato sottocampionamento: in pratica, si ricava una versione a pi\u00f9 bassa risoluzione del segnale di ingresso, evidenziando di conseguenza gli elementi pi\u00f9 importanti, e scartando i piccoli dettagli non rilevanti nel task di classificazione. Per far questo, viene utilizzato un layer di pooling, applicato a cascata rispetto a quello convoluzionale.</p> <p>Il layer di pooling non fa altro che applicare un filtro, di solito di dimensioni \\(2 \\times 2\\) e con un passo di \\(2\\) pixel (quindi senza sovrapposizioni), che applica una funzione di sottocampionamento, scegliendo quindi un unico pixel tra quelli presenti nel filtro. Due funzioni di pooling molto comuni sono le seguenti:</p> <ul> <li>average pooling: questo filtro associa ad ogni finestra dell'immagine in input il valore medio presente nella finestra;</li> <li>max pooling: questo filtro associa ad ogni finestra dell'immagine in input il valore massimo presente nella finestra.</li> </ul> <p>Ottenendo quindi una versione \"sottocampionata\" dell'input, si raggiunge la cosiddetta invarianza a traslazioni locali, ovvero una sorta di \"insensibilit\u00e0\" del modello a traslazioni o rotazioni di entit\u00e0 minima.</p>"},{"location":"material/06_tflow/27_tflow_images/lecture/#273-creazione-di-una-semplice-rete-neurale-per-lelaborazione-delle-immagini","title":"27.3 - Creazione di una semplice rete neurale per l'elaborazione delle immagini","text":"<p>Iniziamo creando una semplice rete neurale per l'elaborazione delle immagini digitali. Per farlo, useremo l'API <code>Sequential</code> di Keras, andando a creare una \"pila\" di layer. Ad esempio:</p> <pre><code>from tensorflow import keras\nmodel = keras.Sequential(\n[\nkeras.Input(shape=(28, 28, 1)),\nkeras.layers.Conv2D(\n32,\n(3, 3),\nactivation='relu',\nname='first_conv_layer'),\nkeras.layers.Conv2D(\n32,\n(3, 3),\nactivation='relu',\nname='second_conv_layer'),\nkeras.layers.Flatten(name='flatten_layer'),\nkeras.layers.Dense(\n10,\nactivation='softmax',\nname='layer_class')\n]\n)\n</code></pre> <p>Nel modello precedente:</p> <ul> <li>creiamo un'architettura con due layer convoluzionali bidimensionali istanziando due oggetti di classe <code>Conv2D</code>;</li> <li>ognuno di questi oggetti accetta come attributi:</li> <li>il numero di filtri da usare nel banco convoluzionale (in particolare, 32);</li> <li>la dimensione di ciascun filtro, in pixel (\\(3 \\times 3\\));</li> <li>la funzione di attivazione da usare (<code>activation = 'relu'</code>);</li> <li>opzionalmente, un nome.</li> </ul> <p>Dopo i due layer convoluzionali notiamo la presenza di un layer di vettorizzazione delle feature estratte, ottenuto tramite un oggetto di classe  <code>Flatten</code>, ed un layer completamente connesso con un numero di neuroni pari al numero di classi coinvolte nel nostro problema (in questo caso, dieci) ed attivazione <code>softmax</code>.</p>"},{"location":"material/06_tflow/28_tricks/exercises/","title":"E28 - TensorFlow &amp; Keras: Tips &amp; Tricks","text":""},{"location":"material/06_tflow/28_tricks/exercises/#e281","title":"E28.1","text":"<p>Scarichiamo il dataset flowers. Per farlo, usiamo il seguente codice:</p> <pre><code>import pathlib\nfrom tensorflow import keras\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = keras.utils.get_file(origin=dataset_url,\nextract=True)\ndata_dir = pathlib.Path(data_dir).parent\ndata_dir = pathlib.Path(data_dir, 'flower_photos')\n</code></pre> <p>Utilizziamo i metodi di Keras per caricare il dataset in memoria ed addestrare un modello per la classificazione di questo tipo:</p> <pre><code>_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\nrescaling_1 (Rescaling)     (None, 150, 150, 3)       0         conv_1 (Conv2D)             (None, 148, 148, 32)      896       max_pool_1 (MaxPooling2D)   (None, 74, 74, 32)        0         conv_2 (Conv2D)             (None, 72, 72, 32)        9248      max_pool_2 (MaxPooling2D)   (None, 36, 36, 32)        0         dropout (Dropout)           (None, 36, 36, 32)        0         flatten_1 (Flatten)         (None, 41472)             0         classification (Dense)      (None, 5)                 207365    _________________________________________________________________\n</code></pre> <p>Inferiamo il numero di classi del dataset (ovvero la <code>X</code> nel precedente sommario) usando l'attributo <code>class_names</code> del dataset ottenuto da <code>image_dataset_from_directory</code>.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/06_tflow/28_tricks/exercises/#e282","title":"E28.2","text":"<p>Utilizziamo gli opportuni callback per terminare l'addestramento del modello visto nell'esercizio 1 dopo 3 epoche nelle quali l'accuracy di validazione non migliora per pi\u00f9 di <code>0.01</code>. Visualizziamo inoltre i risultati ottenuti in TensorBoard.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/06_tflow/28_tricks/exercises/#e283","title":"E28.3","text":"<p>Scarichiamo il dataset Stack Overflow mediante il seguente codice:</p> <pre><code>import pathlib\nfrom tensorflow import keras\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\"\ndata_dir = keras.utils.get_file(origin=dataset_url,\nextract=True,\ncache_subdir='datasets/stack_overflow')\ndata_dir = pathlib.Path(data_dir).parent\ntrain_dir = pathlib.Path(data_dir, 'train')\ntest_dir = pathlib.Path(data_dir, 'test')\n</code></pre> <p>Utilizziamo i metodi di Keras per caricare il dataset in memoria ed addestrare un modello per la classificazione di questo tipo:</p> <pre><code>_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\ndense_1 (Dense)             (None, 64)                64064     dense_2 (Dense)             (None, 4)                 260       _________________________________________________________________\n</code></pre> <p>Usiamo gli stessi callback utilizzati in precedenza.</p> <p>Inferiamo il numero di classi del dataset (ovvero la <code>X</code> nel precedente sommario) usando l'attributo <code>class_names</code> del dataset ottenuto da <code>text_dataset_from_directory</code>.</p> <p>Soluzione</p> <p>La soluzione a questo esercizio \u00e8 contenuta in questo notebook.</p>"},{"location":"material/06_tflow/28_tricks/lecture/","title":"28 - TensorFlow &amp; Keras: Tips &amp; Tricks","text":""},{"location":"material/06_tflow/28_tricks/lecture/#281-dataset","title":"28.1 - Dataset","text":"<p>I dati che abbiamo utilizzato finora erano organizzati sotto forma di array NumPy. Tuttavia, per dataset di grosse dimensioni, potrebbe essere necessario utilizzare degli oggetti di tipo <code>Dataset</code>. In tal senso, Keras ci mette a disposizione diverse tecniche; vediamone alcuni.</p>"},{"location":"material/06_tflow/28_tricks/lecture/#2811-immagini","title":"28.1.1 - Immagini","text":"<p>Per caricare un dataset di immagini a partire da una cartella, possiamo usare la funzione <code>image_dataset_from_directory</code>, che ha una sintassi di questo tipo:</p> <pre><code>train = tf.keras.utils.image_dataset_from_directory(\ndata_dir,\nvalidation_split=0.2,\nsubset='training',\nimage_size=(img_height, img_width),\nbatch_size=batch_size,\nseed=seed)\nval = tf.keras.utils.image_dataset_from_directory(\ndata_dir,\nvalidation_split=0.2,\nsubset='validation',\nimage_size=(img_height, img_width),\nbatch_size=batch_size,\nseed=seed)\n</code></pre> <p>Nel precedente esempio:</p> <ul> <li><code>data_dir</code> \u00e8 la cartella dove sono presenti i dati;</li> <li><code>validation_split</code> indica quanti dati usare per la validazione. Il valore deve essere coerente tra il dataset di train e quello di validazione;</li> <li><code>subset</code> indica se il dataset \u00e8 indirizzato al training o alla validazione;</li> <li><code>image_size</code> rappresenta la dimensione (in pixel) dell'immagine;</li> <li><code>batch_size</code> rappresenta la dimensione del batch di dati da usare;</li> <li><code>seed</code> \u00e8 un parametro che ci assicura la coerenza tra le immagini scelte per il training e quelle scelte per il test.</li> </ul> <p>La cartella <code>data_dir</code> deve essere organizzata come segue:</p> <pre><code>data_dir/\n...class1/\n......1.png\n......2.png\n...class2/\n......1.png\n......2.png\n......3.png\n</code></pre> <p>A questo punto possiamo passare <code>train</code> e <code>val</code> direttamente al metodo <code>fit</code> del nostro modello.</p> <pre><code>model.fit(\ntrain,\nvalidation_data=val,\nepochs=10)\n</code></pre> <p>Nota</p> <p>Un accorgimento utile a migliorare le prestazioni della nostra rete \u00e8 quello di inserire un layer di rescaling qualora si abbia a che fare con immagini a colori. Infatti, i canali RGB possono assumere valori all'interno del range \\([0, 255]\\), mentre \u00e8 consigliabile usare per una rete neurale valori compresi nell'intervallo \\([0, 1]\\). Keras ci mette a disposizione un apposito layer:</p> <p><code>py tf.keras.layers.Rescaling(1./255)</code></p>"},{"location":"material/06_tflow/28_tricks/lecture/#2812-testo","title":"28.1.2 - Testo","text":"<p>Keras offre un metodo simile per creare un dataset a partire da un insieme di file di testo, utilizzando il metodo <code>text_dataset_from_directory</code>.</p> <p>Analogamente al metodo usato per le immagini, <code>text_dataset_from_directory</code> si aspetta una cartella in una certa forma:</p> <pre><code>data_dir/\n...class1/\n......1.txt\n......2.txt\n...class2/\n......1.txt\n......2.txt\n......3.txt\n</code></pre> <p>Per caricare il nostro dataset possiamo usare una forma analoga a quella delle immagini:</p> <pre><code>train = text_dataset_from_direcotry(\ndata_dir,\nbatch_size=batch_size,\nvalidation_split=0.2,\nsubset='training',\nseed=seed)\nval = text_dataset_from_directory(\ndata_dir,\nbatch_size=batch_size,\nvalidation_split=0.2,\nsubset='validation',\nseed=seed)\n</code></pre> <p>I parametri sono esattamente gli stessi, a meno dell'assenza del parametro <code>image_size</code>.</p>"},{"location":"material/06_tflow/28_tricks/lecture/#28121-preparazione-dati-testuali-per-il-trainng","title":"28.1.2.1 - preparazione dati testuali per il trainng","text":"<p>Rispetto alle immagini, i dati testuali richiedono tre ulteriori operazioni, ovvero:</p> <ul> <li>standardizzazione: si tratta di una procedura di preprocessing sul testo, che consiste tipicamente nella rimozione della punteggiatura. Di default, questa operazione converte l'intero testo in minuscolo e rimuove la punteggiatura;</li> <li>tokenizzazione: si tratta di una procedura di suddivisione delle stringhe in token. Ad esempio, si pu\u00f2 suddividere una frase nelle singole parole. Di default, questa operazione suddivide i token in base allo spazio;</li> <li>vettorizzazione: si tratta della procedura di conversione dei token in valori numerici trattabili da un modello di rete neurale. Di default, il metodo di vettorizzazione \u00e8 <code>int</code>.</li> </ul> <p>Questi tre step sono gestiti in automatico da un layer chiamato <code>TextVectorization</code>.</p> <p>Procediamo quindi a creare un layer di TextVectorization utilizzando una vettorizzazione binaria:</p> <pre><code>vectorize_layer = TextVectorization(\nmax_tokens=VOCAB_SIZE,\noutput_mode='binary')\n</code></pre> <p>In particolare, <code>max_tokens</code> permette di stabilire il numero massimo di vocaboli consentiti, mentre l'<code>output_mode</code> indica la modalit\u00e0 con cui sar\u00e0 gestita la sequenza vettorizzat.</p> <p>A questo punto, occorre creare il dataset che sar\u00e0 effettivamente passato al primo layer della rete neurale. In tal senso, dobbiamo tenere conto che i dataset che abbiamo creato mediante <code>text_dataset_from_directory</code> non sono ancora stati vettorizzati, ed inoltre le singole coppie campione/label non sono accessibili mediante le tecniche standard di indicizzazione. Ci\u00f2 \u00e8 legato al fatto che le funzioni <code>*_dataset_from_directory</code> creano un oggetto di tipo <code>BatchDataset</code>, usato da TensorFlow per ottimizzare il caricamento in memoria di dataset di grosse dimensioni.</p> <p>Di conseguenza, dovremo innanzitutto estrarre il testo senza considerare le singole label. Per farlo, possiamo usare la funzione <code>map()</code> del nostro dataset:</p> <pre><code>train_text = train.map(lambda text, labels: text)\n</code></pre> <p>La funzione <code>map()</code> non fa altro che applicare all'intero iterabile la funzione passata come argomento. In tal senso, il parametro passato altro non \u00e8 se non una lambda function, ovvero una funzione anonima che assume una forma sintattica del tipo:</p> <pre><code>lambda args : expression\n</code></pre> <p>e quindi applica l'espressione a valle dei <code>:</code> agli argomenti passati. In questo caso, stiamo semplicemente facendo in modo che tutte le coppie testo/label siano \"mappate\" sul semplice testo.</p> <p>Una volta estratto il testo, dovremo chiamare il metodo <code>adapt</code> del layer di vettorizzazione in modo tale da creare il vocabolario che associ un determinato token numerico a ciascuna stringa.</p> <pre><code>vectorize_layer.adapt(train_text)\n</code></pre> <p>Potremo quindi procedere ad integrare il layer di vettorizzazione all'interno del nostro modello.</p> <p>In tal senso, dovremo assicurarci che il modello abbia un input di forma <code>(1,)</code> e tipo stringa, facendo in modo che la rete abbia un'unica stringa in input per ciascun batch:</p> <pre><code>model.add(\nkeras.Input(shape=(1,),\ndtype=tf.string))\n</code></pre>"},{"location":"material/06_tflow/28_tricks/lecture/#2813-array-numpy","title":"28.1.3 - Array NumPy","text":"<p>Nel caso di un array NumPy, occorre utilizzare il metodo <code>from_tensor_slices</code>:</p> <pre><code>train = from_tensor_slices((x_train, y_train))\nval = from_tensor_slices((x_test, y_test))\n</code></pre>"},{"location":"material/06_tflow/28_tricks/lecture/#282-callback","title":"28.2 - Callback","text":"<p>Un callback \u00e8 un'azione che il modello pu\u00f2 effettuare durante diverse fasi dell'apprendimento.</p> <p>Keras ne offre di numerosi, che possono essere utilizzati ad esempio per monitorare le metriche che abbiamo scelto per la valutazione del modello, o salvare lo stesso su disco.</p> <p>Per usare i callback, dovremo crearne una lista, e passarla al parametro <code>callbacks</code> usato dal metodo <code>fit()</code> del nostro modello.</p> <p>Proviamo, ad esempio, a creare un insieme di callback che permetta di salvare i pesi del modello con una certa frequenza, e che termini il training se lo stesso sta andando in overfitting.</p> <p>Per prima cosa, creiamo un oggetto di tipo <code>ModelCheckpoint</code>, che ci permette di salvare i pesi del modello:</p> <pre><code>mc_callback = keras.callbacks.ModelCheckpoint(\nfilepath=path_to_checkpoints,\nsave_weights_only=True,\nmonitor='val_acc',\nsave_best_only=True)\n</code></pre> <p>In particolare:</p> <ul> <li><code>filepath</code> indica il percorso del file nel quale salveremo i checkpoint;</li> <li><code>save_weights_only</code> istruisce Keras a salvare soltanto i pesi del modello, riducendo lo spazio occupato in memoria;</li> <li><code>monitor</code> indica la metrica da monitorare;</li> <li><code>save_best_only</code> istruisce Keras a salvare soltanto il modello \"migliore\", trascurando quelli ottenuti durante le altre iterazioni.</li> </ul> <p>Proviamo poi a creare un oggetto di tipo <code>EarlyStopping</code>, che ci permette di terminare l'addestramento qualora la metrica monitorata non presenti miglioramenti tra un'epoca e l'altra. Ad esempio:</p> <pre><code>es_callback = keras.callbacks.EarlyStopping(\nmonitor='val_acc',\nmin_delta=0.1,\npatience=3,\nrestore_best_weights=True)\n</code></pre> <p>Nel codice precedente:</p> <ul> <li><code>monitor</code> indica la metrica da monitorare;</li> <li><code>min_delta</code> indica il valore minimo da considerare migliorativo per la metrica;</li> <li><code>patience</code> indica il numero di epoche dopo il quale il training viene interrotto in assenza di miglioramenti;</li> <li><code>restore_best_weights</code> indica se ripristinare i valori migliori ottenuti per i parametri dopo il termine dell'addestramento, o se usare gli ultimi.</li> </ul> <p>Aggiungiamo infine un ultimo callback, da utilizzare per permettere di visualizzare i risultati del nostro training su un tool di visualizzazione chiamato TensorBoard.</p> <pre><code>tb_callback = TensorBoard()\n</code></pre> <p>Per TensorBoard, possiamo lasciare i parametri al loro valore di default. La reference completa \u00e8 disponibile sulla documentazione ufficiale.</p> <p>Possiamo adesso specificare i callback da utilizzare passando le precedenti variabili sotto forma di lista al metodo <code>fit()</code> del nostro modello.</p>"},{"location":"material/06_tflow/28_tricks/lecture/#283-transfer-learning-e-fine-tuning","title":"28.3 - Transfer learning e fine tuning","text":"<p>Le reti neurali, e soprattutto le CNN, presentano un'interessante caratteristica, ovvero quella di apprendere delle feature di carattere generico nei loro primi strati, andandosi a specializzare man mano che si va in profondit\u00e0 nella rete.</p> <p>Partendo da questa considerazione \u00e8 stata elaborata la tecnica del transfer learning, che consiste nel prendere il modello addestrato su un problema e riconfigurarlo per risolverne uno nuovo (ma, ovviamente, simile: ad esempio, un tool che permette di valutare la razza di un gatto pu\u00f2 essere usato per distinguere tra leopardi e tigri). Questa tecnica permette anche di addestrare un numero limitato di parametri, per cui \u00e8 possibile utilizzarla quando si ha a che fare con dataset di dimensioni limitate.</p> <p>In tal senso, il transfer learning segue di solito questi step:</p> <ul> <li>consideriamo i layer ed i pesi di un modello addestrato in precedenza;</li> <li>effettuiamo il freezing (congelamento) di questi layer, fissando i valori dei pesi;</li> <li>creiamo ed inseriamo alcuni layer successivi a quelli congelati per adattarli al nostro problema;</li> <li>addestriamo i nuovi layer sul nostro problema.</li> </ul> <p>Opzionalmente, \u00e8 possibile effettuare un passaggio di fine tuning, \"sbloccando\" il modello ottenuto in precedenza e riaddestrandolo sull'intero dataset con un basso learning rate.</p>"},{"location":"material/06_tflow/29_gans/lecture/","title":"XX - Le Generative Adversarial Networks","text":"<p>Le Generative Adversarial Networks (GAN) rappresentano una delle pi\u00f9 interessanti tra le recenti innovazioni in ambito deep learning. Le GAN sono un modello di tipo generativo: creano, infatti, nuovi dati che \"ricordano\" quelli usati per l'addestramento della rete. Ad esempio, una GAN pu\u00f2 essere addestrata a creare dei volti che, in realt\u00e0, non appartengono ad una persona reale.</p> <p>TODO: ESEMPIO VOLTI GAN</p> <p>Una GAN \u00e8 in grado di ottenere questo livello di realismo facendo \"lavorare in parallelo\" un generatore, che impara a produrre gli output richiesti, ed un discriminatore, il cui compito \u00e8 discernere i dati \"veri\" da quelli mandati in output dal generatore. La GAN sar\u00e0 ritenuta addestrata con successo quando il generatore sar\u00e0 in grado di ingannare il discriminatore.</p>"},{"location":"material/06_tflow/29_gans/lecture/#xx1-i-modelli-generativi","title":"XX.1 - I modelli generativi","text":"<p>Facciamo un passo indietro. Cosa si intende per modello generativo?</p> <p>In breve, un modello generativo \u00e8 un modello statistico in grado di generare nuove istanze appartenenti ad un certo dataset. Di contro, i modelli discriminativi (che abbiamo usato finora) permettono di discriminare tra diverse classi di dati.</p> <p>Cani e gatti</p> <p>Immaginiamo un dataset fatto di foto di cani e gatti. Un modello discriminativo ci permette di capire se la foto rappresenta un cane o un gatto; un modello generativo ci permette di generare la foto di un cane o, in alternativa, quella di un gatto.</p> <p>Pi\u00f9 formalmente, supponiamo di avere una coppia di insiemi \\((X, Y)\\), dove \\(X\\) sono le istanze del nostro dataset, ed \\(Y\\) le label ad esse assegnate. Allora:</p> <p>Modelli generativi</p> <p>I modelli generativi descrivono la probabilit\u00e0 congiunta \\(P(X, Y)\\) o, nel caso di dati non etichettati, la probabilit\u00e0 \\(P(X)\\).</p> <p>Modelli discriminativi</p> <p>I modelli discriminativi descrivono la probabilit\u00e0 condizionale \\(P(Y|X)\\).</p> <p>Appare chiaro come i modelli generativi descrivano la distribuzione dei dati, e ci dicano quanto sia probabile un dato esempio. Ad esempio, un modello che predice la parola successiva in una certa frase \u00e8 tipicamente generativo, perch\u00e9 assegna una probabilit\u00e0 ad una certa sequenza di parole. Di converso, un modello discriminativo ci dice solo quanto \u00e8 probabile che una certa label sia applicata ad una data istanza.</p> <p>Un modello discriminativo ignora la questione di se una data istanza \u00e8 probabile, e ci dice solo quanto probabile \u00e8 che una label sia applicata ad un'istanza.</p> <p>Notiamo che questo \u00e8 una definizione molto generale. Ci sono molti tipi diversi di modelli generativi. Le GAN sono soltanto uno.</p>"},{"location":"material/06_tflow/29_gans/lecture/#modellare-le-probabilita","title":"Modellare le probabilit\u00e0","text":"<p>Non tutti i tipi di modelli devono restituire un numero che rappresenta una probabilit\u00e0. Possiamo modellare la distribuzione dei dati che immita quella distribuzione.</p> <p>Ad esempio, un classificatore discriminativo come un albero decisionale pu\u00f2 etichettare un'istanza senza assegnare una probabilit\u00e0 a quella label. Un classificatore di questo tipo sarebbe sempre un modello perch\u00e9 la distribuzione di tutti i label predetti modellerebbero la distribuzione reale delle label nei dati.</p> <p>In modo simile, un modello generativo pu\u00f2 modellare una distribuzione producendo dei falsi convincenti che sembrano essere estratti da quella stessa distribuzione.</p>"},{"location":"material/06_tflow/29_gans/lecture/#i-modelli-generativi-sono-difficili","title":"I modelli generativi sono difficili","text":"<p>I modelli generativi affrontano un task pi\u00f9 difficile di quello gestito dai modelli discriminativi analoghi. I modelli generativi devono modellare infatti pi\u00f9 dati.</p> <p>Un modello generativo per le immagini pu\u00f2 catturare le correlazioni come come \"cose che sembrano navi dovrebbero probabilmente apparire vicino a cose che sembrano acqua\" e \"gli occhi probabilmente non saranno sulla fronte\". Queste sono distribuzioni complicate.</p> <p>In contrasto, un modello discriminativo pu\u00f2 apprendere la differenza tra \"nave\" e \"non nave\" guardando soltanto pochi pattern. Pu\u00f2 ignorare molte delle correlazioni che il modello generativo deve invece tenere in conto.</p> <p>I modelli discriminativi provano a disegnare dei confini nello spazio dei dati, mentre i modelli generativi provano a modellare come i dati sono disposti nello spazio. Ad esempio, il seguente diagramma mostra i modell discriminativi e generativi per le cifre scritte a mano:</p> <p>TODO: DIAGRAMMA</p> <p>Il modello discriminativo prova ad individuare la diferenza tra gli 0 e gli 1 scritti a mano tracciando una riga nello spazio dei dati. Se fa le giuste assunzioni sulla linea, pu\u00f2 distinguere gli 0 dagli 1 senza doiver modellare dove le istanze sono piazzate nello spazio dei dati su ogni lato della linea.</p> <p>In contrasto,il modello generativo prova a produrre degli 1 e degli 0 convinceenti generando dei numeri che cadono vicino alle controparti vene nello spazio dei dati. Deve modellare la distribuzione attraverso lo spazio dei dati.</p> <p>Le GAN offrono un modo efficace di addestrare questi modelli ricchi che ricordano una distribuzione reale. Per capire comue funzionano dobbiamo capire la struttura base di una GAN.</p>"},{"location":"material/06_tflow/29_gans/lecture/#test","title":"Test","text":"<p>Abbiamo il test della QI per 1000 persone. Modelliamo la distribuzione dei punteggi dei QI mediante la seguente procedura:</p> <ol> <li>lanciamo tre dadi a sei facce * moltiplichiamo il risultato per una costante w</li> <li>ripetiamo 100 volte e prendiamo la media dei risultati</li> </ol> <p>Proviamo diversi valori per w fino a che il risultato della procedura \u00e8 uguale alla media dei punteggi QI reali. Il modello \u00e8 genrativo o discriminativo?</p> <p>Not enough information to tell. This model does indeed fit the definition of one of our two kinds of models. Try again. Discriminative model Incorrect: an analogous discriminative model would try to discriminate between different kinds of IQ scores. For example, a discriminative model might try to classify an IQ as fake or real. Try again. Generative model Correct: with every roll you are effectively generating the IQ of an imaginary person. Furthermore, your generative model captures the fact that IQ scores are distributed normally (that is, on a bell curve). Correct answer.</p> <p>Un modello restituisce una probabilit\u00e0 quando gli diamo un'istanza dei dati. E' generativo o discriminativo?</p> <p>Not enough information to tell. Both generative and discriminative models can estimate probabilities (but they don't have to). Correct answer. Generative model A generative model can estimate the probability of the instance, and also the probability of a class label. Try again. Discriminative model A discriminative model can estimate the probability that an instance belongs to a class. Try again.</p>"},{"location":"material/06_tflow/29_gans/lecture/#anatomia-di-una-gan","title":"Anatomia di una GAN","text":"<p>Una GAN ha due parti:</p> <ul> <li>il generatore, che apprende a generare dati plausibili. Le istanze generate divetano degli esempi negativi per il discriminatore</li> <li>il discriminatore che apprende a distinguere i dati falsi del genratore dai dati reali. il discriminatore penalizza il genaeratore che produce risultati poco plausibili.</li> </ul> <p>Quando inizia il training, il generatore produce ovviamente dati falsi, ed il discriminatore impara rapidamente a dire che \u00e8 falso:</p> <p>TODO: ESEMPIO</p> <p>Man mano che l'addestramento procede, il generatore produce degli oiutput che possono man mano sempre pi\u00f9 ingannare il discriminatore:</p> <p>TODO IMMAGINE</p> <p>Infine, se l'addestramento del generatore va a buon fine, il discriminatore non riesce a dire la differenza tra reale e falso. Inizia a classificare i dati falsi come reali, e l'accuracy diminuisce.</p> <p>TODO IMMAGINE</p> <p>Ecco uno schema dell'intero sistema</p> <p>https://developers.google.com/machine-learning/gan/gan_structure?hl=en</p> <p>Sia il generatore sia il discriminaotre sono reti neurali. L'output del generatore \u00e8 connesso direttamente all'input del discriminatore. Attraverso la backpropagation, la classificazione del discriminatore fornisce un segnale che il generatore usa per aggiornare i suoi pesi.</p>"},{"location":"material/06_tflow/29_gans/lecture/#il-discriminatore","title":"Il discriminatore","text":"<p>Il discriminatore in una GAN \u00e8 semplicemente un classificatore. Prova a distinguere i dati reali dai dati creati dal generatore. Pu\u00f2 usare una qualsiasi archiettura di rete appropriata al tipo di dati da classificare.</p>"},{"location":"material/06_tflow/29_gans/lecture/#dati-di-training-per-il-discriminatore","title":"Dati di training per il discriminatore","text":"<p>I dati di training per il discriminatore provengono da due sorgenti:</p> <ul> <li>istanze di dati reali, come vere immagini di persone. Il discriminatore usa queste istanze come campioni positivi durante il training.</li> <li>istanze di dati falsi creati dal generatore. Il discriminatore usa queste istazne come campioni negativi durante il training.</li> </ul> <p>Nella figura precedente, le due box \"Samples\" rappresentano quesete due sorgenti dati chee vengono inviate al discriminatore. Durante l'addestramento del discriminatore, il generatore non viene addestrato. I suoi pesi rimangono costanti, mentre produce i campioni su cui il discrimniatore verr\u00e0 addestrato.</p>"},{"location":"material/06_tflow/29_gans/lecture/#addestramento-del-discriminatore","title":"Addestramento del discriminatore","text":"<p>Il discriminatore si connette a due funzioni di costo. Durante l'addestreamento del discrimiantore, questo ignora la loss del generatore e usa soltanto la sua. Usiamo la loss del generatore durante l'adestramento del generatore.</p> <p>Durante il trainign del discriminatore:</p> <ol> <li>il discriminaotre classifica sia i dati reali sia quelli falsi dal generatore</li> <li>la loss del discrimiantore penalizza il discriminatore per classificare male un'istanza vera come falsa o una falsa come vera</li> <li>il discriminaotre aggiorna i suoi pesi mediante la backgpropagation dalla loss del discrimiantore attraverso la rete dello stesso</li> </ol>"},{"location":"material/06_tflow/29_gans/lecture/#il-generatore","title":"il generatore","text":"<p>la parte del generatore di una GAN apprende a creare dei dati falsi incororando il feedback dal discriminatore. Apprende a fare in modo che il discriminatore classifichi il suo output come reale.</p> <p>L'addestramento del generatore richiede un'integrazione pi\u00f9 strateta tra il genratore ed il discriminatore rispetto a quella raggiunta durante il training del discriminatore. La porzione della GAN che addestra il generatore include:</p> <ul> <li>inpuyt casuale</li> <li>rete generatrice, che trasforma l'input random in un'istanza dei dati</li> <li>rete discriminatorice, che classifica i dati generati</li> <li>output del discriminatore</li> <li>loss del generatore, che penalizza il generatore se questo non riesce ad imbrogliare il discriminatore</li> </ul>"},{"location":"material/06_tflow/29_gans/lecture/#input-casuale","title":"input casuale","text":"<p>le reti neurali hanno bisogno di un qualche tipo di input. Normalmente daimo in input dati con i quali vogliamo fare qualcosa, come un'istanza che vogliaomo classificare o su cui vogliamo effettuare una predizione. Ma cosa usiamo come input per una rete che manda in output delle nuove istanze dati?</p> <p>Nella sua forma base, una GAN prende del rumore casuale come input. Il generatore quindi trasforma questo rumore in un output significativo. introduciendo rumore, possiamo fare in modo che la GAN produca un'ampia quantit\u00e0 di dati, campionati da diversi posti nella distribuzione obiettivo.</p> <p>GLi espeirmenti suggeriscono che la distribuzione del rumore non conti molto, per cui possiamo scegliere qualcosa da cui sia facile campionare, come una distribuzione unifoirme. Per convenienza, lo spazio dal quale il rumore viene campionato \u00e8 spesso di dimensioni pi\u00f9 piccole rispetto alla dimensionalit\u00e0 dello spazio in output.</p>"},{"location":"material/06_tflow/29_gans/lecture/#usare-il-discriminatore-per-addestrare-il-generatore","title":"usare il discriminatore per addestrare il generatore","text":"<p>Per addestrare una rete neurale, atleriamo i pesi dellar ete per ridurre l'errore o la perdita del suo output. Nella nostra GAN, tuttavia, il generatore non \u00e8 direttamente connesso alla loss che stiamo provando ad influenzare. La loss del generatore penalizza il generatore per produrre unc ampione che la rete discriminativa classifica come falso.</p> <p>Questo pezzo extra di rete deve essere incluso nella backpropagation. La backpropagation modifica ogni peso nella direzione giusta calcolando l'impatto del peso sull'output - come l'output cambierebbe se cambiamo il peso. Ma l'impatto del peso di un generatore dipende dall'impatto dei pesi del discriminatore nel quale va ad inseririsi. Per cui la backpropagation inizia all'usicta e va indietro attraverso il discriminatore nel generatore.</p> <p>Allo stesso tempo, non vogliamo che il discrimiantore cambi durante l'addestramento del generatore. Provare a colpire un target in movimento renderebbe un problema duro ancora pi\u00f9 duro per il generatore.</p> <p>Per cui addestriamo il generatore ocn la seguente procedura:</p> <ol> <li>campioniamo rumore casuale</li> <li>produciamo l'output del generatore da rumore campionato casualmente</li> <li>otteneiamo delle classificazioni reali o false per l'output del generatore</li> <li>calcoliamo la loss dalla classificazione del discriminatore</li> <li>effettuiamo la backpropagation attraverso il discriminatore ed il generatore per ottenere i gradienti</li> <li>usiamo i gardienti per cambiare soltanto i pesi del generatore</li> </ol> <p>Questa \u00e8 un'iterazione del training del generatore. Nella prossima sezione vedremo come unire il training del generatore e del discrimiantore.</p>"},{"location":"material/06_tflow/29_gans/lecture/#gan-training","title":"GAN Training","text":"<p>Dato che una GAN contiene due reti addestrate separatamente, i suoi algoritmi di training devono risolvere due complicazioni:</p> <ul> <li>le GAN devono tenere in conto due diversi tipi di training (generatore e discriminatore)</li> <li>la convergenza della GAN \u00e8 difficile da identificare</li> </ul>"},{"location":"material/06_tflow/29_gans/lecture/#alternare-i-training","title":"Alternare i training","text":"<p>Il generatore ed il discrimanatore hanno diversi processi di training. Per cui come addestriamo la GAN?</p> <p>L'addestramento della GAN avviene a fasi alterne:</p> <ol> <li>il discriminatore si addestra per una o pi\u00f9 epoche</li> <li>il generaotre si addestra per una o pi\u00f9 epoche</li> <li>ripetiamo gli step 1 e 2 per continuare ad addestrare le reti di generazione e discriminazione</li> </ol> <p>Manteniamo il generatore costante durante la fase di disriminazione. Man manco che il training del discriminatore prova a capire come distinguere i dati reali da quelli falsi, deve apprendere a come riconsocere le \"colpe\" del generatore. Questo \u00e8 un problema differente per un genereatore addestrato piuttosto di uno non addestrato che produce output casuale.</p> <p>In modo simile, dobbiamo mantenere il discrimninatore costante durante la fase di training del generatore. Altrimenti il generatore prover\u00e0 a colpire un bersaglio in movimento, e potrebbe non convergere.</p> <p>E' questo andiriviene che permetete alle GAN di affrontare dei problemi altreimneit intrattabili. Possiamo entrare nel problema complesso di genrazione iniziando con un problema di classificazione molto pi\u00f9 semplice. Di converso, se non possiamo addestrare un classificatore a dire la differenza tra dati reali e generati anche per dati generati casualmente, non possiamo iniziare il training della GAN.</p>"},{"location":"material/06_tflow/29_gans/lecture/#convergenza","title":"convergenza","text":"<p>Man mano che il generatore migliora l'addestramento, le performance del discriminatore migliora perch\u00e9 il discrimnaotre non pu\u00f2 facilmente dire la differenza tra reale e falso. Se il generatore ha un successo \"perfetto\"; allora il discriminatreo ha un'accuracy del 50%. Nei fatti, il discriminatore lancia una moneta per fare la sua predizione.</p> <p>Questa progressione pone un problema per la convvergenza dell'intera GAN: il feedback del discriminaotre diventa meno sigificativo nel tempo. Se la GAN continua ad addestrarsioltre il punto dove il discriminaotre sta dando dei feedback completamente casuali, allora il generatore inizia ad addestrarsi su feedback non buoni, e la sua qualit\u00e0 pu\u00f2 collassare.</p> <p>Per una GAN, la convergenza \u00e8 spesso un valore \"mobile\", non stabile.</p>"},{"location":"material/06_tflow/29_gans/lecture/#loss-functions","title":"Loss functions","text":"<p>Le GAN provano a replicare una distribuzione di probabilit\u00e0. Dovrebber quindi usare una loss function che riflette la distanza tra la distribuzione dei dati generati dalla GAN e la distribzuione dei dati reali.</p> <p>Come catturare la differnezaa tra due distribuzioni nelle funzioni di costo della GAN? Questa question \u00e8 un'area di ricerca attiva, e molti approcci sono stati proposti. Vedremo due funzioni di costo comuni per le GAN, entrambe le quali sono implementate in TF-GAN:</p> <ul> <li>minimax loss: la funzione di costo usata nel paper che ha introdotto le GAN (https://arxiv.org/abs/1406.2661)</li> <li>loss di Wasserstein: la funzione di costo di defautl per TF-GAN descritta in un paper del 2017 (https://arxiv.org/abs/1701.07875)</li> </ul> <p>TF-GAN implementa molte altre funzioni di costo.</p>"},{"location":"material/06_tflow/29_gans/lecture/#una-o-due-funzioni-di-costo","title":"UNa o due funzioni di costo?","text":"<p>Una GAN pu\u00f2 avere due funzioni di costo: una per l'addestramento del generator ed uno per il training del discriminator. Come possono le due funzioni di costo lavorare insieme per riflettere una misura di distanza tra distribuzioni di probabilit\u00e0?</p> <p>Nello schema delle loss che vedremo qui, le loss del generator e del descriminator derivano da una singola misura didistanza tra le distribuzioni di probabilit\u00e0. In entrambi questi schemi, comunque, il generator pu\u00f2 influenzare un solo termine nella misura di distanza: il termine che riflette la distribuzione dei dati falsi. Per cui durante il training  del generator lasciamo l'altro termine, che rfilette la distribuzione dei dati reali.</p> <p>Le loss del generator e del discriminator appaiono differenti alla fine, anche se derivano da una singola formula.</p>"},{"location":"material/06_tflow/29_gans/lecture/#minimax-loss","title":"Minimax loss","text":"<p>Nel paper che ha introdtto il GAN, il generatore prova a minimizzare la seguente funzione, mentre il discriminatore prova a massimizzarla:</p> \\[ E_x \\[log(D(x))\\] + E_z [log(1-D(G(z)))] \\] <p>In questa funzione:</p> <ul> <li>\\(D(x)\\) \u00e8 la stima del discriminatore sulla probabilit\u00e0 che l'istanza dei dati reali \\(x\\) sia vera.</li> <li>\\(E_x\\) \u00e8 il valore atteso di tutte le istanze dei dati reali.</li> <li>\\(G(z)\\) \u00e8 l'output del generatore ad un dato rumore \\(z\\).</li> <li>\\(D(G(z))\\) \u00e8 la stima del discriminatore della probabilit\u00e0 che un'istanza falsa sia reale.</li> <li>\\(E_z\\) \u00e8 il valore atteso su tutti gli input casuali del generatore (in effetti, i vaore atteso di tutte le istanze fake generate \\(G(z)\\)).</li> <li>La formula deriva dalla cross-entropia tra le distribuzioni reali e generate.</li> </ul> <p>Il generatore non pu\u00f2 direttamente influenzare ilt ermine \\(log(D(x))\\) nella funzione, per cui, per il genratore, minimizzare la loss \u00e8 equivalente a minimizzare \\(log(1 - D(G(z)))\\).</p>"},{"location":"material/06_tflow/29_gans/lecture/#modified-minimax-loss","title":"Modified Minimax Loss","text":"<p>Il paper originale del GAN nota che la funzione di costo precedente pu\u00f2 far s\u00ec che le GAN rimangano ferme nei primi stage dell'addestramento, qunado il compito del discirminatore \u00e8 molto semplice. Il paper quindi suggerisce di modificare la loss del generatore in modo che questi provi a massimizzare \\(log(D(G(z)))\\).</p>"},{"location":"material/06_tflow/29_gans/lecture/#wasserstein-loss","title":"Wasserstein Loss","text":"<p>Di default, TF-GAN usa la loss di Wasserstein.</p> <p>Questa funzione di costo dipende da una modifca dello schema della GAN (chiamato \"Wasserstein GAN\" o \"WGAN\") nel quale il discriminatore non classifca in effett delle istanze. Per ogni istanza d\u00e0 invece un numero. Questo numero non deve essere inferiore ad 1 o pi\u00f9 grande di ', per cui non possiamo usare 0.5 come soglia per decidere se un'istanza \u00e8 vera o falsa. Il training del discriminator prova a rendere l'output pi\u00f9 grande per istanze reali che per istanze fake.</p> <p>Siccome non pu\u00f2 realmente discriminare tra real e fake, il discriminatore WGAn \u00e8 in effetti chiamato \"critica\" invece di \"discriminatore\". Questa distinzione ha importanza teorica, ma per gli scopi pratici possiamo trattarlo come un acknowledgement che gli input alla funzione di costo non devono essere delle probabilit\u00e0.</p> <p>La funzione di costo stessa \u00e8 molto semplice:</p> <p>Critic Loss: \\(D(x) - D(G(z))\\)</p> <p>Il discrimnatore prova a massimizzare questa funzione. In altre parole, prova a massimizzare la differenza tra i suoi output su istanze reale ed il suo output su istanze false.</p> <p>Generator Loss: \\(D(G(z))\\)</p> <p>Il generatore prova a massimizzare questa funzione. In altre parole, prova a massimizzare l'output del discrimnatroe per le sue istanze false.</p> <p>In queste funzioni:</p> <ul> <li>\\(D(x)\\) sono l'output della critica per una istanza vera.</li> <li>\\(G(z)\\) \u00e8 l'output del generatore quando c'\u00e8 un dato rumore \\(z\\).</li> <li>\\(D(G(z))\\) \u00e8 l'output della critica per un'istanza fake.</li> <li>L'output della critica \\(D\\) deve NON essere tra 1 e 0.</li> <li>Le formule derivano dalla earth mover distance tra le distribuzioni reali e generate.</li> </ul>"},{"location":"material/06_tflow/29_gans/lecture/#requisiti","title":"Requisiti","text":"<p>La giustificazione teorica per la WGAN richiede che i pesi attraverso la GAN possano essere tagliati in modo che rimangano all'interno di un range vincolato.</p>"},{"location":"material/06_tflow/29_gans/lecture/#benefit","title":"Benefit","text":"<p>Le WGAN sono meno vulnerabili a rimanere ferme piuttosto che le GAN minimax-based, ed evitare problemi con i vanisghin gradients. L'earth mover distance ha anche il vantaggio di essere una vera metrica: una misura di distanza in uno spazio di distribuzioni di probabilit\u00e0. La cross-entropy non \u00e8 in tal senso una metrica.</p> <p>Earth Mover Distance: https://en.wikipedia.org/wiki/Earth_mover's_distance</p>"},{"location":"material/06_tflow/29_gans/lecture/#problemi-comuni","title":"Problemi comuni","text":"<p>Le GAN hanno un certo numero di fallimenti comuni. Tutti questi problemi comuni sono aree di ricerca attiva. Mentre nessuno di questi problemi \u00e8 stato completamente risolto, vedremo alcune cose che le persone hanno gi\u00e0 provato.</p>"},{"location":"material/06_tflow/29_gans/lecture/#vanishing-gradients","title":"Vanishing Gradients","text":"<p>La ricerca (https://arxiv.org/pdf/1701.04862.pdf) ha suggerito che se il discriminatore \u00e8 troppo bbuono, allora il training del generatore pu\u00f2 fallire a causa del vanishing gradients (https://wikipedia.org/wiki/Vanishing_gradient_problem). In effetti, un discriminatore ottimale non fornisce abbastanza informazioni per far fare progressi al generatore.</p>"},{"location":"material/06_tflow/29_gans/lecture/#prove-a-rimediare","title":"Prove a rimediare","text":"<ul> <li>Wasserstein loss: la Wasserstein loss \u00e8 progettata per prvenire i vanishing gradients anche quando addestriamo il discriminatore all'ottimalit\u00e0.</li> <li>Modified minimax loss: il paper originalke propone una modifica alla minimax loss per affrontare i vanishign gradients.</li> </ul>"},{"location":"material/06_tflow/29_gans/lecture/#mode-collapse","title":"MOde Collapse","text":"<p>Normalmente vogliamo che il GAN produca un'ampia variet\u00e0 di output. Vogliamo, ad esempio, un diverso volto per ogni input al nostro generatore di volti.</p> <p>Tuttavia, se un generatore prduce un outptu specialmente plausibile, il generatore pu\u00f2 apprendere a produrre solo quell'output. Infatti, il generatore sta sempre provando a trovare l'output che sembra essere pi\u00f9 plausibile al discriminatore.</p> <p>Se il generaotre inizia a produrre lo stesso output (o un piccolo insieme di output) ancora ed ancora, la miglior strategia del discriminatore \u00e8 apprendere a respingere sempre quell'output. Ma se la prossiam generazione del discriminatore rimane fermo in un minimo locale e non trova la miglior starategia, allora \u00e8 pi\u00f9 facile per l'iterazione successiva del generatore per trovare l'output pi\u00f9 plausibile per il discriminatore attuale.</p> <p>Ogni iterazione del generatore sovra-ottimizza per un certo discriminatore, ed il dsicrimiantore non riesce mai ad apprendere il suo percorso al di fuori della trappola. Come risultato il generatore ruota attraverso un piccolo insieme di tipi di output. Questa forma di fallimento del GAN \u00e8 chiamato mode collapse.</p>"},{"location":"material/06_tflow/29_gans/lecture/#tentativi-di-rimediare","title":"Tentativi di rimediare","text":"<p>I seguenti approcci provano a forzare il generatore ad ampliare il suo ambito prevenendo l'ottimizzazione di un singoli discriminatore prefissato:</p> <ul> <li>Wasserstein loss: la Wasserstein loss allevia il mode collapse permettendoci di trainare il discriminatore all'ottimalit\u00e0 senza preoccuparsi dei vanishing gradients. Se il discriminator non si ferma in un minimo locale, apprende a respingere gli outptu su cui si stabilizza il generatore. Per cui il generatore deve imparare qualcosa di nuovo.</li> <li>Unrolled GANs: le unrolled GANs (https://arxiv.org/pdf/1611.02163.pdf) usano una funzione di costo per il generatore che icnorpora non solo l'attuale classificazione del discrimiantor, ma anche l'output delle versioni future del discriminaotre. Per cui il genratore non pu\u00f2 sovraottimizzarsi su un singolo discriminator.</li> </ul>"},{"location":"material/06_tflow/29_gans/lecture/#mancata-convergenza","title":"Mancata convergenza","text":"<p>Le GAN spesso onon convergono.</p>"},{"location":"material/06_tflow/29_gans/lecture/#prove-a-rimediare_1","title":"PRove a rimediare","text":"<p>I ricercatori hanno provato ad usare varie forme di regolarizzazione per migliroare la convergenza delle GAN, inclusi:</p> <ul> <li>aggiungere rumore agli input del discriminator (https://arxiv.org/pdf/1701.04862.pdf)</li> <li>penalizzare i pesi dei discriminatori (https://arxiv.org/pdf/1705.09367.pdf)</li> </ul>"},{"location":"material/06_tflow/29_gans/lecture/#variazioni-tra-gan","title":"Variazioni tra GAN","text":"<p>I ricercatori continuano a trovare delle tecniche GAN migliroate e nuovi usi per le GAN. Ecco un esempio di alcune delle variazioni per darci un'idea delle possibilit\u00e0.</p>"},{"location":"material/06_tflow/29_gans/lecture/#progressive-gans","title":"Progressive GANs","text":"<p>In una progressive GAN, i primi layer del genrator producono immagini a risoluzione molto bassa, ed i conseguenti layer aggiungono dei dettagli. Questa tec ica permette alle GAN per addestrare pi\u00f9 velocemente rispetto alle GAN non progressive, e produce delle immagini a risoluzione pi\u00f9 alte. https://arxiv.org/abs/1710.10196</p>"},{"location":"material/06_tflow/29_gans/lecture/#conditional-gans","title":"Conditional GANs","text":"<p>Le GAN condizionali addestrate su und ataset etichettato e ci permette di specificare le label per ogni istanza generata. Per esempio, una MNIST GAN non condizionale produrrebbe cifre casuali, mentre una MNIST GAN condizionale ci permetterebbe di specificare quale cifra la GAN deve generare.</p> <p>Invece di modellare la probabilit\u00e0 confiunta \\(P(X,Y)\\) la GAN condizionale modella la probabilit\u00e0 condizionale \\(P(X|Y)\\). https://arxiv.org/abs/1411.1784</p>"},{"location":"material/06_tflow/29_gans/lecture/#image-to-image-translation","title":"Image-to-Image Translation","text":"<p>Le GAN che si occupano di Image-to-Image translation prendono un'immagine in input e la mappano ad un'immagine generata in output con propriet\u00e0 difefrenti. Ad esempio, possiamo prendere una maschera con dei blob di colore nella forma di un'auto, e la GAN pu\u00f2 riempire la forma con dei dettagli fotorealistici di un'auto.</p> <p>In modo simile, possiamo addestrare una GAN image-to-image a prendere degli schizzi di bagagli e tradurli in immagini fotorealistiche di bagagli.</p> <p>In questi casi, la loss \u00e8 una combinazione pesata della solita loss basata sul discriminatore e di una loss pixel-wise che penalizza il generatore per discorstarsi dall'immagine sorgente.</p> <p>Isola et al 2016</p>"},{"location":"material/06_tflow/29_gans/lecture/#cyclegan","title":"CycleGAn","text":"<p>La CycleGAN apprende a trasformare immagini da un insieme in immagini che possono plausibilmente appartenere ad un altro insieme.</p> <p>I dati di addestramento per una CycleGAN sono semplicemente due insiemi di immagini. Il sistema non richiede alcuna label o corrispondenze a coppie tra immagini. Zhu et al., 2017</p>"},{"location":"material/06_tflow/29_gans/lecture/#text-to_image-synthesis","title":"Text-to_image Synthesis","text":"<p>Le Text-to_image GAN prendono il testo come input e producono delle immagini che sono plausibili e descritte dal testo. Zhang et al, 2016.</p>"},{"location":"material/06_tflow/29_gans/lecture/#super-resolution","title":"Super-resolution","text":"<p>Le super-resolution GAN aumentano la risoluzione delle immagini, aggiungendo dettagli dove necessario per riempire le aree sfocate. Ledig et al, 2017.</p>"},{"location":"material/06_tflow/29_gans/lecture/#face-inpainting","title":"Face Inpainting","text":"<p>Le GAN sono usate per il task di image inpainitng semantico, nel quale parti delle immagini sono oscurate, ed il sistema prova a riempire le parti mancanti. Yeh et al, 2017</p>"},{"location":"material/06_tflow/29_gans/lecture/#text-to-speech","title":"Text-to-Speech","text":"<p>Non tutte le GAN producono immagini. Ad esempio, alcuni ricercatori hanno anche usato delle GAN per produrre parlato sintetizzato dall'input testuale. Yang et al., 2017</p>"},{"location":"material/06_tflow/29_gans/lecture/#conclusioni","title":"Conclusioni","text":"<p>Dovremmo essere in grado di:</p> <ul> <li>comprendere la differenza tra modelli generativi e discriminativi</li> <li>identificare i problemi che le GAN possono risolvere</li> <li>comprendere il ruolo del generatore e del discriminaotre in una GAN</li> <li>comprendere i vantaggi e svantaggi delle funzioni di costo in comune delle GAN</li> <li>identificare psosibili soluzioni a problemi comuni con l'addestamento delle GAN</li> <li>usare la libreria TF GAN per creare una GAN</li> </ul>"},{"location":"material/appendix/01_python_vs_code/lecture/","title":"Appendice A - Configurazione dell'ambiente di sviluppo Python","text":"<p>Versione video</p> <p>Una versione video di questa procedura di installazione \u00e8 in arrivo.</p>"},{"location":"material/appendix/01_python_vs_code/lecture/#installazione-di-python","title":"Installazione di Python","text":"<ol> <li>Andare al seguente indirizzo, e selezionare la versione adatta al proprio sistema operativo.</li> <li>Iniziare la procedura di installazione (ad esempio, in Windows, cliccando sull'eseguibile appena scaricato). E' fortemente consigliato aggiungere Python al proprio PATH spuntando l'opportuna casella durante l'installazione, come mostrato in figura 1.</li> </ol> Figura 1 - Aggiunta di Python al PATH <ol> <li>Una volta completata la procedura di installazione, aprire uno shell (ad esempio, il prompt dei comandi), e digitare <code>python</code>. Se tutto \u00e8 andato per il verso giusto, apparir\u00e0 una schermata simile a quella mostrata in figura 2.</li> </ol> Figura 2 - Interprete Python"},{"location":"material/appendix/01_python_vs_code/lecture/#installazione-di-visual-studio-code","title":"Installazione di Visual Studio Code","text":"<ol> <li>Andare al seguente indirizzo, e selezionare la versione adatta al proprio sistema operativo.</li> <li>Seguire la procedura di installazione mostrata a schermo. E' anche in questo caso consigliata l'aggiunta di Visual Studio Code al path, come mostrato in figura 3.</li> </ol> Figura 3 - Installazione di Visual Studio Code"},{"location":"material/appendix/02_setup_tflow/lecture/","title":"Appendice B - Setup di TensorFlow","text":"<p>Versione video</p> <p>Una versione video di questa procedura di installazione \u00e8 in arrivo.</p> <p>In questa sezione, vedremo come effettuare il setup di TensorFlow su tre diversi sistemi operativi, ovvero Windows, Linux e MacOS.</p> <p>TensorFlow e Windows</p> <p>A partire dalla versione 2.11, TensorFlow non \u00e8 pi\u00f9 supportato su Windows. Di conseguenza, \u00e8 necessario seguire una procedura differente, dettagliata in questa guida.</p> Windows WSL2LinuxmacOS"},{"location":"material/appendix/02_setup_tflow/lecture/#1-requisiti-di-sistema","title":"1. Requisiti di sistema","text":"<p>I requisiti necessari sono:</p> <ul> <li>Windows 10 aggiornato almeno alla versione 21H2;</li> <li>Windows Subsystem on Linux (WSL2), reperibile da qui.</li> </ul>"},{"location":"material/appendix/02_setup_tflow/lecture/#2-opzionale-setup-della-gpu-nvidia-in-wsl","title":"2. (Opzionale) Setup della GPU NVIDIA in WSL","text":"<p>Qualora si disponga di una GPU NVIDIA, si potr\u00e0 effettuare il setup della stessa su WSL2. </p> <p>Supponendo di aver installato Ubuntu sul WSL2, dovremo per prima cosa entrare nel sottosistema Linux scrivendo da terminale l'istruzione:</p> <pre><code>wsl\n</code></pre> <p>Una volta dentro, dovremo eseguire le seguenti istruzioni da riga di comando:</p> <pre><code>sudo apt-key del 7fa2af80\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.0.0/local_installers/cuda-repo-wsl-ubuntu-12-0-local_12.0.0-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-0-local_12.0.0-1_amd64.deb\nsudo cp /var/cuda-repo-wsl-ubuntu-12-0-local/cuda-*-keyring.gpg /usr/share/keyrings/\nsudo apt-get update\nsudo apt-get -y install cuda\n</code></pre> <p>Per maggior informazioni, potete consultare la guida completa disponibile a questo indirizzo.</p>"},{"location":"material/appendix/02_setup_tflow/lecture/#3-installazione-di-miniconda","title":"3. Installazione di Miniconda","text":"<p>A partire dalla versione 2.11, il metodo raccomandato per l'utilizzo di TensorFlow \u00e8 quello di utilizzare Miniconda, creando un ambiente virtuale separato all'interno del quale andare ad installare tutte le dipendenze necessarie.</p> <p>Da terminale, scriviamo:</p> <pre><code>curl https://repo.anaconda.com/miniconda Miniconda3-latest-Linux-x86_64.sh -o Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n</code></pre> <p>Durante l'installazione, rispondiamo sempre <code>yes</code> alle domande che ci verranno fatte, premendo successivamente <code>Invio</code>.</p>"},{"location":"material/appendix/02_setup_tflow/lecture/#4-creazione-di-un-ambiente-virtuale","title":"4. Creazione di un ambiente virtuale","text":"<p>Una volta terminata l'installazione, riavviamo il sottosistema Linux (per farlo, scriviamo <code>exit</code> e, una volta usciti, <code>wsl</code>). A questo punto potremo creare un nuovo ambiente virtuale basato su Python 3.9 che chiameremo <code>pcs</code>:</p> <pre><code>conda create --name pcs python=3.9\n</code></pre> <p>Possiamo quindi attivare questo ambiente virtuale scrivendo:</p> <pre><code>conda deactivate\nconda activate pcs\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#5-opzionale-setup-della-gpu","title":"5. (Opzionale) Setup della GPU","text":"<p>Questo step ci permette di configurare ed utilizzare la GPU nell'ambiente virtuale del nostro sistema Linux. Per prima cosa, verifichiamo che i driver siano installati usando la seguente istruzione:</p> <pre><code>nvidia-smi\n</code></pre> <p>Qualora non siano installati, occorrer\u00e0 farlo prelevandoli dal sito ufficiale.</p> <p>Configuriamo il PATH del sistema:</p> <pre><code>mkdir -p $CONDA_PREFIX/etc/conda/activate.d\necho 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/' &gt; $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#6-installazione-di-tensorflow","title":"6. Installazione di TensorFlow","text":"<p>Installiamo TensorFlow usando un package manager a nostra scelta (ad esempio, <code>pip</code>):</p> <pre><code>pip install tensorflow\n</code></pre> <p>Verifichiamo l'installazione per la CPU:</p> <pre><code>python3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n</code></pre> <p>e per la GPU:</p> <pre><code>python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#1-requisiti-di-sistema_1","title":"1. Requisiti di sistema","text":"<p>I requisiti necessari sono:</p> <ul> <li>Ubuntu aggiornato almeno alla versione 16.04.</li> </ul>"},{"location":"material/appendix/02_setup_tflow/lecture/#2-installazione-di-miniconda","title":"2. Installazione di Miniconda","text":"<p>A partire dalla versione 2.11, il metodo raccomandato per l'utilizzo di TensorFlow \u00e8 quello di utilizzare Miniconda, creando un ambiente virtuale separato all'interno del quale andare ad installare tutte le dipendenze necessarie.</p> <p>Da terminale, scriviamo:</p> <pre><code>curl https://repo.anaconda.com/miniconda Miniconda3-latest-Linux-x86_64.sh -o Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n</code></pre> <p>Durante l'installazione, rispondiamo sempre <code>yes</code> alle domande che ci verranno fatte, premendo successivamente <code>Invio</code>.</p>"},{"location":"material/appendix/02_setup_tflow/lecture/#3-creazione-di-un-ambiente-virtuale","title":"3. Creazione di un ambiente virtuale","text":"<p>Una volta terminata l'installazione, riavviamo il sottosistema Linux (per farlo, scriviamo <code>exit</code> e, una volta usciti, <code>wsl</code>). A questo punto potremo creare un nuovo ambiente virtuale basato su Python 3.9 che chiameremo <code>pcs</code>:</p> <pre><code>conda create --name pcs python=3.9\n</code></pre> <p>Possiamo quindi attivare questo ambiente virtuale scrivendo:</p> <pre><code>conda deactivate\nconda activate pcs\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#4-opzionale-setup-della-gpu","title":"4. (Opzionale) Setup della GPU","text":"<p>Questo step ci permette di configurare ed utilizzare la GPU nell'ambiente virtuale del nostro sistema Linux. Per prima cosa, verifichiamo che i driver siano installati usando la seguente istruzione:</p> <pre><code>nvidia-smi\n</code></pre> <p>Qualora non siano installati, occorrer\u00e0 farlo prelevandoli dal sito ufficiale.</p> <p>Configuriamo il PATH del sistema:</p> <pre><code>mkdir -p $CONDA_PREFIX/etc/conda/activate.d\necho 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/' &gt; $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#5-installazione-di-tensorflow","title":"5. Installazione di TensorFlow","text":"<p>Installiamo TensorFlow usando un package manager a nostra scelta (ad esempio, <code>pip</code>):</p> <pre><code>pip install tensorflow\n</code></pre> <p>Verifichiamo l'installazione per la CPU:</p> <pre><code>python3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n</code></pre> <p>e per la GPU:</p> <pre><code>python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#errori-in-ubuntu-2204","title":"Errori in Ubuntu 22.04","text":"<p>Nel caso si utilizzi la versione 22.04 di Ubuntu, potremmo trovarci di fronte al seguente errore:</p> <pre><code>Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice.\n...\nCouldn't invoke ptxas --version\n...\nInternalError: libdevice not found at ./libdevice.10.bc [Op:__some_op]\n</code></pre> <p>Per risolverlo, eseguiamo le seguenti istruzioni:</p> <pre><code>conda install -c nvidia cuda-nvcc=11.3.58\nmkdir -p $CONDA_PREFIX/etc/conda/activate.d\nprintf 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\\nexport XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX/lib/\\n' &gt; $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\nsource $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\nmkdir -p $CONDA_PREFIX/lib/nvvm/libdevice\ncp $CONDA_PREFIX/lib/libdevice.10.bc $CONDA_PREFIX/lib/nvvm/libdevice/\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#1-requisiti-di-sistema_2","title":"1. Requisiti di sistema","text":"<p>I requisiti necessari sono:</p> <ul> <li>macOS aggiornato almeno alla versione 10.12.6 (Sierra).</li> </ul>"},{"location":"material/appendix/02_setup_tflow/lecture/#2-verifica-della-versione-di-python-installata","title":"2. Verifica della versione di Python installata","text":"<p>Verifichiamo che sia installato Python dalla versione 3.7 alla 3.10:</p> <pre><code>python3 --version\n</code></pre> <p>e pip nella versione superiore alla 20.3:</p> <pre><code>python3 -m pip --version\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#2-installazione-di-miniconda_1","title":"2. Installazione di Miniconda","text":"<p>A partire dalla versione 2.11, il metodo raccomandato per l'utilizzo di TensorFlow \u00e8 quello di utilizzare Miniconda, creando un ambiente virtuale separato all'interno del quale andare ad installare tutte le dipendenze necessarie.</p> <p>Da terminale, scriviamo:</p> <pre><code>curl https://repo.anaconda.com/miniconda Miniconda3-latest-Linux-x86_64.sh -o Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n</code></pre> <p>Durante l'installazione, rispondiamo sempre <code>yes</code> alle domande che ci verranno fatte, premendo successivamente <code>Invio</code>.</p>"},{"location":"material/appendix/02_setup_tflow/lecture/#3-creazione-di-un-ambiente-virtuale_1","title":"3. Creazione di un ambiente virtuale","text":"<p>Una volta terminata l'installazione, riavviamo il sottosistema Linux (per farlo, scriviamo <code>exit</code> e, una volta usciti, <code>wsl</code>). A questo punto potremo creare un nuovo ambiente virtuale basato su Python 3.9 che chiameremo <code>pcs</code>:</p> <pre><code>conda create --name pcs python=3.9\n</code></pre> <p>Possiamo quindi attivare questo ambiente virtuale scrivendo:</p> <pre><code>conda deactivate\nconda activate pcs\n</code></pre>"},{"location":"material/appendix/02_setup_tflow/lecture/#4-installazione-di-tensorflow","title":"4. Installazione di TensorFlow","text":"<p>Installiamo TensorFlow usando un package manager a nostra scelta (ad esempio, <code>pip</code>):</p> <pre><code>pip install tensorflow\n</code></pre> <p>Verifichiamo l'installazione:</p> <pre><code>python3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n</code></pre>"},{"location":"material/appendix/03_libraries/lecture/","title":"Appendice B: Setup dell'ambiente di lavoro","text":"<p>Per effettuare il setup dell'ambiente di lavoro avremo a disposizione diverse opzioni. Vediamole nel dettaglio, immaginando di voler installare la libreria NumPy.</p>"},{"location":"material/appendix/03_libraries/lecture/#opzione-a-utilizzare-pip","title":"Opzione A: utilizzare <code>pip</code>","text":"<p>La prima opzione, e probabilmente quella maggiormente utilizzata, \u00e8 utilizzare il package manager (ovvero, il gestore di pacchetti) integrato in Python, chiamato <code>pip</code>.</p> <p>Per farlo, apriamo un terminale assicurandoci di avere i diritti di amministratore; in Linux, dovremo usare l'istruzione <code>sudo</code>, a meno che non siamo utenti rott, mentre in Windows ci baster\u00e0 aprire la shell come amministratori. Una volta aperto il terminale, dovremo scrivere:</p> <pre><code>pip install numpy\n</code></pre> <p>Installare una libreria in questo modo \u00e8 sicuramente molto semplice, ma porta con s\u00e8 uno svantaggio: infatti, l'installazione della stessa avviene globalmente, ovvero risulta essere valida per l'intera macchina.</p> <p>Ci\u00f2 potrebbe non sembrare rilevante; tuttavia, in ben determinate situazioni, si pu\u00f2 rendere necessario installare particolari combinazioni di versioni di librerie, per usufruire di funzionalit\u00e0 successivamente deprecate o, al contrario, non presenti in versioni antecedenti. In tal senso, se installiamo una certa libreria globalmente, tutti i nostri programmi dovranno necessariamente utilizzare quella libreria in quella specifica versione, il che ci pu\u00f2 vincolare fortemente a lungo andare.</p>"},{"location":"material/appendix/03_libraries/lecture/#opzione-b-utilizzare-pip-ed-un-ambiente-virtuale","title":"Opzione B: utilizzare <code>pip</code> ed un ambiente virtuale","text":"<p>Un'altra opzione \u00e8 quella di utilizzare <code>pip</code> in un opportuno ambiente virtuale.</p> <p>Quest'ultimo altro non \u00e8 se non un ambiente \"separato\" all'interno del nostro calcolatore, nel quale andremo ad inserire tutte le librerie che utilizzeremo per i progetti da inserire all'interno dell'ambiente (con le versioni specifiche).</p> <p>Per utilizzare questa opzione, dovremo innanzitutto creare un ambiente virtuale. Per farlo, dobbiamo usare un'opportuna libreria Python, che dovremo installare globalmente mediante <code>pip</code>.</p> <p>Nota</p> <p>L'installazione globale delle librerie per la gestione dell'ambiente virtuale \u00e8 strettamente necessaria, e non contraddice il principio descritto nelle righe precedenti: infatti, l'idea \u00e8 che si possa creare un ambiente virtuale in qualsiasi momento.</p> <p>Installiamo quindi la libreria virtualenvwrapper, o l'equivalente porting per Windows virtualenvwrapper-win:</p> <p>===\"Linux\" <pre><code>pip install virtualenvwrapper\n</code></pre> ===\"Windows\" <pre><code>pip install virtualenvwrapper-win\n</code></pre></p> <p>Una volta completata l'installazione, utilizzeremo il comando <code>mkvirtualenv</code>, seguito da un nome a nostra scelta, per creare l'ambiente virtuale. Ad esempio:</p> <pre><code>mkvirtualenv pcs\n</code></pre> <p>Noteremo che, a sinistra del terminale, sar\u00e0 apparsa la scritta <code>(pcs)</code>:</p> <pre><code>(pcs) current_working_directory/\n</code></pre> <p>Questo ci indica che siamo all'interno del nostro ambiente virtuale. Procediamo adesso all'installazione della libreria NumPy mediante <code>pip</code>:</p> <pre><code>(pcs) current_working_directory/ pip install numpy\n</code></pre> <p>In questo modo, avremo installato NumPy esclusivamente all'interno del nostro ambiente virtuale. Per verificarlo, basta eseguire l'istruzione <code>pip freeze</code>, che restituisce tutte le librerie presenti nell'ambiente in cui siamo attualmente, assieme alle loro versioni.</p> <p>Il file <code>requirements.txt</code></p> <p>Pratica comune \u00e8 quella di memorizzare tutte le librerie presenti in un ambiente virtuale in un file chiamato <code>requirements.txt</code>. Cos\u00ec facendo, un altro programmatore sar\u00e0 in grado di \"clonare\" il nostro ambiente virtuale. Per salvare il file <code>requirements.txt</code>, dovremo usare i seguenti comandi:</p> <p><pre><code>pip freeze &gt; requirements.txt\n</code></pre> Per creare un ambiente virtuale come descritto dal file dei requisiti, invece, dovremo eseguire: <pre><code>pip install -r requirements.txt\n</code></pre> dove il flag <code>-r</code> sta per recursively, ed indica a <code>pip</code> di installare in maniera ricorsiva le librerie indicate nel file <code>requirements.txt</code>.</p>"},{"location":"material/appendix/03_libraries/lecture/#opzione-c-utilizzare-una-distribuzione-di-python-per-il-calcolo-scientifico","title":"Opzione C: utilizzare una distribuzione di Python per il calcolo scientifico","text":"<p>La terza opzione \u00e8 quella di utilizzare una distribuzione di Python specificamente pensata per il calcolo scientifico, come Anaconda. In questo caso, baster\u00e0 scaricare l'installer dal sito ufficiale e seguire la normale procedura di installazione.</p> <p>Il vantaggio di utilizzare una distribuzione di questo tipo sta nel fatto che avremo a disposizione di default la maggior parte delle librerie utilizzate nel calcolo scientifico. Tuttavia, occorre tenere in considerazione il fatto che la libreria \u00e8 specificamente pensata soltanto per scopi scientifici, per cui dovremo considerarlo qualora intendessimo utilizzare Python per progetti di altro tipo.</p> <p>Il package manager di Anaconda</p> <p>Nel caso si decida di optare per l'uso di Anaconda, \u00e8 importante ricordare che questa distribuzione ha un suo package manager, chiamato <code>conda</code>. Questo andr\u00e0 a sostituire <code>pip</code> nell'installazione delle librerie non presenti nella distribuzione.</p>"},{"location":"material/appendix/03_libraries/lecture/#opzione-d-utilizzare-un-package-manager-come-pipenv","title":"Opzione D: utilizzare un package manager come <code>pipenv</code>","text":"<p>L'ultima opzione, che \u00e8 anche quella suggerita in caso di utilizzo professionale ed eterogeneo di Python, \u00e8 quella di affidarsi ad un package manager evoluto, come <code>pipenv</code>.</p> <p>Questo package manager, infatti, automatizza e semplifica la creazione di un ambiente virtuale, combinando la stessa con l'utilizzo di <code>pip</code> in pochi, semplici comandi; in generale, quindi, il tool ci fornisce un'interfaccia utente molto pi\u00f9 snella, ed inoltre si occupa autonomamente di selezionare le ultime versioni disponibili per i package che utilizziamo.</p> <p>Per utillizzare <code>pipenv</code>, dovremo per prima cosa installarlo globalmente sulla nostra macchina mediante <code>pip</code>:</p> <pre><code>pip install pipenv\n</code></pre> <p>Una volta installato, andiamo nella cartella dove vogliamo creare il nostro progetto, che ricordiamo includer\u00e0 soltanto la libreria NumPy, e scriviamo:</p> <pre><code>pipenv install numpy\n</code></pre> <p>Vedremo che, al termine della procedura, saranno stati generati due file: il primo, chiamato <code>Pipfile</code>, avr\u00e0 al suo interno tutte le dipendenze che abbiamo aggiunto al nostro progetto, mentre il secondo, <code>Pipfile.lock</code>, conterr\u00e0 delle informazioni dettagliate sulle librerie usate, incluse versioni, repository, e via discorrendo.</p> <p>Tuttavia, <code>pipenv</code> non si limita a creare questi due file, ma provvede anche a definire, in maniera automatica, un nuovo ambiente virtuale, all'interno del quale saranno (ovviamente) memorizzate tutte le librerie installate per il nostro progetto. Per accedere all'ambiente virtuale, dovremo usare il comando <code>pipenv shell</code>, mentre per eseguire un comando senza accedere all'ambiente virtuale dovremo usare il comando <code>pipenv run</code> seguito dal comando che vogliamo eseguire.</p> <p>Ad esempio, se volessimo lanciare un ipotetico script <code>run.py</code> accedendo all'ambiente virtuale, dovremmo scrivere:</p> <pre><code>pipenv shell\npython run.py\n</code></pre> <p>Se non volessimo accedere all'ambiente virtuale, invece, dovremmo scrivere:</p> <pre><code>pipenv run python run.py\n</code></pre>"},{"location":"material/appendix/03_libraries/lecture/#bonus-opzione-utilizzata-nel-corso","title":"Bonus: opzione utilizzata nel corso","text":"<p>Nel corso, utilizzeremo l'approccio basato su Miniconda e <code>pip</code>, che \u00e8, ad oggi, quello suggerito per l'installazione di TensorFlow.</p> <p>Vediamo come impostare l'ambiente di sviluppo a seconda che si stia utilizzando Linux o Windows.</p> WindowsLinux <pre><code>curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -o Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n</code></pre>"},{"location":"material/appendix/03_libraries/lecture/#1-requisiti-di-sistema","title":"1. Requisiti di sistema","text":""},{"location":"material/appendix/04_scope/lecture/","title":"Appendice C - Ambito di una variabile","text":"<p>All'interno di un programma ogni variabile ha una sorta di \"ciclo di vita\", che ne prevede la creazione, utilizzo e, infine, distruzione.</p> <p>L'intero script ha un ambito definito come globale: ci\u00f2 significa che tutte le variabili specificate nel corpo \"principale\" dello script hanno validit\u00e0 in tutto il nostro codice. Le singole funzioni, invece, definiscono un ambito locale, creato alla chiamata della funzione, e distrutto al termine della stessa.</p> <p>Facciamo un esempio. Definiamo una funzione <code>calcolo_voto_accesso_laurea</code> che accetta in ingresso un argomento, ovvero la lista con i voti degli esami.</p> <pre><code>def calcolo_voto_accesso_laurea(voti_esami):\nsomma_voti = 0\nfor voto in voti_esami:\nsomma_voti += voto\nvoto_medio = somma_voti/len(voti_esami)\nvoto_accesso = voto_medio / 3 * 11\nreturn voto_accesso\n</code></pre> <p>Proviamo a chiamarla.</p> <pre><code>lista_voti = [18, 20, 19, 30, 24, 30]\nprint('Il voto di accesso \u00e8: ', calcolo_voto_accesso_laurea(lista_voti))\n</code></pre> <p>A schermo vedremo:</p> <pre><code>Il voto di accesso \u00e8:  86.16666666666666\n</code></pre>"},{"location":"material/appendix/04_scope/lecture/#c1-prima-modifica","title":"C1 - Prima modifica","text":"<p>Facciamo una prima modifica:</p> <pre><code>lista_voti = [18, 20, 19, 30, 24, 30]\ndef calcolo_voto_accesso_laurea(voti_esami):\nprint(f'La lista dei voti \u00e8: {lista_voti}')\nsomma_voti = 0\nfor voto in voti_esami:\nsomma_voti += voto\nvoto_medio = somma_voti/len(voti_esami)\nvoto_accesso = voto_medio / 3 * 11\nreturn voto_accesso\nprint('Il voto di accesso \u00e8: ', calcolo_voto_accesso_laurea(lista_voti))\n</code></pre> <p>Adesso vedremo a schermo due valori:</p> <pre><code>La lista dei voti \u00e8: [18, 20, 19, 30, 24, 30]\nIl voto di accesso \u00e8:  86.16666666666666\n</code></pre>"},{"location":"material/appendix/04_scope/lecture/#c2-seconda-modifica","title":"C2 - Seconda modifica","text":"<p>Proviamo a modificare ancora il codice:</p> <pre><code>lista_voti = [18, 20, 19, 30, 24, 30]\ndef calcolo_voto_accesso_laurea(voti_esami):\nsomma_voti = 0\nfor voto in voti_esami:\nsomma_voti += voto\nvoto_medio = somma_voti/len(voti_esami)\nvoto_accesso = voto_medio / 3 * 11\nreturn voto_accesso\nprint('Il voto medio \u00e8: ', voto_medio)\nprint('Il voto di accesso \u00e8: ', calcolo_voto_accesso_laurea(lista_voti))\n</code></pre> <p>Adesso vedremo a schermo il seguente risultato:</p> <pre><code>Traceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nNameError: name 'voto_medio' is not defined\nIl voto di accesso \u00e8:  86.16666666666666\n</code></pre> <p>Cosa \u00e8 successo? Andiamo un attimo a ritroso, e partiamo dalla prima modifica.</p> <p>In questo caso, infatti, abbiamo provato ad accedere alla variabile globale <code>lista_voti</code>, definita nel corpo \"principale\" dello script, dall'interno della funzione <code>calcola_voto_accesso_laurea</code>. Ci\u00f2 \u00e8 evidentemente possibile, in quanto possiamo accedere ad una variabile globale da un ambito locale.</p> <p>Il contrario, tuttavia, non \u00e8 possibile: infatti, nella seconda modifica, proviamo ad accedere ad una variabile locale alla funzione <code>calcola_voto_accesso_laurea</code> dall'esterno della funzione stessa. Questo non pu\u00f2 avvenire, perch\u00e9 le variabili locali \"scompaiono\" al termine della funzione in cui sono definite, per cui l'interprete ci dar\u00e0 un errore.</p>"},{"location":"material/appendix/05_oop/lecture/","title":"Appendice D - Principi di Programmazione Orientata agli Oggetti","text":"<p>La programmazione orientata agli oggetti (in inglese object-oriented programming, OOP) \u00e8 un paradigma di programmazione che sposta il focus dalle funzioni ai dati. In particolare, la OOP prevede che tutto sia un oggetto: una qualsiasi variabile \u00e8 interpretata come un oggetto, cos\u00ec come anche le funzioni stesse (in alcuni linguaggi).</p> <p>Ci\u00f2 si estende ovviamente anche ai tipi definiti dall'utente, che assumono il nome di classi. Facciamo un esempio.</p>"},{"location":"material/appendix/05_oop/lecture/#la-classe-persona","title":"La classe <code>Persona</code>","text":"<p>Immaginiamo di voler definire una struttura dati che contenga al suo interno le informazioni necessarie a definire una persona, come nome, cognome, genere ed et\u00e0. Per farlo, ovviamente, dovremo \"unire\" tra di loro diversi dati primitivi: potremo usare una stringa per il nome, una per il cognome, una per il genere e, infine, un intero per l'et\u00e0.</p> <p>In tal senso, possiamo creare quindi la classe <code>Persona</code>, che avr\u00e0 quattro attributi, come mostrato in figura.</p> <p></p> <p>Sottolineamo come una classe rappresenti tutte le possibili persone: infatti, si cerca di creare delle strutture dati generiche, che abbiano degli attributi comuni a tutte le possibili istanze. Nel nostro caso, sappiamo che ogni persona ha un nome, un cognome, un genere ed un'et\u00e0, quindi usiamo questi quattro valori come attributi di classe.</p> <p>Differenza tra classe ed istanza</p> <p>Abbiamo detto che una classe rappresenta tutte le possibili istanze della stessa. Ci\u00f2 si traduce, nel nostro esempio, nel fatto che la classe <code>Persona</code> \u00e8 in grado di rappresentare tutte le persone, e un'istanza della classe <code>Persona</code> \u00e8 una singola variabile, o oggetto, che rappresenta una certa persona. Per capirci: un'istanza di <code>Persona</code> \u00e8 \"Angelo, Cardellicchio, Uomo, 37\", mentre un'altra istanza \u00e8 data da \"Frank, Hood, Uomo, 42\", un'altra ancora da \"Camilla, Lilla, Donna, 55\", e cos\u00ec via.</p> <p>Ovviamente, potremo in qualche modo agire con degli opportuni metodi su questi attributi. Ad esempio, se avessimo a disposizione anche il luogo e la data di nascita, potremmo creare un metodo <code>calcola_cf</code> che, per l'appunto, permette di generare il codice fiscale di una singola istanza.</p> <p>Oltre al concetto di classe, tuttavia, la OOP definisce altri tre concetti base. Vediamoli di seguito.</p>"},{"location":"material/appendix/05_oop/lecture/#concetto-1-ereditarieta","title":"Concetto 1: Ereditariet\u00e0","text":"<p>Per ereditariet\u00e0 si intende la capacit\u00e0 di una classe di \"discendere\" da un'altra. Non dobbiamo, per\u00f2, pensare al nostro albero genealogico: infatti, noi abbiamo parte delle caratteristiche di ciascuno dei nostri genitori, mentre una classe figlia eredita in toto le caratteristiche di una classe madre.</p> <p>Ad esempio, potremmo definire la classe <code>Studente</code> come figlia della classe <code>Persona</code>, cui aggiunger\u00e0 i seguenti attributi:</p> <p></p> <p>Possiamo visualizzare questa relazione in ordine gerarchico come segue:</p> <p></p> <p>Da notare che la classe <code>Studente</code> pu\u00f2 aggiungere anche dei metodi, oltre che degli attributi a quelli offerti da <code>Persona</code>, come ad esempio <code>genera_media_voto</code>.</p> <p>In ultimo, notiamo come ogni istanza di <code>Studente</code> \u00e8 un'istanza di <code>Persona</code>, ma non \u00e8 vero il contrario, e quindi non tutte le persone sono degli studenti. Per aiutarci a comprendere questo concetto, possiamo visualizzare gli insiemi delle istanze di <code>Persona</code> e di <code>Studente</code>:</p> <p></p> <p>Generalizzazione e specializzazione</p> <p>La relazione di ereditariet\u00e0 pu\u00f2 anche essere vista in termini di generalizzazione e specializzazione. In questo contesto, la classe <code>Studente</code> \u00e8 una specializzazione di <code>Persona</code>, in quanto sottende ad un insieme pi\u00f9 specifico; al contrario, le persone sono viste come una generalizzazione degli studenti.</p> <p>Ereditariet\u00e0 multipla e multilivello</p> <p>Alcuni linguaggi, compreso Python, offrono la possibilit\u00e0 di ereditare da pi\u00f9 classi; tale concetto \u00e8 chiamato ereditariet\u00e0 multipla. Se invece stabiliamo una vera e propria gerarchia di classi, con una classe \"nonna\", una \"madre\" ed una \"figlia\", avremo una struttura multilivello.</p>"},{"location":"material/appendix/05_oop/lecture/#concetto-2-incapsulamento","title":"Concetto 2: Incapsulamento","text":"<p>Il concetto di incapsulamento prevede che sia possibile accedere ad un metodo (o anche ad un attributo) di una classe esclusivamente mediante la sua interfaccia verso il mondo esterno. Vediamo cosa significa.</p> <p>Immaginiamo di voler calcolare il codice fiscale di una persona: dovremo seguire una procedura ben precisa e moderatamente complessa, che potremo tranquillamente \"nascondere\" al codice che usa la classe <code>Persona</code>, il quale dovr\u00e0 semplicemente invocare il metodo <code>calcola_cf</code>. Tuttavia, se volessimo seguire il principio di modularit\u00e0, che ci suggerisce di \"suddividere\" funzioni complesse in maniera tale da renderle pi\u00f9 semplici, dovremmo creare altre funzioni ausiliarie, che potrebbero calcolare la rappresentazione di nome e cognome (<code>calcola_nc</code>) e i dati alfanumerici derivanti da luogo e data di nascita (<code>calcola_ld</code>). Ovviamente, non vi \u00e8 il bisogno di accedere dall'esterno della classe a questi metodi, in quanto hanno valenza esclusiva nell'ambito del calcolo del codice fiscale: per questo motivo, li si potr\u00e0 dichiarare come privati, e potranno essere acceduti soltanto dall'interno della classe.</p> <p>In questo modo, la classe mantiene un'interfaccia stabile ed essenziale verso l'esterno: il codice che usa la classe avr\u00e0 sempre un punto di accesso ben definito e, nel caso si debbano modificare dei comportamenti interni alla classe, non sar\u00e0 influenzato da dette modifiche. Ad esempio, infatti, se per qualche motivo si decidesse di cambiare l'ordine con cui si mostrano nel codice fiscale la rappresentazione del cognome e del nome, basterebbe modificare il metodo <code>calcola_nome_cognome_codice_fiscale</code>, ed il resto dell'implementazione (sia della classe, sia del codice chiamante) non ne sarebbe influenzata.</p> <p></p>"},{"location":"material/appendix/05_oop/lecture/#concetto-3-polimorfismo","title":"Concetto 3: Polimorfismo","text":"<p>Il concetto di polimorfismo prevede che sia possibile modificare il comportamento associato ad un metodo a seconda della classe che lo utilizza.</p> <p>Immaginiamo ad esempio di specializzare la classe <code>Studente</code> in due ulteriori rappresentazioni, ovvero <code>StudenteUniversitario</code> e <code>StudenteScolastico</code>. Ovviamente, il metodo <code>genera_media_voto</code> sar\u00e0 ereditato da entrambe le classi; tuttavia, l'implementazione dovr\u00e0 essere necessariamente differente, in quanto la media di laurea \u00e8 pesata in modo diverso rispetto alla classica media aritmetica usata nelle scuole fino alla secondaria.</p> <p>Il polimorfismo ci permette di raggiungere questo obiettivo: potremo effettuare una procedura di override del metodo <code>genera_media_voto</code> che, pur conservando la stessa firma, avr\u00e0 differenti implementazioni nelle classi <code>StudenteUniversitario</code> e <code>StudenteScolastico</code>. Ovviamente, il fatto che il metodo conservi la stessa firma rappresenta un vantaggio paragonabile a quello ottenuto mediante il polimorfismo: infatti, un programmatore potr\u00e0 usare il metodo <code>genera_media_voto</code> alla stessa maniera per uno studente universitario ed uno di scuola media secondaria, senza per questo dover tenere a mente due diverse interfacce.</p> <p></p>"},{"location":"material/appendix/06_tips/lecture/","title":"Appendice E - Python","text":""},{"location":"material/appendix/06_tips/lecture/#tabella-degli-operatori-booleani","title":"Tabella degli operatori booleani","text":"Operatore Operazione logica Esempio Risultato and AND 1 and 2 True or OR True or False True not NOT True is not False True"},{"location":"material/appendix/06_tips/lecture/#gestione-delle-eccezioni","title":"Gestione delle Eccezioni","text":""},{"location":"material/appendix/06_tips/lecture/#i-decorator","title":"I decorator","text":"<p>Prima di continuare a parlare dei metodi che \u00e8 possibile definire all'interno di una classe Python, \u00e8 necessario introdurre il concetto di decorator, ovvero una particolare notazione che viene usata in Python (ed in altri linguaggi di programmazione) per indicare una funzione che \"decora\" un'altra funzione.</p>"},{"location":"material/appendix/06_tips/lecture/#funzioni-come-oggetti","title":"Funzioni come oggetti","text":"<p>Python tratta le funzioni come degli oggetti. E' quindi possiible che una funzione restituisca una funzione:</p> <pre><code>def main_character(series):\ndef supernatural():\nreturn \"Sam Winchester\"\ndef breaking_bad():\nreturn \"Walter White\"\nif series == \"Supernatural\":\nreturn supernatural\nelif series == \"Breaking Bad\":\nreturn breaking_bad\n</code></pre> <p>Il valore di ritorno \u00e8 quindi un oggetto. Possiamo provare a chiamarlo dal nostro script:</p> <pre><code>&gt;&gt;&gt; mc = main_character(\"Supernatural\")\n</code></pre> <p>Se provassimo a mandarlo a schermo trattandolo come una variabile, avremmo in uscita una reference a funzione:</p> <pre><code>&gt;&gt;&gt; print(\"Function reference: {}\".format(mc))\nFunction reference: &lt;function main_character.&lt;locals&gt;.supernatural at 0x00000170C448BA60&gt;\n</code></pre> <p>Per visualizzare il risultato, trattiamolo come se fosse una chiamata a funzione:</p> <pre><code>&gt;&gt;&gt; print(\"Function outcoming value: {}\".format(mc()))\nFunction outcoming value: Sam Winchester\n</code></pre>"},{"location":"material/appendix/06_tips/lecture/#funzioni-come-argomenti-di-altre-funzioni","title":"Funzioni come argomenti di altre funzioni","text":"<p>Possiamo passare una fuzione come argomento ad un'altra funzione:</p> <pre><code>def favorite_series(func):\ndef internal_check():\nprint(\"Checking my favorite series...\")\nfunc()\nprint(\"Got it!\")\nreturn internal_check\ndef check():\nprint('Sons of Anarchy')\n</code></pre> <p>Dal nostro script:</p> <pre><code>&gt;&gt;&gt; print_fav_series = favorite_series(check)\n&gt;&gt;&gt; print_fav_series()\nChecking my favorite series...\nSons of Anarchy\nGot it!\n</code></pre> <p>Vediamo quindi come la funzione passata come argomento sar\u00e0 correttamente chiamata internamente al metodo <code>favorite_series</code>.</p>"},{"location":"material/appendix/06_tips/lecture/#definizione-ed-uso-di-decorator","title":"Definizione ed uso di decorator","text":"<p>La sintassi che abbiamo usato \u00e8, per dirla con Manzoni, ampollosa. Python ci offre quindi una sintassi equivalente, ma molto pi\u00f9 accessibile, per usare una funzione come argomento di un'altra funzione, ovvero i decorator. Infatti:</p> <pre><code>@favorite_series\ndef print_fav_series_decorated():\nprint('Breaking Bad')\n&gt;&gt;&gt; print_fav_series_decorated()\nChecking my favorite series...\nBreaking Bad\nGot it!\n</code></pre>"},{"location":"material/appendix/07_algorithms/metrics/","title":"Metrics","text":"<p>Average precision:</p> <p>la AP riassume la curva precision-recall come media pesata delle precisioni ottenute al variare della soglia, con un aumento nel recall dalla precedente soglia usato come peso:</p> \\[ AP = \\sum_{n} (R_n - R_{n-1}) P_n \\] <p>dove \\(P_n\\) ed \\(R_n\\) sono la precisione ed il recall alla \\(n\\)-ma soglia. Questa implementazione non \u00e8 interpolata, ed \u00e8 diversa dal calcolare l'area nella curva precision-recall con la regola trapeziodale, che usa l'interpolazione lineare e pu\u00f2 essere eccessivamente ottimista.</p> <p>ROC AUC</p> <p>Una ROC \u00e8 un plot grafico che illustra le performance di un sistema di classificazione binaria al variare della soglia di discriminazione. Viene creata plottando la frazione di true positive rispetto ai positivi (TPR = true positive rate) rispetto alla frazione di falsi positivi sui negativi (FPR = false positive rate) a diverse impostazioni di soglia. La TPR \u00e8 anche chiamata sensitivity, mentre la FPR \u00e8+ 1 meno la specificity (ovvero il true negative rate).</p> <p>Possiamo clacolare l'area sotto la curva ROC, che \u00e8 chiamata AUC o AUROC. Calcolando l'AUC, la curva viene riassunta in un unico numero.</p> <p>F1 score</p> <p>L'F1 score pu\u00f2 essere interpretato come la media armonica di precisione e recall, dove un F1 score raggiunge il suo valore migliore ad 1 e peggiore a 0. Il contributo relativo di precisione e recall all'F1 score sono uguali.</p>"},{"location":"material/appendix/07_algorithms/01_svd/lecture/","title":"Appendice G.1 - Decomposizione ai valori singolari","text":"<p>La decomposizione ai valori singolari (SVD) \u00e8 una tecnica di decomposizione matriciale, che permette quindi di trovare un prodotto di matrice che equivalga alla matrice iniziale. </p> <p>La decomposizione ai valori singolari prevede che una data matrice \\(M\\) sia decomposta in tre matrici:</p> \\[ M = U \\Sigma V^* \\] <p>dove:</p> <ul> <li>\\(M\\) \u00e8 una generica matrice ad \\(m\\) righe ed \\(n\\) colonne;</li> <li>\\(U\\) \u00e8 la matrice \\(m \\times m\\) dei vettori singolari sinistri;</li> <li>\\(\\Sigma\\) \u00e8 la matrice \\(m \\times n\\) dei valori singolari;</li> <li>\\(V^*\\) \u00e8 la matrice \\(n \\times n\\) dei vettori singolari destri.</li> </ul> <p>Inoltre:</p> <ul> <li>\\(U\\) e \\(V\\) sono matrici ortogonali, per cui \\(U^T = U^{-1}\\) e \\(V^T = V^{-1}\\);</li> <li>\\(\\Sigma\\) \u00e8 una matrice diagonale non necessariamente quadrata.</li> </ul> <p>Prima di dare una definizione intuitiva di SVD, per\u00f2, \u00e8 opportuno introdurre il concetto di trasformazione lineare.</p>"},{"location":"material/appendix/07_algorithms/01_svd/lecture/#trasformazione-1-rescaling-di-matrice","title":"Trasformazione 1: rescaling di matrice","text":"<p>Applichiamo al vettore \\(v\\) una trasformazione lineare definita da una matrice diagonale \\(d\\):</p> \\[ v = \\left[     \\begin{array}{c}     x \\\\     y     \\end{array} \\right] \\\\ d = \\left[     \\begin{array}{cc}     3 &amp; 0 \\\\     0 &amp; 3     \\end{array} \\right] \\] <p>Se moltiplichiamo \\(d\\) per \\(v\\), abbiamo:</p> \\[ \\left[     \\begin{array}{c}     x^{'} \\\\     y^{'}     \\end{array} \\right] = \\\\ \\left[     \\begin{array}{cc}     3 &amp; 0 \\\\     0 &amp; 3     \\end{array} \\right] \\times \\left[     \\begin{array}{c}     x \\\\     y     \\end{array} \\right] = \\\\ = \\left[     \\begin{array}{c}     3x + 0 \\\\     0 + 3y     \\end{array} \\right] = \\\\ \\left[     \\begin{array}{c}     3x \\\\     3y     \\end{array} \\right] \\] <p>In pratica, abbiamo triplicato il nostro vettore!</p>"},{"location":"material/appendix/07_algorithms/01_svd/lecture/#trasformazione-2-rotazione-di-matrice","title":"Trasformazione 2: rotazione di matrice","text":"<p>Laddove le matrici diagonali sono normalmente utilizzate per effettuare un rescaling, le matrici non diagonali possono essere usate per indurre una rotazione su un vettore. Ad esempio, possiamo pensare ad una matrice \\(R\\) di questo tipo:</p> \\[ R = \\left[     \\begin{array}{cc}     cos(\\theta) &amp; sin(\\theta) \\\\     sin(\\theta) &amp; cos(\\theta)     \\end{array} \\right] \\] <p>Se applicata ad un vettore, questa matrice applicher\u00e0 una certa rotazione a \\(\\theta\\):</p> \\[ \\left[     \\begin{array}{c}     x^{'} \\\\     y^{'}     \\end{array} \\right] = \\\\ \\left[     \\begin{array}{c}     x cos(\\theta) + y sin(\\theta) \\\\     x sin(\\theta) + y cos(\\theta)     \\end{array} \\right] \\] <p>Se consideriamo un vettore a coordinate \\(x = 1, y = 0\\), ed un valore di \\(\\theta\\) pari a \\(45\u00b0\\), allora:</p> \\[ x^{'} = 1 \\cdot cos(45) + 0 \\cdot sin(45) = cos(45) \\] <p>e:</p> \\[ y^{'} = 1 \\cdot sin(45) + 0 \\cdot cos(45) = sin(45) \\] <p>In questo caso specifico, i nuovi valori di \\((x^{'}, y^{'})\\) saranno pari a \\(\\sqrt{2}/2\\), per cui avremo \"ruotato\" il nostro punto originario di 45 gradi.</p>"},{"location":"material/appendix/07_algorithms/01_svd/lecture/#interpretazione-della-svd","title":"Interpretazione della SVD","text":"<p>Possiamo quindi adesso applicare le nozioni viste in precedenza per \"comprendere\" la SVD, che pu\u00f2 essere vista come una serie di trasformazioni lineari.</p> <p>In particolare, se partissimo dal cerchio di raggio unitario, ed applicassimo le trasformazioni lineari imposte da una generica matrice \\(M\\), avremmo una certa trasformazione delle coordinate definite sul cerchio. Mediante le tre diverse matrici definite dalla SVD scomponiamo linearmente in tre passi questa trasformazione, imponendo prima una rotazione, poi uno scaling, e poi un'ultima rotazione. Ci\u00f2 implica che il prodotto delle tre matrici in uscita dalla SVD applica una trasformazione lineare equivalente a quella applicata dalla sola matrice \\(M\\).</p> <p>Questo concetto \u00e8 riassunto nella seguente figura.</p> <p></p> <p>Il ruolo principale della SVD \u00e8 quindi quello di definire una serie di valori singolari (la matrice \\(\\Sigma\\)) di una matrice \\(M\\), i quali possono essere ricondotti ai valori originari mediante trasformazioni lineari. In tal senso, se la matrice originaria rappresenta un insieme di feature per un dato dataset, i valori singolari rappresentano un nuovo insieme di queste feature, corrispondenti ad una combinazione lineare di quelle originarie, ordinati secondo il grado di variabilit\u00e0 dei dati originari che riescono a \"rappresentare\", o \"spiegare\".</p> <p>Ne consegue che se un numero ridotto di feature individuate dalla SVD riesce a rappresentare un buon grado di variabilit\u00e0 dei dati iniziali, \u00e8 possibile scartare le feature rimanenti, effettuando quindi un'operazione di riduzione della dimensionalit\u00e0.</p>"},{"location":"material/appendix/07_algorithms/cnn/resnet/","title":"intro","text":"<p>anche se il problema della object classification \u00e8 molto vecchio, la gente lo sta sempre risolvendo per rendere il modello pi\u00f9 robusto. LeNet \u00e8 stata la prima Deep Neural Network nel 1998 volta a risolvere il problema di riconosciemnto delle cifre. Ha 7 layer che sono uno dopo l'altro per riconoscere le cifre scritte negli assegni bancari. Nonostante l'introduzione di LeNet, dati pi\u00f9 avanzati come immagini ad alta risoluzione non possono essere usati per addestrarla.  Inoltre, la potenza computazionale dei sistemi nel 1998 era molto inferiore.</p> <p>La comunit\u00e0 del deep learning ha ottenuto risultati entusisasmenti durante il 2012 con AlexNet, che venne introdotta per risolvere la classification challenge posta da ImageNet. AlexNet ha un totale di 8 layer che sono suddivisi in 5 layer di convoluzione e 3 layer completamente connessi. A differenza di LeNet, AlexNet ha pi\u00f9 filtri per effettuare l'operazione di convoluzione in ogni layer convoluzionale. Oltre al numero di filtri, la dimensione dei filtri usati in AlexNet era 11x11, 5x5 e 3x3. Il numero di parametri presenti in AlexNet \u00e8 circa 62 milioni. L'addestramento avvenne in maniera parallela, usando due GPU Nvidia per addestrare la rete sul dataset ImageNet. AlexNet riusc\u00ec ad ottenere il 57% e l'80.3% come top-1 e top-5 accuracy, rispettivamente. Inoltre, l'idea del Dropout venne intordotta per proteggere il modello dall'overfitting. Di conseguenza, alcuni milioni di parametri vennero usati dai 62 iniziali grazie al dropout.</p> <p>Dopo AlexNet, il successivo campione della competizione ImageNet fu VGG-16. Vi sono molte differenze tra AlexNEt e VGG-16. In primis, VGG-16 ha pi\u00f9 layer di convoluzione,il che implica che la ricerca inizi\u00f2 a concentrarsi sul come aumentare la profondit\u00e0 della rete. Secondo, VGG-16 usava soltanto i kernel 3x3 in ogni layer di convoluzione per effettuare l'operazione di convoluzione. A differenza di AlexNet, i piccli kernel di VGG-165 possono estrarre delle feature fini presenti nell'immagine. L'architettura di VGG-16 ha complessivamente 5 blocchi. I primi due blocchi della rete hanno 2 layer di convoluzione ed n layer di max-pooling in ogni blocco. I rimanenti tre blocchi della rete hanno 3 layer di convoluzione ed un layer di max-pooling. Terzo, tre layer completamente connessi sono aggiunti dopo il quinto blocco della rete: i primi due layer hanno 4096 neuroni ed il terzo ha 1000 neuroni per fare il task di classificazione in ImageNet. Quindi, la comunit\u00e0 di deep learning si riferisce a VGG-16 come una dlele reti pi\u00f9 ampie mai create. Inoltre, il numero di parametri nei primi due layer completamente connessi di VGG-16 ha circa 100 milioni sui 138 complessivi della rete. Il layer finale +\u00e8 un layer di softmax. Le accuracy top-1 e top-5 sono del 71.3 e 90.1 rispettivamente.</p>"},{"location":"material/appendix/07_algorithms/cnn/resnet/#googlenet-network-in-network","title":"googlenet: network in network","text":"<p>dopo VGG-16, GOogle ha creato GoogleNet, chiamata anche Inception-V1, con un valore di accuracy pi\u00f9 alto rispetto al suo predecessore. A differenza delle reti precedenti, GoogleNet ha una architettura pi\u00f9 piccola ma innovativa. Per prima cosa, le reti come VGG-16 hannoi layer di convoluzione l'uno dietro l'altro, ma GoogleNet dispone i layer di pooling e di convoluzione in una maniera parallela, per estrarre le feature usando diverse dimensioni del kernel. L'intenzione complessiva \u00e8 quella di aumentare la profondita della retee guadagnare un livello di performance pi\u00f9 alto rispetto ai vincitori precedenti della classification challenge di ImageNet. Secondariamente, la rete usa delle convoluzioni \\(1 \\times 1\\) per controllare la dimensione del volume passato per ulteriore processing in ogni modulo inception. Il modulo inception \u00e8 la collezione di operazione di convoluzione e pooling effettuate in maniera parallela in modo che lef feature possano essere estratte a scale differenti. Terzo, il numero di parametri presenti nella rete \u00e8 24 milioni, che rende Gloogle NEt meno costosa dal punto di vista computazionale se confrontata con AlexNet e VGG-16. Quarto, la rete usa un layer di Global Average Pooling invece dei layer completamente connessi. GoogleNet ha ottenuto il top-5 error pi\u00f9 basso, di 6.67%.</p>"},{"location":"material/appendix/07_algorithms/cnn/resnet/#deep-residual-network","title":"deep residual network","text":"<p>Il vincitore di ImageNet nel 2015 \u00e8 statoResNet152, ovvero una REsidual NEtwork con 152 layer variant Vedremo di coprire il concetto alla base di ResNet che pu\u00f2 essere generalizzato. Prima della spiegazione delle deep residual network, vorremmo parlare delle deep network semplici (le reti che hanno un maggior numero di convoluzioni, pooling e activation layer uno dietro l'altro). Dal 2013, la comunit\u00e0 del deep learning ha iniziato a creare delle reti pi\u00f9 profonde perch\u00e9 erano in grado di ottenere valori di accuracy maggiori. Inoltre, reti pi\u00f9 profonde possono rappresentare feature pi\u00f9 complesse, quindi la robustezza e le performance del modello possono esesre aumentate. Tuttavia, mettere molti layer l'uno dietro l'altro non funziona sempre: quando si addestrano reti pi\u00f9 oprfonode, si pu\u00f2 infatti osservare il problema del degrado dell'accuracy. In altre parole, aggiungere pi\u00f9 layer della rete fa in modo che il valore di accuracy si saturi, oppure inizi rapidamente a scendere. Il colpevole \u00e8 l'effetto di vanishing gradient, che pu\u00f2 essere osservato nelle reti pi profonde.</p> <p>Durante la backpropagation, l'errore viene calcolato, ed i valori del gradiente vengono determiani. I gradienti sono mandati agli hidden layer, ed i pesi vengono aggiornati in accordo. Il processo di determinare il gradiente e mandarlo indietro al successivo layer nascosto continua fino a che l'input layer non viene raggiunto. Il gradiente diventa sempre pi\u00f9 piccolo man mano che raggiunge il fondo della rete. Quindi, i pesi dei layer iniziali si aggiorneranno molto lentamente, o rimarranno gli stessi. In altre parole i layer iniziali della rete non apprenderanno in maniera efficace. Quindi, il training della rete non converger\u00e0, e l'accuracy inizier\u00e0 a degradrasi o saturare ad un certo valore. Anche se il problema del vanishing gradient \u00e8 stato affrnato usando l'inizializzazione normalizzata dei pesi, l'accuracy delle reti pi\u00f9 profonde continuava a non aumentare.</p>"},{"location":"material/appendix/07_algorithms/cnn/resnet/#cosa-e-la-deep-residual-netowrk","title":"cosa \u00e8 la deep residual netowrk","text":"<p>Le deep residual netwokr sono molto simili alle reti che hanno convoluzione, poling activatione  fully connecte duno dietro l0'latro. L'unica costruzione che le differenzia dalle reti \"semplici\" \u00e8 la cosiddetta identity connection tra i layer. </p> <pre><code>graph TD\n    A(fa:fa-spinner) -- x --&gt; B[Weight Layer I];\n    B -- ReLU --&gt; C[Weight Layer II];\n    C -- \"F(x)\" --&gt; D((+));\n    A -- Identity connection --&gt; D;\n    D -- \"ReLU(F(x) + x)\" --&gt;E(fa:fa-spinner);</code></pre> <p>Possiamo vedere l'identity connection come la freccia curva che si origina dall'input e va verso la fine del residual block.</p>"},{"location":"material/appendix/07_algorithms/cnn/resnet/#qual-e-lintuizione-dietro-il-residual-block","title":"qual \u00e8 l'intuizione dietro il residual block?","text":"<p>Come abbiamo visto prima, aumentare il numero di layer nella rete degrada improvvisamente l'accuracy della stessa. si voleva una architettura pi\u00f9 profonda che potesse lavorare bene o almeno allo stesso livello di una rete pi\u00f9 shallow. Ora, proviamo ad immaginare una classica deep netowrk. Assumiamo che la funzioen che stiamo provando ad apprendere dopo ogni layer sia data da \\(A_i(x)\\) dove \\(A\\) la funzione di output dell'\\(i\\)-mo layer per il dato input \\(x\\). POssiamo riferirci al prossimo grafico per comprendere il concetto.</p> <pre><code>graph TD\n    A[Input Layer] --&gt; B[Conv Layer 1];\n    B -- \"B1 A1\" --&gt; C[Conv Layer 2];\n    C -- \"B2 A2\" --&gt; D(fa:fa-spinner);\n    D -- \"$B_{n-1} A_{n-1}$\" --&gt; E[Conv Layer n];\n    E -- \"Bn An\" --&gt; F[Fully connected layer];\n    F --&gt; G[Output layer]</code></pre> <p>In questo modo, la rete sta provando ad apprendere direttamente queste funzioni di output, ovvero senza alcun supporto extra. In pratica, non \u00e8 possibile per la rete apprendere queste funzioni ideali \\(A_1, A_2, A_3, \\ldots, A_n\\)). La rete pu\u00f2 apprendere solo le funzioni \\(B_1, B_2, B_3, \\ldots, B_n\\) che sono pi\u00f9 vicine alle An. TUttavia, la nostra rete \"presunta\" si comporta cos\u00ec male che non pu\u00f2 neanche apprendere Bn, che sarebbe vicina ad An, a causa dell'\u00eceffetto dei vanishing gradient (AND ALSO DUE TO THE UNSUPPORTED WAY OF TRAINING??????).</p> <p>Il supporto per il training sarebbe dato dall'aggiunta dell'identity mapping al residual output. Per prima cosa, vediamo qual \u00e8 il singificato di identity mapping. In breve, applicare l'identity mapping all'input ci d\u00e0 l'output che \u00e8 lo stesso dell'input (AI=A: dove l'A \u00e8 la matrice di input ed I \u00e8 l'Identity Mapping).</p> <p>https://cv-tricks.com/keras/understand-implement-resnets/#:~:text=ResNet%20uses%20Batch%20Normalization%20at,network%20from%20vanishing%20gradient%20problem.</p>"},{"location":"material/appendix/07_algorithms/cnn/resnet/#1-il-problema-delle-plain-network","title":"1. il problema delle plain network","text":"<p>le normali reti di deep learning hanno i conv layer quindi i layer fully connected per i task di classificazione come AlexNet, ZFNet e VGGNet. Quando le plain networ sono abbastanza profonde, pu\u00f2 avvenire il problema dei vainshing gradient.</p> <p>Durante la backpropagation, uando le derivate parziali della funzione dell'errore rispetto all'attuale peso in gi iterazione di training, questo ha l'effetto di moltiplicare \\(n\\) di di questi piccoli o grandi numeri per calcolare i gradienti dei layer frontali in una rete ad \\(n\\) livelli.</p> <p>quando la rete \u00e8 profonda, e si moltiplicano \\(n\\) di questi piccoli numeri, il gradiente diventer\u00e0 zero (vanishing).</p> <p>Quando la rete \u00e8 prfonoda, e si moltiplicano \\(n\\) di questi grossi numeri, il gradiente diventer\u00e0 troppo grande (exploded).</p> <p>Ci aspettiamo che le reti pi\u00f9 profonde abbiano predizioni pi\u00f9 accurate. Tuttavia, quando ci\u00f2 non avviene, \u00e8 probabile che ci sia un degradation problem legato ai vanishing gradient.</p>"},{"location":"material/appendix/07_algorithms/cnn/resnet/#2-skipshortcut-connection-in-residual-network-resnet","title":"2. Skip/Shortcut Connection in Residual Network (ResNet)","text":"<p>Per risolvere il problema dei gradienti, una skip/shortcut connection viene aggiunta per fare in modo che si aggiunga l'input \\(x\\) all'output dopo pochi weight laeyr, come mostrato di seguito.</p> <pre><code>flowchart TD\n    A(fa:fa-spinner) --&gt; B[x];\n    B --&gt; C[layer];\n    C -- relu --&gt; E((+));\n    B --&gt; E;\n    E -- relu --&gt; F(fa:fa-spinner);</code></pre> <p>Indichiamo l'output del layer 1 con \\(F(x)\\), e l'output in uscita al layer sommatore come \\(H(x) = F(x) + x\\). Di conseguenza, il layer sta apprendendo un tipo di residual mapping, dato che \\(F(x) = H(x) - x\\).</p> <p>Anche se c'\u00e8 un vanishing gradient per il weight layer, abbiamo sempre l'identit\u00e0 \\(x\\) to TRANSFER BACK ai layer precedenti.</p> <p>https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8</p> <p>https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803</p>"},{"location":"material/appendix/07_algorithms/xai/shap/lecture/","title":"XAI con gli Shapley values","text":"<p>Gli Shapley values sono un approccio molto utiizzato per la teoria dei giochi coperativa che ha delle propriet\u00e0 affascinati. </p>"},{"location":"material/appendix/07_algorithms/xai/shap/lecture/#spiegare-un-modello-di-regresisone-lineare","title":"Spiegare un modello di regresisone lineare","text":"<p>Prima di usare i valori di Shapley per spiegare dei modelli complessi, \u00e8 utile comprendere come funzioanno per dei modelli semplici. Uno dei tipi pi\u00f9 semplice di modello \u00e8 quello di regressione lineare. Usiamo il California housing dataset. Questo \u00e8 fatto di 20.640 isolati di case in California nel 1990, con il nostro obiettivo che \u00e8 quello di predire il logaritmo naturale del prezzo emediano di una casa a partire da otto diverse feature:</p> <ul> <li>MedInc: income medio in un isolato</li> <li>HouseAge et\u00e0 media delle case in un isolato</li> <li>AveRooms: numero medio di camere per ciascuna propriet\u00e0</li> <li>AveBedrms: numero medio di camere da letto per propriet\u00e0</li> <li>Population: popolazione dell'isolato</li> <li>AveOccup: numero medio di membri delle propriet\u00e0</li> <li>Latitude: latitudine dell'isolato</li> <li>Longitude: longitudine dell'isolato</li> </ul> <pre><code>import pandas as pd\nimport shap\nimport sklearn\nX, y = shap.datasets.california(n_points=1000)\nX100 = shap.utils.sample(X, 100)\nmodel = sklearn.linear_model.LinearRegression()\nmodel.fit(X, y)\n</code></pre>"},{"location":"material/appendix/07_algorithms/xai/shap/lecture/#esame-dei-coefficienti-del-modello","title":"Esame dei coefficienti del modello","text":"<p>Il modo pi\u00f9 comune di comprendere un modello lineare \u00e8 quello di esaminare i coefficienti appresi per ciascuna feature. Questi coefficienti ci indicano quanto dell'output del modello cambia quando cambiamo ciascuna delle feature dell'input.</p> <pre><code>print('Coefficienti del modello: \\n')\nfor i in range(X.shape[1]):\nprint(X.columns[i], '=', model.coef_[i].round(5))\n</code></pre> <p>I coefficienti ci indicano cosa succede quando cambiamo il valore di uan feature di input, tuttavia da soli non sono un buon modo per misurare l'importanza complessiva di una feature. Questo avviene pech\u00e9 il valore di ogni coefficiente dipende dalla scala delle feature di input. Se per esempio dovessimo misurare l'et\u00e0 di una casa in minuti piuttosto che anni, il coefficiente per lo HouseAge dioventerebe 0.0115 /  (365 * 24 * 60). Chiaramente, il numero di anni passatp per una caasa non \u00e8 diverso dal numero di minuti, ma il valore del suo coefficiente \u00e8 molto pi\u00f9 ampio. Questo significa che la magnitudine di un coefficiente non \u00e8 necessariamente una buona misura dell'importanza della feature in un modello lineare.</p> <p>Da qui: https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html#A-more-complete-picture-using-partial-dependence-plots</p>"},{"location":"material/notebooks/","title":"Indice dei notebook","text":"<p>In questa pagina \u00e8 presente la raccolta dei notebook presentati durante le lezioni.</p> Notebook Link Algebra in NumPy Polinomi in NumPy Statistica in NumPy Pandas Matplotlib Seaborn"},{"location":"material/nuovo/batch_norm/","title":"Batch norm","text":"<p>Why does Batch Norm work? There is no dispute that Batch Norm works wonderfully well and provides substantial measurable benefits to deep learning architecture design and training. However, curiously, there is still no universally agreed answer about what gives it its amazing powers.</p> <p>To be sure, many theories have been proposed. But over the years, there is disagreement about which of those theories is the right one.</p> <p>The first explanation by the original inventors for why Batch Norm worked, was based on something called Internal Covariate Shift. Later in another paper by MIT researchers, that theory was refuted, and an alternate view was proposed based on Smoothening of the Loss and Gradient curves. These are the two most well-known hypotheses, so let\u2019s go over them below.</p> <p>Theory 1 \u2014 Internal Covariate Shift If you\u2019re like me, I\u2019m sure you find this terminology quite intimidating! \ud83d\ude04 What does it mean, in simple language?</p> <p>Let\u2019s say that we want to train a model and the ideal target output function (although we don\u2019t know it ahead of time) that the model needs to learn is as below.</p> <p>https://towardsdatascience.com/batch-norm-explained-visually-why-does-it-work-90b98bcc58a0</p> <p>https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739</p>"},{"location":"material/nuovo/image_segmentation/","title":"Image Segmentation","text":"<p>La instance segmentation permette ai nostri modelli di computer vision di conoscere i specific contorni di un'oggetto in un'immagine.</p> <p>La instance segmentation, conosciuta anche come image segmentation, \u00e8 il task che riconosce gli oggetti in immagini assieme alla loro forma associata. \u00e8 un'estenseione della object detection dove ogni predizione inclue anche una forma, in modo differente a semplicemente una bounding box defintia da un punto centrale, un'altezza ed una larghezza.</p> <p>Grazie alla instance segmentation, l'applicazione pu\u00f2 determinare il numero di oggetti in un'immagine, la classificazione, ed il loro contorno.</p> <p>E' utile nei casi dove dobbiamo misurare la dimensione degli oggetti individuati (ad esempio una foglia di pomodoro), tagliarli fuori dal background (ad esempio, per la rimopzione del background) o individuare oggetti ruotati ed oblunghi (ad esempio un ponte in un'immagine satellitare).</p>"},{"location":"material/nuovo/image_segmentation/#comparare-la-instance-segmentation-ad-altri-algoritmi-di-computer-vision","title":"Comparare la instance segmentation ad altri algoritmi di computer vision","text":"<p>Come si confronta la instance segmentation ad altri algoritmi utili a risolvere problemi di computer vision?</p>"},{"location":"material/nuovo/image_segmentation/#instance-segmentation-vs-object-detection","title":"Instance Segmentation vs Object Detection","text":"<p>Sia la instance segmentation sia la object detection identificano la posizione di un oggetto in un'immagine. tuttavia, l'object detection predice soltanto la bounding box dell'oggetto, e non il contorno.</p> <p>Ecco alcune cose da sapere:</p> <ul> <li>il labeling per la segmentation richiede pi\u00f9 tempo</li> <li>\u00e8 pi\u00f9 complesso addestrare dei modelli di instance segmentation</li> <li>i modelli per  l'instance segmentation sono normalmente pi\u00f9 grandi, lenti, e meno ottimizzati</li> <li>i modelli di instance segmentation possono richiedere dataset pi\u00f9 grandi per ottenere la stessa accuracy dei mdoelli di object detection.</li> </ul> <p>Il consiglio \u00e8 di usare la instance segmentation se la specifict\u00e0 del contorno dell'oggetto \u00e8 richiesta dall'applciazione specifica. Spesso \u00e8 meglio provare la object detection prima, \u00e8erch\u00e9 \u00e8 pi\u00f9\u00e0 semplice e facile da testare, e pi\u00f9 veloce ed accurata in fase di esecuzione.</p> <p>Ad esempio, l'intance segmentation pu\u00f2 essere usata per misurare l'area di un LAWN da immagini satellitari. Tuttavia, se dobbiamo identificare tutti gli alberi su un LAWN, un modello pi\u00f9 prudente da usare sarebbe quello di object detection</p>"},{"location":"material/nuovo/image_segmentation/#instance-segmentation-vs-semantic-segmentation","title":"Instance segmentation vs Semantic segmentation","text":"<p>La semantic segmentation etichetta ogni pixel in un'immagine con una label di classe. In modo simile all'instance semgentation, possiamo vedere i controrni di un oggetto in un'immagine, ma  adifferenza della intance segmantation, non possiamo contare o differenziare tra oggetti separati se questi sono sovrapposti.</p>"},{"location":"material/nuovo/image_segmentation/#come-effettuare-il-labeling","title":"COme effettuare il labeling","text":"<p>Le imagini per i problemi di instance segmentation devono essere etichettate nella maniera pi\u00f9 precisa possibile, evidenziando il contorno dell'oggetto da annotare e quindi assegnando l'oggettoa d una classe.</p> <p>Una volta etichettato il dataset, si pul\u00f2 addestrare il modello.</p> <p>Il formato pi\u00f9 comune per i dataset di instance semgentation \u00e8 COCO, che registra i punti della segmentazione in una serie di coppie x, y.</p>"},{"location":"material/nuovo/normality/","title":"Assunzione di normalit\u00e0","text":"<p>Una grossa parte del campo della statisitca riguarda i dati che sono estratti da una distribuzione gaussiana.</p> <p>Se usiamo dei metodi che assumono una distribuzione gaussiana, ed i nostri dati sono stati estrattid a una distribuzione differente, quello che troveremo potrebbe essere fuorviante o, semplicemente, errato.</p> <p>Vi \u00e8 un gran numero di tecniche che possiamo usare per controlalre che i nostri campioni siano gaussiani (o simili) per usare tecniche standard, oppure non gaussiani per usare metodi non parmaetrici.</p> <p>Questo \u00e8 un punto chiave quando dobbiamo scegliere i metodi statistici per i nostri campioni. In altre parole:</p> <pre><code>if dati_gaussiani:\nusa_metodi_parametrici()\nelse:\nusa_metodi_non_parametrici()\n</code></pre> <p>Vi \u00e8 anche una terra di nessuno nella quale possiamo presupporre che i dati siano sufficientemente gaussiani per usare i metodi parametrici, o che possiamo usare tecniche di data preprataion per trasformare i dati in modod che siano sufficientemente gaussiani da usare metodi parametrici.</p> <p>Ci sono tre aree pricnipali dove potremmo dover fare questa valutazione nel machine learning, ovvero:</p> <ul> <li>dati di ingresso al modello nel caso di fitting;</li> <li>valutzione dei risultati del modello in caso di model selection;</li> <li>errori dresidui dalle predizioni del modello in caso di regressione.</li> </ul> <p>Vedremo brevemente due classi di tecniche per controllare se un campione di dati \u00e8 gaussiano, ovvero:</p> <ul> <li>metodi grafici, che plottano i dati e valutano qualitativamente se sembrano gaussiani;</li> <li>test statistici: metodi che calcolano delle statistiche sui dat e quantificano la probabilit\u00e0 che i dati siano statit estratti da una distribzuone gaussiana.</li> </ul> <p>I metodi di quest'ultimo tipo sono sesso chiamati test di normalit\u00e0.</p>"},{"location":"material/nuovo/object_detection/","title":"Object detection","text":"<p>La object detection \u00e8 una tecnica di computer vision che localizza ed identifica gli oggetti in un'immagine. Grazie alla versatilit\u00e0 di questa tecnica, \u00e8 una delle tecniche pi\u00f9 utilizzate in ambito di computer vision.</p> <p>https://blog.roboflow.com/object-detection/</p>"},{"location":"material/nuovo/transformers/","title":"Transformer","text":"<p>Si sente spesso parlare molto dei Transformer, e per buone ragioni. Hanno preso il mondo dell'NLP negli ultimi anni. Quella dei Trasformer \u00e8 un'architettura che usa l'Attention per migliorare significativamente le performance dei modelli di traduzione NLP. Venne introdotta per la prima volta nel paper Attention is all you need e si \u00e8 rapidamente stabilita come l'architettura leader per la maggior parte delle applicazioni sui dati testuali.</p> <p>Da quel momento, numerosi progetti inclusi BERT di Google o GPT di OpenAI si sono basati su queste fondamenta, ed hanno avuto dei risultati che facilmente hanno battuto i benchmark allo stato dell'arte.</p> <p>https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452</p> <p>https://towardsdatascience.com/transformers-explained-visually-part-2-how-it-works-step-by-step-b49fa4a64f34</p>"},{"location":"material/nuovo/yolo/","title":"YOLO","text":""},{"location":"material/nuovo/yolo/#introduzione-alla-object-detection","title":"Introduzione alla Object Detection","text":"<p>La object detection \u00e8 una tecnica usata in ambito di computer vision per l'identificazione e la localizzazione di oggetti all'interno di un'immagine o di un video.</p> <p>La localizzazione \u00e8 il processo di identificare la posizione corretta di uno o pi\u00f9 oggetti usando delle bounding box, che corrispondono o rectangular shapes around the objects. </p> <p>This process is sometimes confused with image classification or image recognition, which aims to predict the class of an image or an object within an image into one of the categories or classes. </p> <p>The illustration below corresponds to the visual representation of the previous explanation. The object detected within the image is \u201cPerson.\u201d </p> <p>In this conceptual blog, you will first understand the benefits of object detection, before introducing YOLO, the state-of-the-art object detection algorithm. </p> <p>In the second part, we will focus more on the YOLO algorithm and how it works. After that, we will provide some real-life applications using YOLO. </p> <p>The last section will explain how YOLO evolved from 2015 to 2020 before concluding on the next steps. </p>"},{"location":"material/nuovo/yolo/#cosa-e-yolo","title":"Cosa \u00e8 YOLO?","text":"<p>You Only Look Once (YOLO) is a state-of-the-art, real-time object detection algorithm introduced in 2015 by Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi in their famous research paper \u201cYou Only Look Once: Unified, Real-Time Object Detection\u201d. </p> <p>The authors frame the object detection problem as a regression problem instead of a classification task by spatially separating bounding boxes and associating probabilities to each of the detected images using a single convolutional neural network (CNN). </p> <p>Some of the reasons why YOLO is leading the competition include its:</p> <p>Speed  Detection accuracy  Good generalization  Open-source 1- Speed YOLO is extremely fast because it does not deal with complex pipelines. It can process images at 45 Frames Per Second (FPS). In addition, YOLO reaches more than twice the mean Average Precision (mAP) compared to other real-time systems, which makes it a great candidate for real-time processing. </p> <p>From the graphic below, we observe that YOLO is far beyond the other object detectors with 91 FPS.</p> <p>2- High detection accuracy YOLO is far beyond other state-of-the-art models in accuracy with very few background errors. </p> <p>3- Better generalization This is especially true for the new versions of YOLO, which will be discussed later in the article. With those advancements, YOLO pushed a little further by providing a better generalization for new domains, which makes it great for applications relying on fast and robust object detection. </p> <p>For instance the Automatic Detection of Melanoma with Yolo Deep Convolutional Neural Networks paper shows that the first version YOLOv1 has the lowest mean average precision for the automatic detection of melanoma disease, compared to YOLOv2 and YOLOv3.</p> <p>4- Open source  Making YOLO open-source led the community to constantly improve the model. This is one of the reasons why YOLO has made so many improvements in such a limited time. </p>"},{"location":"material/nuovo/yolo/#architettura-di-yolo","title":"Architettura di YOLO","text":"<p>L'architettura di YOLO prende spunto da quella di GoogleNet. Ha 24layer convoluzionali, quattro layer di max-pooling, e due layer completamente connessi.</p> <p>L'architettura funziona come segue:</p> <ul> <li>l'immagine di input viene ridimensionata a \\(448 \\times 448\\) peima di andare nella rete convoluzionale</li> <li>una convoluzione \\(1 \\times 1\\)</li> </ul> <p>he architecture works as follows:</p> <p>Resizes the input image into 448x448 before going through the convolutional network. A 1x1 convolution is first applied to reduce the number of channels, which is then followed by a 3x3 convolution to generate a cuboidal output. The activation function under the hood is ReLU, except for the final layer, which uses a linear activation function. Some additional techniques, such as batch normalization and dropout, respectively regularize the model and prevent it from overfitting. By completing the Deep Learning in Python course, you will be ready to use Keras to train and test complex, multi-output networks and dive deeper into deep learning.</p> <p>How Does YOLO Object Detection Work? Now that you understand the architecture, let\u2019s have a high-level overview of how the YOLO algorithm performs object detection using a simple use case.</p> <p>\u201cImagine you built a YOLO application that detects players and soccer balls from a given image. </p> <p>But how can you explain this process to someone, especially non-initiated people?</p> <p>\u2192 That is the whole point of this section. You will understand the whole process of how YOLO performs object detection; how to get image (B) from image (A)\u201d</p> <p>Il funzionamento dell'algoritmo \u00e8 legato a questi quattro step:</p>"},{"location":"material/nuovo/yolo/#1-residual-blocks","title":"1. Residual blocks","text":"<p>Il primo step di YOLO inzia dividendo l'immagine originaria \\(A\\) in una cella di \\(N \\times N\\) griglie di ugual forma. Ogni cella nella griglia \u00e8 quindi repsonsabile per la localizzazione e predizione della classe dell'oggetto che copre, assieme ai valori di probabilit\u00e0 e confidenza. </p>"},{"location":"material/nuovo/yolo/#2-bounding-box-regression","title":"2. Bounding box regression","text":"<p>Il passo successivo \u00e8 determinare i bounding box che corrisponde ai rettangoli che evidenziano tutti gli oggetti nell'immagine. POssiamo avere tante bounding box quanti sono gli oggetti in una data immagine.</p> <p>YOLO determian gli attributi di questi bouniding box usando un singolo modulo di regressione nel seguente formato:</p> \\[ Y=[pc, bx, by, bh, bw, c1, c2] \\] <p>dove:</p> <ul> <li>\\(Y\\) \u00e8 la rappresentazione integrale per ciascun bounding bxo;</li> <li>\\(p_c\\) corrisponde al punteggio di probabilit\u00e0 della griglia contentente un oggetto. Ad esempio, tutte le griglie rosse avranno un punteggio di probabilit\u00e0 pi\u00f9 alto di zero.</li> <li>\\(b_x, b_y\\) sono le coordinate \\(x\\) ed \\(y\\) del centro delle bounding box rispetto alla griglia che le contiene.</li> <li>\\(b_h, b_w\\) corrispodnono all'altezza ed all'ampiezza della bounding box rispetto alla griglia che la contiene.</li> <li>\\(c_1\\) e \\(c_2\\) corrispondono alle classi del nostro caso d'uso.</li> </ul> <p>TODO ESEMPIO</p>"},{"location":"material/nuovo/yolo/#3-intersection-over-unions-o-iou","title":"3. Intersection Over Unions o IoU","text":"<p>La maggior parte delle volte, un singolo oggetto in un'immagine pu\u00f2 avere pi\u00f9 box candidate per la predizione, anche se non tutti sono rilevanti. L'obiettivo della IoU (valore tra 0 ed 1) \u00e8 scartatere queste box e mantenere solo quelle rilevanti. La logica dietro a questo \u00e8 la seguente:</p> <ul> <li>l'utente definisce la soglia di selezione della IoU, ad esempio, 0.5</li> <li>YOLO quindi calcola la IoU di ogni cella che \u00e8 l'area dell'intersezione divisa da quella dell'unione</li> <li>infine, ignora le predizioni di ogni cella che ha una IoU minore o uguale alla soglia, e consiedera quella con una IoU maggiore della soglia.</li> </ul> <p>TODO ESEMPIO</p>"},{"location":"material/nuovo/yolo/#4-non-max-suppression","title":"4. Non-Max Suppression","text":"<p>Impostare una soglia per la IoU non \u00e8 sempre abbastanza perch\u00e9 un oggetto pu\u00f2 avere pi\u00f9 box con una IoU al di sotto della soglia, e lasciare queste box pu\u00f2 includere del rumore. Possiamo usare la NMS per mantenere solo le box con la probabilit\u00e0 di detection pi\u00f9 alta.</p>"},{"location":"material/nuovo/yolo/#differenze-tra-diverse-versioni-di-yolo","title":"Differenze tra diverse versioni di YOLO","text":"<p>Dalla prima release di YOLO, si sono evolute molte versioni.</p>"},{"location":"material/nuovo/yolo/#yolov1","title":"YOLOv1","text":"<p>La prima versione di YOLO ha migliorato di molto la object detection, grazie alla sua abilit\u00e0 di riconoscere gli oggetti in maniera rapida ed efficienzte.</p> <p>Tuttavia, come moltre altre soluzioni, la prima versione di YOLO ha i suoi limiti:</p> <ul> <li>ci sono problemi nell'individuare immagini di piccola dimensione all'interno di un insieme di immagini, come un gruppo di persone in uno stadio. Questo \u00e8 perch\u00e9 ogni griglia nell'archietttura YOLO \u00e8 progettata per individuare un singolo oggetto.</li> <li>YOLO non \u00e8 in grado di individuare forme nuove o inusuali</li> <li>infine, la funzioen di costo usata per approssimare le pefromance di detection tratta gli errori su bounding box piccole e grandi allo stesso modo, il che crea delle localizzazioni imperfette.</li> </ul>"},{"location":"material/nuovo/yolo/#yolov2-yolo9000","title":"YOLOv2 (YOLO9000)","text":"<p>https://www.datacamp.com/blog/yolo-object-detection-explained</p> <p>YOLOv2 \u00e8 stato creato nel 2016.</p> <p>I miglioramenti includono l'uso di Darknet-19 come nuova architettura, batch normalization, risoluzione degli input pi\u00f9 alta, layer convoluzionali con delle anchor, clustering, e fine-grained features.</p> <p>YOLOv2 usa una risoluzione di \\(448\\times 448\\) invece di \\(224 \\times 224\\), il che rende il modello in grado di modificare i suoi filtri in modo da agire meglio su immagini a pi\u00f9 alta risoluzione. Questo approccio aumenta l'accuracy del 4% mAP, dopo il training di 10 epoche sui dati di ImageNet.</p> <ul> <li>INvece di predire le coordinate esatte delle bounding box degli oggetti come YOLOv1, YOLOv2 semplifica il problema rimpiazzando i layer completamente connessi con delle anchor box. Questo approccio decrementa leggeremnte l'accuracy, ma migliora il recall del modello.</li> <li>Le anchor boxes sono trovate in automatico da YOLOv2 usando il k-means con \\(k=5\\) invece di effettuare una selezione manuale. Questo approccio fornisce un buon compromesso tra il recall e la precsione del modello.</li> <li>le predizioni YOLOv2 p</li> </ul>"},{"location":"material/nuovo/yolo/#yolov8","title":"YOLOv8","text":"<p>YOLOv8 definisce una nuova architettura allo stato dell'arte per la object detection e per la instance segmentration.</p> <p>YOLOv8 \u00e8 il nuovo modello allo stato dell'arte, sviluppato da Ultralytics, gli stessi che hanno creato il modello YOLOv5. YOLOv8 include diversi migliramenti rispetto ad YOLOv5.</p> <p>La serie di modelli YOLO (You Only Look Once) \u00e8 diventata famosa nel mondo della computer vision. La fama di YOLO \u00e8 attribuile alla sua considerevole accuratezza, ottenibile mantenendo comunque una dimensione ridotta del modello. I modelli YOLO possono essere addestrati su una GPU singola, il che li rende accessibili ad un ampio range di sviluppatori, e deployabili su edge o nel cloud.</p> <p>YOLO \u00e8 stato al centro dell'attenzione della computer vision fin dal suo lancio nel 2015 da Joseph Redmond, che lo manteneva in codice C in un framweork scritto da Redmond stesso e chiamato Darknet.</p> <p>L'autore di YOLOv8, Glenn Jocher, ha usato come base la repository di YOLOv3 in PyTorch. Da qui, Ultralytics alla fine ha lanciato il suo primo modello, ovvero YOLOv5.</p> <p>YOLOv5 </p> <p>https://blog.roboflow.com/whats-new-in-yolov8/ </p>"}]}